"Title","Authors","PublicationName","AlternateName","Abstract","Url","AuthorAddress","Year","DOI","ReferenceType","Keywords","PdfRelativePath","CustomId"
"Perceived justice as predictors of a successful pay equity plan: a canadian case study","Cloutier, J. And Lamarche, B.","Gender In Management","","Purpose – this study aims to identify the predictors of successful implementations of pay equity plans. Drawing on the perspective of organizational justice, this study highlights the factors that lead to the establishment of perceived fair pay for female-dominated jobs. Design/methodology/approach – qualitative data were collected from 107 respondents in a canadian company that implemented a pay equity plan as required by the quebec pay equity act. Findings – justice perceptions of employees are based on: uniformity of implementation, bias suppression with respect to the right to fair pay, reliability of information on job content, relevance of job evaluation criteria, qualifications and impartiality of the pay equity committee members and the quality of employees’ representation and process transparency. Research limitations/implications – this study was conducted at a single workplace and among relatively highly educated respondents. Replicating the study may allow to verify the transferability of the results by considering workers’ demographic characteristics and organizational culture. Practical implications – the study highlights the cornerstones that may guide the development of an assessment tool of the effectiveness of pay equity processes. These results will additionally help employers to circumvent difficulties which may otherwise thwart the implementation of pay equity plans. Originality/value – this study highlights how employees construct their perceptions of justice in a specific context. It sheds light on the salient features of the pay equity implementation, the sources of information involved and the justice rules used. This study also highlights the specific forms of the justice rules in this context. © emerald group publishing limited.","","","2015","10.1108/gm-08-2013-0089","","","scopus-2-s2.0-84930168416.pdf","scopus-2-s2.0-84930168416"
"The effect of short-term transcutaneous electrical stimulation of auricular vagus nerve on parameters of heart rate variability","Shvartz, V. And Sizhazhev, E. And Sokolskaya, M. And Koroleva, S. And Enginoev, S. And Kruchinova, S. And Shvartz, E. And Golukhova, E.","Data","","Many previous studies have demonstrated that transcutaneous vagus nerve stimulation (vns) has the potential to exhibit therapeutic effects similar to its invasive counterpart. An objective assessment of vns requires a reliable biomarker of successful vagal activation. Although many potential biomarkers have been proposed, most studies have focused on heart rate variability (hrv). Despite the physiological rationale for hrv as a biomarker for assessing vagal stimulation, data on its effects on hrv are equivocal. To further advance this field, future studies investigating vns should contain adequate methodological specifics that make it possible to compare the results between studies, to replicate studies, and to enhance the safety of study participants. This article describes the design and methodology of a randomized study evaluating the effect of short-term noninvasive stimulation of the auricular branch of the vagus nerve on parameters of hrv. Primary records of rhythmograms of all the subjects, as well as a dataset with clinical, instrumental, and laboratory data of all the current study subjects are in the public domain for possible secondary analysis to all interested researchers. The physiological interpretation of the obtained data is not considered in the article. Dataset: vladimir shvartz, (2023), “auricular vagus stimulation and heart rate variability”, open science framework. https://doi.org/10.17605/osf.io/stu62. Dataset license: cc by 4.0. © 2023 by the authors.","","","2023","10.3390/data8050087","","","scopus-2-s2.0-85160214512.pdf","scopus-2-s2.0-85160214512"
"HPIDB 2.0: a curated database for host-pathogen interactions","Ammari M. G., Gresham C. R., McCarthy F. M., Nanduri B.","Database: The Journal of Biological Databases and Curation","","Identification and analysis of host-pathogen interactions (HPI) is essential to study infectious diseases. However HPI data are sparse in existing molecular interaction databases especially for agricultural host-pathogen systems. Therefore resources that annotate predict and display the HPI that underpin infectious diseases are critical for developing novel intervention strategies. HPIDB 2.0 (http://www.agbase.msstate.edu/hpi/main.html) is a resource for HPI data and contains 45 238 manually curated entries in the current release. Since the first description of the database in 2010 multiple enhancements to HPIDB data and interface services were made that are described here. Notably HPIDB 2.0 now provides targeted biocuration of molecular interaction data. As a member of the International Molecular Exchange consortium annotations provided by HPIDB 2.0 curators meet community standards to provide detailed contextual experimental information and facilitate data sharing. Moreover HPIDB 2.0 provides access to rapidly available community annotations that capture minimum molecular interaction information to address immediate researcher needs for HPI network analysis. In addition to curation HPIDB 2.0 integrates HPI from existing external sources and contains tools to infer additional HPI where annotated data are scarce. Compared to other interaction databases our data collection approach ensures HPIDB 2.0 users access the most comprehensive HPI data from a wide range of pathogens and their hosts (594 pathogen and 70 host species as of February 2016). Improvements also include enhanced search capacity addition of Gene Ontology functional information and implementation of network visualization. The changes made to HPIDB 2.0 content and interface ensure that users especially agricultural researchers are able to easily access and analyse high quality comprehensive HPI data. All HPIDB 2.0 data are updated regularly are publically available for direct download and are disseminated to other molecular interaction resources.Database URL: http://www.agbase.msstate.edu/hpi/main.html.","","","2016","10.1093/database/baw103","","","medline-27374121.pdf","medline-27374121"
"Systematic reviews are rarely used to contextualise new results-a systematic review and meta-analysis of meta-research studies","Draborg E., Andreasen J., Norgaard B., Juhl C. B., Yost J., Brunnhuber K., Robinson K. A., Lund H.","Systematic Reviews","","BACKGROUND: Results of new studies should be interpreted in the context of what is already known to compare results and build the state of the science. This systematic review and meta-analysis aimed to identify and synthesise results from meta-research studies examining if original studies within health use systematic reviews to place their results in the context of earlier similar studies.\\\\\\\\rMETHODS: We searched MEDLINE (OVID) EMBASE (OVID) and the Cochrane Methodology Register for meta-research studies reporting the use of systematic reviews to place results of original clinical studies in the context of existing studies. The primary outcome was the percentage of original studies included in the meta-research studies using systematic reviews or meta-analyses placing new results in the context of existing studies. Two reviewers independently performed screening and data extraction. Data were synthesised using narrative synthesis and a random-effects meta-analysis was performed to estimate the mean proportion of original studies placing their results in the context of earlier studies. The protocol was registered in Open Science Framework.\\\\\\\\rRESULTS: We included 15 meta-research studies representing 1724 original studies. The mean percentage of original studies within these meta-research studies placing their results in the context of existing studies was 30.7% (95% CI [23.8% 37.6%] I2=87.4%). Only one of the meta-research studies integrated results in a meta-analysis while four integrated their results within a systematic review; the remaining cited or referred to a systematic review. The results of this systematic review are characterised by a high degree of heterogeneity and should be interpreted cautiously.\\\\\\\\rCONCLUSION: Our systematic review demonstrates a low rate of and great variability in using systematic reviews to place new results in the context of existing studies. On average one third of the original studies contextualised their results. Improvement is still needed in researchers' use of prior research systematically and transparently-also known as the use of an evidence-based research approach to contribute to the accumulation of new evidence on which future studies should be based.\\\\\\\\rSYSTEMATIC REVIEW REGISTRATION: Open Science registration number https://osf.io/8gkzu/. Copyright © 2022. The Author(s).","","","2022","10.1186/s13643-022-02062-8","","","medline-36064741.pdf","medline-36064741"
"Data anonymization with imprecise rules and its performance evaluations","Inuiguchi, M. And Ichida, H. And Torra, V.","Journal Of Ambient Intelligence And Humanized Computing","","Privacy protection is absolutely imperative for data releases when the utilization of public data and big data is getting popular. In this paper, data anonymization methods using rough set-based rule induction are investigated. It has been shown that many rules with imprecise conclusions can improve the classification accuracy of the rule-based classifier. Data anonymization methods utilizing rules with imprecise conclusions are proposed. The data tables anonymized by one of the proposed methods can preserve the classification accuracy of the rules induced from them. The proposed methods as well as conventional data anonymization methods are compared from two viewpoints: the classification accuracy of rules induced from the anonymized data table and the preservation of data anonymity. The results show the usefulness of the proposed methods. © 2019, springer-verlag gmbh germany, part of springer nature.","","","2019","10.1007/s12652-019-01468-y","","","scopus-2-s2.0-85073947096.pdf","scopus-2-s2.0-85073947096"
"Prioritizing research gaps for national conservation management and policy: the managers’ perspective in estonia","Lõhmus, A. And Fridolin, H. And Leivits, A. And Tõnisson, K. And Rannap, R.","Biodiversity And Conservation","","Conservation scientists often lack explicit understanding of the knowledge problems faced in practical conservation, which can be resolved through communication between the scientists and the managers. Focusing on cost-effectiveness of such communication, we planned and implemented a rapid research gap prioritization procedure for the main stakeholder groups in conservation management and policy (‘managers’) in estonia. The procedure required each research gap to be explicitly linked with its expected application and comprised three steps: (i) preparatory work of the managers to list their main knowledge gaps;  (ii) a seminar for representatives of all the main manager groups to sort out the potentially most influential research topics at the national scale;  (iii) analysis and synopsis writing of the top-voted topics. Researchers provided the methodology, facilitated the procedure, helped to translate practical problems into research topics and checked the topics for existing research. The paper describes the 13 high-priority research topics, which were distinguished among more than 60 topics listed. Land-use planning decisions (notably in forests) were most frequently perceived to lack critical knowledge, while only two priority topics were listed for political decision-making (both in agricultural policy). The priority topics proposed for wetland conservation focused on management techniques to mitigate artificial drainage. Our experience was that, through direct two-way communication between managers and researchers, the perceived knowledge gaps in conservation can be rapidly and transparently formulated as research topics. However, the managers’ views tend to focus on short-term effects of conservation, and a different procedure may be needed for researchers who might vision for longer and less predictable future. © 2019, springer nature b.v.","","","2019","10.1007/s10531-019-01779-8","","","scopus-2-s2.0-85066907026.pdf","scopus-2-s2.0-85066907026"
"Reproducibility in clinical psychology","Hopwood, Christopher J And Vazire, Simine","","","This chapter describes the importance of reproducibility in the scientific method. It reviews recent issues in the social sciences that contributed to the recognition of reproducibility problems, and presents the best practices for conducting reproducible research in clinical psychology. The scientific method is one way of explaining phenomena. It can be contrasted with other methods, such as explanation via tradition or metaphysics, by a few foundational principles. The chapter briefly reviews the distinguishing principles of the scientific method, with a focus on reproducibility. It describes a way to do psychological research that is more likely to lead to reproducible findings. In this alternative approach, scientists think through and preregister studies. They make all methods and data open to the public to the extent possible. Studies have adequate power and use maximally precise measures. Null effects are valued as much as positive effects, and the question shifts from ""is this effect real?"" To ""how substantial is the effect and how precisely can we estimate it?"" Effects are routinely replicated. Journals and universities adjust their incentive structures to reward reproducible science, and the popular press and media follow suit. (Psycinfo database record (c) 2022 apa, all rights reserved)","","","2020","10.1017/9781316995808.035","","","psychinfo-2020-10992-028.pdf","psychinfo-2020-10992-028"
"Blockchain-enabled immutable distributed and highly available clinical research activity logging system for federated COVID-19 data analysis from multiple institutions","Kuo T. T., Pham A., Edelson M. E., Kim J., Chan J., Gupta Y., Ohno-Machado L.","Journal of the American Medical Informatics Association","","OBJECTIVE: We aimed to develop a distributed immutable and highly available cross-cloud blockchain system to facilitate federated data analysis activities among multiple institutions.\\\\\\\\rMATERIALS AND METHODS: We preprocessed 9166 COVID-19 Structured Query Language (SQL) code summary statistics and user activity logs from the GitHub repository of the Reliable Response Data Discovery for COVID-19 (R2D2) Consortium. The repository collected local summary statistics from participating institutions and aggregated the global result to a COVID-19-related clinical query previously posted by clinicians on a website. We developed both on-chain and off-chain components to store/query these activity logs and their associated queries/results on a blockchain for immutability transparency and high availability of research communication. We measured run-time efficiency of contract deployment network transactions and confirmed the accuracy of recorded logs compared to a centralized baseline solution.\\\\\\\\rRESULTS: The smart contract deployment took 4.5 s on an average. The time to record an activity log on blockchain was slightly over 2 s versus 5-9 s for baseline. For querying each query took on an average less than 0.4 s on blockchain versus around 2.1 s for baseline.\\\\\\\\rDISCUSSION: The low deployment recording and querying times confirm the feasibility of our cross-cloud blockchain-based federated data analysis system. We have yet to evaluate the system on a larger network with multiple nodes per cloud to consider how to accommodate a surge in activities and to investigate methods to lower querying time as the blockchain grows.\\\\\\\\rCONCLUSION: Blockchain technology can be used to support federated data analysis among multiple institutions. Copyright © The Author(s) 2023. Published by Oxford University Press on behalf of the American Medical Informatics Association.","","","2023","10.1093/jamia/ocad049","","","medline-36916740.pdf","medline-36916740"
"Fernanda laguna and projects that weave networks. Another way of:reading the:political in:art","Novelli, J.","Itinerarios","","The article analyzes certain artistic projects devised by the poet and plastic artist fernanda laguna. Among the different projects, we will focus on the belleza y felicidad art gallery and publishing house, the eloísa cartonera publishing house, and the belleza y felicidad fiorito art gallery and school. All of them emerge in the context of the crisis of the late 1990s and early 2000s and share related practices that will be thought of in connection with modes of discourse, ways of life and community representations (rancière 2014). Along these lines, our aim is to explore the notion of experimental communities (laddaga 2006) and the deployment of ways of life that these groups and projects proposed in the context of the crisis. Starting from the notion of political art proposed by rancière (2006) we will investigate the potentialities of the different projects and their role in the partition of the sensitive. In this sense, in addition to analyzing the aforementioned projects, we will read the links between the magazine of belleza y felicidad -ceci y fer- and the zines from feminist movements in the united states (especially riot grrrl) whose artistic interventions have uncovered different daily vulnerabilities. © 2021 university of warsaw. All rights reserved.","","","2021","10.7311/itinerarios.33.2021.05","","","scopus-2-s2.0-85139736386.pdf","scopus-2-s2.0-85139736386"
"Culture Change in Older Adult Care Settings: A Bibliometric Review","Ivanitskaya L. V., Bogner M. P.","Gerontologist","","BACKGROUND AND OBJECTIVES: We systematically analyzed research on the culture change movement in the context of global efforts to transform the provision of older adult care in institutional settings.\\\\\\\\rRESEARCH DESIGN AND METHODS: Using Web of Science and Scopus publications relevant to person-centered care culture change or older adult care settings we built bibliometric networks for keywords and terms extracted from titles and abstracts. Overlays depicted corresponding authors' countries publication recency funding scientific impact and concept use.\\\\\\\\rRESULTS: The keyword network for 337 publications revealed variability in culture change settings and study indexing. Term network overlays showed geographical and chronological research variation. Corresponding authors from 14 countries contributed publications mostly from the U.S. (69% of publications) Canada (9%) and Australia (5%). Social environment and person-centeredness studies particularly in dementia care settings were more recent than studies on physical environment quality organizational culture turnover and staffing. Scholars listed funding sources for 38% of publications; funding and scientific impact did not always overlap. Well-cited studies on standards of care and policy were funded at a lower rate than topics of lower impact. Over 60% of titles abstracts or keywords referred to quality and person-centeredness.\\\\\\\\rDISCUSSION AND IMPLICATIONS: Originating in the 1990s in the U.S. culture change quickly became an international phenomenon drawing researchers' attention. Change research has deep roots in quality improvement and person-centered philosophy. We offered practical strategies for querying this hard to access literature. With some database-related limitations empirical data on scientific impact can be used to allocate research funding. Copyright © The Author(s) 2023. Published by Oxford University Press on behalf of The Gerontological Society of America. All rights reserved. For permissions please e-mail: journals.permissions@oup.com.","","","2023","10.1093/geront/gnad128","","","medline-37740248.pdf","medline-37740248"
"Quality properties of execution tracing, an empirical study","Galli, T. And Chiclana, F. And Siewe, F.","Applied System Innovation","","The quality of execution tracing impacts the time to a great extent to locate errors in software components;  moreover, execution tracing is the most suitable tool, in the majority of the cases, for doing postmortem analysis of failures in the field. Nevertheless, software product quality models do not adequately consider execution tracing quality at present neither do they define the quality properties of this important entity in an acceptable manner. Defining these quality properties would be the first step towards creating a quality model for execution tracing. The current research fills this gap by identifying and defining the variables, i.e., the quality properties, on the basis of which the quality of execution tracing can be judged. The present study analyses the experiences of software professionals in focus groups at multinational companies, and also scrutinises the literature to elicit the mentioned quality properties. Moreover, the present study also contributes to knowledge with the combination of methods while computing the saturation point for determining the number of the necessary focus groups. Furthermore, to pay special attention to validity, in addition to the the indicators of qualitative research: credibility, transferability, dependability, and confirmability, the authors also considered content, construct, internal and external validity. © 2021 by the authors. Licensee mdpi, basel, switzerland.","","","2021","10.3390/asi4010020","","","scopus-2-s2.0-85103533651.pdf","scopus-2-s2.0-85103533651"
"Exploring the extent and determinants of knowledge sharing in audit engagements","Chow, C.w. And Ho, J.l. And Vera-Munoz, S.c.","Asia-Pacific Journal Of Accounting And Economics","","Audit firms are faced with increasing demands for audit efficiency and effectiveness. Increasing knowledge sharing in audit engagements can help them respond to this challenge, and this study seeks to advance understanding of the extent and determinants of such sharing. Data collected from auditors of two big four audit firms suggest that both firms have high, but far from complete, levels of knowledge sharing. The factors identified as affecting such sharing range from characteristics of the client to attributes of the audit firm, audit team and individual auditors. A framework is proposed for organizing these factors and relationships. © 2008, copyright taylor & francis group, llc.","","","2008","10.1080/16081625.2008.9720815","","","scopus-2-s2.0-78649481690.pdf","scopus-2-s2.0-78649481690"
"An analysis of gene-finding programs for Neurospora crassa","Kraemer E., Wang J., Guo J., Hopkins S., Arnold J.","Bioinformatics","","MOTIVATION: Computational gene identification plays an important role in genome projects. The approaches used in gene identification programs are often tuned to one particular organism and accuracy for one organism or class of organism does not necessarily translate to accurate predictions for other organisms. In this paper we evaluate five computer programs on their ability to locate coding regions and to predict gene structure in Neurospora crassa. One of these programs (FFG) was designed specifically for gene-finding in N.crassa but the model parameters have not yet been fully 'tuned' and the program should thus be viewed as an initial prototype. The other four programs were neither designed nor tuned for N.crassa.\\\\\\\\rRESULTS: We describe the data sets on which the experiments were performed the approaches employed by the five algorithms: GenScan HMMGene GeneMark Pombe and FFG the methodology of our evaluation and the results of the experiments. Our results show that while none of the programs consistently performs well overall the GenScan program has the best performance on sensitivity and Missing Exons (ME) while the HMMGene and FFG programs have good performance in locating the exons roughly. Additional work motivated by this study includes the creation of a tool for the automated evaluation of gene-finding programs the collection of larger and more reliable data sets for N.crassa parameterization of the model used in FFG to produce a more accurate gene-finding program for this species and a more in-depth evaluation of the reasons that existing programs generally fail for N.crassa.\\\\\\\\rAVAILABILITY: Data sets the FFG program source code and links to the other programs analyzed are available at http://jerry.cs.uga.edu/~wang/genefind.html.\\\\\\\\rCONTACT: eileen@cs.uga.edu.","","","2001","","","","medline-11673234.pdf","medline-11673234"
"Interlaboratory study of the bioluminescence inhibition tests for rapid wastewater toxicity assessment","Farre M., Arranz F., Ribo J., Barcelo D.","Talanta","","Several toxicity procedures are currently being used for the wastewater toxicity assessment. We have undertaken an interlaboratory comparison of the use of different bioluminescence inhibition toxicity tests based on Vibrio fischeri in order to evaluate their reproducibility for the rapid wastewater toxicity assessment. Twenty-two laboratories took part in this study organized by the Institut Catala de Tecnologia (ICT) and the Consejo Superior de Investigaciones Cientificas (CSIC). During the exercise six series of six samples were analyzed along 5 months. Every batch of samples was composed by three real samples and three standard solutions. The real samples were: an untreated effluent of a paper industry a sample from a first settlement of a wastewater treatment plant (WWTP) and the final effluent of the WWTP. The goals of the interlaboratory study were to evaluate the repeatability (r) and reproducibility (R) when different laboratories conduct the test the influence of different matrix samples the variability between different tests based on the same principle: the bioluminescence inhibition of V. fischeri but involving different commercial devices and to determine the rate at which participating laboratories successfully completed tests initiated. The maximum number of outlier values was corresponding to a non-treated effluent from a paper industry. This also was the most complex and toxic sample analyzed. An increase on the non-convergent values obtained for the participants was observed at higher matrix complexity and at lower toxicity level. In comparison with other editions of this interlaboratory study the matrixes of real samples analyzed were more complex nevertheless the final variability coefficient for the exercise was nearby to the average value for the past editions. Due to the high complexity of some samples involved in this intercalibration the stability of real samples were also followed during the test. On the other hand no relation was found between final results and the different devices as show the cluster analysis.","","","2004","10.1016/j.talanta.2003.08.022","","","medline-18969330.pdf","medline-18969330"
"Demonstrating Broadcast Aggregate Keys for Data Sharing in Cloud","Rakshitha K., Rao A. S., Sagar Y., Ramasubbareddy S.","Lecture Notes in Networks and Systems","","In recent years the major issue in cloud computing is providing privacy for getting to re-appropriating information put away on cloud. To store also to share information safely cryptosystem is utilized. In cryptosystem the client needs to scramble the data before securing data on cloud and after that decode the data to get to it. This errand can need numerous keys for information encode just like information decoding. But the problem arises with data integrity where data can be modified or the files can be replaced without the knowledge of the data owner. So to ensure the trustworthiness of the record the information proprietor figures the hash-based message authentication code (HMAC) signature on each encoded document. © 2020 Springer Nature Singapore Pte Ltd.","","","2020","10.1007/978-981-15-2043-3_23","","","scopus-2-s2.0-85081566882.pdf","scopus-2-s2.0-85081566882"
"Trustful ad hoc cross-organizational data exchanges based on the hyperledger fabric framework","Van Hoye, L. And Wauters, T. And De Turck, F. And Volckaert, B.","International Journal Of Network Management","","Organizations share data in a cross-organizational context when they have the goal to derive additional knowledge by aggregating different data sources. The collaborations considered in this article are short-lived and ad hoc, that is, they should be set up in a few minutes at most (e.g., in emergency scenarios). The data sources are located in different domains and are not publicly accessible. When a collaboration is finished, it is however unclear which exchanges happened. This could lead to possible disputes when dishonest organizations are present. The receipt of requests/responses could be falsely denied or their content could be point of discussion. In order to prevent such disputes afterwards, a logging mechanism is needed which generates a replicated irrefutable proof of which exchanges have happened during a single collaboration. Distributed database solutions can be taken from third parties to store the generated logs, but it can be difficult to find a party which is trusted by all participating organizations. Permissioned blockchains provide a solution for this as each organization can act as a consensus participant. Although the consensus mechanism of the permissioned blockchain hyperledger fabric (versions 1.0–1.4) is not fully decentralized, which clashes with the fundamental principle of blockchain, the framework is used in this article as an enabler to set up a distributed database, and a proposal for a logging mechanism is presented which does not require the third party to be fully trusted. A proof of concept is implemented which can be used to experiment with different data exchange setups. It makes use of generic web apis and behaves according to a markov chain in order to create a fully automated data exchange scenario where the participants explore their apis dynamically. The resulting mechanism allows a data-delivering organization to detect missing logs and to take action, for example, (temporarily) suspend collaboration. Furthermore, each organization is incentivized to follow the steps of the logging mechanism as it may lose access to data of others, otherwise. The created proof of concept is scaled to 10 organizations, which autonomously exchange different data types for 10 min, and evaluation results are presented accordingly. © 2020 john wiley & sons, ltd.","","","2020","10.1002/nem.2131","","","scopus-2-s2.0-85089746079.pdf","scopus-2-s2.0-85089746079"
"Estimating sampling interval of terrestrial laser scanning point cloud with neighboring analysis of randomly selected points","Chen, M. And Zhang, X. And Liu, X. And Ji, C. And Zhao, L.","Yingyong Kexue Xuebao/Journal Of Applied Sciences","","This paper focuses on the estimation of sampling interval from terrestrial laser scanning data and presents an estimation method based on the neighboring analysis of randomly selected points. We select n central points from the randomly scanning data and search for k nearest points of each central point. The horizontal and vertical (with z axis) angles between the laser beam of each central point and corresponding neighboring points are calculated. Then histograms of horizontal and vertical angles are constructed respectively, with interval step ∆. The average angle of the interval with the second largest number of points is recognized as the corresponding horizontal or vertical sampling interval. Finally, the median value of the horizontal or vertical sampling values generated from a series of ∆ values is used as the final estimation result. Tests are carried on the data obtained from different scanners and test code is shared on the mathworks community. The test results show that the error of our method is smaller than 0.002◦ with good robustness with respect to different types of targets and parameter settings. © 2022 press of shanghai scientific and technical publishers. All rights reserved.","","","2022","10.3969/j.issn.0255-8297.2022.06.009","","","scopus-2-s2.0-85158149957.pdf","scopus-2-s2.0-85158149957"
"Predicting 30-day readmission risk for patients with chronic obstructive pulmonary disease through a federated machine learning architecture on findable, accessible, interoperable, and reusable (fair) data: development and validation study","Alvarez-Romero, C. And Martinez-Garcia, A. And Vega, J.t. And Díaz-Jimènez, P. And Jimènez-Juan, C. And Nieto-Martín, M.d. And Villarán, E.r. And Kovacevic, T. And Bokan, D. And Hromis, S. And Malbasa, J.d. And Beslać, S. And Zaric, B. And Gencturk, M. And Sinaci, A.a. And Baturone, M.o. And Parra Calderón, C.l.","Jmir Medical Informatics","","Background: owing to the nature of health data, their sharing and reuse for research are limited by legal, technical, and ethical implications. In this sense, to address that challenge and facilitate and promote the discovery of scientific knowledge, the findable, accessible, interoperable, and reusable (fair) principles help organizations to share research data in a secure, appropriate, and useful way for other researchers. Objective: the objective of this study was the fairification of existing health research data sets and applying a federated machine learning architecture on top of the fairified data sets of different health research performing organizations. The entire fair4health solution was validated through the assessment of a federated model for real-time prediction of 30-day readmission risk in patients with chronic obstructive pulmonary disease (copd). Methods: the application of the fair principles on health research data sets in 3 different health care settings enabled a retrospective multicenter study for the development of specific federated machine learning models for the early prediction of 30-day readmission risk in patients with copd. This predictive model was generated upon the fair4health platform. Finally, an observational prospective study with 30 days follow-up was conducted in 2 health care centers from different countries. The same inclusion and exclusion criteria were used in both retrospective and prospective studies. Results: clinical validation was demonstrated through the implementation of federated machine learning models on top of the fairified data sets from different health research performing organizations. The federated model for predicting the 30-day hospital readmission risk was trained using retrospective data from 4.944 patients with copd. The assessment of the predictive model was performed using the data of 100 recruited (22 from spain and 78 from serbia) out of 2070 observed (records viewed) patients during the observational prospective study, which was executed from april 2021 to september 2021. Significant accuracy (0.98) and precision (0.25) of the predictive model generated upon the fair4health platform were observed. Therefore, the generated prediction of 30-day readmission risk was confirmed in 87% (87/100) of cases. Conclusions: implementing a fair data policy in health research performing organizations to facilitate data sharing and reuse is relevant and needed, following the discovery, access, integration, and analysis of health research data. The fair4health project proposes a technological solution in the health domain to facilitate alignment with the fair principles. ©celia alvarez-romero, alicia martinez-garcia, jara ternero vega, pablo díaz-jimènez, carlos jimènez-juan, maría dolores nieto-martín, esther román villarán, tomi kovacevic, darijo bokan, sanja hromis, jelena djekic malbasa, suzana beslać, bojan zaric, mert gencturk, a anil sinaci, manuel ollero baturone, carlos luis parra calderón.","","","2022","10.2196/35307","","","scopus-2-s2.0-85133535592.pdf","scopus-2-s2.0-85133535592"
"Stimulus classification with electrical potential and impedance of living plants: comparing discriminant analysis and deep-learning methods","Buss E., Aust T., Wahby M., Rabbel T. L., Kernbach S., Hamann H.","Bioinspiration & Biomimetics","","The physiology of living organisms such as living plants is complex and particularly difficult to understand on a macroscopic organism-holistic level. Among the many options for studying plant physiology electrical potential and tissue impedance are arguably simple measurement techniques that can be used to gather plant-level information. Despite the many possible uses our research is exclusively driven by the idea of phytosensing that is interpreting living plants' signals to gather information about surrounding environmental conditions. As ready-to-use plant-level physiological models are not available we consider the plant as a blackbox and apply statistics and machine learning to automatically interpret measured signals. In simple plant experiments we exposeZamioculcas zamiifoliaandSolanum lycopersicum(tomato) to four different stimuli: wind heat red light and blue light. We measure electrical potential and tissue impedance signals. Given these signals we evaluate a large variety of methods from statistical discriminant analysis and from deep learning for the classification problem of determining the stimulus to which the plant was exposed. We identify a set of methods that successfully classify stimuli with good accuracy without a clear winner. The statistical approach is competitive partially depending on data availability for the machine learning approach. Our extensive results show the feasibility of the blackbox approach and can be used in future research to select appropriate classifier techniques for a given use case. In our own future research we will exploit these methods to derive a phytosensing approach to monitoring air pollution in urban areas. Copyright Creative Commons Attribution license.","","","2023","10.1088/1748-3190/acbad2","","","medline-36758242.pdf","medline-36758242"
"Improvement of reproducibility in quantitative susceptibility mapping (QSM) and transverse relaxation rates ( R<sub>2</sub><sup> </sup> ) after physiological noise correction","Choi J. Y., Lee J., Nam Y., Lee J., Oh S. H.","Journal of Magnetic Resonance Imaging","","BACKGROUND: Numerous studies have suggested that quantitative susceptibility mapping (QSM) and transverse relaxation rates ( R<sub>2</sub><sup>*</sup> ) are useful to monitor neurological diseases. For clinical use of QSM and R<sub>2</sub><sup>*</sup>  reproducibility is an important feature. However respiration-induced local magnetic field variation makes artifacts in gradient echo-based images and reduces the reproducibility of QSM and R<sub>2</sub><sup>*</sup> . PURPOSE: To investigate the improvement of reproducibility of QSM and R<sub>2</sub><sup>*</sup> after the correction of respiration-induced field variation and to assess the effect of varying types of the region of interest (ROI) analysis on reproducibility. STUDY TYPE: Reproducibility study. POPULATION: Ten controls. FIELD STRENGTH/SEQUENCE: 3T/multiecho gradient echo sequence. ASSESSMENT: Intrascan reproducibility of QSM and R<sub>2</sub><sup>*</sup> was investigated in ROIs before and after the respiration correction. STATISTICAL TESTS: Reproducibility was obtained by the square of voxel-wise correlation coefficients between scans. A paired t-test was performed for comparison between before and after the respiration correction and between QSM and R<sub>2</sub><sup>*</sup> . RESULTS: Based on the ROI analysis reproducibility increased after the respiration correction. Reproducibility in the white matter (11.89% increased in QSM and 23.38% in R<sub>2</sub><sup>*</sup>  P = 0.009 and 0.024 respectively) and deep gray matter (5.50% increased in QSM and 13.96% in R<sub>2</sub><sup>*</sup>  P = 0.024 and 0.019 respectively) increased significantly after the respiration correction. Reproducibility of R<sub>2</sub><sup>*</sup> was higher than that of QSM in the whole brain and cortical gray matter while QSM maps showed higher reproducibility than R<sub>2</sub><sup>*</sup> in the white matter and deep gray matter. DATA CONCLUSION: Respiration-induced error correction significantly improved reproducibility in QSM and R<sub>2</sub><sup>*</sup> mapping. QSM and R<sub>2</sub><sup>*</sup> mapping showed a different level of reproducibility depending on the types of ROI analysis. LEVEL OF EVIDENCE: 4 Technical Efficacy: Stage 1 J. Magn. Reson. Imaging 2018.","","","2019","10.1002/jmri.26522","","","medline-31062456.pdf","medline-31062456"
"Library of pyrolysis-gas chromatography data for synthetic polymers","Smith, C.g.","Journal Of Analytical And Applied Pyrolysis","","In an industrial environment, the analyst often encounters a wide variety of polymeric systems. A key to rapid turn-around-time for the characterization of composition of this assortment of samples involves the use of ""standardized"" analytical techniques which yield reproducible data. These data must be easily compared from one sample to another. A reliable system for identification of copolymer and blend compositions from pyrolysis-gas chromatography has been developed. Using reproducible pyrolysis and chromatographic parameters, ""characteristic"" peaks were identified for a number of industrially important polymers and copolymers. These data were used to develop a library which is readily used to identify the major components in subsequent unknown polymer blends or copolymers. Ingredients of the study included selection of a chromatographic system that gives the most data for a wide assortment of polymers, evaluation of the long-term stability and reproducibility of the chromatographic system, and identification of characteristic pyrolysis products. Examples are given to demonstrate the use of the library for qualitative and quantitative characterization of polymer blend composition. © 1989.","","","1989","10.1016/0165-2370(89)85034-x","","","scopus-2-s2.0-0024620957.pdf","scopus-2-s2.0-0024620957"
"High-content CRISPR screening","Bock C., Datlinger P., Chardon F., Coelho M. A., Dong M. B., Lawson K. A., Lu T., Maroc L., Norman T. M., Song B., Stanley G., Chen S., Garnett M., Li W., Moffat J., Qi L. S., Shapiro R. S., Shendure J., Weissman J. S., Zhuang X.","Nature Reviews. Methods Primers","","CRISPR screens are a powerful source of biological discovery enabling the unbiased interrogation of gene function in a wide range of applications and species. In pooled CRISPR screens various genetically encoded perturbations are introduced into pools of cells. The targeted cells proliferate under a biological challenge such as cell competition drug treatment or viral infection. Subsequently the perturbation-induced effects are evaluated by sequencing-based counting of the guide RNAs that specify each perturbation. The typical results of such screens are ranked lists of genes that confer sensitivity or resistance to the biological challenge of interest. Contributing to the broad utility of CRISPR screens adaptations of the core CRISPR technology make it possible to activate silence or otherwise manipulate the target genes. Moreover high-content read-outs such as single-cell RNA sequencing and spatial imaging help characterize screened cells with unprecedented detail. Dedicated software tools facilitate bioinformatic analysis and enhance reproducibility. CRISPR screening has unravelled various molecular mechanisms in basic biology medical genetics cancer research immunology infectious diseases microbiology and other fields. This Primer describes the basic and advanced concepts of CRISPR screening and its application as a flexible and reliable method for biological discovery biomedical research and drug development - with a special emphasis on high-content methods that make it possible to obtain detailed biological insights directly as part of the screen.","","","2022","10.1038/s43586-022-00098-7","","","medline-37214176.pdf","medline-37214176"
"Key-aggregate searchable encryption under multi-owner setting for group data sharing in the cloud","Li, T. And Liu, Z. And Jia, C. And Fu, Z. And Li, J.","International Journal Of Web And Grid Services","","In recent years, the encryption with keyword search has been widely used in cloud data sharing system to protect privacy and confidentiality when the ciphertext is retrieving. However, selectively sharing encrypted data and related searching abilities among different users via the existing searchable encryption technology certainly will generate a large number of searching trapdoors making the system inflexible and impractical. In this paper, we propose the concept of ""multi-owner key-aggregate searchable encryption"" scheme and its implementation, in which a user can only submit a trapdoor for querying the documents shared by multiple owners who only need to distribute an aggregate key for sharing massive data. Thus, the scheme supports effective data sharing for both multiple owners and users by reducing unnecessary trapdoors which are hard for generating by mobile devices during the querying step. Finally we conduct security analysis and performance evaluation which can show that our system is practical and secure. Copyright © 2018 inderscience enterprises ltd.","","","2018","10.1504/ijwgs.2018.088358","","","scopus-2-s2.0-85037810411.pdf","scopus-2-s2.0-85037810411"
"Replicating the essentially unidimensional model of the mace work-to-family enrichment scale: going beyond goodness-of-fit indices","Schaap, P. And Koekemoer, E. And Brouwers, M.","Sa Journal Of Industrial Psychology","","Orientation: overreliance on goodness-of-fit (gof) indices in confirmatory factor analysis (cfa) model fit evaluations appears to negatively influence the integrity and replicability of research findings in general, and on research to develop work-to-family enrichment (wfe) theory in particular. Research purpose: the purpose of this study was to test for the conceptual replicability of the essentially unidimensional cfa model of the mace work-to-family enrichment scale (mace-w2fe) using bayesian structural equation modelling. Motivation for the study: multidimensional and second-order factor models are commonly reported for wfe instruments, but the more tenable essentially unidimensional model has remained largely untested, because of the limitations of gof indices. Research approach/design and method: two independent cross-sectional study samples of 627 and 346 employees from various industry sectors was used. Bayesian structural equation modelling (bsem) was applied to assess whether model misspecifications at local indicator level were substantive in terms of classical test theory, and justified the rejection of an essentially unidimensional cfa model (the breadth factor) for different mace-w2fe versions. Main findings: in this study it was found that the essentially unidimensional model of the mace-w2fe conceptually replicated across different studies, samples, mace-w2fe versions and statistical theorems. Practical/managerial implications: the mace-w2fe can be univocally scored as a single breadth factor for use in future research. Contribution/value-add: this study demonstrated the value of local indicator misspecification analysis using bsem in countering deficient model testing in wfe studies. © 2022. The authors.","","","2022","10.4102/sajip.v48i0.1960","","","scopus-2-s2.0-85141732310.pdf","scopus-2-s2.0-85141732310"
"Development and testing of surface and instrument disinfectants according to the specifications of the quantitative suspension test","Bode, R.","Hygiene + Medizin","","The new guidelines of the german society for hygiene and medicine relating to the assessment of chemical disinfection procedures contain more stringent requirements and details about the quantification of the effectiveness of these procedures. The proposed in vitro tests for the first time include a description of the quantitative suspension test in addition to the well tried and tested conventional procedures. A series of tests are presented which study the listed instruments and surface disinfectants in their recommended concentrations. Furthermore the authors describe the bactericidal effectiveness of various aldehyde solutions. Non-effective components of commercial preparations, such as for example tensides influence (often decisively) their effectiveness against microorganisms. The reproducibility and exact determination of the reduction procedure in quantitative suspension trials enable a routine application of this in vitro procedure.","","","1982","","","","scopus-2-s2.0-0020357215.pdf","scopus-2-s2.0-0020357215"
"What are the implications of alternative alpha thresholds for hypothesis testing in orthopaedics?","Landy, D.c. And Utset-Ward, T.j. And Lee, M.j.","Clinical Orthopaedics And Related Research","","Backgroundclinical research in orthopaedics typically reports the presence of an association after rejecting a null hypothesis of no association using an alpha threshold of 0.05 at which to evaluate a calculated p value. This arbitrary value is a factor that results in the current difficulties reproducing research findings. A proposal is gaining attention to lower the alpha threshold to 0.005. However, it is currently unknown how alpha thresholds are used in orthopaedics and the distribution of p values reported.questions/purposeswe sought to describe the use of alpha thresholds in two orthopaedic journals by asking (1) how frequently are alpha threshold values reported? (2) how frequently are power calculations reported? (3) how frequently are p values between 0.005 and 0.05 reported for the main hypothesis? (4) are p values less than 0.005 associated with study characteristics such as design and reporting power calculations?Methodsthe 100 most recent original clinical research articles from two leading orthopaedic journals at the time of this proposal were reviewed. For studies without a specified primary hypothesis, a main hypothesis was selected that was most consistent with the title and abstract. The p value for the main hypothesis and lowest p value for each study were recorded. Study characteristics including details of alpha thresholds, beta, and p values were recorded. Associations between study characteristics and p values were described. Of the 200 articles (100 from each journal), 23 were randomized controlled trials, 141 were cohort studies or case series (defined as a study in which authors had access to original data collected for the study purpose), 31 were database studies, and five were classified as other.resultsan alpha threshold was reported in 166 articles (83%) with all but two reporting a value 0.05. Forty-two articles (21%) reported performing a power calculation. The p value for the main hypothesis was less than 0.005 for 88 articles (44%), between 0.05 and 0.005 for 67 (34%), and greater than 0.05 for 29 (15%). The smallest p value was between 0.05 and 0.005 for 39 articles (20%), less than 0.005 for 143 (72%), and either not provided or greater than 0.05 for 18 (9%). Although 50% (65 of 130) cohort and database papers had a main hypothesis p value less than 0.005, only 26% (6 of 23) randomized controlled trials did. Only 36% (15 of 42) articles reporting a power calculation had a p value less than 0.005 compared with 51% (73 of 142) that did not report one.conclusionsalthough a lower alpha threshold may theoretically increase the reproducibility of research findings across orthopaedics, this would preferentially select findings from lower-quality studies or increase the burden on higher quality ones. A more-nuanced approach could be to consider alpha thresholds specific to study characteristics. For example, randomized controlled trials with a prespecified primary hypothesis may still be best evaluated at 0.05 while database studies with an abundance of statistical tests may be best evaluated at a threshold even below 0.005.Clinical relevancesurgeons and scientists in orthopaedics should understand that the default alpha threshold of 0.05 represents an arbitrary value that could be lowered to help reduce type-i errors;  however, it must also be appreciated that such a change could increase type-ii errors, increase resource utilization, and preferentially select findings from lower-quality studies. © 2019 lippincott williams and wilkins. All rights reserved.","","","2019","10.1097/corr.0000000000000843","","","scopus-2-s2.0-85079404216.pdf","scopus-2-s2.0-85079404216"
"Decolonizing open science: southern interventions","Dutta, M. And Ramasubramanian, S. And Barrett, M. And Elers, C. And Sarwatay, D. And Raghunath, P. And Kaur, S. And Dutta, D. And Jayan, P. And Rahman, M. And Tallam, E. And Roy, S. And Falnikar, A. And Johnson, G.m. And Mandal, I. And Dutta, U. And Basnyat, I. And Soriano, C. And Pavarala, V. And Sreekumar, T.t. And Ganesh, S. And Pandi, A.r. And Zapata, D.","Journal Of Communication","","Hegemonic open science, emergent from the circuits of knowledge production in the global north and serving the economic interests of platform capitalism, systematically erase the voices of the subaltern margins from the global south and the southern margins inhabiting the north. Framed within an overarching emancipatory narrative of creating access for and empowering the margins through data exchanged on the global free market, hegemonic open science processes co-opt and erase southern epistemologies, working to create and reproduce new enclosures of extraction that serve data colonialism-capitalism. In this essay, drawing on our ongoing negotiations of community-led culture-centered advocacy and activist strategies that resist the racist, gendered, and classed structures of neocolonial knowledge production in the metropole in the north, we attend to southern practices of openness that radically disrupt the whiteness of hegemonic open science. These decolonizing practices foreground data sovereignty, community ownership, and public ownership of knowledge resources as the bases of resistance to the colonial-capitalist interests of hegemonic open science. © the author(s) 2021.","","","2021","10.1093/joc/jqab027","","","scopus-2-s2.0-85125146052.pdf","scopus-2-s2.0-85125146052"
"The new centennial snow initiative for the greater alpine region (gar). Status report and first results","Jurković, A. And Auer, I. And Böhm, R. And Debit, S. And Orlik, A. And Schöner, W.","Hrvatski Meteoroloski Casopis","","Snow is a significant element in the climate system and has great impact on ecosystem and economy in the alps, too. Astonishingly there is still a strong gap between the data potential and the data availability. Caused by the existing deficits we started a digitising, quality evaluation, homogenising and analysing initiative for the alpine region. For the first time we can present a 21-year (1895-1915) daily, high density dataset that was electronically scanned from historic hydro-yearbooks for recent austria and additional some surrounding regions in italy, slovenia, croatia and czech republic. We hope that our snow initiative will grow to a pan-alpine effort to fill the existing lack of information.","","","2005","","","","scopus-unknown-accession-3099676.pdf","scopus-unknown-accession-3099676"
"The past, present, and future of ego depletion","Inzlicht, Michael And Friese, Malte","Social Psychology","","At the center of social psychology just a few years ago, ego depletion is now widely seen as a controversial topic, one of the chief victims of the replication crisis. Despite over 600 studies of apparent support, many are now asking if ego depletion is even real. Here, we comment on the articles included in this special issue: ego depletion and self-control: conceptual and empirical advances. Specifically, we delineate the contributions and limitations of these articles by embedding them in a brief history of ego depletion, describing the current state of uncertainty about ego depletion's scientific status, and outlining necessary steps for the study of ego depletion to have a healthy future. To us, the most troubling aspect of this controversy is not what it suggests about ego depletion, but what it suggests about social psychology more broadly. If the mere existence of ego depletion is seriously doubted by many, what can be confidently regarded as real in social psychology? By increasing the precision of our theories, continuously validating our manipulations and measures, and practicing the full suite of open science practices, we have the potential to identify legitimate and robust effects and build a cumulative and trustworthy psychological science. (Psycinfo database record (c) 2021 apa, all rights reserved)","","","2019","10.1027/1864-9335/a000398","","","psychinfo-2019-68382-009.pdf","psychinfo-2019-68382-009"
"Perceived managerial (remote leader) trustworthiness as a moderator for the relationship between overall fairness and perceived supervisory (direct leader) trustworthiness","Kong, D.t. And Barsness, Z.i.","Current Psychology","","We investigate the moderating effect of perceived managerial (remote leader) trustworthiness on the relationship between overall fairness and perceived supervisory (direct leader) trustworthiness by integrating fairness heuristic theory and attribution theory. By conducting a field study (study 1) and an experimental study (study 2), we found that perceived managerial trustworthiness attenuated the relationship between overall fairness and perceived supervisory trustworthiness. Additionally, pay-for-performance system functions, as a control variable, were positively related to both forms of perceived trustworthiness (study 2). Our findings advance leader trust/trustworthiness research by proffering a novel view of perceived managerial trustworthiness as a moderator for a psychological process leading to perceived supervisory trustworthiness, rather than merely operating as a factor in parallel to perceived supervisory trustworthiness. Our findings advance fairness research by being the first to identify perceived managerial trustworthiness as a moderator for the fairness heuristic process. The current research also provides practical implications for managing perceived leader trustworthiness. © 2016, springer science+business media new york.","","","2018","10.1007/s12144-016-9511-6","","","scopus-2-s2.0-84990855855.pdf","scopus-2-s2.0-84990855855"
"Policies, resources and services of global alliance of open access scholarly communication platforms","Wan, Y. And Ku, L.","Journal Of Library And Information Science In Agriculture","","[Purpose/significance] with the continuous development of the open access (oa) movement, bibliodiversity is being analyzed and discussed within the framework of global open science strategy. In an inclusive knowledge society, information and knowledge resources should be readily available, interpreted and utilized in appropriate languages and formats. Established in 2019, the global alliance of open access scholarly communication platforms (gloall) mainly includes six national journal publishing platforms, whose establishment and promotion will become a form of bibliodiversity and open access movement. The policies, resources and services of gloall's platforms reflect the emphasis on diversity in regions, languages, and academic evaluations, and are conducive to the collision and compatibility of multiple cultures and ideas emphasized by bibliodiversity. [Method/process] based on the theory of bibliodiversity research and combined with current oa practice, this paper mainly explains, compares and analyzes the policies, resources and services of gloall platforms. The concept of bibliodiversity was first proposed by chilean publishers, during the creation of the ""editores independientes de chile"" collective in the late 1990s. Besides, ""the international declaration of independent publishers 2014"" defined it as ""cultural diversity applied to the world of books"", that is, the critical diversity of products (books, scripts, ebooks, apps and oral literature) made available to readers. Re-examining the oa movement shows that oa under different paths should develop together and complement each other when necessary, rather than just encouraging and promoting one mode. [Results/conclusions] the gloall platforms have similarities in strategic goals and construction principles, like promoting local scientific research, global oa and bibliodiversity. However, since each platform is not systematically constructed in a standardized way and is aimed at different countries or regions, there are differences in specific aspects such as policy formulation, resource construction and service operation. For this reason, these platforms are designed according to the actual situation and publishing needs of their respective countries, and form synergy through alliances to balance the global oa publishing pressure from some international publishing groups. In essence, this publishing market emphasis on the inclusiveness of global oa. The construction experience of gloall has certain reference significance for china to promote oa and build high-end academic exchange platforms. On the one hand, the gloall members are all national oa publishing platforms, promoting the oa movement through international cooperation to find a balance between unity and diversity, and between international development and local development. They have a positive effect on forming an academic exchange ecology that can not only develop bibliodiversity, but also support international academic research. More importantly, building platforms is a means, while exerting international influence is the goal. At present, green oa has the alliances such as coar. While as for golden oa, in addition to transforming academic journals into oa, uniting the world's national open publishing platforms is another way. Therefore, research on gloall in terms of policies, resources, service can help china better grasp the opportunities in the oa movement, fill the gaps in the current service mechanism, and explore more suitable oa modes. © 2022 the authors.","","","2022","10.13998/j.cnki.issn1002-1248.22-0271","","","scopus-2-s2.0-85141761855.pdf","scopus-2-s2.0-85141761855"
"The Impact of Health Information Privacy Concerns on Engagement and Payment Behaviors in Online Health Communities","Wu B., Luo P., Li M., Hu X.","Frontiers in Psychology","","Online health communities (OHCs) have enjoyed increasing popularity in recent years especially in the context of the COVID-19 pandemic. However several concerns have been raised regarding the privacy of users' personal information in OHCs. Considering that OHCs are a type of data-sharing or data-driven platform it is crucial to determine whether users' health information privacy concerns influence their behaviors in OHCs. Thus by conducting a survey this study explores the impact of users' health information privacy concerns on their engagement and payment behavior (Paid) in OHCs. The empirical results show that users' concerns about health information privacy reduce their Paid in OHCs by negatively influencing their OHC engagement. Further analysis reveals that if users have higher benefit appraisals (i.e. perceived informational and emotional support from OHCs) and lower threat appraisals (i.e. perceived severity and vulnerability of information disclosure from OHCs) the negative effect of health information privacy concerns on users' OHC engagement will decrease. Copyright © 2022 Wu Luo Li and Hu.","","","2022","10.3389/fpsyg.2022.861903","","","medline-35465543.pdf","medline-35465543"
"Photocatalytic water splitting","Nishioka, S. And Osterloh, F.e. And Wang, X. And Mallouk, T.e. And Maeda, K.","Nature Reviews Methods Primers","","With the goal of achieving large-scale h2 production from renewable resources, water splitting into h2 and o2 using semiconductor photocatalysts (sometimes called artificial photosynthesis) has been studied for five decades. Unfortunately, the lack of rigour and reproducibility in the data collection and analysis of experimental results has hindered progress in the field. This primer provides a comprehensive overview of proper characterization and evaluation of photocatalysts for overall water splitting. In particular, the primer covers various pitfalls in photocatalysis research, best practices for reproducibility and reliable methods for conducting rigorous experiments. The recommendations are intended to reduce false positives in the literature and to promote progress towards a practical technology for producing h2 from water by using sunlight. © 2023, springer nature limited.","","","2023","10.1038/s43586-023-00226-x","","","scopus-2-s2.0-85160945303.pdf","scopus-2-s2.0-85160945303"
"Developing a community of practice to support the space engineering higher education community","Berthoud, L. And Glester, A.","International Journal Of Engineering Education","","The uk-based space universities network (sun) was formed in 2016 with the aim of enhancing the quality of learning and teaching by providing support and resources to the space science and engineering higher education community. The goal of this research was to pilot the running of this education network as a community of practice and then to use the existing concept of value creation to evaluate it. A community of practice is a recognized way of encouraging interaction and shared best practice to learn together. This paper starts with a review of communities of practice in the literature, then describes the process that led to the foundation of the sun network and its evolution. The methods and process used to establish the infrastructure and regulation of the community are discussed. Next, the uk context, the aims and objectives of sun and the membership of the community are covered. Results include newsletters and email lists which have been used as methods of communication, training of staff has been achieved through workshops by recognized experts and a curated web-based repository of resources has been used to exchange ideas for classes, icebreakers, case studies, questions, shared facilities database and practical exercises. Evaluation of the community has been carried out via a survey of members. In conclusion, a community of practice has found to be a useful vehicle to enable the space higher education community to interact and learn from each other in order to raise the level of space education in the uk. Once firmly established, it is hoped to expand the network through partnerships with similar networks in other countries. © 2018 tempus publications.","","","2018","","","","scopus-2-s2.0-85052685952.pdf","scopus-2-s2.0-85052685952"
"Costing of Essential Health Service Packages: A Systematic Review of Methods From Developing Economies","Jeet G., Masaki E., Vassall A., Prinja S.","Value in Health","","OBJECTIVES: Although an increasing number of countries are adopting essential health service packages (EHSPs) and undertaking their cost assessment standardization of the costing methods and their reporting are imperative to instill confidence in the use of findings of EHSPs as evidence for decision making and resource allocation. This review was conducted to synthesize the EHSP costing reports focusing on the key costing methods and their reporting standards.\\\\\\\\rMETHODS: A systematic review of English language literature (peer-reviewed as well as gray) was conducted. PubMed Embase Scopus NHS Economic Evaluation Database Google Scholar and websites of key institutions were reviewed (2000-2020). Publication characteristics costing methods valuation sources quality transparency and reporting standards were assessed and synthesized.\\\\\\\\rRESULTS: A total of 29 studies from 19 countries were included. Most studies were government reports (69%) and reported the use of ""bottom-up"" approach (76%) OneHealth tool (38%) had international funding (79%) and reported both normative and empirical cost estimates (41%). Six studies (21%) scored ""excellent"" in conduct and reporting. Stand-alone costing of EHSP had higher mean quality score (80). The projected increase in government budget to implement EHSP ranged from 17% to 117%. Limited availability of reliable data on resources prices and coverage of interventions were identified as major limitations for costing of EHSPs.\\\\\\\\rCONCLUSIONS: Substantial differences in the costing methods and reporting standards of EHSPs made comparisons across countries difficult. Existing costing guidelines and checklists should be adapted for EHSPs with more specific methodological guidance to allow harmonization of methods and reporting. Copyright © 2021 ISPOR-The Professional Society for Health Economics and Outcomes Research. Published by Elsevier Inc. All rights reserved.","","","2021","10.1016/j.jval.2021.05.021","","","medline-34711371.pdf","medline-34711371"
"Privacy-preserving multi-party decision tree induction","Zhan, J.z. And Matwin, S. And Chang, L.w.","International Journal Of Business Intelligence And Data Mining","","Data mining is a process to extract useful knowledge from large amounts of data. To conduct data mining, we often need to collect data. However, sometimes the data are distributed among various parties. Privacy concerns may prevent the parties from directly sharing the data and some types of information about the data. How multiple parties can collaboratively conduct data mining without breaching data privacy presents a grand challenge. In this paper, we propose a randomisation-based scheme for multi-parties to conduct data mining computations without disclosing their actual data sets to each other. Copyright © 2007 inderscience enterprises ltd.","","","2007","10.1504/ijbidm.2007.013937","","","scopus-2-s2.0-34250858056.pdf","scopus-2-s2.0-34250858056"
"Proposal for a standardized PSA doubling-time calculation","Ponholzer A., Popper N., Breitenecker F., Schmid H. P., Albrecht W., Loidl W., Madersbacher S., Schramek P., Semjonow A., Rauchenwald M.","Anticancer Research","","PURPOSE: Prostate-specific antigen (PSA) doubling-time (PSA-DT) is an important indicator of progression and survival in men with prostate cancer. Three major limitations regarding PSA-DT determination may lead to inconsistent results: the variety of mathematical methods currently applied the non-standardized handling of input variables and the potential lack of accuracy due to PSA variability. The aim of this project was to develop a reproducible PSA-DT determination tool which simultaneously provides a PSA-DT error estimation.\\\\\\\\rMATERIALS AND METHODS: An internet-based PSA-DT calculation tool via nonlinear optimization implementing the least squares error method using the most recent three PSA values was developed. PSA-DT calculation error is estimated via randomly disturbed measurement data streams (n=65) based on a variable (5-25%) PSA variability.\\\\\\\\rRESULTS: According to a simulation in five men PSA-DT was calculated to be between 1.7 and 15 month (mean: 6.3 month) and determined with another standard tool between 1.3 and 14.5 month (mean: 4.2 month).\\\\\\\\rCONCLUSION: We present a defined open and reproducible PSA-DT calculation and PSA-DT error estimation tool based on a standardized PSA data input. This tool is not better compared to other methods but is scientifically standardized and freely accessible via the following internet address: http://adam.drahtwarenhandlung.at/webapp/mg2008/chapter_prostata4/example_psa.","","","2010","","","","medline-20592353.pdf","medline-20592353"
"Reproducibility of functional network metrics and network structure: a comparison of task-related BOLD resting ASL with BOLD contrast and resting cerebral blood flow","Weber M. J., Detre J. A., Thompson-Schill S. L., Avants B. B.","Cognitive Affective & Behavioral Neuroscience","","Network analysis is an emerging approach to functional connectivity in which the brain is construed as a graph and its connectivity and information processing estimated by mathematical characterizations of graphs. There has been little to no work examining the reproducibility of network metrics derived from different types of functional magnetic resonance imaging (fMRI) data (e.g. resting vs. task related or pulse sequences other than standard blood oxygen level dependent [BOLD] data) or of measures of network structure at levels other than summary statistics. Here we take up these questions comparing the reproducibility of graphs derived from resting arterial spin-labeling perfusion fMRI with those derived from BOLD scans collected while the participant was performing a task. We also examine the reproducibility of the anatomical connectivity implied by the graph by investigating test-retest consistency of the graphs' edges. We compare two measures of graph-edge consistency both within versus between subjects and across data types. We find a dissociation in the reproducibility of network metrics with metrics from resting data most reproducible at lower frequencies and metrics from task-related data most reproducible at higher frequencies; that same dissociation is not recapitulated however in network structure for which the task-related data are most consistent at all frequencies. Implications for the practice of network analysis are discussed.","","","2013","10.3758/s13415-013-0181-7","","","medline-23813017.pdf","medline-23813017"
"Medi-block record: secure data sharing using block chain technology","Singh, C. And Chauhan, D. And Deshmukh, S.a. And Vishnu, S.s. And Walia, R.","Informatics In Medicine Unlocked","","With the advances in the era of artificial intelligence, block chain, cloud computing, big data has the need for secure, decentralized medical record storage and retrieval systems, while cloud storage resolves storage issues but it is difficult to realize the secure sharing of records over the network. The decentralized nature of block chain technology resolves the problem of authentication dependent on third party and imparts secure transmission. This paper proposed block chain based distributed authentication mechanism process and network architecture. Medi-block presents a tamperproof and anonymous identity management model for medical record sharing for hospitals and patients, utilizing the concept of bilinear mapping for the authentication phase and eliminating third party trust issues. It implements two-way authentications between the patients and the hospital. The effectiveness of the proposed authentication scheme is analyzed by ban logic, storage overhead and computing cost. The results presented in the paper demonstrate how a block chain platform based on ban logic can enable medical data sharing while also meeting various security requirements during the authentication phase. Furthermore, reducing average communication time and cost in terms of accessibility meets the requirements of medical data record sharing for integrity, privacy, and availability. © 2021","","","2021","10.1016/j.imu.2021.100624","","","scopus-2-s2.0-85107644737.pdf","scopus-2-s2.0-85107644737"
"Evaluation of open science for co-creation of social innovations: a conceptual framework","Maciuliene, M.","European Public And Social Innovation Review","","Open science is a rapidly expanding and diversifying field of social innovation with significant implications for and potential benefits to society, policy and various academic research areas. However, much is still unknown about the co-creation processes in open science and an overall conceptual framework which aids such understanding is missing. The article aims to address these limitations and identify the key dimensions of an ecosystem allowing co-creation in open science to unfold its social and economic impact. The research presented integrates the literature analysis on co-creation in multi-stakeholder ecosystems and suggest that three important dimensions have to be considered in evaluation of open science ecosystems: framework conditions, system conditions and outcomes. The proposed model was applied in qualitative analysis of thirty-three open science case studies. Based on the results of evaluation, it can be concluded that open science landscape is highly heterogenous, fragmented and not fully coordinated. The fragmentation appeared in all dimensions of evaluation. The outcomes of the research provide a first exploratory step in proposing innovative measures to determine the elements of co-creation practices within open science context. © 2022, sinnergiak social innovation. All rights reserved.","","","2022","10.31637/epsir.22-1.1","","","scopus-2-s2.0-85135198079.pdf","scopus-2-s2.0-85135198079"
"[The background of acid-base interactions in nonaqueous solvents--an analytical approach]","Barcza L., Barczane B. A.","Acta Pharmaceutica Hungarica","","The acid-base determination of different substances by non-aqueous titrations is highly preferred in pharmaceutical analyses since the method is quantitative exact and well reproducible. The modern interpretation of the reactions in nonaqueous solvents started in the past century but several inconsistencies and unsolved problems can still be found in the literature. The acid-base theories of Bronsted-Lowry and Lewis as well as the so-called solvent theory are outlined first then the promoting (and levelling) and the differentiating effects are discussed on the basis of the hydrogen bond concept.","","","2002","","","","medline-12494788.pdf","medline-12494788"
"Shoulder Arthroplasty Trials Are Infrequently Registered: A Systematic Review of Trials","Sims M. T., Sanchez Z. C., Herrington J. M., Hensel J. B., Henning N. M., Scheckel C. J., Vassar M.","PLoS ONE [Electronic Resource]","","INTRODUCTION: With the intent of improving transparency in clinical research the International Committee of Medical Journal Editors (ICMJE) established guidelines in 2005 regarding prospective clinical trial registration. This action worked to address bias related to selective outcome reporting in the medical literature. The objective of this study was to assess and characterize the quality of registration of clinical trials appearing in shoulder arthroplasty-related medical journals. METHODS: All randomized trials involving human subjects pertaining to shoulder arthroplasty published between July 1 2005 and December 31 2015 and indexed in either PubMed or SportDISCUS were analyzed. We assessed the prevalence of registration the timing of registration relative to patient enrollment periods and the variable rates of orthopedic journal compliance with ICMJE and Food and Drug Administration clinical registration standards for our study. RESULTS: Of the 382 articles identified 345 (90.3%) were excluded due to failure to meet inclusion criteria. From the remaining 37 only 12 (32.4%) studies were found to be registered in a trial registry. Ten (10/12 83.3%) of these provided their registration information within the body of the article. None of the included studies from ICMJE-recognized journals were registered. From 34 included studies from non-ICMJE recognized journals 12 (35.3%) were registered. CONCLUSION: The level of compliance with clinical trial registration guidelines in the decade since their release among shoulder arthroplasty trials in orthopedic journals is poor. Given the importance of the issue the prevalence of the problem and the fact that many other medical specialties have already made efforts to improve ICMJE compliance further work on the part of orthopedic surgery journal authors and editors is needed to ensure the publication of unbiased results. Trial registration: Umin000022487.","","","2016","10.1371/journal.pone.0164984","","","medline-27764210.pdf","medline-27764210"
"A guide to visualizing trajectories of change with confidence bands and raw data","Howard, A.l.","Advances In Methods And Practices In Psychological Science","","This tutorial is aimed at researchers working with repeated measures or longitudinal data who are interested in enhancing their visualizations of model-implied mean-level trajectories plotted over time with confidence bands and raw data. The intended audience is researchers who are already modeling their experimental, observational, or other repeated measures data over time using random-effects regression or latent curve modeling but who lack a comprehensive guide to visualize trajectories over time. This tutorial uses an example plotting trajectories from two groups, as seen in random-effects models that include time × group interactions and latent curve models that regress the latent time slope factor onto a grouping variable. This tutorial is also geared toward researchers who are satisfied with their current software environment for modeling repeated measures data but who want to make graphics using r software. Prior knowledge of r is not assumed, and readers can follow along using data and other supporting materials available via osf at https://osf.io/78bk5/. Readers should come away from this tutorial with the tools needed to begin visualizing mean trajectories over time from their own models and enhancing those plots with graphical estimates of uncertainty and raw data that adhere to transparent practices in research reporting. © the author(s) 2021.","","","2021","10.1177/25152459211047228","","","scopus-2-s2.0-85116541800.pdf","scopus-2-s2.0-85116541800"
"Reproducibility of food atopy patch tests over time in the general child population","Jesenak M., Banovcin P., Rennerova Z., Jakusova L., Havlicekova Z., Pohanka V., Villa M. P., Ronchetti R.","International Journal of Dermatology","","BACKGROUND: The atopy patch test (APT) is no longer an experimental method; it is increasingly being used as a standard diagnostic tool for the characterization of patients with aeroallergen- and food-triggered disorders. Some technical aspects of this test still remain to be answered. We aimed to study the reproducibility of this test over time in the general child population.\\\\\\\\rMETHODS: In a general population of 118 children we investigated the reproducibility of duplicate APTs with four food allergens in their native form which were repeated at set intervals from the first test: 7 days (group 1) 14 days (group 2) and 21 days (group 3).\\\\\\\\rRESULTS: We observed very poor reproducibility on both sides of the back in all three studied subgroups. The reproducibility rates and Cohen's kappa values did not improve when we did not consider the side of the back. There were no differences in the prevalence of atopy between the subjects with reproducible and nonreproducible APT results. All three groups studied showed no difference in the prevalence rates of atopy. There was no relationship between APT and skin prick test positivity for the same allergen. Questionnaire-derived data about previous food-related reactions did not help in the evaluation of the doubtful nonreproducible APT results with food allergens.\\\\\\\\rCONCLUSIONS: Our results show that the reproducibility of food APTs is poor and unsatisfactory over time and there is an urgent need for the development of optimal stable and good-quality APT testing substances.","","","2009","10.1111/j.1365-4632.2008.04037.x","","","medline-19702976.pdf","medline-19702976"
"Code-sharing agreements and interconnections in markets for international flights","Hassin, O. And Shy, O.","Review Of International Economics","","The paper investigates the consequences of code-sharing agreements among airline firms competing on international routes, where some passengers interconnect to flights originating or terminating at cities not served by foreign airlines. The authors calculate the precise market share captured by flights operated under code sharing. They compare airfares, market shares, profits, and passengers' welfare before and after the implementation of a code-sharing agreement and demonstrate that code sharing is pareto-improving. © blackwell publishing ltd 2004.","","","2004","10.1111/j.1467-9396.2004.00453.x","","","scopus-2-s2.0-4143122281.pdf","scopus-2-s2.0-4143122281"
"The role of data type and recipient in individuals’ perspectives on sharing passively collected smartphone data for mental health: cross-sectional questionnaire study","Nicholas, J. And Shilton, K. And Schueller, S.m. And Gray, E.l. And Kwasny, M.j. And Mohr, D.c.","Jmir Mhealth And Uhealth","","Background: the growing field of personal sensing harnesses sensor data collected from individuals’ smartphones to understand their behaviors and experiences. Such data could be a powerful tool within mental health care. However, it is important to note that the nature of these data differs from the information usually available to, or discussed with, health care professionals. To design digital mental health tools that are acceptable to users, understanding how personal sensing data can be used and shared is critical. Objective: this study aimed to investigate individuals’ perspectives about sharing different types of sensor data beyond the research context, specifically with doctors, electronic health record (ehr) systems, and family members. Methods: a questionnaire assessed participants’ comfort with sharing six types of sensed data: physical activity, mood, sleep, communication logs, location, and social activity. Participants were asked about their comfort with sharing these data with three different recipients: doctors, ehr systems, and family members. A series of principal component analyses (one for each data recipient) was performed to identify clusters of sensor data types according to participants’ comfort with sharing them. Relationships between recipients and sensor clusters were then explored using generalized estimating equation logistic regression models. Results: a total of 211 participants completed the questionnaire. The majority were female (171/211, 81.0%), and the mean age was 38 years (sd 10.32). Principal component analyses consistently identified two clusters of sensed data across the three data recipients: “health information,” including sleep, mood, and physical activity, and “personal data,” including communication logs, location, and social activity. Overall, participants were significantly more comfortable sharing any type of sensed data with their doctor than with the ehr system or family members (p<.001) and more comfortable sharing “health information” than “personal data” (p<.001). Participant characteristics such as age or presence of depression or anxiety did not influence participants’ comfort with sharing sensed data. Conclusions: the comfort level in sharing sensed data was dependent on both data type and recipient, but not individual characteristics. Given the identified differences in comfort with sensed data sharing, contextual factors of data type and recipient appear to be critically important as we design systems that harness sensor data for mental health treatment and support. © jennifer nicholas, katie shilton, stephen m schueller, elizabeth l gray, mary j kwasny, david c mohr.","","","2019","10.2196/12578","","","scopus-2-s2.0-85066478575.pdf","scopus-2-s2.0-85066478575"
"Transfer learning in heterogeneous collaborative filtering domains","Pan, W. And Yang, Q.","Artificial Intelligence","","A major challenge for collaborative filtering (cf) techniques in recommender systems is the data sparsity that is caused by missing and noisy ratings. This problem is even more serious for cf domains where the ratings are expressed numerically, e.g. as 5-star grades. We assume the 5-star ratings are unordered bins instead of ordinal relative preferences. We observe that, while we may lack the information in numerical ratings, we sometimes have additional auxiliary data in the form of binary ratings. This is especially true given that users can easily express themselves with their preferences expressed as likes or dislikes for items. In this paper, we explore how to use these binary auxiliary preference data to help reduce the impact of data sparsity for cf domains expressed in numerical ratings. We solve this problem by transferring the rating knowledge from some auxiliary data source in binary form (that is, likes or dislikes), to a target numerical rating matrix. In particular, our solution is to model both the numerical ratings and ratings expressed as like or dislike in a principled way. We present a novel framework of transfer by collective factorization (tcf), in which we construct a shared latent space collectively and learn the data-dependent effect separately. A major advantage of the tcf approach over the previous bilinear method of collective matrix factorization is that we are able to capture the data-dependent effect when sharing the data-independent knowledge. This allows us to increase the overall quality of knowledge transfer. We present extensive experimental results to demonstrate the effectiveness of tcf at various sparsity levels, and show improvements of our approach as compared to several state-of-the-art methods. © 2013 elsevier b.v.","","","2013","10.1016/j.artint.2013.01.003","","","scopus-2-s2.0-84874916256.pdf","scopus-2-s2.0-84874916256"
"Is job sharing worthwhile? A cost-benefit analysis in uk universities","Harris, G.","Higher Education","","Around 60 per cent of uk universities practice job sharing. This article is based on a survey of personnel directors in uk universities concerning their perceptions of job sharing. These responses were then used to carry out a cost benefit evaluation of job sharing from the universities' perspective. If productivity of workers in the shared job rose by as little as 0.35 per cent - one third of one per cent - the estimated increase in personnel section costs would be covered. If there was a 5 per cent increase in productivity, the ratio of benefits to costs would be 14.3 to 1. Universities also save as a result of greater retention of staff, and there are also important benefits to society, particularly less overall stress and reduced unemployment levels. © 1997 kluwer academic publishers.","","","1997","10.1023/a:1002927803336","","","scopus-2-s2.0-25844517618.pdf","scopus-2-s2.0-25844517618"
"A protocol for the development of reporting guidelines for IDEAL stage studies","Agha R. A., Hirst A., Khachane A., McCulloch P.","International Journal of Surgery Protocols","","BACKGROUND: New surgical procedures devices and other complex interventions need robust evaluation for safety efficacy and effectiveness. The IDEAL Framework and Recommendations lay out a pathway to achieve this and offer general guidance on how studies at each stage should be reported. However researchers require some assistance in translating theory into practice. We will develop a set of reporting guidelines for each IDEAL stage where deemed necessary through Delphi consensus methodology. METHODS: For each IDEAL stage requiring a new set of reporting guidelines we will use the following process. We will search for the relevant reporting guidelines already in existence and use principles developed by the IDEAL Collaboration to compile the initial long list of potential checklist items. In each round the participants will rate the importance of reporting each element on a nine-point Likert scale as proposed by the GRADE group. Sequential rounds and questionnaire administration and completion will take place until a final set of items is produced. There will then be a final consensus meeting of a working group to condense and refine the final recommendations for the reporting guidelines.","","","2018","10.1016/j.isjp.2018.04.001","","","pubmed-31851736.pdf","pubmed-31851736"
"Recommended methods for conducting human factors experiments on the subjective evaluation of colour rendition","Royer, M. And Houser, K. And Durmus, D. And Esposito, T. And Wei, M.","Lighting Research And Technology","","This article explores the best practices for conducting psychophysical experiments that investigate how colour rendition influences the perception of architectural environments. We offer guidance that covers all stages of research from preliminary development to publication, focusing especially on experiments that investigate qualities such as perceived naturalness, vividness, preference or acceptability in response to changes in the spectral power distribution of light sources. This article is intended to be a consolidated guide for researchers and reviewers of this type of research. Key recommendations include: (1) new work should be motivated by clearly expressed research questions and, when possible, explicit hypotheses that build on the existing body of knowledge, (2) visual stimuli comprising spectral power distributions and visual targets should be deliberately engineered to probe the research questions, (3) experiments should be designed to lessen potential biases, (4) reporting of experimental conditions and statistical analyses should be thorough and (5) results should be contextual, resisting overgeneralization that cannot be supported by the data. Our motivation is to encourage high-quality research that is credible and discourage poor quality research that slows scientific progress and misuses resources. © the chartered institution of building services engineers 2021.","","","2022","10.1177/14771535211019864","","","scopus-2-s2.0-85107299506.pdf","scopus-2-s2.0-85107299506"
"Leveraging anthropological expertise to respond to the COVID-19 global mental health syndemic","Azevedo K. J., Kalvesmaki A. F., Riendeau R. P., Sweet P. A., Holmes S. M.","American Anthropologist","","This commentary asks anthropologists to work within communities to actively address the global mental health impact of COVID-19 and contribute to the pandemic response. Multiple social and physical losses worsened by numerous factors have produced syndemic traumatic stress and suffering across populations highlighting persistent inequalities further amplified by the effects of COVID-19. Specifically anthropologists can work to contribute to the development of mental health programs; confront the racialization of COVID-19 alongside marginalized communities; support real-time policy making with community responses; and innovate transparent collaborative research methods through open science. This pandemic can serve as an opportunity to prioritize research endeavors public service and teaching to better align with societal needs while providing new opportunities for synergy and collaborations between anthropologists in and outside the academy. Anthropologists collaborating directly with mental health clinicians and the public can contribute to knowledge specifically through direct program development and implementation of interventions designed to improve mental well-being. Innovating to find impactful solutions in response to the unprecedented mental health challenges exacerbated by the COVID-19 pandemic has the potential to promote more equitable recovery around the world. Copyright Published 2022. This article is a U.S. Government work and is in the public domain in the USA. American Anthropologist published by Wiley Periodicals LLC on behalf of American Anthropological Association.","","","2022","10.1111/aman.13747","","","medline-35941987.pdf","medline-35941987"
"Assessment Rubrics: Towards Clearer and More Replicable Design Research and Practice","Dawson Phillip","Assessment & Evaluation in Higher Education","","""Rubric"" is a term with a variety of meanings. As the use of rubrics has increased both in research and practice the term has come to represent divergent practices. These range from secret scoring sheets held by teachers to holistic student-developed articulations of quality. Rubrics are evaluated mandated embraced and resisted based on often imprecise and inconsistent understandings of the term. This paper provides a synthesis of the diversity of rubrics and a framework for researchers and practitioners to be clearer about what they mean when they say ""rubric."" Fourteen design elements or decision points are identified that make one rubric different from another. This framework subsumes previous attempts to categorise rubrics and should provide more precision to rubric discussions and debate as well as supporting more replicable research and practice.","","","2017","10.1080/02602938.2015.1111294","","","eric-ej1129724.pdf","eric-ej1129724"
"Mobile access and flexible search over encrypted cloud data in heterogeneous systems","Sun, J. And Xiong, H. And Zhang, H. And Peng, L.","Information Sciences","","Never before has data sharing been more convenient with the rapid popularity and wide adoption of cloud computing. However, mobile access and flexible search with security for outsourced data in heterogeneous systems are two major obstacles prior to practical deployment of cloud computing. To meet the requirements in secure mobile access and flexible search to sensitive data, this paper, for the first time, proposes a versatile primitive referred to as an identity based proxy re-encryption system with outsourced equality test (ibpre-et). This primitive allows a data owner in an identity based broadcast encryption system (ibbe) seamlessly to share his/her data with a data sharer in an identity based encryption system (ibe). Moreover, it supports a data sharer in an ibbe system to perform search functionality on ciphertexts related to a data sharer in an ibe system. We also formally prove that the proposed ibpre-et system is selective secure using a random oracle model. Meanwhile, the theoretic evaluation and experimental result demonstrate our scheme is practical in the heterogeneous system. Finally, we show an application of our ibpre-et to the collaborative office automation system. © 2019","","","2020","10.1016/j.ins.2019.08.026","","","scopus-2-s2.0-85070506425.pdf","scopus-2-s2.0-85070506425"
"The general theory of the quasi-reproducible experiments: how to describe the measured data of complex systems?","Nigmatullin, R.r. And Maione, G. And Lino, P. And Saponaro, F. And Zhang, W.","Communications In Nonlinear Science And Numerical Simulation","","In this paper, we suggest a general theory that enables to describe experiments associated with reproducible or quasi-reproducible data reflecting the dynamical and self-similar properties of a wide class of complex systems. Under complex system we understand a system when the model based on microscopic principles and suppositions about the nature of the matter is absent. This microscopic model is usually determined as ""the best fit"" model. The behavior of the complex system relatively to a control variable (time, frequency, wavelength, etc.) can be described in terms of the so-called intermediate model (im). One can prove that the fitting parameters of the im are associated with the amplitude-frequency response of the segment of the prony series. The segment of the prony series including the set of the decomposition coefficients and the set of the exponential functions (with k = 1,2,. . .,k) is limited by the final mode k. The exponential functions of this decomposition depend on time and are found by the original algorithm described in the paper. This approach serves as a logical continuation of the results obtained earlier in paper [nigmatullin rr, w. Zhang and striccoli d. General theory of experiment containing reproducible data: the reduction to an ideal experiment. Commun nonlinear sci numer simul, 27, (2015), pp 175-192] for reproducible experiments and includes the previous results as a partial case. In this paper, we consider a more complex case when the available data can create short samplings or exhibit some instability during the process of measurements. We give some justified evidences and conditions proving the validity of this theory for the description of a wide class of complex systems in terms of the reduced set of the fitting parameters belonging to the segment of the prony series. The elimination of uncontrollable factors expressed in the form of the apparatus function is discussed.to illustrate how to apply the theory and take advantage of its benefits, we consider the experimental data associated with typical working conditions of the injection system in a common rail diesel engine. In particular, the flow rate of the injected fuel is considered at different reference rail pressures. The measured data are treated by the proposed algorithm to verify the adherence to the proposed general theory. The obtained results demonstrate the undoubted effectiveness of the proposed theory. © 2016 elsevier b.v..","","","2017","10.1016/j.cnsns.2016.05.019","","","scopus-2-s2.0-84973531918.pdf","scopus-2-s2.0-84973531918"
"Evaluating feature-selection stability in next-generation proteomics","Goh W.w. And Wong L.","J Bioinform Comput Biol","","Identifying reproducible yet relevant features is a major challenge in biological research. This is well documented in genomics data. Using a proposed set of three reliability benchmarks, we find that this issue exists also in proteomics for commonly used feature-selection methods, e.g. [Formula: see text]-test and recursive feature elimination. Moreover, due to high test variability, selecting the top proteins based on [formula: see text]-value ranks - even when restricted to high-abundance proteins - does not improve reproducibility. Statistical testing based on networks are believed to be more robust, but this does not always hold true: the commonly used hypergeometric enrichment that tests for enrichment of protein subnets performs abysmally due to its dependence on unstable protein pre-selection steps. We demonstrate here for the first time the utility of a novel suite of network-based algorithms called ranked-based network algorithms (rbnas) on proteomics. These have originally been introduced and tested extensively on genomics data. We show here that they are highly stable, reproducible and select relevant features when applied to proteomics data. It is also evident from these results that use of statistical feature testing on protein expression data should be executed with due caution. Careless use of networks does not resolve poor-performance issues, and can even mislead. We recommend augmenting statistical feature-selection methods with concurrent analysis on stability and reproducibility to improve the quality of the selected features prior to experimental validation.","","","2016","10.1142/s0219720016500293","","","embase-619875728.pdf","embase-619875728"
"Temporospatial shifts within commercial laboratory mouse gut microbiota impact experimental reproducibility","Mandal, R.k. And Denny, J.e. And Waide, M.l. And Li, Q. And Bhutiani, N. And Anderson, C.d. And Baby, B.v. And Jala, V.r. And Egilmez, N.k. And Schmidt, N.w.","Bmc Biology","","Background: experimental reproducibility in mouse models is impacted by both genetics and environment. The generation of reproducible data is critical for the biomedical enterprise and has become a major concern for the scientific community and funding agencies alike. Among the factors that impact reproducibility in experimental mouse models is the variable composition of the microbiota in mice supplied by different commercial vendors. Less attention has been paid to how the microbiota of mice supplied by a particular vendor might change over time. Results: in the course of conducting a series of experiments in a mouse model of malaria, we observed a profound and lasting change in the severity of malaria in mice infected with plasmodium yoelii;  while for several years mice obtained from a specific production suite of a specific commercial vendor were able to clear the parasites effectively in a relatively short time, mice subsequently shipped from the same unit suffered much more severe disease. Gut microbiota analysis of frozen cecal samples identified a distinct and lasting shift in bacteria populations that coincided with the altered response of the later shipments of mice to infection with malaria parasites. Germ-free mice colonized with cecal microbiota from mice within the same production suite before and after this change followed by plasmodium infection provided a direct demonstration that the change in gut microbiota profoundly impacted the severity of malaria. Moreover, spatial changes in gut microbiota composition were also shown to alter the acute bacterial burden following salmonella infection, and tumor burden in a lung tumorigenesis model. Conclusion: these changes in gut bacteria may have impacted the experimental reproducibility of diverse research groups and highlight the need for both laboratory animal providers and researchers to collaborate in determining the methods and criteria needed to stabilize the gut microbiota of animal breeding colonies and research cohorts, and to develop a microbiota solution to increase experimental rigor and reproducibility. © 2020 the author(s).","","","2020","10.1186/s12915-020-00810-7","","","scopus-2-s2.0-85087472876.pdf","scopus-2-s2.0-85087472876"
"Settings, quantification, and statistical analyses beyond p-values for arabidopsis ethylene responses","Lu, J. And Wen, C.-K.","Small Methods","","Ethylene is a gaseous plant hormone and plays various roles in plant growth and development. Studies on ethylene-induced responses have advanced the knowledge about ethylene signaling and effects of its interactions with other plant hormones and with biotic and abiotic cues. Degrees of the ethylene response can be quantified on the basis of the “seedling triple-response assay” that primarily measures the hypocotyl and/or root lengths of etiolated arabidopsis seedlings. Different laboratories perform the assay differently, possibly with various degrees of arbitrariness, and experimental results across independent studies can hardly be shared and compared. An optimal and standardized protocol for the setting of ethylene treatment may facilitate data sharing, reproducing, and new findings. Data collected from experiments are quantified and analyzed statistically to support scientific inference. On the other hand, erroneous statistical practices are criticized for muddling scientific inference, leading to poor reproducibility and false results. Grasping the basic concepts of statistics may avoid erroneous practices and inference. Different settings for ethylene treatment prevalently adapted in the field are compared in this study, analyzed statistically to explain how the settings may affect the outcome, and a standardized conduct for the seedling triple-response assay is proposed. © 2019 wiley-vch verlag gmbh & co. Kgaa, weinheim","","","2020","10.1002/smtd.201900386","","","scopus-2-s2.0-85070675105.pdf","scopus-2-s2.0-85070675105"
"Measuring the use of the active and assisted living prototype carimo for home care service users: evaluation framework and results","Schneider, C. And Trukeschitz, B. And Rieser, H.","Applied Sciences (Switzerland)","","To address the challenges of aging societies, various information and communication technology (ict)-based systems for older people have been developed in recent years. Currently, the evaluation of these so-called active and assisted living (aal) systems usually focuses on the analyses of usability and acceptance, while some also assess their impact. Little is known about the actual take-up of these assistive technologies. This paper presents a framework for measuring the take-up by analyzing the actual usage of aal systems. This evaluation framework covers detailed information regarding the entire process including usage data logging, data preparation, and usage data analysis. We applied the framework on the aal prototype carimo for measuring its take-up during an eight-month field trial in austria and italy. The framework was designed to guide systematic, comparable, and reproducible usage data evaluation in the aal field;  however, the general applicability of the framework has yet to be validated. © 2019 by the authors.","","","2020","10.3390/app10010038","","","scopus-2-s2.0-85079141501.pdf","scopus-2-s2.0-85079141501"
"Reproducible research practices, openness and transparency in health economic evaluations: study protocol for a cross-sectional comparative analysis","Catalá-López, F. And Caulley, L. And Ridao, M. And Hutton, B. And Husereau, D. And Drummond, M.f. And Alonso-Arroyo, A. And Pardo-Fernández, M. And Bernal-Delgado, E. And Meneu, R. And Tabarés-Seisdedos, R. And Repullo, J.r. And Moher, D.","Bmj Open","","There has been a growing awareness of the need for rigorously and transparent reported health research, to ensure the reproducibility of studies by future researchers. Health economic evaluations, the comparative analysis of alternative interventions in terms of their costs and consequences, have been promoted as an important tool to inform decision-making. The objective of this study will be to investigate the extent to which articles of economic evaluations of healthcare interventions indexed in medline incorporate research practices that promote transparency, openness and reproducibility. Methods and analysis this is the study protocol for a cross-sectional comparative analysis. We registered the study protocol within the open science framework (osf.io/gzaxr). We will evaluate a random sample of 600 cost-effectiveness analysis publications, a specific form of health economic evaluations, indexed in medline during 2012 (n=200), 2019 (n=200) and 2022 (n=200). We will include published papers written in english reporting an incremental cost-effectiveness ratio in terms of costs per life years gained, quality-adjusted life years and/or disability-adjusted life years. Screening and selection of articles will be conducted by at least two researchers. Reproducible research practices, openness and transparency in each article will be extracted using a standardised data extraction form by multiple researchers, with a 33% random sample (n=200) extracted in duplicate. Information on general, methodological and reproducibility items will be reported, stratified by year, citation of the consolidated health economic evaluation reporting standards (cheers) statement and journal. Risk ratios with 95% cis will be calculated to represent changes in reporting between 2012-2019 and 2019-2022. Ethics and dissemination due to the nature of the proposed study, no ethical approval will be required. All data will be deposited in a cross-disciplinary public repository. It is anticipated the study findings could be relevant to a variety of audiences. Study findings will be disseminated at scientific conferences and published in peer-reviewed journals. © author(s) (or their employer(s)) 2020. Re-use permitted under cc by-nc. No commercial re-use. See rights and permissions. Published by bmj.","","","2020","10.1136/bmjopen-2019-034463","","","scopus-2-s2.0-85079360066.pdf","scopus-2-s2.0-85079360066"
"Prediction of environmental risks from explosions based on a set of coupled geophysical fields","Gubarev, V.v. And Kovalevskii, V.v. And Khairetdinov, M.s. And Avrorov, S.a. And Voskoboinikova, G.m. And Sedukhina, G.f. And Yakimenko, A.a.","Optoelectronics, Instrumentation And Data Processing","","This paper presents the results of experimental studies and numerical calculations of weather-dependent ecological risks to social infrastructure facilities from the effects of powerful infrasonic vibrations generated by man-made and natural explosions. The results were obtained by applying an original ecologically safe approach developed by the authors and involving the use of seismic vibrators as sources simulating explosions but having much less power compared to the explosions. Such sources generate both seismic and acoustic (seismoacoustic) vibrations with precision metrological power and frequency-time characteristics, which, in contrast to explosions, ensures high reproducibility of research results. Results comparable to explosions are achieved due to the energy accumulation of weak vibroseismoacoustic signals. The propagation of infralow-frequency wave fields is studied depending on weather conditions and taking into account the effect of heterogeneity of the atmosphere. The results of the experiments are compared with those of numerical calculations. © 2014, allerton press, inc.","","","2014","10.3103/s8756699014040013","","","scopus-2-s2.0-84908067344.pdf","scopus-2-s2.0-84908067344"
"Medical guidelines physician density and quality of care: evidence from German SHARE data","Jurges H., Pohl V.","European Journal of Health Economics","","We use German SHARE data to study the relationship between district general practitioner density and the quality of preventive care provided to older adults. We measure physician quality of care as the degree of adherence to medical guidelines (for the management of risk factors for cardiovascular disease and the prevention of falls) as reported by patients. Contrary to theoretical expectations we find only weak and insignificant effects of physician density on quality of care. Our results shed doubt on the notion that increasing physician supply will increase the quality of care provided in Germany's present health care system.","","","2012","10.1007/s10198-011-0372-5","","","medline-22203268.pdf","medline-22203268"
"The operations manual: a mechanism for improving the research process","Bowman A., Wyman J. F., Peters J.","Nursing Research","","BACKGROUND: The development and use of an operations manual has the potential to improve the capacity of nurse scientists to address the complex multifaceted issues associated with conducting research in today's healthcare environment. An operations manual facilitates communication standardizes training and evaluation and enhances the development and standard implementation of clear policies processes and protocols. A 10-year review of methodology articles in relevant nursing journals revealed no attention to this topic.\\\\\\\\rOBJECTIVES: This article will discuss how an operations manual can improve the conduct of research methods and outcomes for both small-scale and large-scale research studies. It also describes the purpose and components of a prototype operations manual for use in quantitative research.\\\\\\\\rCONCLUSION: The operations manual increases reliability and reproducibility of the research while improving the management of study processes. It can prevent costly and untimely delays or errors in the conduct of research.","","","2002","10.1097/00006199-200203000-00011","","","medline-11984385.pdf","medline-11984385"
"Involvement effect on high-educated tourists' perceived credibility of social media","Li, H. And Cao, Y. And Pu, Q.","Biotechnology: An Indian Journal","","Involvement has long been studied as a key factor to determine the individual's perceived credibility about particular information source. The perceived credibility of well-educated people is critical for the destination crisis management because people with high education level always play a significant role of public opinion leaders. To determine the relationship between involvement and individual's perceived credibility of social media, current research first determine the dimensionality of involvement, then examine the effectiveness of new-generated factors in evaluating perceived credibility, and the study also re-examine the dimensions that are utilized to evaluate credibility from prior research. The result reveals that 'interest' significantly influences perceived credibility;  and among perceived credibility, depth is excluded from the linear regression model, which is contrary to previous research. Current study also provide some practical implications to minimize the negative impact of certain crisis on tourism destination. © trade science inc.","","","2014","","","","scopus-2-s2.0-84922811918.pdf","scopus-2-s2.0-84922811918"
"The doctorate in fine art: the importance of exemplars to the research culture","Macleod, K. And Holdridge, L.","International Journal Of Art And Design Education","","The doctorate in fine art has had a troubled history in the uk. Although there are growing numbers of doctorates being undertaken and over forty institutions which offer doctoral study, there is still little understanding of this research culture. There is a developing literature, but it remains curiously focused on research methods and protocols rather than on establishing the character of the culture through what is being produced by doctoral students. Macleod and holdridge have produced an ahrb-funded study of selected exemplars of doctoral submissions. The study seeks to make both a practical and strategic intervention in the ongoing 'making/writing', 'theory/practice' debate. It also seeks to clearly demonstrate how artist researchers have dealt with the academic requirements of the phd and how the production of a substantial written text (generally 30,000 words plus) showing a keen knowledge and criticality of the subject field has been achieved. The exemplars demonstrate both the distinctive and the normative character of the phd in fine art. However, the underpinning empirical research for the study (1996 - ) has also demonstrated the critical independence of such exemplars within the broader field of academic research. Through a brief analysis of three doctoral submissions selected from the study, the paper seeks to draw out some of the more important findings and their implications for the developing research culture. © nsead 2004.","","","2004","10.1111/j.1476-8070.2004.00394.x","","","scopus-2-s2.0-34249363259.pdf","scopus-2-s2.0-34249363259"
"Attitudes toward potential participant registries","Grill, J.d. And Holbrook, A. And Pierce, A. And Hoang, D. And Gillen, D.l.","Journal Of Alzheimer's Disease","","Difficult participant recruitment is a consistent barrier to successful medical research. Potential participant registries represent an increasingly common intervention to overcome this barrier. A variety of models for registries exist, but few data are available to instruct their design and implementation. To provide such data, we surveyed 110 cognitively normal research participants enrolled in a longitudinal study of aging and dementia. Seventy-four (67) individuals participated in the study. Most (78, ci: 0.67, 0.87) participants were likely to enroll in a registry. Willingness to participate was reduced for registries that required enrollment through the internet using a password (26, ci: 0.16, 0.36) or through email (38, ci: 0.27, 0.49). Respondents acknowledged their expectations that researchers share information about their health and risk for disease and their concerns that their data could be shared with for-profit companies. We found no difference in respondent preferences for registries that shared contact information with researchers, compared to honest broker models that take extra precautions to protect registrant confidentiality (28 versus 30;  p 0.46). Compared to those preferring a shared information model, respondents who preferred the honest broker model or who lacked model preference voiced increased concerns about sharing registrant data, especially with for-profit organizations. These results suggest that the design of potential participant registries may impact the population enrolled, and hence the population that will eventually be enrolled in clinical studies. Investigators operating registries may need to offer particular assurances about data security to maximize registry enrollment but also must carefully manage participant expectations. © 2017 - ios press and the authors. All rights reserved.","","","2017","10.3233/jad-160873","","","scopus-2-s2.0-85011593477.pdf","scopus-2-s2.0-85011593477"
"Essential items for reporting of scaling studies of health interventions (succeed): protocol for a systematic review and delphi process","Gogovor, A. And Zomahoun, H.t.v. And Ben Charif, A. And Mclean, R.k.d. And Moher, D. And Milat, A. And Wolfenden, L. And Prévost, K. And Aubin, E. And Rochon, P. And Ekanmian, G. And Sawadogo, J. And Rheault, N. And Légaré, F.","Systematic Reviews","","Background: the lack of a reporting guideline for scaling of evidence-based practices (ebps) studies has prompted the registration of the standards for reporting studies assessing the impact of scaling strategies of ebps (succeed) with equator network. The development of succeed will be guided by the following main steps recommended for developing health research reporting guidelines. Methods: executive committee. We established a committee composed of members of the core research team and of an advisory group. Systematic review. The protocol was registered with the open science framework on 29 november 2019 (https://osf.io/vcwfx/). We will include reporting guidelines or other reports that may include items relevant to studies assessing the impact of scaling strategies. We will search the following electronic databases: embase, psycinfo, cochrane library, cinahl, web of science, from inception. In addition, we will systematically search websites of equator and other relevant organizations. Experts in the field of reporting guidelines will also be contacted. Study selection and data extraction will be conducted independently by two reviewers. A narrative analysis will be conducted to compile a list of items for the delphi exercise. Consensus process. We will invite panelists with expertise in: development of relevant reporting guidelines, methodologists, content experts, patient/member of the public, implementers, journal editors, and funders. We anticipated that three rounds of web-based delphi consensus will be needed for an acceptable degree of agreement. We will use a 9-point scale (1 = extremely irrelevant to 9 = extremely relevant). Participants' response will be categorized as irrelevant (1-3), equivocal (4-6) and relevant (7-9). For each item, the consensus is reached if at least 80% of the participants' votes fall within the same category. The list of items from the final round will be discussed at face-to-face consensus meeting. Guideline validation. Participants will be authors of scaling studies. We will collect quantitative (questionnaire) and qualitative (semi-structured interview) data. Descriptive analyses will be conducted on quantitative data and constant comparative techniques on qualitative data. Discussion: essential items for reporting scaling studies will contribute to better reporting of scaling studies and facilitate the transparency and scaling of evidence-based health interventions. © 2020 the author(s).","","","2020","10.1186/s13643-019-1258-3","","","scopus-2-s2.0-85077765873.pdf","scopus-2-s2.0-85077765873"
"Reproducibility of research and statistical education with r markdown","Cuevas, H. And Solís, C.","Revista De Pedagogia","","The purpose of this study was to use r markdown as a teaching strategy to introduce reproducibility in a statistics course. A case study was proposed;  in which it was required the articulation of skills and knowledge from four disciplines. It was found that r markdown is a feasible option to implement in university classrooms due to its potential to reproduce research results in the teaching of statistics, though a representative proportion expressed reluctance to use it in other activities. It is advisable recommended to carry out experimental studies that include the use of a performance taxonomy, use of programming languagues in statistical analysis as a way to develop the critical thinking to the detriment of desiderative thinking and review alternative computational technologies. © 2018, universidad central de venezuela. All rights reserved.","","","2018","","","","scopus-2-s2.0-85071697577.pdf","scopus-2-s2.0-85071697577"
"Geoai training data：model，quality，and services","Yue, P. And Liu, R. And Shangguan, B. And Cao, Z. And Liu, S. And Xu, H.","Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics And Information Science Of Wuhan University","","The data-driven research paradigm brings a strong demand for training data sharing in geospatial artificial intelligence (geoai). The training data content and organization from different geoai applications are diverse. A unified information model will lay the foundation for geoai training data sharing and interoperability. By analyzing the common features and core attributes of different geoai training data, an information model for training data was proposed, and the training data quality elements and evaluation methods were explored. The results provide a reference for development of geoai training data stores and sharing services. © 2023 beijing institute of technology. All rights reserved.","","","2023","10.13203/j.whugis20230125","","","scopus-2-s2.0-85174483721.pdf","scopus-2-s2.0-85174483721"
"Your case will now be heard: sign language interpreters as problematic accommodations in legal interactions","Brunson J. L.","Journal of Deaf Studies & Deaf Education","","This paper uses data from open-ended videotaped interviews with 12 deaf people to examine their experiences negotiating access during interactions with legal authorities. In every case these deaf persons preferred an accommodation that involved the use of an American Sign Language interpreter and in every case these accommodations were problematic. Three major themes emerged from the informants' narratives: difficulty obtaining the desired accommodation dealing with a problematic accommodation and enduring a partial accommodation. These findings suggest that accommodations involving sign language interpreters are not neutral and transparent and that they often have tangible effects on the experiences of and outcomes for deaf persons in the context of dealing with legal matters. Deaf people have very little control over the accommodation they receive and yet are held fully responsible for ensuring its efficacy. These results are discussed in relation to policies and procedures for ensuring that deaf persons have full access in their interactions with American legal institutions.","","","2008","10.1093/deafed/enm032","","","medline-17595172.pdf","medline-17595172"
"Maximize transparency of clinical trial from trial registry to results disclosure. [Chinese]","Chen J. C.","Chinese Journal of New Drugs","","Clinical trial results disclosure and data sharing can fulfill the value of clinical trial. This paper introduce the history and current trends of the global clinical trial disclosure including the policies development of EMA FDA ICMJE and WHO. Given the advantage of the full transparency of clinical trial China should put more efforts on the clinical trial disclosure and improve the transparency of clinical trial such as the CFDA establish the related policies to guide the clinical trial results disclosure on official registry platform and the National Fund Committee enforce clinical data sharing as the requirement for the fund of academic clinical trials in order to further improve the transpareney of domestic clinical trials. Copyright © 2018 Chinese Journal of New Drugs Co. Ltd. All right reserved.","","","2018","","","","unknown-1281.pdf","unknown-1281"
"Exploring Dynamic Metabolome of the HepG2 Cell Line: Rise and Fall","Kiseleva O. I., Kurbatov I. Y., Arzumanian V. A., Ilgisonis E. V., Vakhrushev I. V., Lupatov A. Y., Ponomarenko E. A., Poverennaya E. V.","Cells","","Both biological and technical variations can discredit the reliability of obtained data in omics studies. In this technical note we investigated the effect of prolonged cultivation of the HepG2 hepatoma cell line on its metabolomic profile. Using the GC x GC-MS approach we determined the degree of metabolic variability across HepG2 cells cultured in uniform conditions for 0 5 10 15 and 20 days. Post-processing of obtained data revealed substantial changes in relative abundances of 110 metabolites among HepG2 samples under investigation. Our findings have implications for interpreting metabolomic results obtained from immortal cells especially in longitudinal studies. There are still plenty of unanswered questions regarding metabolomics variability and many potential areas for future targeted and panoramic research. However we suggest that the metabolome of cell lines is unstable and may undergo significant transformation over time even if the culture conditions remain the same. Considering metabolomics variability on a relatively long-term basis careful experimentation with particular attention to control samples is required to ensure reproducibility and relevance of the research results when testing both fundamentally and practically significant hypotheses.","","","2022","10.3390/cells11223548","","","medline-36428976.pdf","medline-36428976"
"A fingerprint based crypto-biometric system for secure communication","Dwivedi, R. And Dey, S. And Sharma, M.a. And Goel, A.","Journal Of Ambient Intelligence And Humanized Computing","","To maintain secrecy of information during communication, cryptography is considered to be an impressive solution and cryptographic keys play an important role to ensure the security. However, these randomly derived keys (of 256 bits) are hard to memorize. Also, there is a threat of privacy invasion since the storage, protection and transmission of a key over a communication link may lead to information leakage. Therefore, researchers propose to utilize user’s biometric trait to generate the cryptographic key in a session-based communication environment. This avoids the storage of cryptographic keys without negotiating on secrecy. The biometric-based key generation encompasses concerns over biometric template protection, biometric data sharing between users and revocable key generation from biometric. To address the aforementioned concerns, we propose a framework for secure communication between two users using a fingerprint-based crypto-biometric system. First, the feature bit-string are computed from the users’ fingerprint. Next, revocable transformation is applied to derive the private keys of respective users. Then, the diffie–hellman (dh) algorithm is used to generate public keys from private keys of both sender and receiver, which are shared and further used to produce a symmetric cryptographic key at both ends. Here, the biometric data is neither stored nor shared which ensures the security of biometric data. Also, perfect forward secrecy is achieved using session keys. This work also provides the long-term protection of messages communicated between two users. It is evident from the experimental evaluation over four datasets of fvc2002, four datasets of fvc 2004, and nist special database iv that the proposed framework is privacy-preserving and could be utilized for real access control systems. © 2019, springer-verlag gmbh germany, part of springer nature.","","","2020","10.1007/s12652-019-01437-5","","","scopus-2-s2.0-85073781336.pdf","scopus-2-s2.0-85073781336"
"Reporting trends in a regional medication error data-sharing system","Anderson J. G., Ramanujam R., Hensel D. J., Sirio C. A.","Health Care Management Science","","Inter-organizational systems for sharing data about medication errors have emerged as an important strategy for improving patient safety and are expected to encourage not only voluntary error reporting but also learning from errors. Yet few studies have examined the hypothesized benefits of inter-organizational data sharing. The current study examined the developmental trends in information reported by hospitals participating in a regional reporting system for medication errors. A coalition of hospitals in southwestern Pennsylvania under the auspices of the Pittsburgh Regional Healthcare Initiative (PRHI) implemented a voluntary system for quarterly sharing of information about medication errors. Over a 12-month period 25 hospitals shared information about 17000 medication errors. Using latent growth curve analysis we examined longitudinal trends in the quarterly number of errors and associated corrective actions reported by each hospital. Controlling for size teaching status and JCAHO accreditation score for the hospitals as a group error reporting increased at a statistically significant rate over the four quarters. Moreover despite significant baseline differences among hospitals error reporting increased at similar rates across hospitals over subsequent quarters. In contrast the reporting of corrective actions remained unchanged. However the baseline levels of corrective actions reporting were significantly different across hospitals. Although data sharing systems promote error reporting it is unclear whether they encourage corrective actions. If data sharing is intended to promote not just error reporting but also root-cause-analysis and process improvement then the design of the reporting system should emphasize data about these processes as well as errors.","","","2010","10.1007/s10729-009-9111-1","","","medline-20402284.pdf","medline-20402284"
"Hybridisation within brassica and allied genera: evaluation of potential for transgene escape","Fitzjohn, R.g. And Armstrong, T.t. And Newstrom-Lloyd, L.e. And Wilton, A.d. And Cochrane, M.","Euphytica","","Determining the potential for hybridisation between transgenic crops and their relatives is a major component of risk assessment. Recent assessments of the extent of reproductive compatibility between crops and their relatives draw heavily on existing data from experimental crosses to infer the likelihood of hybridisation and introgression. Since the literature in this area continues to grow at a rapid pace, it is essential that such analyses can be easily updated. We used a database approach to assemble data on reproductive compatibility for eight crop species in brassica, raphanus and sinapis, using data from hand pollination, spontaneous (unassisted) pollination and trials using in vitro techniques (e.g. embryo rescue), incorporating 326 studies and 216 species combinations. We found many reports for major crop species (b. juncea, b. napus, b. oleracea and b. rapa), but fewer for minor crops (b. carinata, b. nigra, raphanus sativus and sinapis alba). Many species combinations remain untested, and we highlight these information gaps. While reproductively incompatible species can be discounted as targets for transgene escape, compatible species must be evaluated further in the particular context where transgenic crops are grown. Because the data is retained in a database in a relatively unmodified form, multiple views of the data can be generated;  this review represents one possible view of this data. Our approach also allows new data to be easily incorporated into future reanalyses and can be extended to other crop groups, and as such is a useful method of assembling, analysing and sharing data for risk assessment. © 2007 springer science+business media b.v.","","","2007","10.1007/s10681-007-9444-0","","","scopus-2-s2.0-35348822717.pdf","scopus-2-s2.0-35348822717"
"A Novel Model to Generate Heterogeneous and Realistic Time-Series Data for Post-Stroke Rehabilitation Assessment","Boukhennoufa I., Jarchi D., Zhai X., Utti V., Sanei S., Lee T. K. M., Jackson J., McDonald-Maier K. D.","IEEE Transactions on Neural Systems & Rehabilitation Engineering","","The application of machine learning-based tele-rehabilitation faces the challenge of limited availability of data. To overcome this challenge data augmentation techniques are commonly employed to generate synthetic data that reflect the configurations of real data. One such promising data augmentation technique is the Generative Adversarial Network (GAN). However GANs have been found to suffer from mode collapse a common issue where the generated data fails to capture all the relevant information from the original dataset. In this paper we aim to address the problem of mode collapse in GAN-based data augmentation techniques for post-stroke assessment. We applied the GAN to generate synthetic data for two post-stroke rehabilitation datasets and observed that the original GAN suffered from mode collapse as expected. To address this issue we propose a Time Series Siamese GAN (TS-SGAN) that incorporates a Siamese network and an additional discriminator. Our analysis using the longest common sub-sequence (LCSS) demonstrates that TS-SGAN generates data uniformly for all elements of two testing datasets in contrast to the original GAN. To further evaluate the effectiveness of TS-SGAN we encode the generated dataset into images using Gramian Angular Field and classify them using ResNet-18. Our results show that TS-SGAN achieves a significant accuracy increase of classification accuracy (35.2%-42.07%) for both selected datasets. This represents a substantial improvement over the original GAN.","","","2023","10.1109/tnsre.2023.3283045","","","medline-37276101.pdf","medline-37276101"
"Verifying rigor: analyzing qualitative research in international marketing","Singh, N. And Benmamoun, M. And Meyr, E. And Arikan, R.h.","International Marketing Review","","Purpose: there has been a growing call regarding broad criteria for assessing qualitative methods' reliability and validity in international marketing (im) research. In response, this study synthesizes the past literature to present an overarching, yet adaptable, trustworthiness verification framework for assessing the rigor of various qualitative methods used in im. Design/methodology/approach: the paper draws on qualitative research from various disciplines. It uses content analysis to examine how trustworthiness is conceptualized in qualitative studies in international marketing review (imr) from 2005 to 2019. Findings: the analysis reveals that strategies to ensure rigor and trustworthiness of qualitative research in imr are partially applied. There remain gaps in implementing quality criteria across the trustworthiness dimensions of credibility, transferability, dependability, conformability and ethics. Research limitations/implications: this paper highlights the importance of incorporating strategies for assessing the quality of qualitative research in im research. Since the analysis only focused on imr, future research should explore and test the framework in other im and business journals to reach a broader consensus in assessing qualitative studies' rigor. Originality/value: im researchers have yet to develop a consensus regarding broad criteria for assessing qualitative methods' reliability and validity. This paper is an attempt to fill this gap. © 2021, emerald publishing limited.","","","2021","10.1108/imr-03-2020-0040","","","scopus-2-s2.0-85112217650.pdf","scopus-2-s2.0-85112217650"
"Patient data and patient rights: swiss healthcare stakeholders' ethical awareness regarding large patient data sets - a qualitative study","Mouton Dorey, C. And Baumann, H. And Biller-Andorno, N.","Bmc Medical Ethics","","Background: there is a growing interest in aggregating more biomedical and patient data into large health data sets for research and public benefits. However, collecting and processing patient data raises new ethical issues regarding patient's rights, social justice and trust in public institutions. The aim of this empirical study is to gain an in-depth understanding of the awareness of possible ethical risks and corresponding obligations among those who are involved in projects using patient data, i.e. healthcare professionals, regulators and policy makers. Methods: we used a qualitative design to examine swiss healthcare stakeholders' experiences and perceptions of ethical challenges with regard to patient data in real-life settings where clinical registries are sponsored, created and/or used. A semi-structured interview was carried out with 22 participants (11 physicians, 7 policy-makers, 4 ethical committee members) between july 2014 and january 2015. The interviews were audio-recorded, transcribed, coded and analysed using a thematic method derived from grounded theory. Results: all interviewees were concerned as a matter of priority with the needs of legal and operating norms for the collection and use of data, whereas less interest was shown in issues regarding patient agency, the need for reciprocity, and shared governance in the management and use of clinical registries' patient data. This observed asymmetry highlights a possible tension between public and research interests on the one hand, and the recognition of patients' rights and citizens' involvement on the other. Conclusions: the advocation of further health-related data sharing on the grounds of research and public interest, without due regard for the perspective of patients and donors, could run the risk of fostering distrust towards healthcare data collections. Ultimately, this could diminish the expected social benefits. However, rather than setting patient rights against public interest, new ethical approaches could strengthen both concurrently. On a normative level, this study thus provides material from which to develop further ethical reflection towards a more cooperative approach involving patients and citizens in the governance of their health-related big data. © 2018 the author(s).","","","2018","10.1186/s12910-018-0261-x","","","scopus-2-s2.0-85043249366.pdf","scopus-2-s2.0-85043249366"
"An open web-based module developed to advance data-driven hydrologic process learning","Lane, B. And Garousi-Nejad, I. And Gallagher, M.a. And Tarboton, D.g. And Habib, E.","Hydrological Processes","","The era of ‘big data’ promises to provide new hydrologic insights, and open web-based platforms are being developed and adopted by the hydrologic science community to harness these datasets and data services. This shift accompanies advances in hydrology education and the growth of web-based hydrology learning modules, but their capacity to utilize emerging open platforms and data services to enhance student learning through data-driven activities remains largely untapped. Given that generic equations may not easily translate into local or regional solutions, teaching students to explore how well models or equations work in particular settings or to answer specific problems using real data is essential. This article introduces an open web-based module developed to advance data-driven hydrologic process learning, targeting upper level undergraduate and early graduate students in hydrology and engineering. The module was developed and deployed on the hydrolearn open educational platform, which provides a formal pedagogical structure for developing effective problem-based learning activities. We found that data-driven learning activities utilizing collaborative open web platforms like cuahsi hydroshare and jupyterhub to store and run computational notebooks allowed students to access and work with datasets for systems of personal interest and promoted critical evaluation of results and assumptions. Initial student feedback was generally positive, but also highlighted challenges including trouble-shooting and future-proofing difficulties and some resistance to programming and new software. Opportunities to further enhance hydrology learning include better articulating the benefits of coding and open web platforms upfront, incorporating additional user-support tools, and focusing methods and questions on implementing and adapting notebooks to explore fundamental processes rather than tools and syntax. The profound shift in the field of hydrology toward big data, open data services and reproducible research practices requires hydrology instructors to rethink traditional content delivery and focus instruction on harnessing these datasets and practices in the preparation of future hydrologists and engineers. © 2021 the authors. Hydrological processes published by john wiley & sons ltd.","","","2021","10.1002/hyp.14273","","","scopus-2-s2.0-85111375087.pdf","scopus-2-s2.0-85111375087"
"Data trusted sharing delivery: a blockchain-assisted software-defined content delivery network","Shao, S. And Gong, W. And Yang, H. And Guo, S. And Chen, L. And Xiong, A.","Ieee Internet Of Things Journal","","The 6g wireless network aims to forge a new spectrum, high technical standards of high time and phase synchronization accuracy, and 100% geographic coverage to connect trillions of devices flexibly and efficiently in the future. However, as connectivity increases and applications become novel, it is a challenge to ensure the privacy and security of networks and applications. Blockchain is seen as a promising technology that can improve efficiency, reduce costs, mitigate security, and privacy threats, and establish a trusted data-sharing environment. This article presents a trusted framework based on blockchain technology from the perspective of how to build a trusted software-defined content delivery network. As the peer node of the blockchain, the software-defined network (sdn) controller establishes trust between different regions and a wide range of participants, realizing peer autonomy and flexible business orchestration. The two main purposes of the architecture are to enhance the security of network communications and establish trust relationships between entities in different domains. It includes trusted communication based on routing sandbox, service choreography based on blockchain, proxy server selection strategy based on model predictive control (mpc), and optimization consensus based on practical byzantine fault tolerance. Some simulation experiments verify the effectiveness of the theoretical method. © 2014 ieee.","","","2023","10.1109/jiot.2021.3124091","","","scopus-2-s2.0-85118570315.pdf","scopus-2-s2.0-85118570315"
"Framework for enterprise gis for saudi municipalities","Abdulaal, W.a.","International Journal Of Geographical Information Science","","Municipalities in saudi arabia are working hard to make use of rapid advances in information technology (it), especially geographic information systems (gis), to improve their performance and increase their effectiveness. Most initiatives in it applications, including gis, are limited to individual departments rather than supporting comprehensive institutional operations. This has resulted in fragmented applications with isolated databases. It is obvious that the municipalities lack an overall framework to guide them through building reliable it solutions that care for enterprise or corporate requirements. Because the saudi municipalities share many commonalities, especially among their business functions and organi- zational structures, it is believed that a general framework is necessary to help them to develop their it solutions in general and gis applications in particular, because the majority of municipal decisions are spatially oriented. This article attempts to provide a framework for enterprise gis for saudi municipalities. It starts by reviewing the important issues associated with enterprise gis to establish the basis for building a framework that is suitable for the saudi context. The proposed gis framework emphasizes the enterprise requirements for municipal institutions and considers gis as a major it requirement that can be supported by other related technologies. The suggested framework includes three main factors: business functions, tasks and data requirements. The integration of these factors provides the basis on which the municipalities can advance their aim of automating their functions. Discussion of these factors within saudi context is presented with reference to the municipality of jeddah where data were based upon interviews with key municipal officials in 2004. The main finding of this research article is the identification of municipal functions and tasks that pave the way for determining applications required for the corporate it solution. Furthermore, this article identifies data issues related to municipal data -sources, sharing and management - and calls for establishing a unified municipal data model. Finally, this article suggests that similarities among saudi municipalities lead us to believe that it applications can grow reasonably well by partnership among municipalities. © 2009 taylor & francis.","","","2009","10.1080/13658810701378838","","","scopus-2-s2.0-70449384410.pdf","scopus-2-s2.0-70449384410"
"Research on the relationship between shared leadership and individual creativity-qualitative comparative analysis on the basis of clear set","Sun, M. And Wang, J. And Wen, T.","Sustainability (Switzerland)","","Creativity is the key to obtaining and maintaining competitiveness of modern organizations, and it has attracted much attention from academic circles and management practices. Shared leadership is believed to effectively influence team output. However, research on the impact of individual creativity is still in its infancy. This study adopts the qualitative comparative analysis method, taking 1584 individuals as the research objects, underpinned by a questionnaire-based survey. It investigates the influence of the team’s shared leadership network elements and organizational environmental factors on the individual creativity. We have found that there are six combination of conditions of shared leadership and organizational environmental factors constituting sufficient combination of conditions to increase or decrease individual creativity. Moreover, we have noticed that the low network density of shared leadership is a sufficient and necessary condition of reducing individual creativity. Our results also provide management suggestions for practical activities during the team management. © 2021 by the authors. Licensee mdpi, basel, switzerland.","","","2021","10.3390/su13105445","","","scopus-2-s2.0-85106626149.pdf","scopus-2-s2.0-85106626149"
"Climate change by the numbers: leveraging mathematical skills for science learning online","Thacker, I.","Learning And Instruction","","The purpose of this preregistered study was to test an online intervention that presents participants with novel numbers about climate change after they estimate those numbers. An experimental study design was used to investigate the impact of the intervention on undergraduate students’ climate change understanding and perceptions that human caused climate change is plausible. Findings revealed that posttest climate change knowledge and plausibility perceptions were higher among those randomly assigned to use the intervention compared with those assigned to a control condition, and that supplementing this experience with numeracy instruction was linked with the use of more explicit estimation strategies and greater learning gains for people with adaptive epistemic dispositions. Findings from this study replicate and extend prior research, support the idea that novel data can support knowledge revision, identify estimation strategies used in this context, and offer an open-source online intervention for sharing surprising data with students and teachers. © 2023 elsevier ltd","","","2023","10.1016/j.learninstruc.2023.101782","","","scopus-2-s2.0-85156184014.pdf","scopus-2-s2.0-85156184014"
"Bootstrapping in applied linguistics: assessing its potential using shared data","Plonsky, L. And Egbert, J. And Laflair, G.t.","Applied Linguistics","","Parametric analyses such as t tests and anovas are the norm - if not the default - statistical tests found in quantitative applied linguistics research (gass 2009). Applied statisticians and one applied linguist (larson-hall 2010, 2012;  larson-hall and herrington 2010), however, have argued that this approach may not be appropriate for small samples and/or nonnormally distributed data (e.g. Wilcox 2003), both common in second language (l2) research. They recommend instead 'robust statistics' such as bootstrapping, a nonparametric procedure that randomly resamples from an observed data set to produce a simulated but more stable and statistically accurate outcome. The present study tests the usefulness of bootstrapping by reanalyzing raw data from 26 studies of applied linguistics research. Our results found no evidence of type ii error (false negative). However, 4 out of 16 statistically significant results were not replicated (i.e. a type i error 'misfit' five times higher than an alpha of. 05). We discuss empirically justified suggestions for the use of bootstrapping in the context of broader methodological issues and reforms in applied linguistics (see plonsky 2013, 2014). © 2014 oxford university press 2014.","","","2015","10.1093/applin/amu001","","","scopus-2-s2.0-84894096224.pdf","scopus-2-s2.0-84894096224"
"Multi-task reinforcement learning in partially observable stochastic environments","Li, H. And Liao, X. And Carin, L.","Journal Of Machine Learning Research","","We consider the problem of multi-task reinforcement learning (mtrl) in multiple partially observable stochastic environments. We introduce the regionalized policy representation (rpr) to characterize the agent's behavior in each environment. The rpr is a parametric model of the conditional distribution over current actions given the history of past actions and observations;  the agent's choice of actions is directly based on this conditional distribution, without an intervening model to characterize the environment itself. We propose off-policy batch algorithms to learn the parameters of the rprs, using episodic data collected when following a behavior policy, and show their linkage to policy iteration. We employ the dirichlet process as a nonparametric prior over the rprs across multiple environments. The intrinsic clustering property of the dirichlet process imposes sharing of episodes among similar environments, which effectively reduces the number of episodes required for learning a good policy in each environment, when data sharing is appropriate. The number of distinct rprs and the associated clusters (the sharing patterns) are automatically discovered by exploiting the episodic data as well as the nonparametric nature of the dirichlet process. We demonstrate the effectiveness of the proposed rpr as well as the rpr-based mtrl framework on various problems, including grid-world navigation and multi-aspect target classification. The experimental results show that the rpr is a competitive reinforcement learning algorithm in partially observable domains, and the mtrl consistently achieves better performance than single task reinforcement learning. © 2009 hui li, xuejun liao and lawrence carin.","","","2009","","","","scopus-2-s2.0-66849131425.pdf","scopus-2-s2.0-66849131425"
"Dynamic proof of data possession and replication with tree sharing and batch verification in the cloud","Guo, W. And Qin, S. And Gao, F. And Zhang, H. And Li, W. And Jin, Z. And Wen, Q.","Ieee Transactions On Services Computing","","Cloud storage attracts a lot of clients to join the paradise. For a high data availability, some clients require their files to be replicated and stored on multiple servers. Because clients are generally charged based on the redundancy level required by them, it is critical for clients to obtain convincing evidence that all replicas are stored correctly and are updated to the up-to-date version. In this article, we propose a dynamic proof of data possession and replication (dpdpr) scheme, which is proved to be secure in the defined security model. Our scheme shares a single authenticated tree across multiple replicas, which reduces the tree's storage cost significantly. Our scheme allows for batch verification for multiple challenged leaves and can verify multiple replicas in a single batch way, which considerably save bandwidth and computation resources during audit process. We also evaluate the dpdpr's performance and compare it with the most related scheme. The evaluation results show that our scheme saves almost 66 percent tree's storage cost for three replicas, and obtains almost 60 and 80 percent efficiency improvements in terms of the overall bandwidth and computation costs, respectively, when three replicas are checked and each challenged with 460 blocks. © 2022 ieee.","","","2022","10.1109/tsc.2020.3022812","","","scopus-2-s2.0-85090986445.pdf","scopus-2-s2.0-85090986445"
"Registration of phase 3 crossover trials on clinicaltrials.gov","Zeng, L. And Qureshi, R. And Viswanathan, S. And Drye, L. And Li, T.","Trials","","Background: in a randomized crossover trial, each participant is randomized to a sequence of treatments and treatment effect is estimated based on within-individual difference because each participant serves as his/her own control. This feature makes the design and reporting of randomized crossover trials different from that of parallel trials. Our objective was to characterize phase 3 crossover trials with results reported on clinicaltrials.gov and identify issues and best practices for reporting. Methods: we searched clinicaltrials.gov for phase 3 randomized crossover trials that provided results, registered at least one primary outcome, and included at least one link to a results publication in the record by august 6, 2019. Two reviewers independently assessed the eligibility and extracted information from each record into an electronic form developed and maintained in the systematic review data repository. Results: of the 124 crossover trials analyzed, two thirds were a simple ""intervention a then b""or ""intervention b then a""(ab|ba) design. Most trials (78%, 97/124) provided enough information to understand the participant flow throughout the trial. Baseline characteristics were most often reported for all participants as a single group (52%, 65/124). Primary outcomes and adverse events were most commonly reported ""per intervention""(85%, 105/124, and 80%, 99/124, respectively). Conclusions: the registration and reporting of randomized crossover trials must account for the paired nature of the design. Our observations and recommendations informed the development of guidelines for good reporting practices in the registration and reporting of randomized crossover trials. © 2020 the author(s).","","","2020","10.1186/s13063-020-04545-2","","","scopus-2-s2.0-85087701230.pdf","scopus-2-s2.0-85087701230"
"Risk of bias in observational studies using routinely collected data of comparative effectiveness research: a meta-research study","Nguyen, V.t. And Engleton, M. And Davison, M. And Ravaud, P. And Porcher, R. And Boutron, I.","Bmc Medicine","","Background: to assess the completeness of reporting, research transparency practices, and risk of selection and immortal bias in observational studies using routinely collected data for comparative effectiveness research. Method: we performed a meta-research study by searching pubmed for comparative effectiveness observational studies evaluating therapeutic interventions using routinely collected data published in high impact factor journals from 01/06/2018 to 30/06/2020. We assessed the reporting of the study design (i.e., eligibility, treatment assignment, and the start of follow-up). The risk of selection bias and immortal time bias was determined by assessing if the time of eligibility, the treatment assignment, and the start of follow-up were synchronized to mimic the randomization following the target trial emulation framework. Result: seventy-seven articles were identified. Most studies evaluated pharmacological treatments (69%) with a median sample size of 24,000 individuals. In total, 20% of articles inadequately reported essential information of the study design. One-third of the articles (n = 25, 33%) raised some concerns because of unclear reporting (n = 6, 8%) or were at high risk of selection bias and/or immortal time bias (n = 19, 25%). Only five articles (25%) described a solution to mitigate these biases. Six articles (31%) discussed these biases in the limitations section. Conclusion: reporting of essential information of study design in observational studies remained suboptimal. Selection bias and immortal time bias were common methodological issues that researchers and physicians should be aware of when interpreting the results of observational studies using routinely collected data. © 2021, the author(s).","","","2021","10.1186/s12916-021-02151-w","","","scopus-2-s2.0-85119687130.pdf","scopus-2-s2.0-85119687130"
"Endotoxin removal: how far from the evidence? The EUPHAS 2 Project","Martin E. L., Cruz D. N., Monti G., Casella G., Vesconi S., Ranieri V. M., Ronco C., Antonelli M.","Contributions to Nephrology","","Since 1994 a polystyrene fiber cartridge used for extracorporeal hemoperfusion to which polymyxin B is bound and immobilized has been used in septic patients in order to absorb and remove circulating lipopolysaccharide thereby neutralizing the effects of this endotoxin. This therapy gradually gained acceptance as the amount of evidence increased from initial small clinical studies to a carefully conducted systematic review and ultimately to the multicentered randomized clinical trial conducted in Italy entitled the EUPHAS Study (Early Use of Polymyxin B Hemoperfusion in Abdominal Septic Shock). While the conclusions of this initial randomized controlled trial were in agreement with previous studies it possessed some important limitations including a slow accrual rate enrolling only 64 patients between 2004 and 2007 inability to blind treating physicians and a premature study termination based on the results of the scheduled interim analysis. These limitations resulted in a modest patient sample size which may have overestimated the true magnitude of the clinical effect. Apart from Japan Italy is the current primary user of polymyxin B-hemoperfusion in the treatment of sepsis with about 600 cartridges being used per year. However no structured collection of data has been attempted resulting in the an opportunity to understand the effects of polymyxin B-hemoperfusion on a large diverse sample size. In response Italian investigators and users of this treatment have designed a new prospective multicentered collaborative data collection study entitled EUPHAS 2. The aim of the EUPHAS 2 project is to collect a large database regarding polymyxin B-hemoperfusion treatments in order to better evaluate the efficacy and biological significance of endotoxin removal in clinical practice. Additionally this study aims to verify the reproducibility of the data currently available in the literature evaluate the patient population chosen for treatment and identify subpopulations of patients who may benefit from this treatment more than others. Copyright 2010 S. Karger AG Basel.","","","2010","10.1159/000315926","","","medline-20519906.pdf","medline-20519906"
"The use of systematic reviews and reporting guidelines to advance the implementation of the 3Rs","Avey M. T., Fenwick N., Griffin G.","Journal of the American Association for Laboratory Animal Science: JAALAS","","In 1959 Russell and Burch published The Principles of Humane Experimental Technique which included concrete advice on factors that they considered would govern progress in the implementation of these principles (enunciated as the 3Rs [Replacement Reduction and Refinement in animal-based studies]). One challenge to the implementation of the 3Rs was identified as information retrieval. Here we further explore this challenge-the need for 'research on research'-and the role that systematic reviews and reporting guidelines can play in implementation of the 3Rs. First we examine the 2-fold nature of the challenge of information retrieval: 1) the identification of relevant publications spread throughout a large population of nonrelevant publications and 2) the incomplete reporting of relevant details within those publications. Second we evaluate how systematic reviews and reporting guidelines can be used generally to address this challenge. Third we assess the explicit reporting of the 3Rs in a cohort of preclinical animal systematic reviews. Our results show that Reduction methods are the most commonly reported by authors of systematic reviews but that in general reporting on how findings relate to the 3Rs is limited at best. Although systematic reviews are excellent tools for resolving the challenge of information retrieval their utility for making progress in implementation of the 3Rs may be limited unless authors improve their reporting of these principles.","","","2015","","","","medline-25836961.pdf","medline-25836961"
"The effects of specialized treatment on the recidivism of juvenile sex offenders: a systematic review and meta-analysis","Kettrey, H.h. And Lipsey, M.w.","Journal Of Experimental Criminology","","Objectives: specialized treatment programs for juvenile sex offenders (jsos) are commonly used in juvenile justice systems. Despite their popularity, the evidence base for the effectiveness of these specialized programs is limited in both scope and quality. This systematic review and meta-analysis updates previous meta-analyses while focusing on studies of relatively high methodological quality. Methods: a vigorous literature search guided by explicit inclusion criteria was conducted. Descriptive and statistical information for each eligible study was coded independently by two coders and disagreements resolved by consensus. Odds ratio effect sizes were computed for sexual recidivism and general recidivism outcomes. Mean effect sizes and their heterogeneity were examined with both fixed and random effects meta-analysis. Results: only eight eligible studies were located, seven of which were quasi-experiments. The mean effect size for the seven studies reporting sexual recidivism favored treatment but was not statistically significant (or = 0.74, 95% ci 0.40, 1.36). The mean effect size for general recidivism was significant and also favored treatment (or = 0.58, 95% ci 0.42, 0.81). Conclusions: remarkably little methodologically credible research has been conducted on specialized programs for jsos despite their prevalence. The best available evidence does not support a confident conclusion that they are more effective for reducing sexual recidivism than general treatment as usual in juvenile justice systems. Future research should not only use randomized designs but should also distinguish generalist offenders who are at low risk of sexual recidivism from specialist offenders who are at higher risk of committing future sexual offenses. © 2018, springer science+business media b.v., part of springer nature.","","","2018","10.1007/s11292-018-9329-3","","","scopus-2-s2.0-85046700805.pdf","scopus-2-s2.0-85046700805"
"Certificateless searchable public key encryption scheme for industrial internet of things","Ma, M. And He, D. And Kumar, N. And Choo, K.-K.r. And Chen, J.","Ieee Transactions On Industrial Informatics","","With the widespread adoption of internet of things and cloud computing in different industry sectors, an increasing number of individuals or organizations are outsourcing their industrial internet of things (iiot) data in the cloud server to achieve cost saving and collaboration (e.g., data sharing). However, in this environment, preserving the privacy of data remains a key challenge and inhibiting factor to an even wider adoption of iiot in the cloud environment. To mitigate these issues, in this paper, we design a new secure channel-free certificateless searchable public key encryption with multiple keywords scheme for iiot deployment. We then demonstrate the security of the scheme in the random oracle model against two types of adversaries, where one adversary is given the power to choose a random public key instead of any user's public key and another adversary is allowed to learn the system master key. In the presence of these types of adversaries, we evaluate the performance of the proposed scheme and demonstrate that it achieves (computational) efficiency with low communication cost. © 2017 ieee.","","","2018","10.1109/tii.2017.2703922","","","scopus-2-s2.0-85039853169.pdf","scopus-2-s2.0-85039853169"
"Improving alumni survey response rates: an experiment and cost-benefit analysis","Smith, K. And Bers, T.","Research In Higher Education","","Mail surveys are frequently used in higher education research as a means of collecting data relevant for college decision makers. Despite their prevalence, mail surveys have drawbacks, chief among them the potential for low response rates, which may compromise the credibility of research results and diminish their usefulness. Therefore, it is important for institutional researchers to plan and conduct mail surveys that achieve optimal response rates, especially in populations (i.e., alumni) where low response rates may be a problem. This research tested the effect of the survey procedures suggested by dillman's (1978) total design method on response rate to a mail survey of two-year college alumni. The method used was an experiment with four groups that varied in their degree of adherence to dillman's procedures, i.e., amount of follow-up and degree of personalized approach. Subjects were randomly assigned to groups. Results provided a test of dillman's techniques in an educational setting, further information for institutional researchers about ways to improve response rates, and an analysis of the costs and benefits of using dillman's methods. © 1987 agathon press, inc.","","","1987","10.1007/bf00991999","","","scopus-2-s2.0-0010854586.pdf","scopus-2-s2.0-0010854586"
"A plea for consistency in the reporting of surgical series illustrated with an analysis of 51 follow-up reports of pulmonary metastasectomy in colorectal carcinoma","Fiorentino, F. And Treasure, T.","Journal Of Thoracic Oncology","","The data contained in the follow-up studies of surgical series should ideally be reported in such a way that they are comparable from one follow-up study to another and amenable to amalgamation to draw statistically robust inferences. The authors provide an analysis of 51 reports of pulmonary metastasectomy for colorectal cancer to illustrate the problem. It is in the nature of follow-up studies that data are more plentiful where they concern explicit descriptors of the patient when assessed for surgery and the conduct of the operation itself. Data may be sparse in other respects, because although of interest in a subsequent analysis of outcome, they were not of direct clinical importance at the time of surgery and so were not recorded. The authors cannot surmise about unrecorded data or use them in any analysis. The authors constructed a ""wish-list"" of items and tested the 51 publications against it. They also suggest that the form in which data are presented should include data summaries, which can be amalgamated. For example, means can be aggregated, provided the numerator is known, but medians cannot. In an ideal world, anonymized patient-level data should be retained and remain accessible for future researchers, but there are substantial obstacles for saving and sharing data of this kind. A check list for reports of pulmonary metastasectomy series is offered as a template. Copyright © 2010 by the international association for the study of lung cancer.","","","2010","10.1097/jto.0b013e3181dca351","","","scopus-2-s2.0-77953175713.pdf","scopus-2-s2.0-77953175713"
"Learners’ english vocabulary knowledge prior to formal instruction: the role of learner-related and word-related variables","Puimège, E. And Peters, E.","Language Learning","","This study focused on the mechanisms underlying incidental second language (l2) vocabulary acquisition prior to formal instruction. We designed a cross-sectional study to examine which learner-related and word-related variables affect young learners’ vocabulary knowledge at the level of meaning recognition and meaning recall. We collected data from 616 flemish children between 10 and 12 years old by using a questionnaire about learners’ extramural english, an english vocabulary test, and a dutch vocabulary test. The findings revealed that participating learners frequently engaged in activities involving english before receiving formal instruction and that their amount of extramural english increased with age. The results also showed the rate of vocabulary growth from exposure to extramural english for three contiguous age groups. Further, both word-related and learner-related variables predicted vocabulary knowledge. Cognateness was the most powerful predictor, followed by frequency and concreteness. We also found a positive relationship between extramural english and vocabulary knowledge. Open practices: this article has been awarded an open materials badge. All materials are publicly accessible via the iris repository at https://www.iris-database.org. Learn more about the open practices badges from the center for open science: https://osf.io/tvyxz/wiki. © 2019 language learning research club, university of michigan","","","2019","10.1111/lang.12364","","","scopus-2-s2.0-85066916083.pdf","scopus-2-s2.0-85066916083"
"An independent evaluation of the Lens Opacities Classification System II (LOCS II). The Italian-American Cataract Study Group","Maraini G., Pasquini P., Tomba M. C., Bonacini M., Stazi M. A., Rosmini F., Sperduto R. D.","Ophthalmology","","The Lens Opacities Classification System II (LOCS II) has been offered for use in clinical studies of cataract. The system uses slit lamp and retroillumination photographic standards to grade lens opacities into classes of increasing severity. The authors evaluated the reproducibility and validity of LOCS II before its possible use in a natural history study of age-related cataract. The authors found excellent inter- and intraobserver reproducibility when the LOCS II standard photographs were used for clinical or photographic gradings of cataract. There was a tendency to underestimate posterior subcapsular cataracts on photographic gradings compared with slit-lamp gradings. The accuracy of the photographic gradings of posterior subcapsular opacities tended to decrease as the severity of coexisting opacities increased.","","","1989","10.1016/s0161-6420(89)32841-7","","","medline-2748117.pdf","medline-2748117"
"Policy-driven monitoring and evaluation: Does it support adaptive management of socio-ecological systems?","Waylen K. A., Blackstock K. L., van Hulst F. J., Damian C., Horvath F., Johnson R. K., Kanka R., Kulvik M., Macleod C. J. A., Meissner K., Oprina-Pavelescu M. M., Pino J., Primmer E., Risnoveanu G., Satalova B., Silander J., Spulerova J., Suskevics M., Van Uytvanck J.","Science of the Total Environment","","Inadequate Monitoring and Evaluation (M&E) is often thought to hinder adaptive management of socio-ecological systems. A key influence on environmental management practices are environmental policies: however their consequences for M&E practices have not been well-examined. We examine three policy areas - the Water Framework Directive the Natura 2000 Directives and the Agri-Environment Schemes of the Common Agricultural Policy - whose statutory requirements influence how the environment is managed and monitored across Europe. We use a comparative approach to examine what is monitored how monitoring is carried out and how results are used to update management based on publicly available documentation across nine regional and national cases. The requirements and guidelines of these policies have provided significant impetus for monitoring: however we find this policy-driven M&E usually does not match the ideals of what is needed to inform adaptive management. There is a tendency to focus on understanding state and trends rather than tracking the effect of interventions; a focus on specific biotic and abiotic indicators at the expense of understanding system functions and processes especially social components; and limited attention to how context affects systems though this is sometimes considered via secondary data. The resulting data are sometimes publicly-accessible but it is rarely clear if and how these influence decisions at any level whether this be in the original policy itself or at the level of measures such as site management plans. Adjustments to policy-driven M&E could better enable learning for adaptive management by reconsidering what supports a balanced understanding of socio-ecological systems and decision-making. Useful strategies include making more use of secondary data and more transparency in data-sharing and decision-making. Several countries and policy areas already offer useful examples. Such changes are essential given the influence of policy and the urgency of enabling adaptive management to safeguard socio-ecological systems.","","","2019","10.1016/j.scitotenv.2018.12.462","","","pubmed-30690371.pdf","pubmed-30690371"
"Mining writing center data for information literacy practices","Graves, S.j. And Anders, K.c. And Balester, V.m.","Reference Services Review","","Purpose: the study aims to explore collaborations between writing centers and libraries which create opportunities for providing information literacy intervention for students doing researched writing. This case study gathered data from writing center logs to uncover if and how information literacy activity was occurring during consultations. Design/methodology/approach: a representative sample of writing center logs recorded between september of 2013 and may 2014 was mined for frequencies of library and information literacy terms. Transaction logs were coded and analyzed according to the frames in the association of college and research libraries framework for information literacy for higher education. Findings: information literacy is discussed in only 13 per cent of consultations. Referrals to librarians accounted for less than 1 per cent of all transactions. Students most commonly asked for assistance in formatting citations, but deeper information literacy conversations did occur that provide opportunities for engagement with the framework for information literacy for higher education. Research limitations/implications: transactions were examined from one university. Although findings cannot be generalized, the results were applicable to local services, and this study provides a model useful for libraries and writing centers. Practical implications: this study provides ample direction for future collaborations that will take advantage of the intersections of information literacy and writing instruction to improve student research skills. Originality/value: although much has been written about partnerships between libraries and writing centers, this study uniquely demonstrates a model for data sharing across institutional boundaries and how one library mined existing data from a writing center. © 2017, © emerald publishing limited.","","","2017","10.1108/rsr-07-2016-0043","","","scopus-2-s2.0-85013031087.pdf","scopus-2-s2.0-85013031087"
"Protocol for the development of a reporting guideline for clinical trials with integrated Chinese and western medicine interventions: the CONSORT extension for ICWM","Wang J., Zhang X., Wang P., Han F., Li J., Ma Y., Lyu A., Bian Z.","Frontiers in Medicine","","Background: While Integrated Chinese and Western Medicine (ICWM) has become widely accepted as a necessary intervention for treating various diseases key information about ICWM interventions is often missing in published clinical trials. To facilitate complete transparent and consistent reporting of clinical trials with ICWM interventions an extension of the CONSORT guideline is necessary to be developed: the CONSORT-ICWM guideline.\\\\\\\\rMethods: The CONSORT-ICWM guideline will be developed in five stages in accordance with recommendations for the development of reporting guidelines from the EQUATOR (Enhancing the QUAlity and Transparency Of health Research) Network including (1) project launch and registration; (2) literature review and checklist draft; (3) Delphi survey; (4) consensus meeting; and (5) finalization of the guideline. Additionally the working group will be composed of professors with expertise in integrated medicines traditional Chinese medicines biomedical informatics statistics methodology development of reporting guidelines epidemiology health economics and paper publications.\\\\\\\\rDiscussion: The CONSORT-ICWM guideline is to improve the reporting quality of clinical trials with ICWM interventions by ensuring the reports are complete informative clear and transparent. Copyright © 2023 Wang Zhang Wang Han Li Ma Lyu and Bian.","","","2023","10.3389/fmed.2023.1190560","","","medline-37457590.pdf","medline-37457590"
"Method for Data Quality Assessment of Synthetic Industrial Data","Iantovics L. B., Enachescu C.","Sensors","","Sometimes it is difficult or even impossible to acquire real data from sensors and machines that must be used in research. Such examples are the modern industrial platforms that frequently are reticent to share data. In such situations the only option is to work with synthetic data obtained by simulation. Regarding simulated data a limitation could consist in the fact that the data are not appropriate for research based on poor quality or limited quantity. In such cases the design of algorithms that are tested on that data does not give credible results. For avoiding such situations we consider that mathematically grounded data-quality assessments should be designed according to the specific type of problem that must be solved. In this paper we approach a multivariate type of prediction whose results finally can be used for binary classification. We propose the use of a mathematically grounded data-quality assessment which includes among other things the analysis of predictive power of independent variables used for prediction. We present the assumptions that should be passed by the synthetic data. Different threshold values are established by a human assessor. In the case of research data if all the assumptions pass then we can consider that the data are appropriate for research and can be applied by even using other methods for solving the same type of problem. The applied method finally delivers a classification table on which can be applied any indicators of performed classification quality such as sensitivity specificity accuracy F1 score area under curve (AUC) receiver operating characteristics (ROC) true skill statistics (TSS) and Kappa coefficient. These indicators' values offer the possibility of comparison of the results obtained by applying the considered method with results of any other method applied for solving the same type of problem. For evaluation and validation purposes we performed an experimental case study on a novel synthetic dataset provided by the well-known UCI data repository.","","","2022","10.3390/s22041608","","","medline-35214509.pdf","medline-35214509"
"Do firms harvest from political connections during general elections? Case of pakistan","Ashraf, A. And Hassan, M.k. And Abbas, K. And Zaman, Q.u.","Journal Of Financial Crime","","Purpose: this paper aims to examine the impact of general elections on the stock returns of the politically connected group affiliated firms of pakistan. Design/methodology/approach: this study uses the market model to assess the impact of political connections (pcs) on abnormal stock returns, before and after election events. We have used share price data of non-financial firms of pakistan for the years 2008-2013. Findings: it has been found that behavior of cumulative average abnormal returns (caar) is significantly different for standalone and politically connected group affiliated firms. The results reveal that caars of politically connected group affiliated firms have experienced less deviation as compared to stand alone firms. Therefore, it is argued that politically connected group firms may reduce the impact of political uncertainty on stock returns in comparison to stand alone firms. Practical implications: this study is helpful for policy regulators of pakistan to devise appropriate policies to maintain a level playing field for politically connected and standalone firms. Originality/value: this study provides a new dimension to understand the role and association of pcs and general elections with stock markets returns. © 2020, emerald publishing limited.","","","2020","10.1108/jfc-02-2019-0022","","","scopus-2-s2.0-85079459761.pdf","scopus-2-s2.0-85079459761"
"Guidelines for Proper Reporting of Clinical Significance Including Minimal Clinically Important Difference Patient Acceptable Symptomatic State Substantial Clinical Benefit and Maximal Outcome Improvement","Harris J. D., Brand J. C., Cote M., Waterman B., Dhawan A.","Arthroscopy","","Patient-reported outcome measures (PROM) need to be responsive reliable and validated for the specific condition or treatment. PROMs also need to exhibit a dose-dependent response across a diverse patient population unlimited by floor and ceiling effects. Statistically significant differences between compared groups might not always represent clinically important differences. Measures of clinical significance reflect a spectrum of patient satisfaction after an intervention. A noticeable difference to the patient is assessed with minimal clinically important difference (MCID) patient satisfaction by patient acceptable symptomatic state (PASS) and a ""considerable"" improvement by substantial clinical benefit (SCB). Clinical relevance measured by these clinically significant outcomes (CSO) are limited by ceiling effects. Maximal outcome improvement (MOI) might more accurately account for patients with higher baseline or preoperative PROMs thereby limiting ceiling effects. The acts of measuring (and reporting) patient-centered endpoints may actually be of greater importance than collecting objective clinician-measured data. As the old surgeon's aphorism goes ""nothing ruins good results like good follow-up."" Copyright © 2022 Arthroscopy Association of North America. Published by Elsevier Inc. All rights reserved.","","","2023","10.1016/j.arthro.2022.08.020","","","medline-36603987.pdf","medline-36603987"
"Computer-aided liver volumetry: performance of a fully-automated prototype post-processing solution for whole-organ and lobar segmentation based on MDCT imaging","Fananapazir G., Bashir M. R., Marin D., Boll D. T.","Abdominal Imaging","","PURPOSE: To evaluate the performance of a prototype fully-automated post-processing solution for whole-liver and lobar segmentation based on MDCT datasets.\\\\\\\\rMATERIALS AND METHODS: A polymer liver phantom was used to assess accuracy of post-processing applications comparing phantom volumes determined via Archimedes' principle with MDCT segmented datasets. For the IRB-approved HIPAA-compliant study 25 patients were enrolled. Volumetry performance compared the manual approach with the automated prototype assessing intraobserver variability and interclass correlation for whole-organ and lobar segmentation using ANOVA comparison. Fidelity of segmentation was evaluated qualitatively.\\\\\\\\rRESULTS: Phantom volume was 1581.0 +/- 44.7 mL manually segmented datasets estimated 1628.0 +/- 47.8 mL representing a mean overestimation of 3.0% automatically segmented datasets estimated 1601.9 +/- 0 mL representing a mean overestimation of 1.3%. Whole-liver and segmental volumetry demonstrated no significant intraobserver variability for neither manual nor automated measurements. For whole-liver volumetry automated measurement repetitions resulted in identical values; reproducible whole-organ volumetry was also achieved with manual segmentation p(ANOVA) 0.98. For lobar volumetry automated segmentation improved reproducibility over manual approach without significant measurement differences for either methodology p(ANOVA) 0.95-0.99. Whole-organ and lobar segmentation results from manual and automated segmentation showed no significant differences p(ANOVA) 0.96-1.00. Assessment of segmentation fidelity found that segments I-IV/VI showed greater segmentation inaccuracies compared to the remaining right hepatic lobe segments.\\\\\\\\rCONCLUSION: Automated whole-liver segmentation showed non-inferiority of fully-automated whole-liver segmentation compared to manual approaches with improved reproducibility and post-processing duration; automated dual-seed lobar segmentation showed slight tendencies for underestimating the right hepatic lobe volume and greater variability in edge detection for the left hepatic lobe compared to manual segmentation.","","","2015","10.1007/s00261-014-0276-9","","","medline-25326261.pdf","medline-25326261"
"Parallelization and performance tuning of molecular dynamics code with openmp","Bai, S.-R. And Ran, L.-P. And Lu, K.-L.","Journal Of Central South University Of Technology (English Edition)","","An openmp approach was proposed to parallelize the sequential molecular dynamics (md) code on shared memory machines. When a code is converted from the sequential form to the parallel form, data dependence is a main problem. A traditional sequential molecular dynamics code is anatomized to find the data dependence segments in it, and the two different methods, i.e., recover method and backward mapping method were used to eliminate those data dependencies in order to realize the parallelization of this sequential md code. The performance of the parallelized md code was analyzed by using some performance analysis tools. The results of the test show that the computing size of this code increases sharply form 1 million atoms before parallelization to 20 million atoms after parallelization, and the wall clock during computing is reduced largely. Some hot-spots in this code are found and optimized by improved algorithm. The efficiency of parallel computing is 30% higher than that of before, and the calculation time is saved and larger scale calculation problems are solved.","","","2006","10.1007/s11771-006-0120-7","","","scopus-2-s2.0-33747826607.pdf","scopus-2-s2.0-33747826607"
"Performance of uncertainty evaluation strategies in a food proficiency scheme","Ellison, S.l.r. And Mathieson, K.","Accreditation And Quality Assurance","","A study of the performance of different uncertainty evaluation strategies among 163 voluntary respondents from food proficiency schemes is presented. Strategies included use of: single-laboratory validation data, quality control data, past proficiency testing data, reproducibility data, a measurement equation and the dispersion of replicate observations on the test material. Most performed reasonably well, but the dispersion of replicate observations underestimated uncertainty by a factor of approximately 3. Intended compliance with accreditation requirements was associated with significantly improved uncertainty evaluation performance, while intended compliance with the iso ""guide to the expression of uncertainty in measurement"" had no significant effect. Substituting estimates based on the horwitz or horwitz-thompson models or on pt target standard deviation for the respondents' own estimates of uncertainty led to a marked reduction in poor zeta scores and significant improvement in dispersion of zeta scores. © 2008 lgc limited.","","","2008","10.1007/s00769-007-0353-7","","","scopus-2-s2.0-42149115892.pdf","scopus-2-s2.0-42149115892"
"Reinventing academic publishing online part ii: a socio-technical vision","Whitworth, B. And Friedman, R.","First Monday","","Part i of this paper outlined the limitations of feudal academic knowledge exchange and predicted its decline as cross-disciplinary research expands. Part ii now suggests the next evolutionary step is democratic online knowledge exchange, run by the academic many rather than the few. Using socio-technical tools it is possible to accept all, evaluate all and publish all academic documents. Editors and reviewers will remain, but their role will change, from gatekeepers to guides. However, the increase in knowledge throughput can only be supported by activating the academic community as a whole. Yet that is what socio-technical systems do - activate people to increase common gains. Part 1 argued that scholars must do this or be left behind in the dust of progress. The design proposed here is neither wiki, nor e-journal, nor electronic repository, nor reputation system, but a hybrid of these and other socio-technical functions. It supports print publishing as a permanent archive byproduct useful to a living, online knowledge exchange community. It could also track academic submissions, provide performance transcripts to promotion committees, enable hyperlinks, support attribution, allow data-source sharing, retain anonymous reviewing and support relevance and rigor in evaluation. Rather than a single ""super"" kes, a network of online systems united by a common vision of democratic knowledge exchange is proposed. © first monday, 1995-2009.","","","2009","10.5210/fm.v14i9.2642","","","scopus-2-s2.0-71649087078.pdf","scopus-2-s2.0-71649087078"
"A flexible attribute based data access management scheme for sensor-cloud system","Hong, H. And Sun, Z.","Journal Of Systems Architecture","","Sensor-cloud combines the merits of wsn with cloud computing and has been deployed in many practical applications. Data security is the prerequisite for the implementation of a sensor-cloud system, but conventional security mechanisms cannot fully satisfy the several new security demands arisen in this scenario. To address the challenge of flexible and secure data sharing, in this paper, we design an attribute based data access management scheme for sensor-cloud (abdm-sc). We take the advantages of attribute based cryptography and hash proof primitive to realize fine-grained access control and efficient user authentication. The data captured by the sensors are labeled by attributes and can only be accessed by users processing the valid credentials. During the data sharing procedure, the cloud side and user side only need to conduct one round of interaction. By security proof and performance evaluation, our abdm-sc is equipped with high security level and satisfactory efficiency. © 2021 elsevier b.v.","","","2021","10.1016/j.sysarc.2021.102234","","","scopus-2-s2.0-85109619122.pdf","scopus-2-s2.0-85109619122"
"Subsurface automated samplers for eDNA (SASe) for biological monitoring and research","Formel N., Enochs I. C., Sinigalliano C., Anderson S. R., Thompson L. R.","Hardwarex","","Sampling of environmental DNA (eDNA) in seawater is an increasingly common approach to non-invasively assess marine biodiversity detect cryptic or invasive species and monitor specific groups of organisms. Despite this remarkable utility collection and filtration of eDNA samples in the field still requires considerable time and effort. Recent advancements in automated water samplers have standardized the eDNA collection process allowing researchers to collect eDNA day or night sample in locations that are difficult to access and remove the need for highly trained personnel to perform sampling. However the high cost of purchasing or building these samplers represents a financial hurdle to widespread application. To overcome this difficulty we have designed and built a low-cost subsurface automated sampler for eDNA (SASe). Each sampler is submersible to 55 m can filter a pre-programmable volume of water and preserves eDNA at the site of collection. SASe samplers have replaceable filters and a low build cost (~280 USD vs. >100000 USD for other eDNA samplers) which facilitates repeated field sampling at fine spatial and temporal scales. Lab testing has shown the SASe to be as effective as a standard desktop peristaltic pump for sampling preserving and recovering marine eDNA. SASe design files and operating code are open-source promoting the use of this tool to meet a range of future eDNA research applications including project-specific customizations to the current design. Copyright © 2021 The Authors. Published by Elsevier Ltd.","","","2021","10.1016/j.ohx.2021.e00239","","","medline-35607674.pdf","medline-35607674"
"Option: optimization algorithm benchmarking ontology","Kostovska, A. And Vermetten, D. And Doerr, C. And Dzeroski, S. And Panov, P. And Eftimov, T.","Ieee Transactions On Evolutionary Computation","","Many optimization algorithm benchmarking platforms allow users to share their experimental data to promote reproducible and reusable research. However, different platforms use different data models and formats, which drastically complicates the identification of relevant datasets, their interpretation, and their interoperability. Therefore, a semantically rich, ontology-based, machine-readable data model that can be used by different platforms is highly desirable. In this article, we report on the development of such an ontology, which we call option (optimization algorithm benchmarking ontology). Our ontology provides the vocabulary needed for semantic annotation of the core entities involved in the benchmarking process, such as algorithms, problems, and evaluation measures. It also provides means for automatic data integration, improved interoperability, and powerful querying capabilities, thereby increasing the value of the benchmarking data. We demonstrate the utility of option, by annotating and querying a corpus of benchmark performance data from the bbob collection of the coco framework and yet another black-box optimization benchmark (yabbob) family of the nevergrad environment. In addition, we integrate features of the bbob functional performance landscape into the option knowledge base (kb) using publicly available datasets with exploratory landscape analysis. Finally, we integrate the option kb into the iohprofiler environment and provide users with the ability to perform a meta-analysis of performance data. © 1997-2012 ieee.","","","2023","10.1109/tevc.2022.3232844","","","scopus-2-s2.0-85146246597.pdf","scopus-2-s2.0-85146246597"
"Discrimination of 1990s original automotive paint systems: a collaborative study of black nonmetallic base coat/clear coat finishes using infrared spectroscopy","Ryland S., Bishea G., Brun-Conti L., Eyring M., Flanagan B., Jergovich T., MacDougall D., Suzuki E.","Journal of Forensic Sciences","","The 1990s saw the introduction of significantly new types of paint binder chemistries into the automotive finish coat market. Considering the pronounced changes in the binders that can now be found in automotive paints and their potential use in a wide variety of finishes worldwide the Paint Subgroup of the Scientific Working Group for Materials (SWGMAT) initiated a validation study to investigate the ability of commonly accepted methods of forensic paint examination to differentiate between these newer types of paints. Nine automotive paint systems typical of original equipment applications were acquired from General Motors Corporation in 1992. They consisted of steel panels coated with typical electrocoat primers and/or primer surfacers followed by a black nonmetallic base coat and clear coat. The primary purpose of this study was to evaluate the discrimination power of common forensic techniques when applied to the newer generation original automotive finishes. The second purpose was to evaluate interlaboratory reproducibility of automotive paint spectra collected on a variety of Fourier transform infrared (FT-IR) spectrometers and accessories normally used for forensic paint examinations. The results demonstrate that infrared spectroscopy is an effective tool for discriminating between the major automotive paint manufacturers' formulation types which are currently used in original finishes. Furthermore and equally important the results illustrate that the mid-infrared spectra of these finishes are generally quite reproducible even when comparing data from different laboratories commercial FT-IR instruments and accessories in a ""real world"" mostly uncontrolled environment.","","","2001","10.1520/jfs14908j","","","medline-11210921.pdf","medline-11210921"
"Data-pe: a framework for evaluating data publication policies at scholarly journals","Moles, N.","Data Science Journal","","With the growing importance of data to the scholarly record and the critical role journals play in facilitating data sharing, the complex landscape of scholarly journal data publication policies has become an obstacle for research. This paper outlines data-pe, a framework for evaluating these policies. It takes the form of a conceptual foundation, comprising twelve criteria for evaluation, operationalized through an evaluation tool. Its objective is to function as a flexible means for a variety of stakeholders to appraise individual policies. Examples of the use of the framework are provided and means for the validation of the tool are discussed. © 2015, committee on data for science and technology. All rights reserved.","","","2015","10.2481/dsj.14-047","","","scopus-2-s2.0-85047286029.pdf","scopus-2-s2.0-85047286029"
"Effectiveness of an mhrd workshop on instrumentation – an empirical study","William Dharma Raja, B. And Sasikala, V.","International Journal Of Scientific And Technology Research","","Instrumentation refers to the tools or means by which investigators attempt to measure variables or items of interest in the data-collection process. Present paper evaluates the effectiveness of the workshop on instrumentation organised by the centre for techer resource and academic support, under school of education sanctioned under pandit madan mohan malaviya national mission on teachers and teaching (pmmmnmtt) scheme by the mhrd, government of india in imparting knowledge on construction of a quality research tool among/for research scholars and young supervisors. Pre-test post-test single group design was adopted to evaluate the effectiveness of the workshop on imparting important criteria, principles, development and construction of a quality research instrument. The subjects for the study were 25 research scholars and young supervisor who were the participants of the workshop from four states of india. The data was collected using an 'achievement test on tool construction‘ developed and validated by the investigators. The twelve hours of intensive lectures and hands on training on instrumentation piloted by two well renowned resource persons were the intervention. The results of paired t-test analysis revealed that there was a statistically significant difference among research scholars and young supervisors. The findings of the study revealed that workshop on instrumentation significantly impacted the participants to gain knowledge of designing a reliable, valid and credible research instrument. © ijstr 2019.","","","2019","","","","scopus-2-s2.0-85075155614.pdf","scopus-2-s2.0-85075155614"
"Prediction of RNA binding sites in proteins from amino acid sequence","Terribilini M., Lee J. H., Yan C., Jernigan R. L., Honavar V., Dobbs D.","Rna-A Publication of the Rna Society","","RNA-protein interactions are vitally important in a wide range of biological processes including regulation of gene expression protein synthesis and replication and assembly of many viruses. We have developed a computational tool for predicting which amino acids of an RNA binding protein participate in RNA-protein interactions using only the protein sequence as input. RNABindR was developed using machine learning on a validated nonredundant data set of interfaces from known RNA-protein complexes in the Protein Data Bank. It generates a classifier that captures primary sequence signals sufficient for predicting which amino acids in a given protein are located in the RNA-protein interface. In leave-one-out cross-validation experiments RNABindR identifies interface residues with >85% overall accuracy. It can be calibrated by the user to obtain either high specificity or high sensitivity for interface residues. RNABindR implementing a Naive Bayes classifier performs as well as a more complex neural network classifier (to our knowledge the only previously published sequence-based method for RNA binding site prediction) and offers the advantages of speed simplicity and interpretability of results. RNABindR predictions on the human telomerase protein hTERT are in good agreement with experimental data. The availability of computational tools for predicting which residues in an RNA binding protein are likely to contact RNA should facilitate design of experiments to directly test RNA binding function and contribute to our understanding of the diversity mechanisms and regulation of RNA-protein complexes in biological systems. (RNABindR is available as a Web tool from http://bindr.gdcb.iastate.edu.).","","","2006","","","","medline-16790841.pdf","medline-16790841"
"Analysis of science, technology and innovation (sti) policies of india from 1958 to 2020","Sattiraju, V.k. And Janodia, M.d.","Journal Of Science And Technology Policy Management","","Purpose: the purpose of this paper is to analyse innovation policies in india from 1958 to 2020. A policy tools framework was developed to compare the innovation policies in india. India developed and implemented four innovation policies from 1958 to 2013. The recent policy change was brought in the year 2020 with releasing the draft of the science, technology and innovation policy (stip 2020). The authors analysed the recent draft of stip 2020 with the earlier four innovation policies. Design/methodology/approach: innovation policies implemented from 1958 to 2013 in india were studied and analysed in the “text as a data approach” and a comparative policy analysis tool was designed for this purpose. The recent draft of stip 2020 was evaluated and the provisions of the fifth draft of stip 2020 were compared with the previous four innovation policies' design and formulation. The cpa tool design consists of five broad themes awareness and capacity building;  finance and infrastructure;  resource management and governance;  outreach and networking;  and policy implementation and evaluation. Findings: draft stip 2020 has many features similar to earlier policies. However, policy has focused on bringing in more clarity about national challenges, goals and objectives, yet it needs better implementation to achieve stated outcomes more effectively and efficiently. New initiatives include strengthening the innovation system with open science, improving sti education, expanding the financial landscape, establishing national sti observatory acting as a central repository of all data related to the sti ecosystem and accountable research ecosystem, promoting translational and foundational research of global standards, promoting entrepreneurship, self-reliance, mainstream science communication and public engagement and decentralised institutional mechanisms. Thus, the stip 2020 is ambitious in its approach to promoting sti in india and needs a supportive mechanism to achieve the stated objectives. Research limitations/implications: current comparative policy analysis focused only on identifying similarities and differences among innovation policies implemented in india from 1958 to 2020 and its evolutionary changes in policy and its instruments choice. The recent draft stip 2020 is not approved and has no update regarding its approval and implementation by the government. The revised and yet to implement stip 2020 may have variances in the policy instruments. The earlier policies are so broad and without specific problem statements. They were released as statements and resolutions which makes it is challenging to understand the impact of each policy. Similar policy tools in sti 2013 and stip 2020 were only considered to observe the policy instrument choice. The achievements of the innovation policies implemented before stip 2020 are not included. Evolutionary changes in the problem statements and policy tools prescribed in innovation policies are studied. Originality/value: department of science and technology, government of india, released a draft of stip in 2020. The draft of stip was evaluated with previous innovation policies. To the authors’ understanding, this is the first attempt to evaluate the stips of india using the “text as a data” approach. The tool can be validated by using it for cpa of innovation policies of other emerging, developed and least developed economies to understand cross-country variations in policy instrument choice by policymakers. © 2023, emerald publishing limited.","","","2023","10.1108/jstpm-02-2022-0030","","","scopus-2-s2.0-85165430889.pdf","scopus-2-s2.0-85165430889"
"A resident-led initiative to improve patient safety event reporting in an internal medicine residency program","Zarrabi K., Cummings K., Lum N., Taub E., Goolsarran N.","Journal of Community Hospital Internal Medicine Perspectives","","BACKGROUND: Despite the Clinical Learning Environment Review's recommendations of their use patient safety event reporting systems are underutilized by residents.\\\\\\\\rOBJECTIVE: We aimed to identify perceived barriers to event reporting amongst internal medicine residents and implement a targeted quality improvement initiative to address the identified barriers and increase overall resident event report rates.\\\\\\\\rMETHODS: A total of 94 Internal Medicine (IM) residents participated in the educational intervention in 2018. We measured residents' perception of barriers to event reporting and employed the results of the questionnaire to create a skill-based educational workshop. We conducted the plan-do-study-act model to test a structured educational intervention and its effectiveness on pre-post IM residents' event report rates and compared it to report rates of Non-Internal Medicine (Non-IM) residents. Additionally we assessed pre-post intervention knowledge skills and attitudes in event reporting.\\\\\\\\rRESULTS: 94/94 (100%) of IM residents had a significantly higher median percent of patient safety event reporting when compared to pre-intervention (23.6% compared to 5.88% p-value = 0.0030) and when compared to Non-IM residents (23.6% compared to 5.31% p-value = 0.0002). Residents performed better on the post-test compared to the pre-test (90% compared to 30% p-value = 0.0001) for knowledge. 100% of the critical action items were completed and 90% of participants reported their perception of the event reporting process improved.\\\\\\\\rCONCLUSIONS: By elucidating common reasons why residents are not reporting patient safety events a specific intervention can be created to target the identified impediments and improve resident event reporting.\\\\\\\\rABBREVIATIONS: IM: Internal Medicine IM; Non-IM: Non-Internal Medicine; IOM: Institute of Medicine I; ACGME CLER: Accreditation Council for Graduate Medical Education Clinical Learning Environment Review; GME: Graduate Medical Education; IRB: Institutional Review Board; PDSA: Plan Do Study Act. Copyright © 2020 The Author(s). Published by Informa UK Limited trading as Taylor & Francis Group on behalf of Greater Baltimore Medical Center.","","","2020","10.1080/20009666.2020.1740507","","","medline-32850045.pdf","medline-32850045"
"Identification and characterization of human observational studies in nutritional epidemiology on gut microbiomics for joint data analysis","Pinart, M. And Nimptsch, K. And Forslund, S.k. And Schlicht, K. And Gueimonde, M. And Brigidi, P. And Turroni, S. And Ahrens, W. And Hebestreit, A. And Wolters, M. And Dötsch, A. And Nöthlings, U. And Oluwagbemigun, K. And Cuadrat, R.r.c. And Schulze, M.b. And Standl, M. And Schloter, M. And De Angelis, M. And Iozzo, P. And Guzzardi, M.a. And Vlaemynck, G. And Penders, J. And Jonkers, D.m.a.e. And Stemmer, M. And Chiesa, G. And Cavalieri, D. And De Filippo, C. And Ercolini, D. And De Filippis, F. And Ribet, D. And Achamrah, N. And Tavolacci, M.-P. And Déchelotte, P. And Bouwman, J. And Laudes, M. And Pischon, T.","Nutrients","","In any research field, data access and data integration are major challenges that even large, well-established consortia face. Although data sharing initiatives are increasing, joint data analyses on nutrition and microbiomics in health and disease are still scarce. We aimed to identify observational studies with data on nutrition and gut microbiome composition from the intestinal microbiomics (intimic) knowledge platform following the findable, accessible, interoperable, and reusable (fair) principles. An adapted template from the european nutritional phenotype assessment and data sharing initiative (enpadasi) consortium was used to collect microbiome-specific information and other related factors. In total, 23 studies (17 longitudinal and 6 cross-sectional) were identified from italy (7), germany (6), netherlands (3), spain (2), belgium (1), and france (1) or multiple countries (3). Of these, 21 studies collected information on both dietary intake (24 h dietary recall, food frequency questionnaire (ffq), or food records) and gut microbiome. All studies collected stool samples. The most often used sequencing platform was illumina miseq, and the preferred hypervariable regions of the 16s rrna gene were v3–v4 or v4. The combination of datasets will allow for sufficiently powered investigations to increase the knowledge and understanding of the relationship between food and gut microbiome in health and disease. © 2021 by the authors. Licensee mdpi, basel, switzerland.","","","2021","10.3390/nu13093292","","","scopus-2-s2.0-85115159512.pdf","scopus-2-s2.0-85115159512"
"The role of evaluation in gifted program development: coordinators’ portraits of progress","Vantassel-Baska, J.","Gifted Child Today","","This article presents a description of the potential impacts from six different school-based evaluations, based on the perceptions of program coordinators and evaluators 1 to 3 years after the evaluation was conducted. It shares data on what recommendations of the evaluation were implemented and the rationale behind these decisions. Coordinators also commented on the perceived value and benefit of having the evaluation conducted and provided thoughts about having an evaluation conducted in the future. The article concludes with a set of lessons learned from the evaluation experience. © 2019 the author(s).","","","2019","10.1177/1076217519862323","","","scopus-2-s2.0-85073252433.pdf","scopus-2-s2.0-85073252433"
"What student evaluations are not: scholarship of teaching and learning using student evaluations","Ali, A. And Crawford, J. And Cejnar, L. And Harman, K. And Sim, K.n.","Journal Of University Teaching And Learning Practice","","In this editorial, we stay committed to the objective of the journal of university teaching and learning practice regarding sharing, evaluating, and developing stronger evidence-based practice papers by focusing on the topic of national and institutional student evaluations. We create an important theoretical and practical foundation for authors considering publishing with our journal on studies that utilise student surveys as their primary method of data collection. The editorial begins by providing a comprehensive overview of the history and emergence of student evaluations dating back to medieval times, we trace the evolution of student evaluations to present day looking at the rationale behind the induction of such tools. Following this, we discuss the validity of student evaluations through an exploration of factors such as student satisfaction, the timing of when student surveys are administered, and the idiosyncrasies regarding paper-based and online evaluations. We then further discuss the reliability of student evaluations by contextualising what student evaluations do not say and uncover how various forms of bias can influence the ways student evaluations are both completed and interpreted. Through this we assert that due to confounding factors of bias that influence the results of student evaluations, they cannot always be thought of as wholly objective data collection tools. This then leads into our discussion of the contemporary social contexts within which student evaluations are situated and how both micro and macro dynamics influence student experiences of teaching and learning, where we contest that broader external factors experienced by students can skew the ways teaching is both perceived and evaluated. We conclude our editorial by critically envisioning a new direction for future manuscript submissions to our journal. We assert that although the use of student evaluations as evidence of teaching practice may be inherently flawed, there nonetheless remains merit in their use following critical and reflexive engagement throughout the research process. As such, we are hopeful that our critical review of student evaluation-based scholarship may be utilised to leverage higher quality research output. © 2021, university of wollongong. All rights reserved.","","","2021","10.53761/1.18.8.1","","","scopus-2-s2.0-85125598807.pdf","scopus-2-s2.0-85125598807"
"Frequent exposure to varied home cage sizes alters pain sensitivity and some key inflammation-related biomarkers","Oyewole, A.l. And Oyafemi, K.o. And Badmus, K.s. And Omoleye, J.o. And Abubakar, M.f. And Adeniyi-Raheem, O. And Amedu, A.-H. And Lawal, D.l. And Ijiyode, A.o. And Yussuf, A.o. And Ishola, S.s. And Sulaimon, F.a. And Alli-Oluwafuyi, A.o. And Nafiu, A.b. And Akinola, O. And Olajide, O.j. And Amin, A. And Abdulmajeed, W.i. And Michael, O.s. And Adeyanju, O.a. And Ogunjimi, G.l.","Journal Of Neuroscience Methods","","Background: nature and size of rodent cages vary from one laboratory or country to another. Little is however known about the physiological implications of exposure to diverse cage sizes in animal-based experiments. Method: here, two groups of male swiss mice (control group – cage stationed, and test group – cage migrated) were used for this study. The cage-migrated mice were exposed daily to various cage sizes used across laboratories in nigeria while the cage-stationed mice exposed daily to different but the same cage size and shape. At the end of the 30 days exposure, top-rated paradigms were used to profile changes in physiological behaviours, and this was followed by evaluation of histological and biochemical metrics. Results: the study showed a significant (p < 0.05) decrease in blood glucose levels (at 60 and 120 min of oral glucose tolerance test) in the cage-migrated mice compared to cage-stationed mice. Strikingly, peripheral oxidative stress (plasma malondialdehyde) and pain sensitivity (formalin test, hot-and-cold plate test, and von frey test) decreased significantly in cage-migrated mice compared to cage-stationed animals. Also, the pro-inflammation mediators (il-6 and nf-κb) increased significantly in cage-migrated mice compared to cage-stationed mice. However, emotion-linked behaviours, neurotransmitters (serotonin, noradrenaline and gaba), brain and plasma electrolytes were not significantly difference in cage-migrated animals compared to cage-stationed mice. Conclusion: taken together, these results suggest that varied size cage-to-cage exposure of experimental mice could affect targeted behavioural and biomolecular parameters of pain and inflammation, thus diminishing research reproducibility, precipitating false negative/positive results and leading to poor translational outcomes. © 2020 elsevier b.v.","","","2020","10.1016/j.jneumeth.2020.108890","","","scopus-2-s2.0-85089415533.pdf","scopus-2-s2.0-85089415533"
"The role of metadata in reproducible computational research","Leipzig J., Nust D., Hoyt C. T., Ram K., Greenberg J.","Patterns","","Reproducible computational research (RCR) is the keystone of the scientific method for in silico analyses packaging the transformation of raw data to published results. In addition to its role in research integrity improving the reproducibility of scientific studies can accelerate evaluation and reuse. This potential and wide support for the FAIR principles have motivated interest in metadata standards supporting reproducibility. Metadata provide context and provenance to raw data and methods and are essential to both discovery and validation. Despite this shared connection with scientific data few studies have explicitly described how metadata enable reproducible computational research. This review employs a functional content analysis to identify metadata standards that support reproducibility across an analytic stack consisting of input data tools notebooks pipelines and publications. Our review provides background context explores gaps and discovers component trends of embeddedness and methodology weight from which we derive recommendations for future work.","","","2021","10.1016/j.patter.2021.100322","","","pubmed-34553169.pdf","pubmed-34553169"
"Subjective quality assessment of h.264/avc video streaming with packet losses","De Simone, F. And Naccari, M. And Tagliasacchi, M. And Dufaux, F. And Tubaro, S. And Ebrahimi, T.","Eurasip Journal On Image And Video Processing","","Research in the field of video quality assessment relies on the availability of subjective scores, collected by means of experiments in which groups of people are asked to rate the quality of video sequences. The availability of subjective scores is fundamental to enable validation and comparative benchmarking of the objective algorithms that try to predict human perception of video quality by automatically analyzing the video sequences, in a way to support reproducible and reliable research results. In this paper, a publicly available database of subjective quality scores and corrupted video sequences is described. The scores refer to 156 sequences at cif and 4cif spatial resolutions, encoded with h.264/avc and corrupted by simulating the transmission over an error-prone network. The subjective evaluation has been performed by 40 subjects at the premises of two academic institutions, in standard-compliant controlled environments. In order to support reproducible research in the field of full-reference, reduced-reference, and no-reference video quality assessment algorithms, both the uncompressed files and the h.264/avc bitstreams, as well as the packet loss patterns, have been made available to the research community. © 2011 francesca de simone et al.","","","2011","10.1155/2011/190431","","","scopus-2-s2.0-79955052061.pdf","scopus-2-s2.0-79955052061"
"Identifying interesting networks of criminal activity","Marshall, B.","Studies In Computational Intelligence","","While electronic records management systems (rms) make it possible for investigators to quickly query large volumes of law enforcement (le) data, much more can be done to effectively use police records to support investigational processes. Detectives frequently identify interesting networks of association and draw them up in link charts to help generate leads, focus investigations, and facilitate communication. A variety of multi-jurisdictional data sharing initiatives facilitate access to increasingly large data sets. Methodologies that display, analyze, or help create useful representations of criminal networks are needed to help sift through massive quantities of available associational data. This chapter discusses a model for analyzing criminal data which employs obtainable, sharable datasets in support of realistic investigational tasks, and illustrates the key issues by demonstrating how a cross-jurisdictional dataset can be used to identify a network of interesting criminal associations. Models of this kind are needed to guide the development of policies, procedures, and technical components appropriate for investigational tasks as agencies work to move beyond administrative efficiency towards investigational effectiveness. © 2008 springer-verlag berlin heidelberg.","","","2008","10.1007/978-3-540-69209-6_8","","","scopus-2-s2.0-45949101693.pdf","scopus-2-s2.0-45949101693"
"Geenar: a web tool for reproducible maldi-tof analysis","Del Prete E. And Facchiano A. And Profumo A. And Angelini C. And Romano P.","Front. Genet","","Mass spectrometry is a widely applied technology with a strong impact in the proteomics field. Maldi-tof is a combined technology in mass spectrometry with many applications in characterizing biological samples from different sources, such as the identification of cancer biomarkers, the detection of food frauds, the identification of doping substances in athletes' fluids, and so on. The massive quantity of data, in the form of mass spectra, are often biased and altered by different sources of noise. Therefore, extracting the most relevant features that characterize the samples is often challenging and requires combining several computational methods. Here, we present geenar, a novel web tool that provides a complete workflow for pre-processing, analyzing, visualizing, and comparing maldi-tof mass spectra. Geenar is user-friendly, provides many different functionalities for the analysis of the mass spectra, and supports reproducible research since it produces a human-readable report that contains function parameters, results, and the code used for processing the mass spectra. First, we illustrate the features available in geenar. Then, we describe its internal structure. Finally, we prove its capabilities in analyzing oncological datasets by presenting two case studies related to ovarian cancer and colorectal cancer. Geenar is available at http://proteomics.hsanmartino.it/geenar/.© copyright © 2021 del prete, facchiano, profumo, angelini and romano.","","","2021","10.3389/fgene.2021.635814","","","embase-634734080.pdf","embase-634734080"
"Reproducibility of Automated Breast Ultrasonography and Handheld Ultrasonography for Breast Lesion Size Measurement","Park K. W., Ko E. Y., Park S., Han B. K., Ko E. S., Choi J. S., Kwon M. R.","Ultrasound Quarterly","","ABSTRACT: The purpose of our study was to evaluate the reproducibility of size measurement of breast lesions using automated breast ultrasonography (ABUS) compared with that with handheld ultrasonography (HHUS). Three breast radiologists performed HHUS and measured the lesions size in 2 different phantoms: lesions with various shape size and same stiffness (phantom 1) and lesions with same shape size and various stiffness (phantom 2). After 1 month the same radiologists measured the lesion size of the same breast phantoms in the images obtained using ABUS. We evaluated interobserver variability between 3 radiologists in ABUS and HHUS and intraobserver variability of radiologists between ABUS and HHUS. Intraclass correlation coefficient (ICC) was used in statistical analysis. The measured size of lesions on HHUS was slightly larger than that on ABUS in both phantom 1 and 2 although not statistically significant (P = 0.314 P = 0.858). There were no significant differences in size measurements between the radiologists' measurements and the reference size in phantom 2 (P = 0.862). The ICCs for the interobserver agreement between the 3 radiologists were 0.98 to 0.99 on ABUS and 0.99 to 1.00 on HHUS respectively. The ICCs for the intraobserver agreement between ABUS and HHUS were 0.97 to 0.97 in phantom 1 and 0.98 to 0.99 in phantom 2. In conclusion ABUS showed excellent interobserver and intraobserver agreement with HHUS in measuring size of the lesions regardless of shape size and stiffness. Therefore ABUS mixed with HHUS can be used reliably in following up breast lesions size. Copyright © 2022 Wolters Kluwer Health Inc. All rights reserved.","","","2022","10.1097/ruq.0000000000000568","","","medline-35001027.pdf","medline-35001027"
"Improving workflow efficiencies in protein formulation laboratories using visual basic for applications","Ratnaswamy, G. And Dharmavaram, V.","Journal Of Laboratory Automation","","The protein formulation group develops stable formulations for both clinical and marketed protein therapeutics;  this involves a systematic search of a large variable space. Several studies are set up each exploring the effect of a few variables at a time on protein stability. The amount of data generated from each study is substantial and is compounded as more studies are carried out. The business process from the data perspective was mapped to identify the data flow between the sub-processes. A number of redundancies in data entry that resulted in duplication of effort on the part of the researcher were identified. A custom microsoft excel add-in package, using visual basic for applications, has been developed in-house. To increase productivity and efficiency, at every step in the process, namely, planning, preparation, and execution and evaluation of the studies, these macros and templates allow automatic flow of information through the sub-processes. This has significantly reduced manual entry of data and errors in transcription and thereby led to savings in time and increased speed, reliability, and accuracy. Another advantage of using the macros is that the data format is standardized, facilitating the sharing of data and transfer of projects between teams. Further, metadata available through the use of the macros were used creatively to provide additional tools for overall project tracking. © 2007, society for laboratory automation and screening. All rights reserved.","","","2007","10.1016/j.jala.2006.08.007","","","scopus-2-s2.0-33847760764.pdf","scopus-2-s2.0-33847760764"
"Knowledge management practice at a bulgarian bank: a case study","Shah, M.h. And Rahneva, N. And Ahmed, R.","International Journal Of Knowledge Management","","This paper reports on knowledge management (km) practices in the customer service and lending departments of one of bulgaria's top retail banks and investigates how km processes can be further improved. The bank's km activities have been studied using observations, interviews and informal discussions for data collection. Findings were compared and contrasted with existing literature in similar contexts. Although rudiments of knowledge sharing are evident from the km activities in different departments of the bank, the limitations such as resistance to change of the implemented km systems are impeding the effectiveness of the knowledge management process. More training and incentives are needed to increase knowledge creation and sharing. Moreover, a clearly articulated km strategy along with success criteria and commitment and support from senior management is needed. There is a severe lack of knowledge management studies in bulgarian context in general and bulgarian banking sector in particular. The authors' findings will potentially help in improving knowledge sharing practice as well as provide a valuable insight into knowledge management related issues in the bulgarian context. The findings from this research can be useful to companies from eastern europe and other regions in improving their knowledge sharing practice. Copyright © 2014, igi global.","","","2014","10.4018/ijkm.2014070104","","","scopus-2-s2.0-84924072446.pdf","scopus-2-s2.0-84924072446"
"Comparison & magnitude credibility: whom to trust when reports are conflicting?","Zhou, S. And Zhang, H. And Shen, B.","Open Communication Journal","","This study used the concepts of comparison credibility and magnitude credibility to assess perceived news media credibility in china. It also investigated which sources people trusted more when they encountered conflicting reports regarding different kinds of stories including entertainment news, disaster news and political news. A random sample from three major metropolises (n = 1,844) were telephone interviewed. Results indicated that television was perceived as the most trustworthy. Regardless of the type of stories, people trusted national chinese media over other media outlets. Implications on credibility research are discussed. © zhou et al.;  Licensee bentham open.","","","2014","10.2174/1874916x01408010001","","","scopus-2-s2.0-84928717222.pdf","scopus-2-s2.0-84928717222"
"Transparency fallacy: unintended consequences of stakeholder claims on responsibility in supply chains","Gold, S. And Heikkurinen, P.","Accounting, Auditing And Accountability Journal","","Purpose: the purpose of this paper is to focus on the research question of how stakeholder claims for transparency work as a means to support responsibility in the international supply chain. Design/methodology/approach: this theoretical study analyses the relationship between stakeholder claims for corporate transparency and responsible business in the global context, and develops a conceptual model for further theoretical and empirical work. Findings: the study finds that the call for corporate transparency is insufficient as a means to increase responsibility within international supply chains. The erroneous belief that stakeholder claims for transparency will lead to responsible behaviour is identified as the “transparency fallacy”. The fallacy emerges from the denial of opacity in organisations and the blindness to the conditions of international supply chains (including complexity, distance, and resistance) that work against attempts to increase transparency. Research limitations/implications: acknowledging the limits of the transparency mechanism in both management theory and practice is necessary in order to advance responsible business in the international arena. Being conceptual in nature, the generic limitations of the type of research apply. Practical implications: while acknowledging opacity, corporate managers and stakeholders should focus on changing the supply chain conditions to support responsible behaviour. This includes reducing complexity, distance, and resistance in the supply network. Originality/value: this study contests the commonly assumed link between corporate transparency and responsibility, and sheds light on the limits and unintended consequences of stakeholder attempts to impose transparency on business organisations. © 2018, emerald publishing limited.","","","2018","10.1108/aaaj-06-2015-2088","","","scopus-2-s2.0-85041723591.pdf","scopus-2-s2.0-85041723591"
"A secure and computable blockchain‐based data sharing scheme in iot system","Sun, S. And Du, R. And Chen, S.","Information (Switzerland)","","The internet of things (iot) devices are expected to collect vast amounts of data that support different kinds of applications such as health monitor, smart home, and traffic management. However, its characteristics such as resource‐constrained nature, dynamicity, and large‐scale growth bring challenges to secure iot data sharing. Nowadays, blockchain‐based ciphertext‐policy attribute‐based encryption (cp‐abe) was proposed to realize secure iot data sharing. In blockchain‐based cp‐abe data sharing schemes, the data are encrypted and stored in the cloud. Once users want to process the data, they should download and then decrypt the ciphertext in the clientend, and after processing the data, users encrypt and upload the ciphertext onto the cloud. This outweighs the advantage of using cloud computing resources. Fully homomorphic encryption (fhe) and homomorphic signature technology may be adopted to realize ciphertext computation and for correctness checking of ciphertext computation results. In this paper, we propose a secure and computable iot data sharing system to ensure users enjoying the computation convenience of the cloud‐end. Specifically, the proposed system integrates cp‐abe and fhe to realize secure iot data sharing and ciphertext computation. In addition, we generated homomorphic signatures of ciphertexts to enable users to check the correctness of the ciphertext computation results. Moreover, to supervise the cloud, providing the honest iot data access control, storage, and computing services for users, we recorded the access policy of the data, the hash of the data, the signature of the ciphertext, and the homomorphic signature of the ciphertext on the blockchain. The performance evaluation and security analysis show the proposed scheme is practical and secure. © 2021 by the authors. Licensee mdpi, basel, switzerland.","","","2021","10.3390/info12020047","","","scopus-2-s2.0-85100574284.pdf","scopus-2-s2.0-85100574284"
"Deferential trespassing: looking through and at an intersectional lens","Beckmann, J.f.","New Directions For Child And Adolescent Development","","In this article, i comment on the prospect of integrating an intersectionality perspective into the developmental sciences. I do this by sharing impressions, insights, and questions that have emerged whilst attempting to look at and to look through an intersectionality lens. My comments focus on three main topics. First, i speculate what forms such an integration could take and argue that an integration that productively contributes to shaping developmental science into a transdisciplinary field is likely to change intersectionality research itself. I then reflect on the perceived ambiguity in terms of the unit of analysis (e.g., social systems vs. individuals) and the focus of research questions (i.e., description vs. explanation vs. intervention) in intersectionality research. Clarity and transparency in this regard is instrumental to productively identifying conceptual and methodological overlaps or intersections with other subdisciplines in developmental sciences. Finally, i highlight the importance of development being more comprehensively reflected in the conceptualizations, the research questions, and the subsequently employed methodologies in intersectionality research. I conclude with a plea for allowing our expertise to intersect to transdisciplinarily work toward creating systemic and perpetual progress in the developmental sciences—something, i believe to resonate strongly with intersectionality researchers. © 2018 wiley periodicals, inc.","","","2018","10.1002/cad.20243","","","scopus-2-s2.0-85054632945.pdf","scopus-2-s2.0-85054632945"
"Research on the conversion of land use classification data in ""the coordination of urban planning and land use planning""","Zhan, Q. And Han, W. And Zhao, Z. And Xiao, R. And Huang, Q. And Liu, W.","Journal Of Geomatics","","Land use status data of urban planning and land use planning generally come from two departments, with their different focuses and their inherent difference. To improve the availability of data, the paper selects a test area in wuhan, studies the conversion of land use standards and its data, evaluates quantitatively the conversion effect and reliability, and divides them into ""direct convertible"" class,better consistency ""can be considered"" class and large difference ""need to manually intervene"" class. This paper also sorts out the reasons combined with remote sensing image and proposes optimization suggestions to reduce data difference and the workload of manual intervention in data conversion. © 2018 wuhan university.","","","2018","10.14188/j.2095-6045.2018377","","","scopus-2-s2.0-85061510095.pdf","scopus-2-s2.0-85061510095"
"Data input module for Birth Defects Systems Manager","Knudsen K. B., Singh A. V., Knudsen T. B.","Reproductive Toxicology","","The need for a computational bioinformatics infrastructure to manage the vast digital information from functional genomics and proteomics motivated us to develop Birth Defects Systems Manager (BDSM) as an open resource to facilitate analysis and discovery in developmental biology and developmental toxicity. This report describes the design development and implementation of the data loading module of BDSM referred to as LoadBDSM. It includes a shared data directory resource that can be granted various levels of security for different research groups or investigators to manage experimental datasets individually or in groups. LoadBDSM allows the upload of data and experiment details using controlled semantics for developmental exposure (toxicant dosing scenario intervention) biological sample (species tissue stage) and disease outcome (time risk phenotype). It adheres to existing controlled vocabulary plus rules of inference (ontologies) for experiment data and metadata annotations. LoadBDSM extends the capabilities of BDSM to support the emergence of ""embryo-formatics"" defined here as the data information and knowledge from genomic sciences applied to or derived from an embryological context. This includes but is not limited to delineating pathways and biological regulatory networks for specific chemicals or classes of developmental toxicants developing novel biomarkers indicative of exposure and/or predictive of adverse effects and integrating modern computing and information technology with data from molecular biology.","","","2005","10.1016/j.reprotox.2005.04.002","","","medline-15923107.pdf","medline-15923107"
"The structure of affective action representations: temporal binding of affective response codes","Eder A. B., Musseler J., Hommel B.","Psychological Research","","Two experiments examined the hypothesis that preparing an action with a specific affective connotation involves the binding of this action to an affective code reflecting this connotation. This integration into an action plan should lead to a temporary occupation of the affective code which should impair the concurrent representation of affectively congruent events such as the planning of another action with the same valence. This hypothesis was tested with a dual-task setup that required a speeded choice between approach- and avoidance-type lever movements after having planned and before having executed an evaluative button press. In line with the code-occupation hypothesis slower lever movements were observed when the lever movement was affectively compatible with the prepared evaluative button press than when the two actions were affectively incompatible. Lever movements related to approach and avoidance and evaluative button presses thus seem to share a code that represents affective meaning. A model of affective action control that is based on the theory of event coding is discussed.","","","2012","10.1007/s00426-011-0327-6","","","medline-21442406.pdf","medline-21442406"
"Hydrods: data services in support of physically based, distributed hydrological models","Gichamo, T.z. And Sazib, N.s. And Tarboton, D.g. And Dash, P.","Environmental Modelling And Software","","Physically based distributed hydrologic models require geospatial and time-series data that take considerable time and effort in processing them into model inputs. Tools that automate and speed up input processing facilitate the application of these models. In this study, we developed a set of web-based data services called hydrods to provide hydrologic data processing ‘software as a service.’ Hydrods provides functions for processing watershed, terrain, canopy, climate, and soil data. The services are accessed through a python client library that facilitates developing simple but effective data processing workflows with python. Evaluations of hydrods by setting up the utah energy balance and topnet models for multiple headwater watersheds in the colorado river basin show that hydrods reduces the input preparation time compared to manual processing. It also removes the requirements for software installation and maintenance by the user, and the python workflows enhance reproducibility of hydrologic data processing and tracking of provenance. © 2020 elsevier ltd","","","2020","10.1016/j.envsoft.2020.104623","","","scopus-2-s2.0-85078225127.pdf","scopus-2-s2.0-85078225127"
"Using collaborative research to facilitate student learning","Thompson, C.j. And Mcneill, J.a. And Sherwood, G.d. And Starck, P.l.","Western Journal Of Nursing Research","","Developing research partnerships between academia and the service sector is an innovative way to meet the demand for high-quality, cost-effective, and clinically oriented research. Undergraduate student participation in clinical research is an educational strategy to facilitate positive mindsets toward research. This article outlines the methodological steps in recruiting and training undergraduate students for clinical research teams to benefit nurse educators, nurse researchers, students, and institutional partners. Student volunteers collected data for a study examining patient satisfaction with pain management practices. The research proposal was used to demonstrate principles of the research process and to familiarize the students with the study. A detailed study protocol guided the entire team through the project. Student sensitivity to pain assessment and management was enhanced. Learning the research process and the students' appreciation for the rigors of research were reinforced using this experiential model. Student evaluation of the research experience is presented.","","","2001","10.1177/01939450122045348","","","scopus-2-s2.0-0035434894.pdf","scopus-2-s2.0-0035434894"
"Octane (ontario-wide cancer targeted nucleic acid evaluation): a platform for intraprovincial, national, and international clinical data-sharing","Malone, E.r. And Saleh, R.r. And Yu, C. And Ahmed, L. And Pugh, T. And Torchia, J. And Bartlett, J. And Virtanen, C. And Hotte, S.j. And Hilton, J. And Welch, S. And Robinson, A. And Mccready, E. And Lo, B. And Sadikovic, B. And Feilotter, H. And Hanna, T.p. And Kamel-Reid, S. And Stockley, T.l. And Siu, L.l. And Bedard, P.l.","Current Oncology","","Cancer is a genetic disease resulting from germline or somatic genetic aberrations. Rapid progress in the field of genomics in recent years is allowing for increased characterization and understanding of the various forms of the disease. The ontario-wide cancer targeted nucleic acid evaluation (octane) clinical trial, open at cancer centres across ontario, aims to increase access to genomic sequencing of tumours and to facilitate the collection of clinical data related to enrolled patients and their clinical outcomes. The study is designed to assess the clinical utility of next-generation sequencing (ngs) in cancer patient care, including enhancement of treatment options available to patients. A core aim of the study is to encourage collaboration between cancer hospitals within ontario while also increasing international collaboration in terms of sharing the newly generated data. The single-payer provincial health care system in ontario provides a unique opportunity to develop a province-wide registry of ngs testing and a repository of genomically characterized, clinically annotated samples. It also provides an important opportunity to use province-wide real-world data to evaluate outcomes and the cost of ngs for patients with advanced cancer. The octane study is attempting to translate knowledge to help deliver precision oncology in a canadian environment. In this article, we discuss the background to the study and its implementation, current status, and future directions. © 2019 multimed inc.","","","2019","10.3747/co.26.5235","","","scopus-2-s2.0-85074252424.pdf","scopus-2-s2.0-85074252424"
"Current limitations in cyberbullying detection: on evaluation criteria, reproducibility, and data scarcity","Emmery, C. And Verhoeven, B. And De Pauw, G. And Jacobs, G. And Van Hee, C. And Lefever, E. And Desmet, B. And Hoste, V. And Daelemans, W.","Language Resources And Evaluation","","The detection of online cyberbullying has seen an increase in societal importance, popularity in research, and available open data. Nevertheless, while computational power and affordability of resources continue to increase, the access restrictions on high-quality data limit the applicability of state-of-the-art techniques. Consequently, much of the recent research uses small, heterogeneous datasets, without a thorough evaluation of applicability. In this paper, we further illustrate these issues, as we (i) evaluate many publicly available resources for this task and demonstrate difficulties with data collection. These predominantly yield small datasets that fail to capture the required complex social dynamics and impede direct comparison of progress. We (ii) conduct an extensive set of experiments that indicate a general lack of cross-domain generalization of classifiers trained on these sources, and openly provide this framework to replicate and extend our evaluation criteria. Finally, we (iii) present an effective crowdsourcing method: simulating real-life bullying scenarios in a lab setting generates plausible data that can be effectively used to enrich real data. This largely circumvents the restrictions on data that can be collected, and increases classifier performance. We believe these contributions can aid in improving the empirical practices of future research in the field. © 2020, the author(s).","","","2021","10.1007/s10579-020-09509-1","","","scopus-2-s2.0-85096126271.pdf","scopus-2-s2.0-85096126271"
"Espacomp medication adherence reporting guideline (emerge)","De Geest, S. And Zullig, L.l. And Dunbar-Jacob, J. And Helmy, R. And Hughes, D.a. And Wilson, I.b. And Vrijens, B.","Annals Of Internal Medicine","","Research on assessing or managing medication adherence applies approaches from observational, interventional, and implementation science that spans many disciplines and demands coherent conceptualization, valid methods, appropriate analyses, and complete and accurate reporting. To ensure such reporting, the european society for patient adherence, compliance, and persistence (espacomp) medication adherence reporting guideline (emerge) recommends standard reporting approaches based on an accepted taxonomy. This guideline is derived from a literature review, a reactive delphi study with 26 medication adherence experts from many countries and disciplines, and feedback from espacomp members. It is designed to supplement existing guidelines for health research reporting and is structured around 4 minimum reporting criteria and 17 items reflecting best reporting practice. By enhancing and harmonizing research reporting, emerge aims to advance research and, ultimately, patient outcomes. © 2018 american college of physicians.","","","2018","10.7326/m18-0543","","","scopus-2-s2.0-85049756982.pdf","scopus-2-s2.0-85049756982"
"Geoweaver_cwl: transforming geoweaver ai workflows to common workflow language to extend interoperability","Kale, A. And Sun, Z. And Fan, C. And Ma, X.","Applied Computing And Geosciences","","Recently, workflow management platforms are gaining more attention in the artificial intelligence (ai) community. Traditionally, researchers self-managed their workflows in a manual and tedious way that heavily relies on their memory. Due to the complexity and unpredictability of ai models, they often struggled to track and manage all the data, steps, and history of the workflow. Ai workflows are time-consuming, redundant, and error-prone, especially when big data is involved. A common strategy to make these workflows more manageable is to use a workflow management system, and we recommend geoweaver, an open-source workflow management system that enables users to create, modify and reuse ai workflows all in one place. To make our work in geoweaver reusable by the other workflow management systems, we created an add-on functionality geoweaver_cwl, a python package that automatically converts geoweaver ai workflows into the common workflow language (cwl) format. It will allow researchers to easily share, exchange, modify, reuse, and build a new workflow from existing ones in other cwl-compliant software. A user study was conducted with the existing workflows created by geoweaver to collect suggestions and fill in the gaps between our package and geoweaver. The evaluation confirms that geoweaver_cwl can lead to a well-versed ai process while disclosing opportunities for further extensions. The geoweaver_cwl package is publicly released online at https://pypi.org/project/geoweaver-cwl/0.0.1/. © 2023 the authors","","","2023","10.1016/j.acags.2023.100126","","","scopus-2-s2.0-85162006949.pdf","scopus-2-s2.0-85162006949"
"On the molecular basis of uracil recognition in DNA: comparative study of T-A versus U-A structure dynamics and open base pair kinetics","Fadda E., Pomes R.","Nucleic Acids Research","","Uracil (U) can be found in DNA as a mismatch paired either to adenine (A) or to guanine (G). Removal of U from DNA is performed by a class of enzymes known as uracil-DNA-glycosylases (UDG). Recent studies suggest that recognition of U-A and U-G mismatches by UDG takes place via an extra-helical mechanism. In this work we use molecular dynamics simulations to analyze the structure dynamics and open base pair kinetics of U-A base pairs relative to their natural T-A counterpart in 12 dodecamers. Our results show that the presence of U does not alter the local conformation of B-DNA. Breathing dynamics and base pair closing kinetics are only weakly dependent on the presence of U versus T with open T-A and U-A pairs lifetimes in the nanosecond timescale. Additionally we observed spontaneous base flipping in U-A pairs. We analyze the structure and dynamics for this event and compare the results to available crystallographic data of open base pair conformations. Our results are in agreement with both structural and kinetic data derived from NMR imino proton exchange measurements providing the first detailed description at the molecular level of elusive events such as spontaneous base pair opening and flipping in mismatched U-A sequences in DNA. Based on these results we propose that base pair flipping can occur spontaneously at room temperature via a 3-step mechanism with an open base pair intermediate. Implications for the molecular basis of U recognition by UDG are discussed.","","","2011","10.1093/nar/gkq812","","","medline-20876689.pdf","medline-20876689"
"Epics: a framework for enforcing security policies in composite web services","Ranchal, R. And Bhargava, B. And Angin, P. And Othmane, L.b.","Ieee Transactions On Services Computing","","With advances in cloud computing and the emergence of service marketplaces, the popularity of composite services marks a paradigm shift from single-domain monolithic systems to cross-domain distributed services, which raises important privacy and security concerns. Access control becomes a challenge in such systems because authentication, authorization and data disclosure may take place across endpoints that are not known to clients. The clients lack options for specifying policies to control the sharing of their data and have to rely on service providers which offer limited selection of security and privacy preferences. This lack of awareness and loss of control over data sharing increases threats to a client's data and diminishes trust in these systems. We propose epics, an efficient and effective solution for enforcing security policies in composite web services that protects data privacy throughout the service interaction lifecycle. The solution ensures that the data are distributed along with the client policies that dictate data access and an execution monitor that controls data disclosure. It empowers data owners with control of data disclosure decisions during interactions with remote services and reduces the risk of unauthorized access. The paper presents the design, implementation, and evaluation of the epics framework. © 2008-2012 ieee.","","","2019","10.1109/tsc.2018.2797277","","","scopus-2-s2.0-85040991113.pdf","scopus-2-s2.0-85040991113"
"Gaining insight into interdisciplinary research and education programmes: a framework for evaluation","Carr, G. And Loucks, D.p. And Blöschl, G.","Research Policy","","Greater understanding of how interdisciplinary research and education evolves is critical for identifying and implementing appropriate programme management strategies. In this paper a programme evaluation framework is presented. It is based on social learning processes (individual learning, interdisciplinary research practices, and interaction between researchers with different backgrounds);  social capital outcomes (ability to interact, interpersonal connectivity, and shared understanding);  and knowledge and human capital outcomes (new knowledge that integrates multiple research fields). The framework is illustrated on an established case study doctoral programme. Data are collected via mixed qualitative/quantitative methods to reveal several interesting findings about how interdisciplinary research evolves and can be supported. Firstly, different aspects of individual learning seem to contribute to a researcher's ability to interact with researchers from other research fields and work collaboratively. These include learning new material from different research fields, learning how to learn new material and learning how to integrate different material. Secondly, shared interdisciplinary research practices can be identified that may be common to other programmes and support interaction and shared understanding between different researchers. They include clarification and questioning, harnessing differences and setting defensible research boundaries. Thirdly, intensive interaction between researchers from different backgrounds support connectivity between the researchers, further enabling collaborative work. The case study data suggest that social learning processes and social capital outcomes precede new interdisciplinary research findings and are therefore a critical aspect to consider in interdisciplinary programme management. © 2017 the authors","","","2018","10.1016/j.respol.2017.09.010","","","scopus-2-s2.0-85033491209.pdf","scopus-2-s2.0-85033491209"
"Influences on evidence: putting the cart before the horse","Bero, L.","Journal And Proceedings Of The Royal Society Of New South Wales","","Conflicts of interest, particularly those related to financial gain, can influence policymaking, and mechanisms exist to try to minimize their impact on decisions. There has been a great deal of investigation and concern about the role of evidence in policymaking compared to other influences. But have we been putting the cart before the horse? Should we be paying more attention to what influences the evidence? Conflicts of interest can bias the design, methods, conduct, interpretation and publication of research. These biased findings deviate from the truth and have led decision makers to underestimate harms or overestimate effectiveness of interventions. The research community has responded by increasing transparency about the research enterprise. But this is not enough. We should strive to reduce the influence of conflicts of interest on research so we can have trustworthy evidence. © the royal society of nsw.","","","2018","","","","scopus-2-s2.0-85051278175.pdf","scopus-2-s2.0-85051278175"
"Involving patient research partners has a significant impact on outcomes research: a responsive evaluation of the international OMERACT conferences","de Wit M., Abma T., Koelewijn-van Loon M., Collins S., Kirwan J.","BMJ Open","","OBJECTIVE: To assess the inclusion of patients as international research partners in Outcome Measures in Rheumatology (OMERACT) conferences and how this has influenced the scope and conduct of outcomes research in rheumatology.\\\\\\\\rDESIGN: A thematic content analysis of OMERACT internal documents publications and conference proceedings followed by a responsive evaluation including 32 qualitative semistructured interviews.\\\\\\\\rSETTING: The international biannual research conference OMERACT 10 (Malaysia 2010).\\\\\\\\rPARTICIPANTS: Senior researchers (n=10) junior researchers (n=2) representatives of the pharmaceutical industry and regulators (n=2) conference staff (n=2) new patient delegates (n=8) and experienced patient delegates (n=8).\\\\\\\\rRESULTS: The role of patients evolved over 10 years from a single patient focus group to full participation in all areas of the meeting and inclusion in research group meetings between conferences. Five main categories of impact emerged: widening the research agenda; including patient relevant outcomes in core sets; enhancing patient reported instruments; changing the culture of OMERACT and consequences outside OMERACT. Patient participants identified previously neglected outcome domains such as fatigue sleep disturbances and flares which prompted collaborative working on new programmes of research. Specific benefits and challenges for patients and professionals were identified such as personal fulfilment widening of research interests difficulties in establishing equal partnerships and concerns about loss of research rigour.\\\\\\\\rCONCLUSIONS: Including patients as partners in OMERACT conferences has widened its focus and adjusted the way of working. It has resulted in new developments in the research agenda and the use of more patient-relevant outcomes in clinical trials. These collaborations have influenced perceptions and beliefs among many patients and researchers and led to wider patient involvement as partners in research.","","","2013","10.1136/bmjopen-2012-002241","","","medline-23667160.pdf","medline-23667160"
"Fall definitions faller classifications and outcomes used in falls research among people with multiple sclerosis: a systematic review","O'Malley N., Clifford A. M., Comber L., Coote S.","Disability & Rehabilitation","","PURPOSE: To identify the definitions of a fall faller classifications and outcomes used in prospectively-recorded falls research among people with Multiple Sclerosis (MS).\\\\\\\\rMETHODS: A systematic review of peer-reviewed journal articles was conducted using electronic databases. Relevant data were extracted by one reviewer and verified by a second independent reviewer.\\\\\\\\rRESULTS: Twenty-six papers met the inclusion criteria. A relative degree of heterogeneity existed amongst studies for the outcomes of interest to this review. Thirteen different fall definitions were identified. Fourteen different falls outcomes were used across the included studies with six of these reported by only one study each. Data regarding injurious falls were presented by only eight papers. The majority (n = 17) of papers classified individuals as a faller if they fell at least once.\\\\\\\\rCONCLUSIONS: This review highlights the large variation in fall definitions faller classifications and outcomes used in this research field. This hinders cross-comparison and pooling of data thereby preventing researchers and clinicians from drawing conclusive findings from existing literature. The creation of an international standard for the definition of a fall faller classification and falls outcomes would allow for transparent and coordinated falls research for people with MS facilitating progression in this research field.Implications for rehabilitationFalls are a common occurrence among people with Multiple Sclerosis (MS) resulting in numerous negative consequences. There is large heterogeneity in the definitions methods and outcomes used in falls research for people with MS. This lack of standardisation prevents the accurate cross-comparison and pooling of data impeding the identification of falls risk factors and effective falls prevention interventions for people with MS.Consequently clinicians should interpret the outcomes of falls research for people with MS with caution particularly when comparing studies regarding falls risk assessments and falls prevention interventions for use in clinical practice.","","","2022","10.1080/09638288.2020.1786173","","","medline-32628889.pdf","medline-32628889"
"The quality of reporting of orthopaedic randomized trials with use of a checklist for nonpharmacological therapies","Chan S., Bhandari M.","Journal of Bone & Joint Surgery - American Volume","","BACKGROUND: The Consolidated Standards of Reporting Trials statement for the reporting of randomized controlled trials has been limited by its applicability to surgical trials. In response a Checklist to Evaluate a Report of a Nonpharmacological Trial was recently developed by the Consolidated Standards of Reporting Trials group to address reporting issues in surgical trials. We aimed (1) to apply the checklist for nonpharmacological therapies to orthopaedic randomized controlled trials across multiple journals from 2004 through 2005 and (2) to survey authors when methodological safeguards itemized in the checklist were not reported to determine whether they actually had been performed. We hypothesized that lack of reporting of a methodological safeguard did not necessarily mean it had not been conducted.\\\\\\\\rMETHODS: We searched for relevant orthopaedic randomized controlled trials across eight journals in the period from January 2004 through December 2005. We applied the Checklist to Evaluate a Report of a Nonpharmacological Trial to all eligible studies. We contacted authors to determine what methodological safeguards were actually used especially when details remained unclear from the publication.\\\\\\\\rRESULTS: We included eighty-seven randomized controlled trials from eighty-five scientific reports. In assessing the randomized controlled trials with the checklist for nonpharmacological therapies seventy-three studies (84%) had unclear reporting of treatment allocation concealment. Only seventeen studies (20%) mentioned surgeon skill or experience. The blinding of patients ward staff rehabilitation staff clinical outcome assessors and nonclinical outcome assessors was unclear in forty-eight (55%) sixty-three (72%) sixty-four (74%) forty (46%) and thirty-three studies (38%) respectively. Authors from forty-three randomized controlled trials responded to our survey. The results of the survey showed that 41% (95% confidence interval 25% to 58%) of the trials had adequate allocation concealment when this had been unclear from the report. Although the surgical experience of the investigators was rarely reported most authors (70%) acknowledged that they had defined ""surgical expertise criteria"" such as minimum case criteria specialized training and clinical performance. The survey also showed that 28% to 40% of the trials had blinding of relevant groups despite the fact that the reporting of such blinding had been unclear in the publications.\\\\\\\\rCONCLUSIONS: The quality of reporting in the orthopaedic literature was highly variable. Readers should not assume that bias-reducing safeguards that were not reported in a randomized controlled trial did not occur. Our study reinforces the need for the consistent use of a tool like the Checklist to Evaluate a Report of a Nonpharmacological Trial to assess the methodology of surgical trials.","","","2007","10.2106/jbjs.f.01591","","","medline-17768194.pdf","medline-17768194"
"Modelling digital circular economy framework in the agricultural sector. An application in southern italy †","Crovella, T. And Paiano, A. And Lagioia, G. And Cilardi, A.m. And Trotta, L.","Engineering Proceedings","","The transition towards circular economy (ce) in agriculture requires a large amount of data in order to map the consumption of natural resources and negative externalities. This paper aims to identify a digital framework for collecting and sharing data fundamental for stakeholders with the purpose of implementing the best ce model. The methodology used is based on the guidelines of the stakeholder engagement and through a survey, and the authors have mapped the lack of data and built a set by replicable sustainability indicators. The results obtained can be used for the definition of regional policy strategies and interventions for ce model implementation. © 2021 by the authors.","","","2021","10.3390/engproc2021009015","","","scopus-2-s2.0-85129889777.pdf","scopus-2-s2.0-85129889777"
"Compiler-directed code restructuring for improving performance of mpsocs","Chen, G. And Kandemir, M.","Ieee Transactions On Parallel And Distributed Systems","","One of the critical goals in code optimization for multi-processor-system-on-a-chip (mpsoc) architectures is to minimize the number of off-chip memory accesses. This is because such accesses can be extremely costly from both performance and power angles. While conventional data locality optimization techniques can be used for improving data access pattern of each processor independently, such techniques usually do not consider locality for shared data. This paper proposes a strategy that reduces the number of off-chip references due to shared data. It achieves this goal by restructuring a parallelized application code in such a fashion that a given data block is accessed by parallel processors within the same time frame, so that its reuse is maximized while it is in the on-chip memory space. This tends to minimize the number of off-chip references since the accesses to a given data block are clustered within a short period of time during execution. Our approach employs a polyhedral tool that helps us isolate computations that manipulate a given data block. In order to test the effectiveness of our approach, we implemented it using a publicly-available compiler infrastructure and conducted experiments with twelve data-intensive embedded applications. Our results show that optimizing data locality for shared data elements is very useful in practice. © 2008 ieee.","","","2008","10.1109/tpds.2007.70760","","","scopus-2-s2.0-49349089791.pdf","scopus-2-s2.0-49349089791"
"Data integration for materials research","Carey, N.s. And Budavári, T. And Daphalapurkar, N. And Ramesh, K.t.","Integrating Materials And Manufacturing Innovation","","Introduction: a new data science initiative in materials research has been launched at the johns hopkins university within the materials in extreme dynamic environments (mede) collaborative research alliance (cra). Our first goal is to build a solution that facilitates seamless data sharing among mede scientists. We expect to shorten the design and development cycle of new materials by providing integrated storage, database, and analysis services, building on proven components of the sciserver project developed at the institute for data intensive engineering and science (idies). Case description: here we present our system design and demonstrate the power of our approach through a use-case that enables easy comparison of simulations and measurements. This prototype effort, focusing on boron carbide (bc), brings together multiple materials research elements in the ceramics group within the mede cra. Discussion and evaluation: the sciserver platform offers single-sign on access to various general purpose data analysis tools familiar to materials scientists in mede. During the case study deployment, users appreciated the simple data file upload process, automated database ingestion, and platform applicability to both students of the art and power users. Conclusions: from our case study experience in aggregating data from both simulations and physical experiments, we developed a template workflow from which a user may run a common data comparison task outright or customize to another purpose. Next, we turn to acquiring data from more mede groups and expanding the user base to the metals group. © 2016, carey et al.","","","2016","10.1186/s40192-016-0049-0","","","scopus-2-s2.0-85051593274.pdf","scopus-2-s2.0-85051593274"
"Agree-s: agree ii extension for surgical interventions – united european gastroenterology and european association for endoscopic surgery methodological guide","Logullo, P. And Florez, I.d. And Antoniou, G.a. And Markar, S. And López-Cano, M. And Silecchia, G. And Tsokani, S. And Mavridis, D. And Brouwers, M. And Antoniou, S.a. And Sami Abdel Dayem Amer, Y. And Bertolaccini, L. And Alonso-Coello, P. And Akl, E.a. And Chand, M. And Como, J.j. And De Borst, G.j. And Di Saverio, S. And Emile, S. And Eom, B.w. And Gorter, R. And Hanna, G. And Immonen, K. And Lai, Q. And Lumen, N. And Mathew, J.l. And Montendori, A. And Moya, M. And Pellino, G. And Sanabria, A. And Saratzis, A. And Smart, N. And Stefanidis, D. And Zaninotto, G. And The Gap Consortium And The Gap Consortium","United European Gastroenterology Journal","","Background: the appraisal of guidelines for research and evaluation (agree) ii instrument has been developed to inform the methodology, reporting and appraisal of clinical practice guidelines. Evidence suggests that the quality of surgical guidelines can be improved, and the structure and content of agree ii can be modified to help enhance the quality of guidelines of surgical interventions. Objective: to develop an extension of agree ii specifically designed for guidelines of surgical interventions. Methods: in the tripartite guideline assessment project (gap) funded by united european gastroenterology and the european association for endoscopic surgery, (i) we assessed the quality of surgical guidelines and we identified factors associated with higher quality (gap i);  (ii) we applied correlation analysis, factor analysis and the item response theory to inform an adaption of agree ii for the purposes of surgical guidelines (gap ii);  and (iii) we developed an agree ii extension for surgical interventions, informed by the results of gap i, gap ii, and a delphi process of stakeholders, including representation from interventional and surgical disciplines;  the guideline international network (gin);  the grading of recommendations assessment, development and evaluation (grade) working group;  the enhancing the quality and transparency of health research (equator) initiative;  and representation of surgical journal editors and patient/public. Results: we developed agree-s, an agree ii extension for surgical interventions, which comprises 24 items organized in 6 domains;  scope and purpose, stakeholders, evidence synthesis, development of recommendations, editorial independence, and implementation and update. The panel of stakeholders proposed 3 additional items: development of a guideline protocol, consideration of practice variability and surgical/interventional expertise in different settings, and specification of infrastructures required to implement the recommendations. Three of the existing items were amended, 7 items were rearranged among the domains, and one item was removed. The domain rigour of development was divided into domains on evidence synthesis and development of recommendations. The new domain development of recommendations incorporates items from the original agree ii domain clarity of presentation. Conclusion: agree-s is an evidence-based and stakeholder-informed extension of the agree ii instrument, that can be used as a guide for the development and adaption of guidelines on surgical interventions. © 2022 the authors. United european gastroenterology journal published by wiley periodicals llc on behalf of united european gastroenterology.","","","2022","10.1002/ueg2.12231","","","scopus-2-s2.0-85129399070.pdf","scopus-2-s2.0-85129399070"
"A parallel and forward private searchable public-key encryption for cloud-based data sharing","Chen, B. And Wu, L. And Li, L. And Choo, K.-K.r. And He, D.","Ieee Access","","Data sharing through the cloud is flourishing with the development of cloud computing technology. The new wave of technology will also give rise to new security challenges, particularly the data confidentiality in cloud-based sharing applications. Searchable encryption is considered as one of the most promising solutions for balancing data confidentiality and usability. However, most existing searchable encryption schemes cannot simultaneously satisfy requirements for both high search efficiency and strong security due to lack of some must-have properties, such as parallel search and forward security. To address this problem, we propose a variant searchable encryption with parallelism and forward privacy, namely the parallel and forward private searchable public-key encryption (pfp-spe). Pfp-spe scheme achieves both the parallelism and forward privacy at the expense of slightly higher storage costs. Pfp-spe has similar search efficiency with that of some searchable symmetric encryption schemes but no key distribution problem. The security analysis and the performance evaluation on a real-world dataset demonstrate that the proposed scheme is suitable for practical application. © 2013 ieee.","","","2020","10.1109/access.2020.2971089","","","scopus-2-s2.0-85081105298.pdf","scopus-2-s2.0-85081105298"
"Atri edc: a novel cloud-native remote data capture system for large multicenter alzheimer's disease and alzheimer's disease-related dementias clinical trials","Jimenez-Maggiora, G.a. And Bruschi, S. And Qiu, H. And So, J.-S. And Aisen, P.s.","Jamia Open","","Objective: the alzheimer's therapeutic research institute (atri) developed a novel clinical data management system, the atri electronic data capture system (atri edc), to address the complex regulatory, operational, and data requirements that arise in the conduct of multicenter alzheimer's disease and alzheimer's disease-related dementias (ad/adrds) clinical trials. We describe the system, its utility, and the broader implications for the field of clinical trials and clinical research informatics. Materials and methods: the atri edc system was developed, tested, and validated using community-based agile software development methods and cloud-native single-page application design principles. It offers an increasing number of application modules, supports a high degree of study-specific configuration, and empowers study teams to effectively communicate and collaborate on the accurate and timely completion of study activities. Results: to date, the atri edc system supports 10 clinical studies, collecting study data for 4596 participants. Three case descriptions further illustrate how the system's capabilities support diverse study-specific requirements. Discussion: the atri edc system has several advantages: its modular capabilities can accommodate rapidly evolving research designs and technologies;  its community-based agile development approach and community-friendly licensing model encourage collaboration per the principles of open science;  finally, with continued development and community building efforts, the system has the potential to facilitate the effective conduct of clinical studies beyond the field of ad/adrd. Conclusion: by effectively addressing the requirements of multicenter ad/adrd studies, the atri edc system supports atri's scientific mission of rigorously testing new ad/adrd therapies and facilitating the effective conduct of multicenter clinical studies. © 2022 the author(s).","","","2022","10.1093/jamiaopen/ooab119","","","scopus-2-s2.0-85133152206.pdf","scopus-2-s2.0-85133152206"
"Stability of gene rankings from RNAi screens","Siebourg J., Merdes G., Misselwitz B., Hardt W. D., Beerenwinkel N.","Bioinformatics","","MOTIVATION: Genome-wide RNA interference (RNAi) experiments are becoming a widely used approach for identifying intracellular molecular pathways of specific functions. However detecting all relevant genes involved in a biological process is challenging because typically only few samples per gene knock-down are available and readouts tend to be very noisy. We investigate the reliability of top scoring hit lists obtained from RNAi screens compare the performance of different ranking methods and propose a new ranking method to improve the reproducibility of gene selection.\\\\\\\\rRESULTS: The performance of different ranking methods is assessed by the size of the stable sets they produce i.e. the subsets of genes which are estimated to be re-selected with high probability in independent validation experiments. Using stability selection we also define a new ranking method called stability ranking to improve the stability of any given base ranking method. Ranking methods based on mean median t-test and rank-sum test and their stability-augmented counterparts are compared in simulation studies and on three microscopy image RNAi datasets. We find that the rank-sum test offers the most favorable trade-off between ranking stability and accuracy and that stability ranking improves the reproducibility of all and the accuracy of several ranking methods.\\\\\\\\rAVAILABILITY: Stability ranking is freely available as the R/Bioconductor package staRank at http://www.cbg.ethz.ch/software/staRank.","","","2012","10.1093/bioinformatics/bts192","","","medline-22513992.pdf","medline-22513992"
"National collaboration in geo-spatial information: narssgeoportal case study","Ibrahim, R.e. And Elramly, A.","Spatial Information Research","","The egyptian government is seeking collaboration between the authorities to build a data sharing platform to support the national development projects. The development projects need to be planned, managed and monitored in addition to the ongoing egyptian economy support. However, the current management structure will not be able to manage national resources effectively without access to adequate information, analysis tools, and monitoring systems. National authority for remote sensing and space sciences (narss) took the initiatives and developed a platform for the national collaboration to share the geo-spatial information required for e-government and the sustainable development. Narss extended the efforts and built a full proposal for the “national collaboration for sustainable development spatial decision support portal”. Then, the proposal was communicated to a high level committee between the interested authorities to proceed forward with the proposed project. The research process was inherently intermixed design, building and evaluation of the platform. The process was also developed within collaborative and organizational context. Multiple research channels were employed in order to collect data that was necessary for delivering the project results such as memos, progress reports and prototypes. As a result, narssgeoportal was successfully developed in accordance with the government authorities’ needs. This paper presents a case study showing the developed approach to build the geospatial data sharing systems required to provide support for the nationwide development. The paper also discusses the challenges during the implementation phase and provides the recommendations that should be taken into consideration during planning. © 2017, korean spatial information society.","","","2017","10.1007/s41324-017-0098-2","","","scopus-2-s2.0-85031938794.pdf","scopus-2-s2.0-85031938794"
"Parental perspectives on consent for participation in large-scale, non-biological data repositories","Manhas K.p. And Page S. And Dodd S.x. And Letourneau N. And Ambrose A. And Cui X. And Tough S.c.","Life Sci Soc Policy","","Background: data sharing presents several challenges to the informed consent process. Unique challenges emerge when sharing pediatric or pregnancy-related data. Here, parent preferences for sharing non-biological data are examined., methods: groups (n=4 groups, 18 participants) and individual interviews (n=19 participants) were conducted with participants from two provincial, longitudinal pregnancy cohorts (aob and apron). Qualitative content analysis was applied to transcripts of semi-structured interviews., results: participants were supportive of a broad, one-time consent model or a tiered consent model. These preferences were grounded in the perceived obligations for reciprocity and accuracy. Parents want reciprocity among participants, repositories and researchers regarding respect and trust. Furthermore, parents' worry about the interrelationships between the validity of the consent processes and secondary data use., conclusions: though parent participants agree that their research data should be made available for secondary use, they believe their consent is still required. Given their understanding that obtaining and informed consent can be challenging in the case of secondary use, parents agreed that a broad, one-time consent model was acceptable, reducing the logistical burden while maintaining respect for their contribution. This broad model also maintained participant trust in the research and secondary use of their data. The broad, one-time model also reflected parents' perspectives surrounding child involvement in the consent process. The majority of parents felt decision made during childhood were the parents responsibility and should remain in parental purview until the child reaches the age of majority.","","","2016","10.1186/s40504-016-0034-6","","","embase-615999061.pdf","embase-615999061"
"Impact of new Food and Drug Administration regulations on college university and experiment station researchers","Willett L. B.","Journal of Dairy Science","","The Good Laboratory Practice regulations adopted by the Food and Drug Administration describe specific procedures to assure the integrity of the research results. Those studies conducted with the intent to provide data on the safety of drugs and chemicals will be required to comply with the published relations. The process of bringing research laboratories into compliance with the regulations may be either arduous or fairly routine depending on the organization goals and type of research. Typically the Good Laboratory Practice regulations will increase sharply the cost of health safety information. Hiring more and better trained technical and professional personnel will be much of this expense. If university and experiment station researchers choose to avoid compliance with these regulations then agricultural research science may not continue to be recognized as an authority on the safety of products used for production of human food. Irrespective of whether universities choose to conduct regulated research or delegate this role to other segments of society academic institutions must assume the role of training those individuals needed to conduct toxicity research.","","","1981","10.3168/jds.s0022-0302(81)82781-6","","","medline-7320313.pdf","medline-7320313"
"Competitive communities of practice, knowledge sharing, and machiavellian participation: a case study","Schofield, K. And Analoui, B. And Brooks, J. And Hussain, S.f.","International Journal Of Training And Development","","This paper explores the emergence of machiavellian behaviour in a community of practice (cop). The cop was initiated by the top management team (tmt) as a management development initiative. Participants in a manufacturing setting were encouraged to engage in a series of problem-solving tasks with counterparts from across the organization in a short-term cop. A qualitative case study, using in-depth interviews, was conducted in a large processing plant in the middle eastern kingdom of bahrain. This is an empirical case study that explores employee participation in a short-term management development programme which sought to create cops to enable knowledge sharing. A competitive element was introduced, and we contend this promoted behaviour which served the individuals rather than the cop. The findings indicate that tmt intervention changes the dynamics of cops, reducing knowledge sharing and collaboration among community members. Recommendations are made to practitioners to be cognizant of the possibility of machiavellian participation in cops. © 2018 brian towers (britow) and john wiley & sons ltd.","","","2018","10.1111/ijtd.12129","","","scopus-2-s2.0-85050454802.pdf","scopus-2-s2.0-85050454802"
"On the evaluation of progressive point-sampled geometry","Liu, Y.-J.","International Journal Of Image And Graphics","","Nowadays, point set surfaces have attracted much research attention due to the widespread laser range scanners. In this paper we evaluate several well known methods in terms of progressive point-sampled geometry. The selection of these methods is based on a classification of different surface representations. To serve as a common basis for comparison, a general progressive framework is adopted. The comparison has been done with both data from graphics and cad models. In addition to surface reconstruction quality and time and space efficiency, several other properties inherent in point sampled geometry, such as sharp feature preservation and data density uniformness, are also considered in the evaluation of progressive geometry. © 2010 world scientific publishing company.","","","2010","10.1142/s0219467810003676","","","scopus-2-s2.0-85073156360.pdf","scopus-2-s2.0-85073156360"
"Predictive power of wastewater for nowcasting infectious disease transmission: A retrospective case study of five sewershed areas in Louisville Kentucky","Klaassen F., Holm R. H., Smith T., Cohen T., Bhatnagar A., Menzies N. A.","Environmental Research","","BACKGROUND: Epidemiological nowcasting traditionally relies on count surveillance data. The availability and quality of such count data may vary over time limiting representation of true infections. Wastewater data correlates with traditional surveillance data and may provide additional value for nowcasting disease trends.\\\\\\\\rMETHODS: We obtained SARS-CoV-2 case death wastewater and serosurvey data for Jefferson County Kentucky (USA) between August 2020 and March 2021 and parameterized an existing nowcasting model using combinations of these data. We assessed the predictive performance and variability at the sewershed level and compared the effects of adding or replacing wastewater data to case and death reports.\\\\\\\\rFINDINGS: Adding wastewater data minimally improved the predictive performance of nowcasts compared to a model fitted to case and death data (Weighted Interval Score (WIS) 0.208 versus 0.223) and reduced the predictive performance compared to a model fitted to deaths data (WIS 0.517 versus 0.500). Adding wastewater data to deaths data improved the nowcasts agreement to estimates from models using cases and deaths data. These findings were consistent across individual sewersheds as well as for models fit to the aggregated total data of 5 sewersheds. Retrospective reconstructions of epidemiological dynamics created using different combinations of data were in general agreement (coverage >75%).\\\\\\\\rINTERPRETATION: These findings show wastewater data may be valuable for infectious disease nowcasting when clinical surveillance data are absent such as early in a pandemic or in low-resource settings where systematic collection of epidemiologic data is difficult. Copyright © 2023 The Authors. Published by Elsevier Inc. All rights reserved.","","","2024","10.1016/j.envres.2023.117395","","","medline-37838198.pdf","medline-37838198"
"Knowledge sharing in emerging economies","Burke, M.e.","Library Review","","One of the new factors in eastern european countries (and there is an acknowledgement that this aspect is displayed in other countries too) is this concept of freely sharing information, i.e. the concept of what is known in knowledge management (km) literature of “knowledge sharing”. Sharing only takes place where there is trust and where there is a shared feeling of ownership of goals. The reasons behind the tendency to share are based on the kind of interpersonal relations between co-workers inherent within the organization and the effects of social relationships within organizational teams. Strengthening the social relationships between individuals in the team is crucial in motivating team members to share knowledge. The purpose of this paper is to add to the understanding of how km impacts on an small- to medium-sized enterprise (sme) and create a framework of best practice of km in smes. New research is currently investigating the concept of “sharing social relationships” and one of the aims of the project is to investigate the barriers to sharing information in a particular type of business — that of the (sme) in order to form a comparative study. The results of the study will be used to from a model of “information sharing best practice” for sme which are setting up or using km systems. The paper will examine the barriers to sharing in two newly emerging economies (poland and hungary) and one relatively established economy (the uk). At the time of writing, the work with poland and hungary has been completed and this paper gives the initial results from the hungarian study. The findings are complex and varied but in the case of the hungarian results there is a clear energy, enthusiasm and commitment to knowledge sharing in order to ensure the success of the business. Emerging economies are by their nature changing economies and so this work forms a snapshot of life at a particular moment in time. The paper shows that there is a need for an increase in training, and that government support is helpful and enabling. Knowledge sharing is important and the study described in the paper will allow cross comparisons between different countries. It is intended that a model of best practice will be one of the outcomes of the project. © 2011, emerald group publishing limited","","","2011","10.1108/00242531111100531","","","scopus-2-s2.0-79551670365.pdf","scopus-2-s2.0-79551670365"
"Analyzing interactional contexts in a data-sharing focus group","Murdoch J., Poland F., Salter C.","Qualitative Health Research","","In this article we describe the use of a data-sharing focus group for triangulation with face-to-face interviews. In contrast to member-checking triangulation this focus group was undertaken to provide a different interactional context to analyze moral discourses in talk about asthma medicine taking. Using principles of discursive psychology to analyze data participants adopted strategies to manage dilemmas of identification with research findings. Talk about medicine taking was contextualized to the demands of the interaction. Strategies included avoiding direct reference to findings; collectively aligning with medical perspectives; and using stories to carry opinions. Participants also expressed moral discourses around managing asthma in everyday life. These discursive variations strengthened assertions of the role of morality in participants' talk and highlighted advantages in engaging with participants' strategies in focus groups. Different viewpoints identified in this research create problems for member checking suggesting that researchers need to be sensitive in considering methods of sharing data with participants.","","","2010","10.1177/1049732310361612","","","medline-20154297.pdf","medline-20154297"
"You ain’t seen nothing yet transparency’s (lack of) effect on source and message credibility","Karlsson, M. And Clerwall, C. And Nord, L.","Journalism Studies","","It has been suggested that transparency will change the way journalism is being produced as well as increase its credibility. However, little research has been conducted to assess the connection between transparency and credibility. This study utilizes an experimental setting with 1320 respondents to measure what impact transparency has on source and message credibility from a user perspective. The results reveal an almost total absence of any transparency effect on either source or message credibility, although some small significant effects could be observed primarily regarding internal hyperlinks, comments and contextual information. Although further research is needed in this area, the study suggests that transparency does not affect the credibility of journalism in the eyes of the contemporary audience and thus has limited appeal as a new norm in journalism. © 2014 taylor & francis.","","","2014","10.1080/1461670x.2014.886837","","","scopus-2-s2.0-85013760773.pdf","scopus-2-s2.0-85013760773"
"Data governance and the need for organization-wide guidance to enable and facilitate data sharing: lessons learned from north carolina","Proescholdbell, S. And Geary, S. And Tenenbaum, J.d.","Journal Of Public Health Management And Practice","","Public health agencies’ core mission is to protect the health of the general population. Critical to this mission is utilizing data to better understand public health problems, identify risk and protective factors, identify intervention opportunities for prevention, and evaluate impact. Yet, historically, data sharing, even between internal partners within an agency, has often been cumbersome due to organizational history, culture, silos, and lack of clear guidance. These initial barriers and challenges can doom even simple data sharing efforts with clear public health value and cast a shroud on an already complex and challenging process. Copyright © 2022 wolters kluwer health, inc. All rights reserved.","","","2022","10.1097/phh.0000000000001553","","","scopus-2-s2.0-85135202395.pdf","scopus-2-s2.0-85135202395"
"Societal impact of university research in the written press: media attention in the context of SIUR and the open science agenda among social scientists in Flanders Belgium","Jonker H., Vanlee F., Ysebaert W.","Scientometrics","","Transferring scientific knowledge to non-academic audiences is an essential aspect of the open science agenda which calls for scholars to pursue a popularization of their research. Accordingly purposefully introducing scientific insights to the public at large is almost univocally deemed commendable. Indeed in today's models of research evaluation the objects and activities considered are being extended beyond peer-reviewed journal articles to include non-scholarly popular communication. Although altmetrics offer one instrumental way to count some interactions with lay audiences their reliance on social media makes them susceptible to manipulation and mostly reflect circulation among niche audiences. In comparison attention from non-scholarly media like newspapers and magazines seems a more relevant pathway to effectuate societal impact due to its recognition in qualitative assessment tools and its broad societal reach. Based on a case study of social scientists' attention by newspapers and magazines in Flanders (northern Dutch-speaking region of Belgium) in 2019 this paper highlights that frequent participation in the public debate is reserved for high-status researchers only. Results show highly skewed media appearance patterns in both career position and gender as eight male professors accounted for almost half of all 2019 media attention for social scientists. Because media attention is highly subject-dependent moreover certain disciplines and fields offer easier pathways to popularization in media than others. Both the open science agenda and research assessment models value presence of researchers in popular media adding written press attention to existing evaluation assessments however would disproportionately disadvantage early career researchers and exacerbate existing inequalities in academia.\\\\\\\\rSupplementary Information: The online version contains supplementary material available at 10.1007/s11192-022-04374-x. Copyright © Akademiai Kiado Budapest Hungary 2022.","","","2022","10.1007/s11192-022-04374-x","","","medline-35502440.pdf","medline-35502440"
"Motivations and fears driving participation in collaborative research infrastructure for animal tracking","Crewe T.l. And Kendal D. And Campbell H.a.","Plos One","","Anthropogenic derived environmental change is challenging earth's biodiversity. To implement effective management, it is imperative to understand how organisms are responding over broad spatiotemporal scales. Collection of these data is generally beyond the budget of individual researchers and the integration and sharing of ecological data and associated infrastructure is becoming more common. However, user groups differ in their expectations, standards of performance, and desired outputs from research investment, and accommodating the motivations and fears of potential users from the outset may lead to higher levels of participation. Here we report upon a study of the australian ornithology community, which was instigated to better understand perceptions around participation in nationally coordinated research infrastructure for detecting and tracking the movement of birds. The community was surveyed through a questionnaire and individuals were asked to score their motivations and fears around participation. Principal components analysis was used to reduce the dimensionality of the data and identify groups of questions where respondents behaved similarly. Linear regressions and model selection were then applied to the principal components to determine how career stage, employment role, and years of biotelemetry experience affected the respondent's motivations and fears for participation. The analysis showed that across all sectors (academic, government, ngo) there was strong motivation to participate and belief that national shared biotelemetry infrastructure would facilitate bird management and conservation. However, results did show that a cross-sector cohort of the australian ornithology community were keen and ready to progress collaborative infrastructure for tracking birds, and measures including data-sharing agreements could increase participation. It also informed that securing initial funding would be a significant challenge, and a better option to proceed may be for independent groups to coordinate through existing database infrastructure to form the foundation from which a national network could grow.copyright © 2020 crewe et al. This is an open access article distributed under the terms of the creative commons attribution license, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","","2020","10.1371/journal.pone.0241964","","","embase-2010139047.pdf","embase-2010139047"
"Mobile data sharing and high availability","Hongisto, M.","Vtt Tiedotteita - Valtion Teknillinen Tutkimuskeskus","","This work introduces a model for decentralised and platform-independent data sharing for highly dynamic networks. The goal is not to deliver a solution that can be considered similar to database systems. Communication and replication challenges are presented and examined from the perspective of nomadic computing. The aim has been to provide highly available data sharing over features over mobile distributed systems. The primary functionality of the data-sharing model introduced here has been validated with simulations. A fully functional data-sharing model has been implemented and tested in a simulated environment. A simulated environment was chosen over real network conditions in order to offer data distribution pattern tracking in several different network topologies and environments. This study provides understanding of the data sharing factors that are important in decentralised distribution models. These factors include location determination for replica storing and control message propagation over weak connections. Smart data distribution is crucial for weakly connected networks to offer access to shared resources. In heterogeneous environments, it is also necessary to consider possible transmission resource savings, and an idea for partitioning data into small elements is introduced. A data distribution algorithm based on this understanding is designed and evaluated. According to technology surveys and the evaluation of data sharing implementation, it is clear that the optimistic replication schema is the choice for data distribution over weakly connected networks. This requires conflict solving for eventual consistency, or any equivalent method to provide the correct operation for applications. A decentralised data management model is the best alternative to operate in weakly connected networks, as it is able to function regardless of network partitions. The data sharing approach presented here provides full adaptability to different network topologies and computing platforms, and it is able to offer data sharing services for any device to some degree. A decentralised data sharing approach introduces new challenges;  these are discussed, and their viability for implementation is estimated. Copyright © vtt 2002.","","","2002","","","","scopus-2-s2.0-84884717935.pdf","scopus-2-s2.0-84884717935"
"[""Probiotic medicine"" and certainty of the evidence.]","Koch M., Capurso L.","Recenti Progressi in Medicina","","These are excellent times for probiotic medicine. We have discovered more than 150000 genomes of the microbiome which can be aggregated into 4930 species. However the dream of microbiome-based medicine requires a new approach - an ecological and evolutionary understanding of host-microbe interactions rather than a qualitative analysis of species. Yet researchers still disagree on what constitutes a healthy microbiome or how to define an altered one. There is still uncertainty as to which properties of the microbiome will represent the most informative biomarkers in clinical and epidemiological studies. And little is known about how the microbiomes of different regions of the body such as the mouth intestines or skin interact. It is time to re-establish the foundations for the certainty of evidence in myocrobiome-based medicine. We believe robust new pillars are needed: starting clinical trials whenever possible; extending the role of N-of-1 trials; ending the ""one probiotic for every disease"" principle; reduce the number of outcomes of each research; search for the replicability of the results (the best test for the validity of an intervention with probiotics is not statistical significance but the replication of the result). Again we would like to urge probiotic medicine researchers not to publish in ""pirate"" journals.","","","2021","10.1701/3551.35253","","","medline-33576347.pdf","medline-33576347"
"Developing generalized sampling schemes with known error properties: the case of a moving observer","Takashina, N. And Economo, E.p.","Ecography","","Pattern in space and time is central to ecology, and adequately designed ecological sampling is needed to resolve those patterns, pursue ecological questions and design conservation strategies. Recently, there has been an explosion of various ecological data due to the proliferation of online data-sharing platforms, citizen science programs and new technology such as unmanned aerial vehicles (uavs), but data reliability, consistency and the error properties of the sampling method are usually uncertain. While there are a number of standard survey protocols for different taxa, they often subjectively designed and standardization is meant to facilitate repeatability rather than produce a quantitative evaluation of the data (e.g. error properties). Here, we describe an ecological survey scheme consisting of an ‘algorithm' to be followed in the field that will result in a standard set of data as well as the error properties of the data. While many such sampling schemes could be developed that target different types of organisms, we focus on one case of a moving observer attempting to detect a species in the field (e.g. a birder, uav, etc.) with the goal of producing a presence–absence map. The multiscale model developed is spatially explicit and accommodates inherent survey tradeoffs such as sampling speed, detectability and map resolution. Given a set of sampling parameters, the model provides estimates of the total sampling time and map accuracy translated into the probability of false negative. Additionally it also provides an actual and sampled occupancy–area curve across mapping resolutions that can be utilized to discuss sampling effects. While the proposed sampling framework is simple, the same general approach could be adapted for other conditions to meet the needs of a particular taxon. If a set of ‘canonical' sampling algorithms could be developed with known mathematical properties, it would enhance reliability and usage of ecological datasets. © 2020 the authors. Ecography published by john wiley & sons ltd on behalf of nordic society oikos","","","2021","10.1111/ecog.05198","","","scopus-2-s2.0-85097026428.pdf","scopus-2-s2.0-85097026428"
"3d visualization of adverse natural conditions for adjustment of land cadastral value","Avrunev, E.i. And Gatina, N.v. And Kozina, M.v. And Popov, V.k.","Bulletin Of The Tomsk Polytechnic University, Geo Assets Engineering","","The research is relevant due to the fact that cadastral valuation of land is concerned to be an important part of land plots management. Thus, accuracy and quantity of its results are of great importance for scientific methodological fundamentals of valuation as well as for practice. Being reformed, the system of cadastral valuation of land is not able to provide integration and sharing data from various sources. The aim of the research is to suggest accounting for adverse geotechnical conditions at cadastral valuation of land with the help of geoinformational analysis and 3d cartographic modeling of flooding within the boundaries of urban land. The applied methods: theoretical analysis, methods of research, generalization and other established analytical methods, geoinforma' tional analysis, methods of cartographic data visualization, 3d modeling of geospatial data. Results. On the exemple of levoberezhye area in tomsk the authors have carried out the geoinformational analysis on the basis of geotechnical research and spring flood monitoring. The analysis results in outline sketch map of zoning levoberezhye according to the most favorable hydrological conditions. Specifying the need for the integrated approach to determine the factors of cadastral value, which include the influence of hydrological conditions, resulted in 3d digital modeling of relief and geological constitution of levobe' rezhye area. This modeling is able to meet the scientific and practical challenge of accounting for adverse geotechnical conditions of ca' dastral valuation, keeping the unified state register of immovable property, urban planning and managing territorial entity. Thus the authors proposed the approach to evaluation of negative geotechnical processes and phenomena progressing in urban areas for adjust' ment of cadastral value. © 2018 tomsk polytechnic university publishing house. All rights reserved.","","","2019","10.18799/24131830/2019/1/68","","","scopus-2-s2.0-85061692917.pdf","scopus-2-s2.0-85061692917"
"Ranking differentially expressed genes from Affymetrix gene expression data: methods with reproducibility sensitivity and specificity","Kadota K., Nakai Y., Shimizu K.","Algorithms For Molecular Biology","","BACKGROUND: To identify differentially expressed genes (DEGs) from microarray data users of the Affymetrix GeneChip system need to select both a preprocessing algorithm to obtain expression-level measurements and a way of ranking genes to obtain the most plausible candidates. We recently recommended suitable combinations of a preprocessing algorithm and gene ranking method that can be used to identify DEGs with a higher level of sensitivity and specificity. However in addition to these recommendations researchers also want to know which combinations enhance reproducibility.\\\\\\\\rRESULTS: We compared eight conventional methods for ranking genes: weighted average difference (WAD) average difference (AD) fold change (FC) rank products (RP) moderated t statistic (modT) significance analysis of microarrays (samT) shrinkage t statistic (shrinkT) and intensity-based moderated t statistic (ibmT) with six preprocessing algorithms (PLIER VSN FARMS multi-mgMOS (mmgMOS) MBEI and GCRMA). A total of 36 real experimental datasets was evaluated on the basis of the area under the receiver operating characteristic curve (AUC) as a measure for both sensitivity and specificity. We found that the RP method performed well for VSN- FARMS- MBEI- and GCRMA-preprocessed data and the WAD method performed well for mmgMOS-preprocessed data. Our analysis of the MicroArray Quality Control (MAQC) project's datasets showed that the FC-based gene ranking methods (WAD AD FC and RP) had a higher level of reproducibility: The percentages of overlapping genes (POGs) across different sites for the FC-based methods were higher overall than those for the t-statistic-based methods (modT samT shrinkT and ibmT). In particular POG values for WAD were the highest overall among the FC-based methods irrespective of the choice of preprocessing algorithm.\\\\\\\\rCONCLUSION: Our results demonstrate that to increase sensitivity specificity and reproducibility in microarray analyses we need to select suitable combinations of preprocessing algorithms and gene ranking methods. We recommend the use of FC-based methods in particular RP or WAD.","","","2009","10.1186/1748-7188-4-7","","","medline-19386098.pdf","medline-19386098"
"A critical evaluation of the 2011 ECHA reports on compliance with the REACH and CLP regulations and on the use of alternatives to testing on animals for compliance with the REACH regulation","Spielmann H., Sauer U. G., Mekenyan O.","ATLA-Alternatives to Laboratory Animals","","On 30 June 2011 the European Chemicals Agency published two reports one on the functioning of the REACH system the other on the use of alternatives to animal testing in compliance with that system. The data presented are based on information gained during the first registration period under the REACH system which included high production volume chemicals and substances of very high concern which have the most extensive information requirements. A total of 25460 registration dossiers were received covering 3400 existing so-called 'phase-in' substances and 900 new so-called 'non-phase-in' substances. Data sharing and the joint submission of data are reported to have worked successfully. In the registration dossiers for these substances results from new animal tests were included for less than 1% of all the endpoints; testing proposals (required for 'higher-tier' information requirements) were submitted for 711 in vivo tests involving vertebrate animals. The registrants mainly used old existing experimental data or options for the adaptation (waiving) of information requirements before collecting new information. For predicting substance toxicity 'read-across' was the second most-used approach followed by 'weight-of-evidence'. In vitro toxicity tests played a minor role and were only used when the respective test methods had gained the status of regulatory acceptance. All in all a successful start to the REACH programme was reported particularly since in contrast to most predictions it did not contribute to a significant increase in toxicity testing in animals. Copyright 2011 FRAME.","","","2011","10.1177/026119291103900509","","","medline-22103941.pdf","medline-22103941"
"A knowledge graph based approach to social science surveys","Pan, J.z. And Edelstein, E. And Bansky, P. And Wyner, A.","Data Intelligence","","Recent success of knowledge graphs has spurred interest in applying them in open science, such as on intelligent survey systems for scientists. However, efforts to understand the quality of candidate survey questions provided by these methods have been limited. Indeed, existing methods do not consider the type of on-the-fly content planning that is possible for face-to-face surveys and hence do not guarantee that selection of subsequent questions is based on response to previous questions in a survey. To address this limitation, we propose a dynamic and informative solution for an intelligent survey system that is based on knowledge graphs. To illustrate our proposal, we look into social science surveys, focusing on ordering the questions of a questionnaire component by their level of acceptance, along with conditional triggers that further customise participants’ experience. Our main findings are: (i) evaluation of the proposed approach shows that the dynamic component can be beneficial in terms of lowering the number of questions asked per variable, thus allowing more informative data to be collected in a survey of equivalent length;  and (ii) a primary advantage of the proposed approach is that it enables grouping of participants according to their responses, so that participants are not only served appropriate follow-up questions, but their responses to these questions may be analysed in the context of some initial categorisation. We believe that the proposed approach can easily be applied to other social science surveys based on grouping definitions in their contexts. The knowledge-graph-based intelligent survey approach proposed in our work allows online questionnaires to approach face-to-face interaction in their level of informativity and responsiveness, as well as duplicating certain advantages of interview-based data collection. © 2021 chinese academy of sciences.","","","2021","10.1162/dint_a_00107","","","scopus-2-s2.0-85118212118.pdf","scopus-2-s2.0-85118212118"
"From generic pathways to ICT-supported horizontally integrated care: the SmartCare approach and convergence with future Internet assembly","Urosevic V., Mitic M.","Studies in Health Technology & Informatics","","Successful service integration in policy and practice requires both technology innovation and service process innovation being pursued and implemented at the same time. The SmartCare project (partially EC-funded under CIP ICT PSP Program) aims to achieve this through development piloting and evaluation of ICT-based services horizontally integrating health and social care in ten pilot regions including Kraljevo region in Serbia. The project has identified and adopted two generic highest-level common thematic pathways in joint consolidation phase - integrated support for long-term care and integrated support after hospital discharge. A common set of standard functional specifications for an open ICT platform enabling the delivery of integrated care is being defined around the challenges of data sharing coordination and communication in these two formalized pathways. Implementation and system integration on technology and architecture level are to be based on open standards multivendor interoperability and leveraging on the current evolving open specification technology foundations developed in relevant projects across the European Research Area.","","","2014","","","","medline-24743080.pdf","medline-24743080"
"Evaluating Research Transparency and Openness in Communication Sciences and Disorders Journals","Schroeder S. R., Gaeta L., El Amin M., Chow J. C., Borders J. C.","Journal of Speech Language & Hearing Research","","PURPOSE: To improve the credibility reproducibility and clinical utility of research findings many scientific fields are implementing transparent and open research practices. Such open science practices include researchers making their data publicly available and preregistering their hypotheses and analyses. A way to enhance the adoption of open science practices is for journals to encourage or require submitting authors to participate in such practices. Accordingly the American Speech-Language-Hearing Association's Journals Program has recently announced their intention to promote open science practices. Here we quantitatively assess the extent to which several journals in communication sciences and disorders (CSD) encourage or require participation in several open science practices by using the Transparency and Openness Promotion (TOP) Factor metric.\\\\\\\\rMETHOD: TOP Factors were assessed for 34 CSD journals as well as several journals in related fields. TOP Factors measure the level of implementation across 10 open science-related practices (e.g. data transparency analysis plan preregistration and replication) for a total possible score of 29 points.\\\\\\\\rRESULTS: Collectively CSD journals had very low TOP Factors (M = 1.4 range: 0-8). The related fields of Psychology (M = 4.0) Rehabilitation (M = 3.2) Linguistics (M = 1.7) and Education (M = 1.6) also had low scores though Psychology and Rehabilitation had higher scores than CSD.\\\\\\\\rCONCLUSION: CSD journals currently have low levels of encouraging or requiring participation in open science practices which may impede adoption. Open Science Form: https://doi.org/10.23641/asha.21699458.","","","2023","10.1044/2022_jslhr-22-00330","","","medline-36516469.pdf","medline-36516469"
"Poster: Enabling Comparable and Reproducible Simulations for V2X Research","Hardes T., Logan D., Sommer C., Klingler F., Kargl F., Altintas O., Sommer C., Higuchi T., Klingler F.","","","Simulations are a prime performance evaluation technique for new Vehicle to Everything (V2X) methods and approaches. However after decades of simulation-backed research comparability and reproducibility of simulation studies is still low. In this work we first survey road traffic simulation parameters (that is scenarios) employed in recent scientific publications revealing that many publications still do not adequately describe simulation scenarios to make the results comprehensible. As just one example over 40% of the simulations using either a Manhattan Grid or Chicago Grid do not provide information about the number of lanes. At the same time our survey reveals that even though employed road traffic scenarios are very use case specific there exist many commonalities. We therefore advocate basing research on use case specific variants of a set of these common standard road traffic scenarios. We accompany this recommendation with Simple Synthetic Scenarios for Sumo (sss4s) a simple reference implementation to generate such variants. © 2021 IEEE.","","","2021","10.1109/vnc52810.2021.9644677","","","scopus-2-s2.0-85123788956.pdf","scopus-2-s2.0-85123788956"
"A dataset of cold-water coral distribution records","Balogh V., Fragkopoulou E., Serrao E. A., Assis J.","Data in Brief","","Species distribution data are key for monitoring present and future biodiversity patterns and informing conservation and management strategies. Large biodiversity information facilities often contain spatial and taxonomic errors that reduce the quality of the provided data. Moreover datasets are frequently shared in varying formats inhibiting proper integration and interoperability. Here we provide a quality-controlled dataset of the diversity and distribution of cold-water corals which provide key ecosystem services and are considered vulnerable to human activities and climate change effects. We use the common term cold-water corals to refer to species of the orders Alcyonacea Antipatharia Pennatulacea Scleractinia Zoantharia of the subphylum Anthozoa and order Anthoathecata of the class Hydrozoa. Distribution records were collated from multiple sources standardized using the Darwin Core Standard dereplicated taxonomically corrected and flagged for potential vertical and geographic distribution errors based on peer-reviewed published literature and expert consulting. This resulted in 817559 quality-controlled records of 1170 accepted species of cold-water corals openly available under the FAIR principle of Findability Accessibility Interoperability and Reusability of data. The dataset represents the most updated baseline for the global cold-water coral diversity and it can be used by the broad scientific community to provide insights into biodiversity patterns and their drivers identify regions of high biodiversity and endemicity and project potential redistribution under future climate change. It can also be used by managers and stakeholders to guide biodiversity conservation and prioritization actions against biodiversity loss. Copyright © 2023 The Authors.","","","2023","10.1016/j.dib.2023.109223","","","medline-37383736.pdf","medline-37383736"
"Assessing adverse health effects of long-term exposure to low levels of ambient air pollution: phase 1","Dominici F. And Schwartz J. And Di Q. And Braun D. And Choirat C. And Zanobetti A.","Res Rep Health Eff Inst","","Introduction: this report provides a summary of major findings and key conclusions supported by a health effects institute grant aimed at ""assessing adverse health effects of long-term exposure to low levels of ambient pollution."" Our study was designed to advance four critical areas of inquiry and methods development. Method(s): first, our work focused on predicting short- and long-term exposures to ambient pm2.5 mass (particulate matter <= 2.5mum in aerodynamic diameter) and ozone (o3) at high spatial resolution (1 km x 1 km) for the continental united states during the period 2000-2012 and linking these predictions to health data. Second, we developed new causal inference methods for exposure-response (er) that account for exposure error and adjust for measured confounders. We applied these methods to data from the new england region. Third, we applied standard regression methods using medicare claims data to estimate health effects that are associated with short- and long-term exposure to low levels of ambient air pollution. We conducted sensitivity analyses to assess potential confounding bias due to lack of extensive information on behavioral risk factors in the medicare population using the medicare current beneficiary survey (mcbs) (nationally representative sample of approximately 15,000 medicare enrollees per year), which includes abundant data on individual-level risk factors including smoking. Finally, we have begun developing tools for reproducible research - including approaches for data sharing, record linkage, and statistical software. Result(s): our hei-funded work has supported an extensive portfolio of analysis and the development of statistical methods that can be used to robustly understand the health effects of long- and short-term exposure to low levels of ambient air pollution. This report provides a high-level overview of statistical methods, data analysis, and key findings, as grouped into the following four areas: (1) exposure assessment and data access;  (2) epidemiological studies of ambient exposures to air pollution at low levels;  (3) methodological contributions in causal inference;  and (4) open science research data platform. Conclusion(s): our body of work, advanced by hei, lends extensive evidence that short- and long-term exposure to pm2.5 and o3 is harmful to human health, increasing the risks of hospitalization and death, even at levels that are well below the national ambient air quality standards (naaqs).Copyright © 2020 health effects institute. All rights reserved.","","","2019","","","","embase-632668858.pdf","embase-632668858"
"Adherence to preexposure prophylaxis: current, emerging, and anticipated bases of evidence","Amico, K.r. And Stirratt, M.j.","Clinical Infectious Diseases","","Despite considerable discussion and debate about adherence to preexposure prophylaxis (prep) for human immunodeficiency virus (hiv), scant data are available that characterize patterns of adherence to open-label prep. The current evidence base is instead dominated by research on adherence to placebo-controlled investigational drug by way of drug detection in active-arm participants of large randomized controlled trials (rcts). Important differences between the context of blinded rcts and open-label use suggest caution when generalizing from study product adherence to real-world prep use. Evidence specific to open-label prep adherence is presently sparse but will expand rapidly over the next few years as roll-out, demonstration projects, and more rigorous research collect and present findings. The current evidence bases established cannot yet predict uptake, adherence, or persistence with open-label effective prep. Emerging evidence suggests that some cohorts could execute better adherence in open-label use vs placebo-controlled research. Uptake of prep is presently slow in the united states;  whether this changes as grassroots and community efforts increase awareness of prep as an effective hiv prevention option remains to be determined. As recommended by multiple guidelines for prep use, all current demonstration projects offer prep education and/or counseling. Prep support approaches generally fall into community-based, technology, monitoring, and integrated sexual health promotion approaches. Developing and implementing research that moves beyond simple correlates of either study product use or open-label prep adherence toward more comprehensive models of sociobehavioral and socioecological adherence determinants would greatly accelerate progress. Intervention research is needed to identify effective models of support for open-label prep adherence. © 2014 the author . Published by oxford university press on behalf of the infectious diseases society of america.","","","2014","10.1093/cid/ciu266","","","scopus-2-s2.0-84904816119.pdf","scopus-2-s2.0-84904816119"
"The data sharing paradox: bigtechs in finance","Borgogno, O. And Colangelo, G.","European Competition Journal","","The european wave of regulatory interventions aimed at promoting access to data and data sharing shows no signs of stopping. However, concerns are being expressed about alleged unintended consequences of data portability in financial markets. In particular, new calls have been voiced to contain the engagement of bigtech platforms with retail banking. The paper argues that asymmetrical regulatory measures imposed on bigtechs entry in the financial industry may tilt the market in favour of incumbent banks. Indeed, as fintech start-ups seem more likely to work alongside incumbent banks rather than compete with them, limiting the entry of bigtechs may remove the only effective source of competitive pressure for traditional bank, thereby ultimately frustrating the pro-competitive potential of the access to account rule enshrined in the revised payment service directive (psd2). © 2020 informa uk limited, trading as taylor & francis group.","","","2020","10.1080/17441056.2020.1812285","","","scopus-2-s2.0-85092023554.pdf","scopus-2-s2.0-85092023554"
"Design of data sharing platform based on blockchain and ipfs technology","Li, W. And Zhou, Z. And Fan, W. And Gao, J.","Wireless Communications And Mobile Computing","","With the continuous development of the information age, data sharing and exchange are gradually increasing. The internet and big data technology provide a guarantee for data sharing and transmission. At present, as the amount of data increases rapidly, how to realize data sharing has become a huge challenge. To solve this problem, this paper proposes a data sharing platform based on the combination of blockchain and interplanetary file system (ipfs) technology to solve the data sharing and storage. Firstly, by constructing the alliance blockchain, the consensus mechanism of computing power competition is used to maintain the data written into the blockchain, and the ipfs data storage system is established to store data using distributed storage, file splitting, and splicing technologies. Secondly, a data sharing platform composed of blockchain module, ipfs module, encryption and decryption module, and fast retrieval module is built. Data encryption is processed by encryption and decryption module, and the processed data is uploaded to the ipfs module;  the abstract and other information are finally written into the blockchain through the blockchain module. The fast retrieval module can quickly locate the required data according to the retrieval conditions in the mass blockchain data;  finally, the security and storage of data sharing platform are guaranteed through security and performance evaluation. The research results solve the problem of large amount of data sharing, realize the data decentralization, and ensure the data storage security. © 2022 weijing li et al.","","","2022","10.1155/2022/3937725","","","scopus-2-s2.0-85135075844.pdf","scopus-2-s2.0-85135075844"
"Toward an Ethical Framework for the Text Mining of Social Media for Health Research: A Systematic Review","Ford E., Shepherd S., Jones K., Hassan L.","Frontiers in Digital Health","","Background: Text-mining techniques are advancing all the time and vast corpora of social media text can be analyzed for users' views and experiences related to their health. There is great promise for new insights into health issues such as drug side effects and spread of disease as well as patient experiences of health conditions and health care. However this emerging field lacks ethical consensus and guidance. We aimed to bring together a comprehensive body of opinion views and recommendations in this area so that academic researchers new to the field can understand relevant ethical issues. Methods: After registration of a protocol in PROSPERO three parallel systematic searches were conducted to identify academic articles comprising commentaries opinion and recommendations on ethical practice in social media text mining for health research and gray literature guidelines and recommendations. These were integrated with social media users' views from qualitative studies. Papers and reports that met the inclusion criteria were analyzed thematically to identify key themes and an overarching set of themes was deduced. Results: A total of 47 reports and articles were reviewed and eight themes were identified. Commentators suggested that publicly posted social media data could be used without consent and formal research ethics approval provided that the anonymity of users is ensured although we note that privacy settings are difficult for users to navigate on some sites. Even without the need for formal approvals we note ethical issues: to actively identify and minimize possible harms to conduct research for public benefit rather than private gain to ensure transparency and quality of data access and analysis methods and to abide by the law and terms and conditions of social media sites. Conclusion: Although social media text mining can often legally and reasonably proceed without formal ethics approvals we recommend improving ethical standards in health-related research by increasing transparency of the purpose of research data access and analysis methods; consultation with social media users and target groups to identify and mitigate against potential harms that could arise; and ensuring the anonymity of social media users. Copyright © 2021 Ford Shepherd Jones and Hassan.","","","2020","10.3389/fdgth.2020.592237","","","medline-34713062.pdf","medline-34713062"
"A statistical approach for estimating fish diet compositions from multiple data sources: Gulf of California case study","Ainsworth C. H., Kaplan I. C., Levin P. S., Mangel M.","Ecological Applications","","Trophic ecosystem models are one promising tool for providing ecosystem-based management advice. Diet and interaction rate parameters are critical in defining the behavior of these models and will greatly influence any predictions made in response to management perturbations. However most trophic ecosystem models must rely on a patchwork of data availability and must contend with knowledge gaps and poor quantification of uncertainty. Here we present a statistical method for combining diet information from field samples and literature to describe trophic relationships at the level of functional groups. In this example original fieldwork in the northern Gulf of California Mexico provides gut content data for targeted and untargeted fish species. The field data are pooled with diet composition information from FishBase an online data repository. Diet information is averaged across stomachs to represent an average predator and then the data are bootstrapped to generate likelihood profiles. These are fit to a Dirichlet function and from the resulting marginal distributions maximum-likelihood estimates are generated with confidence intervals representing the likely contribution to diet for each predator-prey combination. We characterize trophic linkages into two broad feeding guilds pelagic and demersal feeders and explore differentiation within those guilds. We present an abbreviated food web for the northern Gulf of California based on the results of this study. This food web will form the basis of a trophic dynamic model. Compared to the common method of averaging diet compositions across predators this statistical approach is less influenced by the presence of long tails in the distributions which correspond to rare feeding events and is therefore better suited to small data sets.","","","2010","10.1890/09-0611.1","","","medline-21265451.pdf","medline-21265451"
"Establishing mechanisms to conduct multi-institutional research--fatigue in patients with cancer: an exercise intervention","Mock, V. And Ropka, M.e. And Rhodes, V.a. And Pickett, M. And Grimm, P.m. And Mcdaniel, R. And Lin, E.m. And Allocca, P. And Dienemann, J.a. And Haisfield-Wolfe, M.e. And Stewart, K.j. And Mccorkle, R.","Oncology Nursing Forum","","Purposes/objectives: to describe the process of establishing a multi-institutional interdisciplinary team of oncology researchers and conducting a pilot study of an exercise intervention for fatigue. Data sources: project meeting minutes and records, research team members' logs, subjects' research records, the research study proposal, and team members' individual and collective shared experiences. Data synthesis: site investigators established research teams at five academic medical centers. Fifty subjects were enrolled in the study and tested during their cancer treatment. Study methods, including instrumentation, were evaluated carefully and revised. Conclusions: the multi-institutional network of researchers is an effective and efficient model for testing an intervention to manage fatigue during cancer treatment. Implications for nursing practice: exercise is a feasible and potentially beneficial intervention to combat distressing cancer treatment-related fatigue. A pilot study is essential to determine the best methods for conducting a clinical trial and to develop the teams of researchers necessary for such a project.","","","1998","","","","scopus-2-s2.0-0032165090.pdf","scopus-2-s2.0-0032165090"
"Verifying intervention fidelity procedures for a palliative home care intervention with pilot study results","Piamjariyakul, U. And Smothers, A. And Young, S. And Morrissey, E. And Petitte, T. And Wen, S. And Zulfikar, R. And Sangani, R. And Shafique, S. And Smith, C.e. And Bosak, K.","Research In Nursing And Health","","Fidelity (consistency of intervention implementation) is essential to rigorous research. Intervention fidelity maintains study internal validity, intervention reproducibility, and transparency in the research conduct. The purpose of this manuscript is to describe intervention fidelity strategies/procedures developed for a pilot study testing a new palliative care nursing intervention (fampalcare) for families managing advanced lung disease. The procedures described herein are based on the fidelity best practices recommendations from the nih consortium. An evidence-based checklist guided observational ratings of the fidelity procedures used and the intervention content implemented in each intervention session. Descriptive data on how participants understood (received), enacted, or used the intervention information were summarized. The fidelity checklist observational scores found ≥93% of the planned intervention content was implemented, and the fidelity strategies were adhered to consistently during each intervention session. The small variation (7%) in implementation was expected and related to participants' varying experiences, input, and/or questions. The helpfulness scale items include participants' ability to use home care resources, to anticipate and manage end-of-life symptoms, and to use advance directive forms. The high ratings (m = 4.4) on the 1–5 (very helpful) likert helpfulness scale verified participants utilized the information from the intervention. Furthermore, there was an improvement in patients' breathlessness scores and completion of advance directive forms at 3 months after baseline. It is essential to plan intervention fidelity strategies to use throughout a study and to report fidelity results. © 2021 wiley periodicals llc","","","2021","10.1002/nur.22166","","","scopus-2-s2.0-85108891945.pdf","scopus-2-s2.0-85108891945"
"The Use and Abuse of Transcranial Magnetic Stimulation to Modulate Corticospinal Excitability in Humans","Heroux M. E., Taylor J. L., Gandevia S. C.","PLoS ONE [Electronic Resource]","","The magnitude and direction of reported physiological effects induced using transcranial magnetic stimulation (TMS) to modulate human motor cortical excitability have proven difficult to replicate routinely. We conducted an online survey on the prevalence and possible causes of these reproducibility issues. A total of 153 researchers were identified via their publications and invited to complete an anonymous internet-based survey that asked about their experience trying to reproduce published findings for various TMS protocols. The prevalence of questionable research practices known to contribute to low reproducibility was also determined. We received 47 completed surveys from researchers with an average of 16.4 published papers (95% CI 10.8-22.0) that used TMS to modulate motor cortical excitability. Respondents also had a mean of 4.0 (2.5-5.7) relevant completed studies that would never be published. Across a range of TMS protocols 45-60% of respondents found similar results to those in the original publications; the other respondents were able to reproduce the original effects only sometimes or not at all. Only 20% of respondents used formal power calculations to determine study sample sizes. Others relied on previously published studies (25%) personal experience (24%) or flexible post-hoc criteria (41%). Approximately 44% of respondents knew researchers who engaged in questionable research practices (range 30-81%) yet only 18% admitted to engaging in them (range 6-38%) [corrected]. These practices included screening subjects to find those that respond in a desired way to a TMS protocol selectively reporting results and rejecting data based on a gut feeling. In a sample of 56 published papers that were inspected not a single questionable research practice was reported. Our survey revealed that approximately 50% of researchers are unable to reproduce published TMS effects. Researchers need to start increasing study sample size and eliminating--or at least reporting--questionable research practices in order to make the outcomes of TMS research reproducible.","","","2015","10.1371/journal.pone.0144151","","","medline-26629998.pdf","medline-26629998"
"Hope, disappointment and perseverance: reflections of people with myalgic encephalomyelitis/chronic fatigue syndrome (me/cfs) and multiple sclerosis participating in biomedical research. A qualitative focus group study","Lacerda, E.m. And Mcdermott, C. And Kingdon, C.c. And Butterworth, J. And Cliff, J.m. And Nacul, L.","Health Expectations","","Background: the clinical understanding and research excellence in me/cfs group (cureme) at the london school of hygiene & tropical medicine has supported and undertaken studies in immunology, genetics, virology, clinical medicine, epidemiology and disability. It established the uk me/cfs biobank (ukmeb), which stores data and samples from three groups: participants with me/cfs, multiple sclerosis (ms) and healthy controls. Patient and public involvement have played a central role from its inception. Aim: to explore the views of participants with me/cfs and ms on cureme research findings, dissemination and future biomedical research priorities. Method: five me/cfs and ms focus groups were conducted at two uk sites. Discussions were transcribed and analysed thematically. Results: a total of 28 ukmeb participants took part: 16 with me/cfs and 12 with ms. Five themes emerged: (a) seeking coherence: participants’ reactions to initial research findings;  (b) seeking acceptance: participants explore issues of stigma and validation;  (c) seeking a diagnosis: participants explore issues around diagnosis in their lives;  (d) seeking a better future: participants’ ideas on future research;  and (e) seeking to share understanding: participants’ views on dissemination. Focus groups perceived progress in me/cfs and ms research in terms of “putting together a jigsaw” of evidence through perseverance and collaboration. Conclusion: this study provides insight into the emotional, social and practical importance of research to people with ms and me/cfs, suggesting a range of research topics for the future. Findings should inform biomedical research directions in me/cfs and ms, adding patients’ voices to a call for a more collaborative research culture. © 2019 the authors health expectations published by john wiley & sons ltd","","","2019","10.1111/hex.12857","","","scopus-2-s2.0-85066507774.pdf","scopus-2-s2.0-85066507774"
"For learning analytics to be sustainable under gdpr—consequences and way forward","Karunaratne, T.","Sustainability (Switzerland)","","Personalized learning is one of the main focuses in 21st‐century education, and learning analytics (la) has been recognized as a supportive tool for enhancing personalization. Meanwhile, the general data protection regulations (gdpr), which concern the protection of personal data, came into effect in 2018. However, contemporary research lacks the essential knowledge of how and in which ways the presence of gdpr influence la research and practices. Hence, this study intends to examine the requirements for sustaining la under the light of gdpr. According to the study outcomes, the legal obligations for la could be simplified to data anonymization with consequences of limitations to personalized interventions, one of the powers of la. Explicit consent from the data subjects (students) prior to any data processing is mandatory under gdpr. The consent agreements must include the purpose, types of data, and how, when and where the data is processed. Moreover, transparency of the complete process of storing, retrieving, and analysing data as well as how the results are used should be explicitly documented in la applications. The need for academic institutions to have specific regulations for supporting la is emphasized. Regulations for sharing data with third parties is left as a further extension of this study. © 2021 by the author. Licensee mdpi, basel, switzerland.","","","2021","10.3390/su132011524","","","scopus-2-s2.0-85117397963.pdf","scopus-2-s2.0-85117397963"
"Metabolomic analysis using optimized NMR and statistical methods","Aranibar N., Ott K. H., Roongta V., Mueller L.","Analytical Biochemistry","","NMR-based metabolomics requires robust automated methodologies and the accuracy of NMR-based metabolomics data is greatly influenced by the reproducibility of data acquisition and processing methods. Effective water resonance signal suppression and reproducible spectral phasing and baseline traces across series of related samples are crucial for statistical analysis. We assess robustness repeatability sensitivity selectivity and practicality of commonly used solvent peak suppression methods in the NMR analysis of biofluids with respect to the automated processing of the NMR spectra and the impact of pulse sequence and data processing methods on the sensitivity of pattern recognition and statistical analysis of the metabolite profiles. We introduce two modifications to the excitation sculpting pulse sequence whereby the excitation solvent suppression pulse cascade is preceded by low-power water resonance presaturation pulses during the relaxation delay. Our analysis indicates that combining water presaturation with excitation sculpting water suppression delivers the most reproducible and information-rich NMR spectra of biofluids.","","","2006","10.1016/j.ab.2006.04.014","","","medline-16762305.pdf","medline-16762305"
"P-Value Demystified","Sil A., Betkerur J., Das N. K.","Indian Dermatology Online Journal","","Biomedical research relies on proving (or disproving) a research hypothesis and P value becomes a cornerstone of ""null hypothesis significance testing."" P value is the maximum probability of getting the observed outcome by chance. For a statistical test to achieve significance the error by chance must be less than 5%. The pros are the P value that gives the strength of evidence against the null hypothesis. We can reject a null hypothesis depending on a small P value. However the value of P is a function of sample size. When the sample size is large the P value is destined to be small or ""significant."" P value is condemned by one school of thought who claims that focusing more on P value undermines the generalizability and reproducibility of research. For such a situation presently the scientific world is inclined in knowing the effect size confidence interval and the descriptive statistics; thus researchers need to highlight them along with the P value. In spite of all the criticism it needs to be understood that P value carries paramount importance in ""precise"" understanding of the estimation of the difference calculated by ""null hypothesis significance testing."" Choosing the correct test for assessing the significance of the difference is profoundly important. The choice can be arrived by asking oneself three questions namely the type of data whether the data is paired or not and on the number of study groups (two or more). It is worth mentioning that association between variables agreement between assessments time-trend cannot be arrived by calculating the P value alone but needs to highlight the correlation and regression coefficients odds ratio relative risk etc. Copyright: © 2019 Indian Dermatology Online Journal.","","","2019","10.4103/idoj.idoj_368_19","","","medline-32195200.pdf","medline-32195200"
"Strategies to enhance recruitment of rural-dwelling older people into community-based trials","Anuruang S., Davidson P. M., Jackson D., Hickman L.","Nurse Researcher","","AIM: To describe strategies that can enhance the recruitment of rural-dwelling older people into clinical trials.\\\\\\\\rBACKGROUND: Recruitment to studies can be time-consuming and challenging. Moreover there are challenges associated with recruiting older people particularly those living in rural areas. Nevertheless an adequate sample size is crucial to the validity of randomised controlled trials (RCTs).\\\\\\\\rDATA SOURCES: The authors draw on the literature and their personal experiences to present a range of flexible and inclusive strategies that have been successfully used to recruit older people into clinical trials.\\\\\\\\rREVIEW METHODS: This paper describes attempts to improve recruitment of rural-dwelling older Thai people to a clinical trial.\\\\\\\\rDISCUSSION: To attract potential participants researchers should consider minimising the burden of their study and maximising its benefits or convenience for participants. Three factors that may influence participation rates are: personal factors of participants researchers' personal attributes and protocol factors. In addition three important strategies contribute to improving recruitment: understanding the culture of the research setting identifying the 'gatekeepers' in the setting and building trust with stakeholders.\\\\\\\\rCONCLUSION: Even though the study covered did not recruit a large number of participants these understandings were crucial and enabled recruitment of a sufficient number of participants in a reasonable timeframe.\\\\\\\\rIMPLICATIONS FOR PRACTICE/RESEARCH: These strategies may be of use in rural settings and with different communities including urban communities.","","","2015","10.7748/nr.23.1.40.e1345","","","medline-26365075.pdf","medline-26365075"
"A non-targeted data processing workflow for volatile organic compound data acquired using comprehensive two-dimensional gas chromatography with dual channel detection","Byrne J.m. And Dubois L.m. And Baker J.d. And Focant J.-F. And Perrault K.a.","Methodsx","","There has been an influx of technology for comprehensive two-dimensional gas chromatography analyses in recent years, calling for development of guided workflows and rigorous reporting of processes. This research focuses on the processing method for data collected on a dual channel detection system using flame ionization detection (fid) and quadrupole mass spectrometry (qms) for the analysis of volatile organic compounds (vocs). The samples analyzed were kava (piper methysticum), which has a rich voc profile that benefits substantially from a multidimensional approach due to enhanced peak capacity. The procedure which was customized here was the data processing workflow from a manual single-sample analysis to an integrated batch workflow that can be applied across studies. * Parameter choice for baseline correction and peak detection were defined when handling batch data. * Elution regions were defined using qms data to automate compound identification. * Stencils were transformed onto fid data and sequenced for quantitative information.this dataset can be used as a training tool, as all details, methods and results for the workflow have been provided for users to compare with. The focus on data workflow reproducibility in the field of multidimensional chromatography will assist in adoption by users in new application areas.copyright © 2020 the author(s)","","","2020","10.1016/j.mex.2020.101009","","","embase-2007311094.pdf","embase-2007311094"
"Health information technology, foresight and strategic decision making for iran: a qualitative study","Hemmat, M. And Ayatollahi, H. And Maleki, M. And Saghaf, F.","Iranian Journal Of Information Processing Management","","Given the importance of information technology in health sector, planning and identifying the prospect and a future road map is important in this area. For this purpose, applying a systematic approach to study the future of health information technology is essential. The key technology is one of the approaches used in the foresight studies and it is conducted by interviewing experts. The aim of this study was to use key technology approach to identify the most important health information technologies for iran until 2025. This qualitative study was conducted in two phases. The first phase was related to developing a mind map of health information technologies based on the literature review and an expert panel results. In the second phase, semi-structured interviews were conducted with 13 experts to identify the key health information technologies for iran until 2025. In the first phase, content analysis and in the second phase, framework analysis was used to analyze data. According to the results, the main themes were immediate, cheap, stable, and secure access to the maximum health records of the entire population, equitable access to resources and services of the health counter, development of knowledge management in medical and health sciences, development of governmental electronic services (backup) in health system, development of m-health, it governance in health and development of national hit infrastructure. In total, 19 key health information technologies were identified which were related to the main themes. The development of electronic health records, national health information network, data sharing, patient’s personal health record (phr), m-health, clinical decision support systems and health information technology infrastructure were found to be the most important health information technologies for iran until 2025. It seems that identifying key health information technologies can help to facilitate strategic and operational planning in this area and help to allocate resources realistically. © 2019 iranian research institute for scientific information and documentation. All rights reserved.","","","2019","","","","scopus-2-s2.0-85064203156.pdf","scopus-2-s2.0-85064203156"
"Incomplete time-series gene expression in integrative study for islet autoimmunity prediction","Tanvir Ahmed K., Cheng S., Li Q., Yong J., Zhang W.","Briefings in Bioinformatics","","Type 1 diabetes (T1D) outcome prediction plays a vital role in identifying novel risk factors ensuring early patient care and designing cohort studies. TEDDY is a longitudinal cohort study that collects a vast amount of multi-omics and clinical data from its participants to explore the progression and markers of T1D. However missing data in the omics profiles make the outcome prediction a difficult task. TEDDY collected time series gene expression for less than 6% of enrolled participants. Additionally for the participants whose gene expressions are collected 79% time steps are missing. This study introduces an advanced bioinformatics framework for gene expression imputation and islet autoimmunity (IA) prediction. The imputation model generates synthetic data for participants with partially or entirely missing gene expression. The prediction model integrates the synthetic gene expression with other risk factors to achieve better predictive performance. Comprehensive experiments on TEDDY datasets show that: (1) Our pipeline can effectively integrate synthetic gene expression with family history HLA genotype and SNPs to better predict IA status at 2 years (sensitivity 0.622 AUC 0.715) compared with the individual datasets and state-of-the-art results in the literature (AUC 0.682). (2) The synthetic gene expression contains predictive signals as strong as the true gene expression reducing reliance on expensive and long-term longitudinal data collection. (3) Time series gene expression is crucial to the proposed improvement and shows significantly better predictive ability than cross-sectional gene expression. (4) Our pipeline is robust to limited data availability. Availability: Code is available at https://github.com/compbiolabucf/TEDDY. Copyright © The Author(s) 2022. Published by Oxford University Press. All rights reserved. For Permissions please email: journals.permissions@oup.com.","","","2023","10.1093/bib/bbac537","","","medline-36513375.pdf","medline-36513375"
"Efficient verifiable key-aggregate keyword searchable encryption for data sharing in outsourcing storage","Wang, X. And Cheng, X. And Xie, Y.","Ieee Access","","In a secure data sharing system, users can selectively retrieve encrypted files by performing keyword search over the ciphertext of data. Most of the existing searchable encryption schemes can provide security protection for both data owner and users. Nevertheless, three pivotal issues need to be addressed. Firstly, the cloud might return a wrong result or incomplete result for some reasons, e.g., saving the computing resources. Secondly, users need to store massive keys to generate trapdoors and decrypt the ciphertext of data, which brings great challenges to users' key management. Thirdly, when users perform keyword search over a large number of files, they need to generate and submit massive trapdoors, which is unrealistic. Proceeding from these points, in this paper, we propose an efficient verifiable key-aggregate keyword searchable encryption (evkakse) scheme. In this scheme, the data owner distributes only one aggregate key to users for keyword search, decryption and verification, who can use the aggregate key to generate a single trapdoor for keyword search over shared files. Generally, we define the requirements of the scheme, analyze the threat models and give a valid construction. Furthermore, our security analysis and experimental evaluation demonstrate that the scheme is efficient and secure. © 2013 ieee.","","","2020","10.1109/access.2019.2961169","","","scopus-2-s2.0-85078761525.pdf","scopus-2-s2.0-85078761525"
"Assessing Adherence to Responsible Reporting of Suicide Guidelines in the Canadian News Media: A 1-year Examination of Day-to-day Suicide Coverage","Antebi L., Carmichael V., Whitley R.","Canadian Journal of Psychiatry","","Objective: This study aims to examine routine day-to-day suicide reporting in the Canadian media giving a descriptive overview of the tone and content of news articles. The primary objective is to assess adherence to responsible reporting of suicide recommendations in news articles about suicide. A secondary objective is to categorize these articles according to their focus. A tertiary objective is to compare guideline adherence across the different categories of articles. Method(s): We collected news articles containing the keyword ""suicide"" from 47 Canadian news sources between April 1 2019 and March 31 2020. Articles were read and coded for their adherence to responsible reporting of suicide recommendations. Articles were also allotted into categories according to their focus and primary suicide discussed. Frequency counts and percentages of adherence were calculated for all key variables-both overall and by category of article. Chi-square tests were also conducted to assess for variations in adherence by category of article. Result(s): The procedures resulted in 1330 coded articles. On the one hand there was high overall adherence to several recommendations. For example over 80% of articles did not give a monocausal explanation glamourize the death appear on the front page include sensational language or use discouraged words. On the other hand there was low adherence to other recommendations especially those related to putatively protective content. For example less than 25% included help-seeking information quoted an expert or included educational content. Cross-category analysis indicated that articles about events/policies/research and Indigenous people had the highest proportions of adherence while articles about murder-suicide and high-profile suicides had the lowest adherence. Conclusion(s): While a substantial proportion of articles generally adhere to suicide reporting recommendations several guidelines are frequently underapplied especially those concerning putatively helpful content. This indicates room for improvement in the responsible reporting of suicide. Copyright © The Author(s) 2020.","","","2020","10.1177/0706743720936462","","","medline-32588647.pdf","medline-32588647"
"Data checkers: a grid-based ui for managing patient-generated data sharing to support collaborative self-care","Hung, P.-Y. And Canada, D. And Meade, M.a. And Ackerman, M.s.","Frontiers In Computer Science","","Chronic health conditions are becoming increasingly prevalent. As part of chronic care, sharing patient-generated health data (pghd) is likely to play a prominent role. Sharing pghd is increasingly recognized as potentially useful for not only monitoring health conditions but for informing and supporting collaboration with caregivers and healthcare providers. In this paper, we describe a new design for the fine-grained control over sharing one's pghd to support collaborative self-care, one that centers on giving people with health conditions control over their own data. The system, data checkers (dc), uses a grid-based interface and a preview feature to provide users with the ability to control data access and dissemination. Dc is of particular use in the case of severe chronic conditions, such as spinal cord injuries and disorders (sci/d), that require not just intermittent involvement of healthcare providers but daily support and assistance from caregivers. In this paper, after providing relevant background information, we articulate our steps for developing this innovative system for sharing pghd including (a) use of a co-design process;  (b) identification of design requirements;  and (c) creation of the dc system. We then present a qualitative evaluation of dc to show how dc satisfied these design requirements in a way that provided advantages for care. Our work extends existing research in the areas of human-computer interaction (hci), computer-supported cooperative work (cscw), ubiquitous computing (ubicomp), and health informatics about sharing data and pghd. Copyright © 2022 hung, canada, meade and ackerman.","","","2022","10.3389/fcomp.2021.639748","","","scopus-2-s2.0-85124086173.pdf","scopus-2-s2.0-85124086173"
"Buffer analysis for a data sharing environment with skewed data access","Dan, A. And Dias, D.m. And Yu, P.s.","Ieee Transactions On Knowledge And Data Engineering","","In this concise paper, we examine the effect of skewed database access on the transaction response time in a multisystem data sharing environment, where each computing node has access to shared data on disks, and has a local buffer of recently accessed granules. Skewness in data access can increase data contention since most accesses go to few data items. For the same reason, it can also increase the buffer hit probability. We quantify the resultant effect on the transaction response time, which depends not only on the various system parameters but also on the concurrency control (cc) protocol. Furthermore, the cc protocol can give rise to rerun transactions that have different buffer hit probabilities. In a multisystem environment, when a data block gets updated by a system, any copies of that block in other system’s local buffers are invalidated. Combining these effects, we find that higher skew does not necessarily lead to worse performance, and that with skewed access optimistic cc is more robust than pessimistic cc. Examining the buffer hit probability as a function of the buffer size, we find that the effectiveness of additional buffer allocation can be broken down into multiple regions that depend on the access frequency distribution. © 1994 ieee","","","1994","10.1109/69.277776","","","scopus-2-s2.0-0028404960.pdf","scopus-2-s2.0-0028404960"
"A Lens for Evaluating Genetic Information Governance Models: Balancing Equity Efficiency and Sustainability","Skorve E., Vassilakopoulou P., Aanestad M., Grunfeld T.","Studies in Health Technology & Informatics","","This paper draws from the literature on collective action and the governance of the commons to address the governance of genetic data on variants of specific genes. Specifically the data arrangements under study relate to the BRCA genes (BRCA1 and BRCA2) which are linked to breast and ovarian cancer. These data are stored in global genetic data repositories and accessed by researchers and clinicians from both public and private institutions. The current BRCA data arrangements are fragmented and politicized as there are multiple tensions around data ownership and sharing. Three key principles are proposed for forming and evaluating data governance arrangements in the field. These principles are: equity efficiency and sustainability.","","","2017","","","","medline-28423802.pdf","medline-28423802"
"A batch process for high dimensional imputation","Waggoner, P.d.","Computational Statistics","","This paper describes a correlation-based batch process for addressing high dimensional imputation problems. There are relatively few algorithms designed to efficiently handle imputation of missing data in high dimensional contexts. Fewer still are flexible enough to natively handle mixed-type data, often requiring lengthy pre-processing to get the data into proper shape, and then post-processing to return the data to usable form. Such decisions as well as assumptions made by many methods (e.g., data generating process) limit their performance, flexibility, and usability. Built on a set of complementary algorithms for nonparametric imputation via chained random forests, i introduce a batching process to ease computational costs associated with high dimensional imputation by subsetting data based on ranked cross-feature absolute correlations. The algorithm then imputes each batch separately, and joins imputed subsets in the final step. The process, hdimpute, is fast and accurate. As a result, high dimensional imputation is more accessible, and researchers are not forced to decide between speed or accuracy. Complementary software is available in the form of an r package, and is openly developed on github under the mit public license. In the spirit of open science, collaboration and engagement with the actively developing software are encouraged. © 2023, the author(s), under exclusive licence to springer-verlag gmbh germany, part of springer nature.","","","2023","10.1007/s00180-023-01325-9","","","scopus-2-s2.0-85146386385.pdf","scopus-2-s2.0-85146386385"
"Semantic-aware privacy-preserving online location trajectory data sharing","Zheng, Z. And Li, Z. And Jiang, H. And Zhang, L.y. And Tu, D.","Ieee Transactions On Information Forensics And Security","","Although users can obtain various services by sharing their location information online with location-based service providers, it reveals sensitive information about users. However, existing privacy-preserving techniques in the online scenario suffer from the following shortcomings. First, they model the correlations between the real trajectory and the distorted trajectory as undirected, which makes them unable to accurately quantify the data privacy leakage caused by sharing the distorted trajectory. Second, they are unable to protect semantic privacy, i.e., attackers can obtain the victims' visit purpose by using the point of interest information without knowing the real location data. Additionally, they fail to balance semantic-aware data utility and privacy protection. To make the case even worse, compared to the offline scenario, sharing trajectory online in real time does not have access to the overall location trajectory. In this paper, we propose a novel semantic-aware privacy-preserving online location trajectory sharing mechanism, called semantic-aware information-theoretic privacy (seitp), to protect both data privacy and semantic privacy while the semantic-aware data utility can be preserved. In particular, we put forward two new metrics of privacy to capture data privacy leakage and semantic privacy leakage, respectively. Besides, to quantify the semantic-aware trajectory data utility, we propose a semantic-aware utility metric. With those metrics, the shortcoming of failing to guarantee the data utility is avoided naturally through structuring a multi-objective optimization problem. Then, we theoretically prove that the new construction can protect both data and semantic privacy. Finally, the experimental evaluations based on the real-world private vehicle trajectory dataset demonstrate that seitp outperforms existing mechanisms. © 2005-2012 ieee.","","","2022","10.1109/tifs.2022.3181855","","","scopus-2-s2.0-85132734002.pdf","scopus-2-s2.0-85132734002"
"Stability of scientific big data sharing mechanism based on two-way principal-agent","Zhang, W. And Zhang, J.","Aims Mathematics","","In the era of big data, facing the data-intensive scientific paradigm shift and the explosion of scientific big data, there is an urgent need for alliance cooperation between heterogeneous research groups to actively open and share scientific big data to support china's economic development, technological innovation and national security. Therefore, the study of scientific big data sharing mechanism has very important practical significance. We think science big data sharing is an ecosystem that is constantly evolving to higher-order ecological evolution. Based on the dual perspectives of psychological contract and contractual contract, the scientific big data sharing strategy evolution mechanism and sharing strategy incentive mechanism are explored .The research finds that the cooperation of scientific research groups is bound by psychological contract and contractual contract;  stochastic evolutionary game has stronger explanatory power for sharing strategy evolution, complementarity is positive indicator, random interference and moral risk are negative indicators;  two-way principal agent can describe alliance members are mutually entrusted, and the shared strategy incentive contract consists of fixed wages and incentive wages, which are proportional to risk. © 2023 the author(s), licensee aims press.","","","2023","10.3934/math.2023955","","","scopus-2-s2.0-85161375955.pdf","scopus-2-s2.0-85161375955"
"Quality of reporting in 41 randomized controlled clinical trials of chinese medicine for cancer pain","Xu, L. And Wei, P.-K. And Sun, D.-Z. And Lao, L.","World Chinese Journal Of Digestology","","Aim: to highlight the importance and necessity of quality assurance in clinical trial reporting by analyzing 41 papers on of chinese medicine for cancer pain. Methods: a search for clinical trial reports published from 1986 to 2006 on the effects, mechanisms, safety and application of chinese herbal medicine in cancer pain management was conducted using the cbm, chinese medical current contents (cmcc) and weipu (available since 1989) databases in chinese, and pubmed and embase in english. We evaluated the methodological quality of the articles, following the guidelines set forth in levels of evidence of human studies of cancer in complementary and alternative medicine by the national cancer institute (nci) and quality of reporting of randomized controlled trials of herbal medicine interventions by gagnier et al. Results: some research information was insufficiently reported, including methods of randomization, inclusion and exclusion criteria, outcome measurements, blinding and concealment, quality control and quality assurance of herbal preparations, and adverse events. Conclusion: two crucial elements of high quality scientific reporting are the provision of sufficient research information and the transparency of research methodology. Insufficient reporting may be one of the major reasons. Chinese medicine is not widely and globally used to treat cancer pain.","","","2007","10.11569/wcjd.v15.i35.3764","","","scopus-2-s2.0-41149113464.pdf","scopus-2-s2.0-41149113464"
"Reconsidering what makes syntheses of psychological intervention studies useful","Sakaluk, J.k. And De Santis, C. And Kilshaw, R. And Pittelkow, M.-M. And Brandes, C.m. And Boness, C.l. And Botanov, Y. And Williams, A.j. And Wendt, D.c. And Lorenzo-Luaces, L. And Schleider, J. And Van Ravenzwaaij, D.","Nature Reviews Psychology","","Syntheses of literature on psychological interventions have defined the state of knowledge and helped to identify evidence-based practices for researchers, practitioners, educators and policymakers. Nevertheless, it is complicated to appraise the usefulness of syntheses owing to long-standing methodological issues and the rapid rate of research production. In this perspective, we examine how syntheses of psychological interventions could be more useful. We argue that syntheses should move beyond the myopic lens of intervention impact based on a one-time, contested selection of literature and comprehensible only to intensively trained readers. Rather, syntheses should become ‘living’ documents that integrate data on intervention impact, consistency, research credibility and sampling inclusivity, all of which must then be presented in a modular way that is also accessible to people of limited expertise. Although existing resources make pursuit of this goal possible, reaching it will require a dramatic change in the ways in which psychologists collaborate and in which syntheses are conducted, disseminated and institutionally supported. © 2023, springer nature america, inc.","","","2023","10.1038/s44159-023-00213-9","","","scopus-2-s2.0-85165891638.pdf","scopus-2-s2.0-85165891638"
"Comparability and reproducibility of biomedical data","Huang, Y. And Gottardo, R.","Briefings In Bioinformatics","","With the development of novel assay technologies, biomedical experiments and analyses have gone through substantial evolution. Today, a typical experiment can simultaneously measure hundreds to thousands of individual features (e.g. genes) in dozens of biological conditions, resulting in gigabytes of data that need to be processed and analyzed. Because of the multiple steps involved in the data generation and analysis and the lack of details provided, it can be difficult for independent researchers to try to reproduce a published study. With the recent outrage following the halt of a cancer clinical trial due to the lack of reproducibility of the published study, researchers are now facing heavy pressure to ensure that their results are reproducible. Despite the global demand, too many published studies remain non-reproducible mainly due to the lack of availability of experimental protocol, data and/or computer code. Scientific discovery is an iterative process, where a published study generates new knowledge and data, resulting in new follow-up studies or clinical trials based on these results. As such, it is important for the results of a study to be quickly confirmed or discarded to avoid wasting time and money on novel projects. The availability of high-quality, reproducible data will also lead to more powerful analyses (or meta-analyses) where multiple data sets are combined to generate new knowledge. In this article, we review some of the recent developments regarding biomedical reproducibility and comparability and discuss some of the areas where the overall field could be improved. © the author 2012. Published by oxford university press.","","","2013","10.1093/bib/bbs078","","","scopus-2-s2.0-84889004965.pdf","scopus-2-s2.0-84889004965"
"Evaluating impact from research: a methodological framework","Reed, M.s. And Ferré, M. And Martin-Ortega, J. And Blanche, R. And Lawford-Rolfe, R. And Dallimer, M. And Holden, J.","Research Policy","","Background: interest in impact evaluation has grown rapidly as research funders increasingly demand evidence that their investments lead to public benefits. Aims: this paper analyses literature to provide a new definition of research impact and impact evaluation, develops a typology of research impact evaluation designs, and proposes a methodological framework to guide evaluations of the significance and reach of impact that can be attributed to research. Method: an adapted grounded theory analysis of research impact evaluation frameworks drawn from cross-disciplinary peer-reviewed and grey literature. Results: recognizing the subjective nature of impacts as they are perceived by different groups in different times, places and cultures, we define research impact evaluation as the process of assessing the significance and reach of both positive and negative effects of research. Five types of impact evaluation design are identified encompassing a range of evaluation methods and approaches: i) experimental and statistical methods;  ii) textual, oral and arts-based methods;  iii) systems analysis methods;  iv) indicator-based approaches;  and v) evidence synthesis approaches. Our guidance enables impact evaluation design to be tailored to the aims and context of the evaluation, for example choosing a design to establish a body of research as a necessary (e.g. a significant contributing factor amongst many) or sufficient (e.g. sole, direct) cause of impact, and choosing the most appropriate evaluation design for the type of impact being evaluated. Conclusion: using the proposed definitions, typology and methodological framework, researchers, funders and other stakeholders working across multiple disciplines can select a suitable evaluation design and methods to evidence the impact of research from any discipline. © 2020","","","2021","10.1016/j.respol.2020.104147","","","scopus-2-s2.0-85098954100.pdf","scopus-2-s2.0-85098954100"
"Analysis of the effectiveness of the road-crash database in the united arab emirates","Hawas, Y.e. And Khan, M.b. And Maraqa, M.a.","Journal Of Transportation Safety And Security","","This study presents an approach to assess the effectiveness of road-crash databases in providing meaningful analysis. The assessment was done for the case of the database system in the united arab emirates. The assessment was based on feedback from two groups: one involved crash investigators and database managers, and the second involved other traffic safety experts. A quantitative geographical information system-based data analysis was also included to illustrate some deficiencies in the existing database. The survey of crash investigators and database managers focused on aspects including database utilization, technology for providing data services, methods of data collection, sufficiency of the traffic crash report, difficulties in the traffic crash report, and sufficiency of pedestrian crash data. The experts' survey addressed aspects of difficulties of the traffic crash report and database system, required data for crash analyses, need of in-depth crash data, need for global positioning system data, involving a private party in handling the database system, and permissible extent of data sharing. The conducted analyses were used to subjectively quantify the importance and the perceived level of satisfaction of the surveyed aspects. This was then used to propose measures to upgrade the database system and the crash investigation process to overcome the identified deficiencies. © 2012 copyright taylor and francis group, llc.","","","2012","10.1080/19439962.2012.659417","","","scopus-2-s2.0-84864693264.pdf","scopus-2-s2.0-84864693264"
"Information, communications and media technologies for sustainability: constructing data-driven policy narratives","Sharma, R. And Shaikh, A.a. And Bekoe, S. And Ramasubramanian, G.","Sustainability (Switzerland)","","This paper introduces the idea of data-driven narratives to examine how the use of infor-mation, communications, and media technologies (icmts) impacts the sustainable growth of econ-omies. While icmts have regularly been advocated as a policy tool for growth and development, there is a research gap in empirical studies validating how such policies may be effective. This analysis is based on historical panel data from 39 economies across the developed north (19) and developing south (20). The industry-standard cross-industry standard process for data mining (crisp-dm) methodology was applied to construct narratives that weave extant theories with empirical data. The art of developing data-driven narratives is rarely addressed in previous research articles. In the narrative approach, prior research on how icmts and sustainable growth are quantitatively scored and measured is reviewed. Panel data from authoritative sources such as the united nations, world economic forum, and sustainable society index were collected, cleansed, and conglomer-ated for data analytics. This was followed by evidence-based reasoning to examine any possible relationships between icmt development and the sustainable growth of economies across the “north” and “south”. The findings reveal that there are differentiated outcomes in sustainable growth in high-and low-income economies. This poses legitimate questions as to whether low-income economies will be able to meet the un’s sustainable development goals by 2030 through the intermediation of icmts. It is the intended contribution of this paper to exemplify how data-driven narratives using crisp may construct rich stories about icmt for sustainability for the pur-poses of sharing good practice as well as lessons learned. © 2021 by the authors. Licensee mdpi, basel, switzerland.","","","2021","10.3390/su13052903","","","scopus-2-s2.0-85102887654.pdf","scopus-2-s2.0-85102887654"
"Informed consent in a tuberculosis genetic study in cameroon: information overload, situational vulnerability and diagnostic misconception","Mohammed-Ali, A.i. And Gebremeskel, E.i. And Yenshu, E. And Nji, T. And Ntabe, A.c. And Wanji, S. And Tangwa, G.b. And Munung, N.s.","Research Ethics","","Concerns around comprehension and recall of consent information by research participants have typically been associated with low health and research literacy levels. In genomics research, this concern is heightened as the scientific and ethical complexities of genetics research, such as biobanking, genetic susceptibility, data sharing, and incidental findings may be more difficult for potential research participants to understand. However, challenges to research participants’ comprehension of consent information may be compounded by factors beyond health and research literacy levels. To identify factors that may impact research participants’ understanding and recall of consent information, we designed a qualitative study to explore whether participants enrolled in a tuberculosis genetics study (tbgen-africa) in cameroon understood the objectives of the study, the risks and benefits and certain key aspects of the study such as biobanking and data sharing. The results showed that research participants had limited understanding and/or recall of the tbgen-africa study goals and methods. Some participants were of the opinion that tbgen-africa was not a genetics study because tuberculosis is not an inheritable condition. Factors that may have hindered understanding and/or recall of study information are diagnostic misconception (research participants consider research as part of medical diagnosis), and information overload and situational vulnerability (consent at a time of physical and emotional distress). There is a need for improved practices to support research participants’ understanding of consent information in genetics studies including designing the consent process in ways that minimize psychological distress and diagnostic/therapeutic misconception. © the author(s) 2022.","","","2022","10.1177/17470161221106674","","","scopus-2-s2.0-85131863179.pdf","scopus-2-s2.0-85131863179"
"A demonstration of reproducible state-of-the-art energy disaggregation using NILMTK","Batra N., Kukunuri R., Pandey A., Malakar R., Kumar R., Krystalakos O., Zhong M., Meira P., Parson O.","","","Non-intrusive load monitoring (NILM) or energy disaggregation involves separating the household energy measured at the aggregate level into constituent appliances. The NILM toolkit (NILMTK) was introduced in 2014 towards making NILM research reproducible. NILMTK has served as the reference library for data set parsers and reference benchmark algorithm implementations. However few publications presenting algorithmic contributions within the field went on to contribute implementations back to the toolkit. This work presents a demonstration of a new version of NILMTK [2] which has a rewrite of the disaggregation API and a new experiment API which lower the barrier to entry for algorithm developers and simplify the definition of algorithm comparison experiments. This demo also marks the release of NILMTK-contrib: a new repository containing NILMTK-compatible implementations of 3 benchmarks and 9 recent disaggregation algorithms. The demonstration covers an extensive empirical evaluation using a number of publicly available data sets across three important experiment scenarios to showcase the ease of performing reproducible research in NILMTK. © 2019 Association for Computing Machinery.","","","2019","10.1145/3360322.3360999","","","scopus-2-s2.0-85077293639.pdf","scopus-2-s2.0-85077293639"
"Pre-registration nursing students’ perceptions and experience of intentional rounding: a cross-sectional study","Ryan, E.l.j. And Jackson, D. And Woods, C. And Usher, K.j.","Nurse Education In Practice","","This paper examines pre-registration nursing students’ perceptions of the practice of intentional rounding and perceived benefits for nurses and patients. Intentional rounding was developed to ensure nursing staff regularly check on patients to ensure that all care needs are met. It has been linked to a reduction in falls and call bell use, and an increase in patient safety. No previous studies have examined pre-registration nursing students’ role in the practice of intentional rounding during clinical placements nor the perceptions of rounding practices, important from a future workforce perspective. A cross-sectional multisite study was undertaken, and pre-registration nursing students completed the nurses’ perceptions of patient rounding scale between august 2017– june 2018, distributed using online education platforms and email. Strobe reporting guidelines were used to report findings. Participants perceived positive benefits in intentional rounding for nurses and patients. Mixed opinions surrounded the sufficiency of education received around the intervention. Previous nursing experience was linked to opposing opinions of intentional rounding, depending on education levels. Participants had a positive perception of intentional rounding practices overall. Education surrounding intentional rounding needs to be consistent, and introduced before students are expected to actively participate in the practice of rounding on clinical placement. © 2020 elsevier ltd","","","2020","10.1016/j.nepr.2019.102691","","","scopus-2-s2.0-85077653593.pdf","scopus-2-s2.0-85077653593"
"Diet composition as a source of variation in experimental animal models of cancer cachexia","Giles, K. And Guan, C. And Jagoe, T.r. And Mazurak, V.","Journal Of Cachexia, Sarcopenia And Muscle","","Background: a variety of experimental animal models are used extensively to study mechanisms underlying cancer cachexia, and to identify potential treatments. The important potential confounding effect of dietary composition and intake used in many preclinical studies of cancer cachexia is frequently overlooked. Dietary designs applied in experimental studies should maximize the applicability to human cancer cachexia, meeting the essential requirements of the species used in the study, matched between treatment and control groups as well as also being generally similar to human consumption. Methods: a literature review of scientific studies using animal models of cancer and cancer cachexia with dietary interventions was performed. Studies that investigated interventions using lipid sources were selected as the focus of discussion. Results: the search revealed a number of nutrient intervention studies (n=44), with the majority including n-3 fatty acids (n=16), mainly eicosapentaenoic acid and/or docosahexaenoic acid. A review of the literature revealed that the majority of studies do not provide information about dietary design;  food intake or pair-feeding is rarely reported. Further, there is a lack of standardization in dietary design, content, source, and overall composition in animal models of cancer cachexia. A model is proposed with the intent of guiding dietary design in preclinical studies to enable comparisons of dietary treatments within the same study, translation across different study designs, as well as application to human nutrient intakes. Conclusion: the potential for experimental endpoints to be affected by variations in food intake, macronutrient content, and diet composition is likely. Diet content and composition should be reported, and food intake assessed. Minimum standards for diet definition in cachexia studies would improve reproducibility of pre-clinical studies and aid the interpretation and translation of results to humans with cancer. © 2016 john wiley & sons ltd.","","","2016","10.1002/jcsm.12058","","","scopus-2-s2.0-84951980981.pdf","scopus-2-s2.0-84951980981"
"The quality of reporting in clinical research: the consort and strobe initiatives","Bolignano, D. And Mattace-Raso, F. And Torino, C. And D'arrigo, G. And Elhafeez, S.a. And Provenzano, F. And Zoccali, C. And Tripepi, G.","Aging Clinical And Experimental Research","","Inaccurate reporting of data hampers the generalizability and the correct interpretation of results of scientific medical papers. The consolidated standards of reporting trials (consort) and strengthening the reporting of observational studies in epidemiology (strobe) initiatives, both included in the enhancing the quality and transparency of health research (equator) international network, have elaborated appropriate guidelines in order to improve the transparence, clearness and completeness of scientific literature. The consort statement consists of a 25 items checklist and a flow-chart diagram which provide guidance to authors on how to report randomized clinical trials. The strobe is a checklist of 22 items which should be addressed when observational studies (case-control, cohort and cross-sectional) are made up. Many editorial committees and prestigious international journals have now embraced these guidelines to improve the quality and methodology of their scientific reports. © 2013 springer international publishing switzerland.","","","2013","10.1007/s40520-013-0007-z","","","scopus-2-s2.0-84887026610.pdf","scopus-2-s2.0-84887026610"
"A robust knockoff filter for sparse regression analysis of microbiome compositional data","Monti, G.s. And Filzmoser, P.","Computational Statistics","","Microbiome data analysis often relies on the identification of a subset of potential biomarkers associated with a clinical outcome of interest. Robust zerosum regression, an elastic-net penalized compositional regression built on the least trimmed squares estimator, is a variable selection procedure capable to cope with the high dimensionality of these data, their compositional nature, and, at the same time, it guarantees robustness against the presence of outliers. The necessity of discovering “true” effects and to improve clinical research quality and reproducibility has motivated us to propose a two-step robust compositional knockoff filter procedure, which allows selecting the set of relevant biomarkers, among the many measured features having a nonzero effect on the response, controlling the expected fraction of false positives. We demonstrate the effectiveness of our proposal in an extensive simulation study, and illustrate its usefulness in an application to intestinal microbiome analysis. © 2022, the author(s).","","","2022","10.1007/s00180-022-01268-7","","","scopus-2-s2.0-85136303356.pdf","scopus-2-s2.0-85136303356"
"19. Putting it together","Anonymous","Scandinavian Journal of Public Health","","The goal of these Guidelines is to benefit populations at risk through improving the quality of responses to the health aspects of disasters. This will be achieved through the development of methods that open disasters to structured reproducible research and thereby contributing to the science of health disaster management. Five major barriers were identified that impaired our ability to attain these goals: (1) lack of a endorsed terminology (2) lack of a standard descriptive system for society and its functions; (3) lack of structured description of disaster phases based on their properties; (4) widely distributed grey literature; and (5) no common structure to reports. In response to these findings many commonly held processes have been deconstructed into a total of four frameworks the use of which should help in meeting the goal. The use of the frameworks should provide further insight into the epidemiology of disasters in addition to the insight of the value of interventions provided for relief recovery and/or preparedness once a disaster occurs or a hazard has been identified. The way forward should include the development of consensus on definitions used in the health aspects of disasters and for a repository of interventions applied in specific settings that include their respective effectiveness in attaining the goal for which they were selected. In addition existing literature and future reports should be forced into the frameworks to facilitate our understanding and to develop the science of health disaster evolution of standards best practices and competencies but also to test and further improve these Guidelines. The frameworks should be augmented by standardised data collection instruments including templates for the gathering organisation and synthesis of data.","","","2014","10.1177/1403494813515128","","","medline-24785816.pdf","medline-24785816"
"The ethics of big data as a public good: which public? Whose good?","Taylor, L.","Philosophical Transactions Of The Royal Society A: Mathematical, Physical And Engineering Sciences","","International development and humanitarian organizations are increasingly calling for digital data to be treated as a public good because of its value in supplementing scarce national statistics and informing interventions, including in emergencies. In response to this claim, a 'responsible data' movement has evolved to discuss guidelines and frameworks that will establish ethical principles for data sharing. However, this movement is not gaining traction with those who hold the highest-value data, particularly mobile network operators who are proving reluctant to make data collected in low-and middle-income countries accessible through intermediaries. This paper evaluates how the argument for 'data as a public good' fits with the corporate reality of big data, exploring existing models for data sharing. I draw on the idea of corporate data as an ecosystem involving often conflicting rights, duties and claims, in comparison to the utilitarian claim that data's humanitarian value makes it imperative to share them. I assess the power dynamics implied by the idea of data as a public good, and how differing incentives lead actors to adopt particular ethical positions with regard to the use of data. This article is part of the themed issue 'the ethical impact of data science'. © 2016 the author(s) published by the royal society. All rights reserved.","","","2016","10.1098/rsta.2016.0126","","","scopus-2-s2.0-85000936665.pdf","scopus-2-s2.0-85000936665"
"Ethical frameworks in clinical research processes during covid-19: a scoping review","Kasherman, L. And Madariaga, A. And Liu, Q. And Bonilla, L. And Mcmullen, M. And Liu, S.l. And Wang, L. And Fazelzad, R. And Karakasis, K. And Heesters, A.m. And Oza, A.m.","Bmj Open","","Objectives in response to the covid-19 pandemic there have been significant developments in research, its conduct and the supporting ethical framework. While many protocols have been delayed, halted or modified, other research efforts have been accelerated, generating controversy. The goal of this paper is to determine the rates of references surrounding the ethical oversight of research as reported in current covid-19-related research publications. Design scoping review. Setting population-based observational or interventional studies from december 2019 to may 2020 with sample size of two or more. Studies were searched through electronic databases including medline, embase, and cochrane central register of controlled trials. Participants eligibility criteria included participants within published studies who tested positive for covid-19. Main outcomes and measures data were extracted and charting methods included taking note of references to ethical frameworks, institutional review board (irb), ethics committee (ec) or research ethics board (reb) involvement, consent processes, and other variables. Results 11 556 articles were screened, with 656 included in the final analysis. References to ethics were present in 530 (80.8%) studies, with 491 (74.8%) involving irb/ecs/rebs and 126 (19.2%) not referencing ethics. Consent processes were outlined in 201 (30.6%) studies, with 198 (30.2%) reporting that they obtained consent waivers, however, 257 (39.2%) did not mention consent at all. Differences (p<0.001) in ethics-related references were apparent when analysed by continent, publication type, sample size and if. Conclusions the majority of published articles pertaining to covid-19 research made mention of ethical considerations, however, national and regional variations in research ethics review requirements introduce heterogeneity between studies and raise important questions about the conduct of scientific research during global public emergencies. Trial registration number open science framework: https://osfio/z67wb. ©","","","2021","10.1136/bmjopen-2020-047076","","","scopus-2-s2.0-85111465609.pdf","scopus-2-s2.0-85111465609"
"What is the best available science? A comparison of marine scientists, managers, and interest groups in the united states","Wolters, E.a. And Steel, B.s. And Lach, D. And Kloepfer, D.","Ocean And Coastal Management","","In recent years there have been calls among decision makers, interest groups, citizens, and scientists alike for the use of the ""best available science"" when making environmental policy and managing natural resources. The assumption is that including scientists and the best available scientific information will improve the quality of complex policy decisions. Others have argued, however, that science and scientists are just one source of expertise concerning environmental management and increasing involvement will not necessarily lead to better policy. We report on a study examining the attitudes and orientations of marine scientists, resource managers, and interest group representatives concerning factors that may affect scientific credibility, the credibility of scientific research produced by various organizations, and perceptions of the ability of certain groups to understand scientific research. Using national random sample surveys and interviews of marine scientists, marine managers, and interest groups involved in marine policy issues conducted in 2011, we examine indicators of scientific credibility, data, research and reputation;  the ability of scientists to communicate findings;  and the role of scientists in the policy process. Further, we explore what factors contribute to credible science, the credibility of the science produced by various organizations, and the scientific literacy of various policy actors. © 2016 elsevier ltd.","","","2016","10.1016/j.ocecoaman.2016.01.011","","","scopus-2-s2.0-84961346547.pdf","scopus-2-s2.0-84961346547"
"An empirical study for radio frequency identification (rfid) adoption by smes in the taiwanese information technology (it) industry","Chen, H. And Papazafeiropoulou, A.","Asian Academy Of Management Journal","","Radio frequency identification (rfid) technology represents a common standard for data storage and retrieval that could improve collaboration and data sharing between non-competing organisations. With the advent of rfid, organisations have the opportunity to rethink how their organisation will operate and integrate in the supply chain. Especially for small to medium sized enterprises (smes), that they have limited resources adopting such an innovative technology (i.e. Rfid) the adoption decision can be daunting. Literature indicates that smes that decide to go on with implementation have so far only a few guidelines from either private companies or public authorities regarding awareness on specific opportunities and risks. This research is therefore trying to explore in detail the factors that affect smes' rfid adoption in the taiwan information technology (it) manufacturing industry. We are employing exploratory factor analysis (efa) techniques and utilising a questionnaire survey in order to collect and analyse our data. After classifying the responding smes into three different adopters categories named ready adopter, initiator adopter and unprepared adopter using efa technique our results show that each category has some specific adoption factors related to their unique situation. These are for ready adopters: cost and management, for initiator adopters: competitiveness and process efficiency and unprepared adopters: it management difficulties, it implementation difficulties and cost of implementation. A smes rfid adoption model is then proposed. It is anticipated that the findings of this research will not only enhance the research in rfid adoption in smes, but can also act as a reference for practitioners in the industry and researchers in the academic field. © asian academy of management and penerbit universiti sains malaysia, 2012.","","","2012","","","","scopus-2-s2.0-84871855370.pdf","scopus-2-s2.0-84871855370"
"Extensibility and composability of a multi-stencil domain specific framework","Coullon, H. And Bigot, J. And Perez, C.","International Journal Of Parallel Programming","","As the computation power of modern high performance architectures increases, their heterogeneity and complexity also become more important. One of the big challenges of exascale is to reach programming models that give access to high performance computing (hpc) to many scientists and not only to a few hpc specialists. One relevant solution to ease parallel programming for scientists is domain specific language (dsl). However, one problem to avoid with dsls is to mutualize existing codes and libraries instead of implementing each solution from scratch. For example, this phenomenon occurs for stencil-based numerical simulations, for which a large number of languages has been proposed without code reuse between them. The multi-stencil framework (msf) presented in this paper combines a new dsl to component-based programming models to enhance code reuse and separation of concerns in the specific case of stencils. Msf can easily choose one parallelization technique or another, one optimization or another, as well as one back-end implementation or another. It is shown that msf can reach same performances than a non component-based mpi implementation over 16,384 cores. Finally, the performance model of the framework for hybrid parallelization is validated by evaluations. © 2017, springer science+business media, llc, part of springer nature.","","","2019","10.1007/s10766-017-0539-5","","","scopus-2-s2.0-85034622453.pdf","scopus-2-s2.0-85034622453"
"Quality analysis of operative reports and referral data for appendiceal neoplasms with peritoneal dissemination","Mangieri C. W., Moaven O., Votanopoulos K. I., Shen P., Levine E. A.","Surgery","","BACKGROUND: Peritoneal metastasis from appendiceal neoplasms is a rare disease usually found unexpectedly and is associated with deficits in quality reporting of findings.\\\\\\\\rMETHODS: Retrospective review of our appendiceal peritoneal metastases carcinomatosis database evaluating quality of index operative and pathology reports. Operative report quality was graded by 2 standards; general quality based on Royal College of Surgeons quality metrics and peritoneal metastases assessment. Pathology report quality was assessed by the accuracy of diagnosis.\\\\\\\\rRESULTS: Three hundred and seventy-five index operative reports and 490 outside pathology reports were reviewed. General quality of the index operative reports was excellent with nearly 80% of reports encompassing all the Royal College of Surgeons quality metrics. Peritoneal metastases assessment was poor. Forty-four percent of the reports performed no peritoneal evaluation while 48.3% only involved partial peritoneal evaluation. Only 7.7% of the reports performed a complete evaluation. Of the pathology reports 48.4% had discrepancies with final pathologic findings. Low-grade disease and high-grade disease were misdiagnosed 36.06% and 62.7% of the time respectively. Discordant treatment occurred in 15.3% and 30.0% of cases for misdiagnosed low-grade and high-grade disease respectively. Incomplete cytoreduction was attempted in nearly a third of referral cases which was associated with a significantly increased risk for ultimate incomplete cytoreduction with an odds ratio of 4.72.\\\\\\\\rCONCLUSION: This review finds that referral operative reports' descriptions of the technical aspects of a procedure is usually complete. However oncologic parameters and descriptions of peritoneal metastases are frequently incomplete. Further pathology reports from outside institutions can lead to inappropriate clinical management decisions. We propose a simplified algorithm to assist nonperitoneal surface malignancy surgeons. Copyright © 2020 Elsevier Inc. All rights reserved.","","","2021","10.1016/j.surg.2020.10.001","","","medline-33190916.pdf","medline-33190916"
"Methodological considerations in risk assessment research","Fazel, Seena And Bjorkly, Stal","","","There has been increasing awareness in scientific research of the importance of accounting for possible biases and the need for transparency. This ""research on research"" has been driven in part by the problems of publication bias in treatment and observational research, and also by the lack of validation for risk factors, associations, and biomarkers in many areas of science, including psychology (baker, 2015). Furthermore, much research is not applied in clinical practice, sometimes because interventions are not detailed sufficiently in publications to allow for their implementation. This has led some prominent commentators to estimate that more than 90% of all scientific research may be wasted as a consequence. (Psycinfo database record (c) 2021 apa, all rights reserved)","","","2016","10.1093/acprof:oso/9780199386291.003.0002","","","psychinfo-2016-40455-002.pdf","psychinfo-2016-40455-002"
"Artificial intelligence – will we be replaced by robots?","Delahunty, M.","Medical Writing","","Advances in artificial intelligence (ai) increasingly dominate the news with billions of dollars in funding invested to combine ai with machine learning and data science across many disciplines, including medicine and healthcare. Within the context of scholarly scientific and academic publishing, ai is seen also as a potential means of bringing more speed, efficiency, and effectiveness to current and increasingly challenged processes and systems as well as supporting open science principles. © 2019, european medical writers association. All rights reserved.","","","2019","","","","scopus-2-s2.0-85073564192.pdf","scopus-2-s2.0-85073564192"
"Validation and regulatory acceptance of alternative methods for toxicity evaluation","Ohno, Y.","Bulletin Of National Institute Of Health Sciences","","For regulatory acceptance of alternative methods (ams) to animal toxicity tests, their reproducibility and relevance should be determined by intra- and inter-laboratory validation. Appropriate procedures of the validation and regulatory acceptance of ams were recommended by oecd in 1996. According to those principles, several in vitro methods like skin corrosivity tests and phototoxicity tests were evaluated and accepted by ecvam (european center for the validation of alternative methods), iccvam (the interagency coordinating committee on the validation of alternative methods), and oecd. Because of the difficulties in conducting inter-laboratory validation and relatively short period remained until eu's ban of animal experiments for safety evaluation of cosmetics, ecvam and iccvam have recently started cooperation in validation and evaluation of ams. It is also necessary to establish jacvam (japanese center for the validation of am) to contribute the issue and for the evaluation of new toxicity tests originated in japan.","","","2004","","","","scopus-unknown-accession-2752511.pdf","scopus-unknown-accession-2752511"
"The use and abuse of multiple outcomes in randomized controlled depression trials","Tyler K. M., Normand S. L., Horton N. J.","Contemporary Clinical Trials","","OBJECTIVE: Multiple outcomes are commonly analyzed in randomized trials. Interpretation of the results of trials with many outcomes is not always straightforward. We characterize the prevalence and factors associated with multiple outcomes in reports of clinical trials of depression methods used to account for these outcomes and concordance between published analyses and original protocol specifications.\\\\\\\\rMETHODS: A PubMed search for randomized controlled depression trials that included multiple outcomes published between January 2007 and October 2008 in 6 medical journals. Original study protocols were reviewed where available. Parallel data collection by 2 abstractors was used to determine trial registration information the number of outcomes and analytical method.\\\\\\\\rRESULTS: Of the 55 included trials nearly half of the papers reported more than 1 primary outcome while almost all (90.9% n = 50) reported more than 2 combined primary or secondary outcomes. Relatively few of the studies (5.8% n = 3) adjusted for multiple outcomes. While most studies had published protocols in clinical trial registries (76.4% n = 42) many did not specify outcomes in the protocol (n = 11) and a number had discrepancies with the published report.\\\\\\\\rCONCLUSIONS: Multiple outcomes are prevalent in randomized controlled depression trials and appropriate statistical analyses to account for these methods are rarely used. Not all studies filed protocols and there were discrepancies between these protocols and published reports. These issues complicate interpretability of trial results and in some cases may lead to spurious conclusions. Promulgation of guidelines to improve analysis and reporting of multiple outcomes is warranted. Copyright © 2010 Elsevier Inc. All rights reserved.","","","2011","10.1016/j.cct.2010.12.007","","","medline-21185405.pdf","medline-21185405"
"Distributed data bases. A summary of research","Deppe, M.e. And Fry, J.p.","Computer Networks (1976)","","The overall objective for distributed data bases is the sharing of data among several distinct but inter-connected computing facilities through an integrating mechanism. A review of the literature indicates that little progress has been made in this area due to the large number of technological problems involved. Some researchers have obtained analytical/theoretical results in the area of physical data allocation under the restrictive assumptions of static and known access patterns and independence between programs and data. The remaining unsolved technological and operational problems include measurement and evaluation techniques, maintenance of multiple image files, and security/privacy. In the next five to ten years significant benefits would accrue if data translation techniques, an integrated data base control system, and the integrated data base schema and physically distributed data issues were investigated. © 1976.","","","1976","10.1016/0376-5075(76)90018-0","","","scopus-2-s2.0-49549129596.pdf","scopus-2-s2.0-49549129596"
"Ensuring participant safety and trial integrity with clinical trials oversight","Godfrey C., Payton M., Tasker S., Proestel S., Schouten J. T.","Journal of Acquired Immune Deficiency Syndromes: JAIDS","","Clinical trial oversight is a critical element that ensures the protection of research participants and integrity of the data collected. The trial sponsor a local Institutional Review Board and independent monitoring committees all contribute with complementary but overlapping responsibilities. Consistency among these groups is essential for the smooth conduct of a clinical trial but may be challenging in resource-limited settings (RLS). Capacity building and training for RLS may improve clinical trials oversight and ultimately medical management. In this article we review the components necessary for optimal clinical trial oversight and the issues that arise in the RLS with some suggested strategies for improvement.","","","2014","10.1097/qai.0000000000000041","","","medline-24321985.pdf","medline-24321985"
"Research on cim update and extension based on ontology","Zhe, C. And Dong, L.","Research Journal Of Applied Sciences, Engineering And Technology","","The problem of model difference exists in the application integration based on cim. Difference caused by diverse versions will lead to semantic conflict and inconsistency, which make data sharing impossible. To solve this problem, we need to perform research on cim update and extension. Therefore we propose a cim update and extension research method based on ontology. In this study the cim update and extension are divided into four scenarios, add, delete, change and rename and corresponded algorithm are discussed. Finally, we conduct an experiment based on real model and compare the results with the ones did manually to verify this research's effectiveness and practicality. © maxwell scientific organization, 2013.","","","2013","10.19026/rjaset.6.3738","","","scopus-2-s2.0-84881309227.pdf","scopus-2-s2.0-84881309227"
"The New Serious Incident Response Scheme and the Responsive Regulation of Abuse in Aged Care","Barry L., Hughes P.","Journal of Law & Medicine","","In response to criticisms of the reporting criteria for abuse in aged care that were aired in the Australian Law Reform Commission's Report into Elder Abuse and more recently the Royal Commission into Aged Care Quality and Safety a new Serious Incident Response Scheme (SIRS) came into effect in April 2021. The new SIRS expands the definition of elder abuse and removes the exemption for reporting resident on resident abuse where the perpetrator has a diagnosed cognitive impairment. The Aged Care Quality Commission has outlined a comprehensive plan for the new SIRS in line with their model of responsive regulation. This article questions the extent to which the new scheme will improve regulation of reporting and management of resident-to-resident assaults and reduce abuse in the aged care sector if not accompanied by improvements in the staffing levels and working conditions for the aged care workforce.","","","2022","","","","medline-35819386.pdf","medline-35819386"
"Systematic review and critical appraisal of Childhood Trauma Questionnaire - Short Form (CTQ-SF)","Georgieva S., Tomas J. M., Navarro-Perez J. J.","Child Abuse & Neglect","","BACKGROUND: Child maltreatment is a complex and multidimensional construct that encompasses a great number of risk factors. The Childhood Trauma Questionnaire - Short Form one of the most widely used and validated instruments to assess childhood maltreatment in the past ten years is a retrospective instrument that assesses several types of childhood abuse and maltreatment which is divided into five dimensions.\\\\\\\\rOBJECTIVE: The objectives of this systematic review are to critically appraise compare and summarize the methodological quality and psychometric properties of published research articles validating the Childhood Trauma Questionnaire - Short Form utilizing the COSMIN checklist.\\\\\\\\rMETHOD: Articles published in English or Spanish in the past ten years in the databases of Scopus Web of Science and ProQuest and which directly or indirectly analyzed psychometric properties of the CTQ-SF were screened examined and assessed utilizing the COSMIN checklist.\\\\\\\\rRESULTS: Main results indicate that there is a general pattern of assessing the same three psychometric properties (internal consistency structural validity and hypothesis testing) in a variety of samples but leaving unassessed the rest of properties examined by the COSMIN checklist. Additionally there are some problems with the internal consistency of several factors.\\\\\\\\rIMPLICATIONS AND CONCLUSIONS: While replicability and internal consistency are good psychometric indicators of the CTQ-SF there is a big scientific gap of information regarding some psychometric properties. It is suggested that future research should address the remaining psychometric properties reliability measurement error content validity cross cultural and criterion validity as well as re-examining internal consistency of some dimensions in order to advance in the knowledge on childhood maltreatment assessment. Copyright © 2021 Elsevier Ltd. All rights reserved.","","","2021","10.1016/j.chiabu.2021.105223","","","medline-34352686.pdf","medline-34352686"
"Lightweight privacy-preserving data sharing scheme for internet of medical things","Zhao, Z. And Hsu, C. And Harn, L. And Yang, Q. And Ke, L.","Wireless Communications And Mobile Computing","","Internet of medical things (iomt) is a kind of internet of things (iot) that includes patients and medical sensors. Patients can share real-time medical data collected in iomt with medical professionals. This enables medical professionals to provide patients with efficient medical services. Due to the high efficiency of cloud computing, patients prefer to share gathering medical information using cloud servers. However, sharing medical data on the cloud server will cause security issues, because these data involve the privacy of patients. Although recently many researchers have designed data sharing schemes in medical domain for security purpose, most of them cannot guarantee the anonymity of patients and provide access control for shared health data, and further, they are not lightweight enough for iomt. Due to these security and efficiency issues, a novel lightweight privacy-preserving data sharing scheme is constructed in this paper for iomt. This scheme can achieve the anonymity of patients and access control of shared medical data. At the same time, it satisfies all described security features. In addition, this scheme can achieve lightweight computations by using elliptic curve cryptography (ecc), xor operations, and hash function. Furthermore, performance evaluation demonstrates that the proposed scheme takes less computation cost through comparison with similar solutions. Therefore, it is fairly an attractive solution for efficient and secure data sharing in iomt. © 2021 zhuo zhao et al.","","","2021","10.1155/2021/8402138","","","scopus-2-s2.0-85116393432.pdf","scopus-2-s2.0-85116393432"
"Assessing the quality of RCTs on the effect of beta-elemene one ingredient of a Chinese herb against malignant tumors","Peng X., Zhao Y., Liang X., Wu L., Cui S., Guo A., Wang W.","Contemporary Clinical Trials","","OBJECTIVE: To evaluate the quality of randomized controlled trials (RCTs) for Elemene injections one ingredient of Chinese herb Curcuma wenyujin for malignant tumors widely used in clinical practice in China.\\\\\\\\rMETHODS: We used a systematic sample of 127 reports of RCTs that used Elemene injections as an intervention. The quality of each report was assessed using the number of Consolidated Standards for Reporting of Trials (CONSORT) checklist items included the frequency of allocation concealment and a 5-point quality assessment instrument (Jadad).\\\\\\\\rRESULTS: 69.44% of the CONSORT checklist items was included in the reports. Only 2 (1.57%) RCTs reported allocation concealment by sealed envelopes. 123 (96.85%) reports described baseline demographic and clinical characteristics of each group. But only 5 (3.94%) of 127 RCTs reported statistics analysis results of baseline data. None of the reports stated in the methods section that intention-to-treat (ITT) analysis was used although 111 (87.40%) reports described the number of participants (denominator) in each group included in each analysis. Information regarding adverse events was reported in 83.46% of the RCTs. However the quality of reports were low as assessed by the Jadad scale.\\\\\\\\rCONCLUSIONS: The methodological quality of RCTs of Elemene injection against malignant tumors was low. Therefore the effect of Elemene injection being used in clinical settings needs to be confirmed by further RCTs. Meanwhile there is a need to supervise and urge researchers in China to conform to Good Clinical Practice (GCP) and CONSORT guidelines when reporting.","","","2006","10.1016/j.cct.2005.07.002","","","medline-16243588.pdf","medline-16243588"
"Reducing patient re-identification risk for laboratory results within research datasets","Atreya R. V., Smith J. C., McCoy A. B., Malin B., Miller R. A.","Journal of the American Medical Informatics Association","","OBJECTIVE: To try to lower patient re-identification risks for biomedical research databases containing laboratory test results while also minimizing changes in clinical data interpretation.\\\\\\\\rMATERIALS AND METHODS: In our threat model an attacker obtains 5-7 laboratory results from one patient and uses them as a search key to discover the corresponding record in a de-identified biomedical research database. To test our models the existing Vanderbilt TIME database of 8.5 million Safe Harbor de-identified laboratory results from 61 280 patients was used. The uniqueness of unaltered laboratory results in the dataset was examined and then two data perturbation models were applied-simple random offsets and an expert-derived clinical meaning-preserving model. A rank-based re-identification algorithm to mimic an attack was used. The re-identification risk and the retention of clinical meaning for each model's perturbed laboratory results were assessed.\\\\\\\\rRESULTS: Differences in re-identification rates between the algorithms were small despite substantial divergence in altered clinical meaning. The expert algorithm maintained the clinical meaning of laboratory results better (affecting up to 4% of test results) than simple perturbation (affecting up to 26%).\\\\\\\\rDISCUSSION AND CONCLUSION: With growing impetus for sharing clinical data for research and in view of healthcare-related federal privacy regulation methods to mitigate risks of re-identification are important. A practical expert-derived perturbation algorithm that demonstrated potential utility was developed. Similar approaches might enable administrators to select data protection scheme parameters that meet their preferences in the trade-off between the protection of privacy and the retention of clinical meaning of shared data.","","","2013","10.1136/amiajnl-2012-001026","","","medline-22822040.pdf","medline-22822040"
"Launching pcornet, a national patient-centered clinical research network","Fleurence, R.l. And Curtis, L.h. And Califf, R.m. And Platt, R. And Selby, J.v. And Brown, J.s.","Journal Of The American Medical Informatics Association","","The patient-centered outcomes research institute (pcori) has launched pcornet, a major initiative to support an effective, sustainable national research infrastructure that will advance the use of electronic health data in comparative effectiveness research (cer) and other types of research. In december 2013, pcori's board of governors funded 11 clinical data research networks (cdrns) and 18 patient-powered research networks (pprns) for a period of 18 months. Cdrns are based on the electronic health records and other electronic sources of very large populations receiving healthcare within integrated or networked delivery systems. Pprns are built primarily by communities of motivated patients, forming partnerships with researchers. These patients intend to participate in clinical research, by generating questions, sharing data, volunteering for interventional trials, and interpreting and disseminating results. Rapidly building a new national resource to facilitate a large-scale, patientcentered cer is associated with a number of technical, regulatory, and organizational challenges, which are described here.","","","2014","10.1136/amiajnl-2014-002747","","","scopus-2-s2.0-84902386646.pdf","scopus-2-s2.0-84902386646"
"The persistence of earnings and earnings components after the adoption of ifrs","Doukakis, L.c.","Managerial Finance","","Purpose – this paper seeks to examine the persistence of earnings and earnings components after the adoption of international financial reporting standards (ifrs). Design/methodology/approach – the study analyses two years before and two years after the adoption of ifrs in order to examine whether the adoption of ifrs materially affects the persistence, as well as the explanatory power of earnings and earnings components. Findings – the results confirm that disaggregating reported earnings into operating income, non-operating income and extraordinary charge and credit, captures differences in the information content of the underlying events. Consequently, earnings disaggregation can be used to improve prediction of future profitability. The results suggest that ifrs measurement and reporting guidelines do not seem to improve the persistence of earnings and earnings components. Originality/value – this is the first study that examines whether the mandatory adoption of ifrs has an impact on the information content of earnings components for future profitability. © 2010, © emerald group publishing limited.","","","2010","10.1108/03074351011081286","","","scopus-2-s2.0-85015636029.pdf","scopus-2-s2.0-85015636029"
"Knowledge exchange and productivity spill-overs in bangladeshi garment factories","Menzel, A.","Journal Of Economic Behavior And Organization","","Knowledge sharing between employees has long been viewed as a major driver of firm productivity growth, and the strength of productivity spill-overs within firms is a common measure of knowledge sharing. Using data from three bangladeshi garment factories, i first find that spill-overs are stronger within organizational sub-divisions of the factories than across. I then show that a management intervention that routinely brought together workers producing the same garments to exchange production knowledge further strengthened spill-overs within sub-divisions, but not across, when it was implemented in randomly selected sub-divisions. These findings suggest that boundaries between sub-divisions pose strong frictions to knowledge sharing within firms. © 2021 elsevier b.v.","","","2021","10.1016/j.jebo.2021.03.005","","","scopus-2-s2.0-85104136387.pdf","scopus-2-s2.0-85104136387"
"Alaska native people's perceptions understandings and expectations for research involving biological specimens","Hiratsuka V. Y., Brown J. K., Hoeft T. J., Dillard D. A.","International Journal of Circumpolar Health","","OBJECTIVES: Members of racially and ethnically diverse groups have been persistently underrepresented in biomedical research in general possibly due to mistrust with the medical and research community. This article describes the perceptions understandings and expectations of Alaska Native people about research involving the collection and storage of biological specimens.\\\\\\\\rSTUDY DESIGN: Stratified focus groups.\\\\\\\\rMETHODS: Twenty-nine focus groups with Alaska Native people (n = 178) were held in 14 locations using a semi-structured moderator guide. ATLAS.ti was used for thematic analysis through iterative readings and coding. Alaska Native peoples' perceptions understandings and expectations of researcher beneficence informed consent processes and provision of research findings were elicited.\\\\\\\\rRESULTS AND CONCLUSIONS: Alaska Native people desired extensive disclosure of information beyond that typically provided in consent and results dissemination processes. Information germane to the motivation and intent of researchers and specifics of specimen storage and destruction were specifically requested. A clear and extensive process of informed consent and continued improvements in sharing results may enhance the transparency of research intent conduct and use of obtained results among Alaska Native people. Meeting expectations may improve relationships between researchers and the Alaska Native population which could result in increased research participation. Our findings offer a guide for researchers and communities when planning and implementing research with biological specimens.","","","2012","10.3402/ijch.v71i0.18642","","","medline-22663942.pdf","medline-22663942"
"Safe futures for java","Welc, A. And Jagannathan, S. And Hosking, A.","Acm Sigplan Notices","","A future is a simple and elegant abstraction that allows concurrency to be expressed often through a relatively small rewrite of a sequential program. In the absence of side-effects, futures serve as benign annotations that mark potentially concurrent regions of code. Unfortunately, when computation relies heavily on mutation as is the case in java, its meaning is less clear, and much of its intended simplicity lost. This paper explores the definition and implementation of safe futures for java. One can think of safe futures as truly transparent annotations on method calls, which designate opportunities for concurrency. Serial programs can be made concurrent simply by replacing standard method calls with future invocations. Most significantly, even though some parts of the program are executed concurrently and may indeed operate on shared data, the semblance of serial execution is nonetheless preserved. Thus, program reasoning is simplified since data dependencies present in a sequential program are not violated in a version augmented with safe futures. Besides presenting a programming model and api for safe futures, we formalize the safety conditions that must be satisfied to ensure equivalence between a sequential java program and its future-annotated counterpart. A detailed implementation study is also provided. Our implementation exploits techniques such as object versioning and task revocation to guarantee necessary safety conditions. We also present an extensive experimental evaluation of our implementation to quantify overheads and limitations. Our experiments indicate that for programs with modest mutation rates on shared data, applications can use futures to profitably exploit parallelism, without sacrificing safety. Copyright 2005 acm.","","","2005","10.1145/1103845.1094845","","","scopus-2-s2.0-33745198925.pdf","scopus-2-s2.0-33745198925"
"Association of a common rs9939609 variant in the fat mass and obesity-associated (FTO) gene with obesity and metabolic phenotypes in a Taiwanese population: a replication study","Hsiao T. J., Lin E.","Journal of Genetics","","It is a key challenge to conduct reproducibility in genetic research especially association studies in obesity. While susceptibility of a single-nucleotide polymorphism (SNP) rs9939609 in the fat mass and obesity-associated (FTO) gene to obesity has been reported in various populations data from Asians is less conclusive. This replication study was carried out to test whether the FTO rs9939609 SNP is a predictive factor for obesity and obesity-related metabolic traits in a Taiwanese population. A total of 1188 Taiwanese subjects were recruited for this study. The FTO rs9939609 SNP was genotyped by the Taqman assay. Obesity-related metabolic traits such as triglyceride waist circumference systolic and diastolic blood pressure total cholesterol creatinine alanine aminotransferase and fasting glucose were measured. Our data revealed that the FTO rs9939609 SNP exhibited a significant association with obesity (BMI >= 30 kg/m2) among the subjects (P = 0.026). However the FTO rs9939609 SNP did not exhibit any significant association with obesity-related metabolic traits among the subjects. Our results indicated that the FTO rs9939609 SNP may be linked with the risk of obesity in Taiwanese subjects.","","","2016","","","","medline-27659330.pdf","medline-27659330"
"A cautionary note on microcredentialing in entrepreneurship education","Phelan, S.e. And Glackin, C.e.","Entrepreneurship Education And Pedagogy","","A recent trend in entrepreneurship education has been the emergence of microcredentials. This note provides some cautionary observations on the current state of microcredentials in entrepreneurship, organized around the themes of credibility, legitimacy, and relevance. It then provides some recommendations for the future development of the field, including creating evaluation mechanisms, establishing international standards in entrepreneurship, undertaking more research to establish credibility, forming alliances, and safeguarding relevance. © the european society of cardiology 2020.","","","2021","10.1177/2515127419899599","","","scopus-2-s2.0-85115629170.pdf","scopus-2-s2.0-85115629170"
"Use of Machine Learning and Artificial Intelligence Methods in Geriatric Mental Health Research Involving Electronic Health Record or Administrative Claims Data: A Systematic Review","Chowdhury M., Cervantes E. G., Chan W. Y., Seitz D. P.","Frontiers in psychiatry Frontiers Research Foundation","","Introduction: Electronic health records (EHR) and administrative healthcare data (AHD) are frequently used in geriatric mental health research to answer various health research questions. However there is an increasing amount and complexity of data available that may lend itself to alternative analytic approaches using machine learning (ML) or artificial intelligence (AI) methods. We performed a systematic review of the current application of ML or AI approaches to the analysis of EHR and AHD in geriatric mental health. Methods: We searched MEDLINE Embase and PsycINFO to identify potential studies. We included all articles that used ML or AI methods on topics related to geriatric mental health utilizing EHR or AHD data. We assessed study quality either by Prediction model Risk OF Bias ASsessment Tool (PROBAST) or Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) checklist. Results: We initially identified 391 articles through an electronic database and reference search and 21 articles met inclusion criteria. Among the selected studies EHR was the most used data type and the datasets were mainly structured. A variety of ML and AI methods were used with prediction or classification being the main application of ML or AI with the random forest as the most common ML technique. Dementia was the most common mental health condition observed. The relative advantages of ML or AI techniques compared to biostatistical methods were generally not assessed. Only in three studies low risk of bias (ROB) was observed according to all the PROBAST domains but in none according to QUADAS-2 domains. The quality of study reporting could be further improved. Conclusion: There are currently relatively few studies using ML and AI in geriatric mental health research using EHR and AHD methods although this field is expanding. Aside from dementia there are few studies of other geriatric mental health conditions. The lack of consistent information in the selected studies precludes precise comparisons between them. Improving the quality of reporting of ML and AI work in the future would help improve research in the field. Other courses of improvement include using common data models to collect/organize data and common datasets for ML model validation. Copyright © 2021 Chowdhury Cervantes Chan and Seitz.","","","2021","10.3389/fpsyt.2021.738466","","","medline-34616322.pdf","medline-34616322"
"Benefit sharing on transboundary rivers: case study and theoretical exploration","Zhang, C. And Fan, Y. And Hu, W.","Journal Of Resources And Ecology","","Benefit sharing on transboundary rivers is an approach to address equitable and reasonable development and utilization of transboundary water resources (twr). Through analyzing a few typical benefit sharing cases, this paper provides a systematic discussion of the theory of twr benefits sharing. Twr features a kind of common pool resources (cprs). Its benefit sharing subjects are the riparian countries. The shared benefits usually include flood prevention, power generation, navigation, irrigation, contributions to society and culture, etc. The benefit sharing modes mainly include shared benefits and responsibilities, reciprocal rights and obligations, equal benefit distribution, cost proportion-based benefit sharing, and demand-based benefit sharing. The first step in the realization process of benefit sharing is the sharing of data and information. Second is the benefit identification and evaluation. Third is the establishment of a mechanism to guarantee the benefit sharing. The conditions for realizing benefit sharing depends on, first, if the riparian countries are willing to cooperate with each other;  second, whether the cooperation can bring incremental benefit or cost reduction in comparison with unilateral operation;  and third, if the benefit distribution is equitable and reasonable and can stand the test of time. © 2019, editorial office of journal of resources and ecology. All rights reserved.","","","2019","10.5814/j.issn.1674-764x.2019.01.001","","","scopus-2-s2.0-85091191979.pdf","scopus-2-s2.0-85091191979"
"Complying with data handling requirements in cloud storage systems","Henze, M. And Matzutt, R. And Hiller, J. And Muhmer, E. And Ziegeldorf, J.h. And Van Der Giet, J. And Wehrle, K.","Ieee Transactions On Cloud Computing","","In past years, cloud storage systems saw an enormous rise in usage. However, despite their popularity and importance as underlying infrastructure for more complex cloud services, today's cloud storage systems do not account for compliance with regulatory, organizational, or contractual data handling requirements by design. Since legislation increasingly responds to rising data protection and privacy concerns, complying with data handling requirements becomes a crucial property for cloud storage systems. We present prada, a practical approach to account for compliance with data handling requirements in key-value based cloud storage systems. To achieve this goal, prada introduces a transparent data handling layer, which empowers clients to request specific data handling requirements and enables operators of cloud storage systems to comply with them. We implement prada on top of the distributed database cassandra and show in our evaluation that complying with data handling requirements in cloud storage systems is practical in real-world cloud deployments as used for microblogging, data sharing in the internet of things, and distributed email storage. © 2013 ieee.","","","2022","10.1109/tcc.2020.3000336","","","scopus-2-s2.0-85138897798.pdf","scopus-2-s2.0-85138897798"
"Developing a national dataset of bicycle infrastructure for canada using open data sources","Ferster, C. And Nelson, T. And Manaugh, K. And Beairsto, J. And Laberee, K. And Winters, M.","Environment And Planning B: Urban Analytics And City Science","","High-quality and consistent cycling infrastructure data are needed to advance research into equity and safety and for planning active transportation. With recent growth in cycling and investments in cycling infrastructure, there are concerns that these investments have not been equitable across communities. There is no consistent and complete national dataset for cycling infrastructure in canada. Our goal is to develop a national cycling infrastructure dataset by (1) classifying openstreetmap (osm) using the canadian bikeway comfort and safety classification system (can-bics) as consistent criteria and categorisation for comfort class and infrastructure type;  (2) performing a site-specific accuracy assessment by comparing the classification with more than 2000 reference points from a stratified random sample in 15 cities;  and (3) presenting summary results from the national dataset. Based on reference data collected in 15 test cities, the classification had an estimated accuracy of 76 ± 3% for presence or absence of infrastructure, 71 ± 4% for comfort class and 69 ± 4% (by length) for infrastructure type. High comfort infrastructure was slightly underestimated (since bike paths were sometimes confused with multi-use paths) and low comfort infrastructure was slightly overestimated. Nationally, we identified 22,992 km of cycling infrastructure meeting can-bics standards and 48,953 km of non-conforming infrastructure. Multi-use paths are the most common infrastructure type by length (16.6%), followed by painted bike lanes (11.0%), and then high comfort infrastructure (cycle tracks, local street bikeways and bike paths) (4.3%). There was a wider range in access to cycling infrastructure in small cities than in medium and large cities. To reduce repeated effort assembling data and increase reproducible active transportation research, we encourage contribution to osm. © the author(s) 2023.","","","2023","10.1177/23998083231159905","","","scopus-2-s2.0-85150658431.pdf","scopus-2-s2.0-85150658431"
"Secure data sharing with flexible cross-domain authorization in autonomous vehicle systems","Sun, J. And Xu, G. And Zhang, T. And Cheng, X. And Han, X. And Tang, M.","Ieee Transactions On Intelligent Transportation Systems","","As an increasingly prevalent technology in intelligent autonomous transportation systems, autonomous vehicle platoon has been indicated the ability to significantly reduce fuel consumption as well as heighten highway safety and throughput. However, existing efforts rarely focus on protecting data confidentiality and authenticity in autonomous vehicle platoons. How to ensure secure and high-fidelity platoon-level communication is still in its infancy. This paper makes the first attempt for efficient and secure communication across autonomous vehicle platoons. Specifically, we present pdsm-fc, the first privacy-preserving data share mechanism with flexible cross-domain authorization over distinctive platoons. The key insight of pdsm-fc is the design of a new ciphertext conversion technique, which allows a ciphertext to be easily converted into another type of ciphertext, facilitating efficient access by all entities holding the legitimate authorization. As a result, pdsm-fc can achieve high-fidelity data communication between two unique platoons in ciphertext, so as to complete specific tasks including platoon integration. Rigorous security analysis shows that pdsm-fc is secure against various attacks such as collusion, forgery and chosen-plaintext attacks. Moreover, theoretical evaluation and extensive experiments demonstrate the practicability of pdsm-fc in terms of functionality, storage and computation overheads. © 2000-2011 ieee.","","","2023","10.1109/tits.2022.3157309","","","scopus-2-s2.0-85126539624.pdf","scopus-2-s2.0-85126539624"
"An adaptive secure and practical data sharing system with verifiable outsourced decryption","Xu, S. And Han, X. And Xu, G. And Ning, J. And Huang, X. And Deng, R.h.","Ieee Transactions On Services Computing","","Cloud computing is the widespread acceptance of a promising paradigm offering a substantial amount of storage and data services on demand. To preserve data confidentiality, many cryptosystems have been introduced. However, current solutions are incompatible with the resource-constrained end-devices because of a variety of vulnerabilities in terms of practicality and security. In this paper, we propose a practical and secure data-sharing system by introducing a new design of attribute-based encryption with verifiable outsourced decryption (vo-abe for short). Our system offers: (1) data sharing at a fine-grained level;  (2) a scalable key issuing protocol without any secure channel;  (3) a verifiable outsourced decryption mechanism for resource-constrained end-devices against the malicious cloud service provider;  and (4) adaptive security against the real-world attacks. To formalize our solution with cryptographic analysis, we present the formal definition of vo-abe and its concrete construction with provable security. In particular, our design leverages the techniques of the traditional abe, verifiable outsourced decryption, and randomness extractor to support fine-grained access control, cost-effective data sharing, and security assurance with high entropy. Moreover, our design is provably secure in the adaptive model under the standard assumption, which offers a stronger security guarantee since the state-of-the-art solution is selectively secure under the non-standard assumption and suffers from a variety of real-world attacks. The implementation and evaluation demonstrate that our solution enjoys superior functionality and better performance than the relevant solutions. More importantly, our solution is compatible with the resource-constrained end-devices since the decryption mechanism takes around 1.1ms and is 22.7x faster than the state-of-the-art solution. Ieee","","","2023","10.1109/tsc.2023.3321314","","","scopus-2-s2.0-85174804290.pdf","scopus-2-s2.0-85174804290"
"Future of benchmarking: more data more sharing and better patient care","Anonymous","Healthcare Benchmarks","","Automated systems that provide whatever regulatory information is needed when it is needed; sharing of data to improve quality; data mined for specific groups of patients: Those are just a few of the trends predicted by health care experts asked to comment on the future of benchmarking and data strategies. Such improvements are needed; many hospitals continually run into problems when it comes to finding the right data sets for targeted patient groups.","","","2001","","","","medline-11372493.pdf","medline-11372493"
"System for quality-assured data analysis: flexible, reproducible scientific workflows","Fowler J. And San Lucas F.a. And Scheet P.","Genet. Epidemiol","","The reproducibility of scientific processes is one of the paramount problems of bioinformatics, an engineering problem that must be addressed to perform good research. The system for quality-assured data analysis (syqada), described here, seeks to address reproducibility by managing many of the details of procedural bookkeeping in bioinformatics in as simple and transparent a manner as possible. Syqada has been used by persons with backgrounds ranging from expert programmer to unix novice, to perform and repeat dozens of diverse bioinformatics workflows on tens of thousands of samples, consuming over 80 cpu-months of computing on over 300,000 individual tasks of scores of projects on laptops, computer servers, and computing clusters. Syqada is especially well-suited for paired-sample analyses found in cancer tumor-normal studies. Syqada executable source code, documentation, tutorial examples, and workflows used in our lab is available from http://scheet.org/software.html.copyright © 2018 wiley periodicals, inc.","","","2019","10.1002/gepi.22178","","","embase-625571835.pdf","embase-625571835"
"Green supply chain management and smes: a qualitative study","Hijaz, S. And Al-Hujran, O. And Al-Debei, M.m. And Abu-Khajil, N.","International Journal Of Business Information Systems","","In this study, we aim at evaluating the current state of the jordanian marketplace in the context of green supply chain management (gscm). We conducted interviews with five smes and thus qualitative data were collected. Data analysis was performed and nvivo 10th version software was also utilised. Data were coded and themes were then generated. Highlighted findings were such that insignificant attention from smes in jordan is being paid towards the environment. Smes were found not to be seriously ready and willing to take actions so as to help in reducing environmental threats. Moreover, it was found that smes in jordan are still suffering and not doing well in critical aspects related to gscm such as product delivery time, currency exchange, the use of information systems for data sharing, tax increments, and indecent competition. Various suggestions were offered in this study and we also propose solutions according to the identified insufficiencies. © 2015 inderscience enterprises ltd.","","","2015","10.1504/ijbis.2015.067264","","","scopus-2-s2.0-84922326535.pdf","scopus-2-s2.0-84922326535"
"Replication crisis p-hacking and open science. An inquiry into questionable research practices in student projects and impulses for the teaching environment","Brachem Johannes, Frank Maximilian, Kvetnaya Tatiana, Schramm Leonhard F., Volz Leonhard","Psychologische Rundschau","","(German) In den letzten Jahren gab es innerhalb der Psychologie eine intensive Auseinandersetzung mit den Auswirkungen der Replikationskrise sowie dem hieraus entstandenen Diskurs uber die Weiterentwicklung der Disziplin. Als ein Grund fur die mangelnde Replizierbarkeit psychologischer Forschung wurde die Verwendung fragwurdiger Forschungspraktiken (eng. QRPs) identifiziert. Wahrend es umfangreiche Untersuchungen zur Pravalenz von QRPs unter Wissenschaftler*innen gibt ist bisher wenig uber die Verbreitung dieser Praktiken unter Studierenden bekannt. Mit der hier vorgestellten Arbeit wurde erstmals eine grosere Befragung unter 1397 Psychologie- Studierenden im deutschsprachigen Raum durchgefuhrt um die Verbreitung von QRPs in studentischen Projekten sowie den aktuellen Stand der akademischen Lehre in Bezug auf die Replikationskrise und Open Science zu erheben. Die gemeinsame Betrachtung der Lehre und des Einsatzes fragwurdiger Forschungspraktiken versprechen Aufschluss daruber wie die psychologische Lehre mit dem empirischen Vorgehen der Studierenden zusammenhangt. Die Ergebnisse zeigen dass QRPs auch in studentischen Projekten vorkommen wobei grose Unterschiede in der Verbreitung einzelner QRPs bestehen. Auch zwischen den verschiedenen Projekttypen zeigten sich Unterschiede so war die Anwendung von QRPs in Experimentalpraktika am starksten und in Masterarbeiten am schwachsten ausgepragt. Unsere Daten weisen insgesamt darauf hin dass die selbstberichtete Verbreitung von QRPs uber den Studienverlauf abnimmt. Zudem scheint ein Grosteil der Studierenden bereits mit der Thematik der Replikationskrise in der Lehre in Beruhrung gekommen zu sein. Deren Behandlung findet grostenteils in der Methodenlehre und weniger in inhaltlich spezialisierten Lehrveranstaltungen statt. Wir geben abschliesend Impulse zur Weiterentwicklung der psychologischen Lehre in denen die Prinzipien der Offenheit Transparenz und Kollaboration beim Hervorbringen inhaltlich robuster Forschung bereits wahrend des Studiums im Vordergrund stehen. (PsycInfo Database Record (c) 2022 APA all rights reserved)","","","2022","10.1026/0033-3042/a000562","","","wos-000739573100001.pdf","wos-000739573100001"
"Reconstructing 3d virtual environments within a collaborative e-infrastructure","Coro, G. And Palma, M. And Ellenbroek, A. And Panichi, G. And Nair, T. And Pagano, P.","Concurrency And Computation: Practice And Experience","","Sets of two-dimensional images are insufficient to capture the development in time and space of three-dimensional structures. The 2d “flattening” of photographs results in a significant loss of features especially if the photos were taken by one person. Automatically collecting and aligning photos in order to render 3d structures from 2d images without specialised equipment is currently a complex process that requires specialist knowledge with often limited results. In this paper, an open science oriented workflow is proposed where an on-line file system is used to share photos of an object or an environment and to produce a virtual reality scene as a navigable 3d reconstruction that can be shared with other people. Our workflow is based on a distributed e-infrastructure and overcomes common limitations of other approaches by having all the used technology integrated on the same platform and by not requiring specialist knowledge. A performance evaluation of the 3d reconstruction process embedded in the workflow is reported against a commercial software and an open-source software in terms of computational efficiency and reconstruction accuracy, and three marine science use cases are reported to show potential applications of the workflow. © 2018 john wiley & sons, ltd.","","","2019","10.1002/cpe.5028","","","scopus-2-s2.0-85054374880.pdf","scopus-2-s2.0-85054374880"
"Performance analysis of two famous cryptographic algorithms on mixed data","Adeniyi, E.a. And Imoize, A.l. And Awotunde, J.b. And Lee, C.-C. And Falola, P. And Jimoh, R.g. And Ajagbe, S.a.","Journal Of Computer Science","","The rapid development of digital data sharing has made information security a crucial concern in data communication. The information security system heavily relies on encryption methods. These algorithms employ strategies to increase data secrecy and privacy by obscuring the information, which only those parties who have the accompanying key can decode or decrypt. Nevertheless, these methods also use a lot of computational resources, including battery life, memory, and cpu time. So, to determine the optimal algorithm to utilize moving forward, it is necessary to assess the performance of various cryptographic algorithms. Therefore, this study evaluates two well-known cryptographies (rsa and elgamal) using mixed data such as binary, text, and image files. Cpu internal clock was used to obtain the time complexity used by both algorithms during encryption and decryption. The algorithms used cpu internal memory to obtain memory usage during the encryption and decryption of mixed data. Evaluation criteria such as encryption time, decryption time, and throughput were used to compare these encryption algorithms. The response time, confidentiality, bandwidth, and integrity are all factors in the cryptography approach. The results revealed that rsa is a time-efficient and resourceful model, while the elgamal algorithm is a memory-efficient and resourceful model. © 2023 emmanuel abidemi adeniyi, agbotiname lucky imoize, joseph bamidele awotunde, cheng-chi lee, peace falola, rasheed gbenga jimoh and sunday adeola ajagbe. This open-access article is distributed under a creative commons attribution (cc-by) 4.0 license.","","","2023","10.3844/jcssp.2023.694.706","","","scopus-2-s2.0-85162081491.pdf","scopus-2-s2.0-85162081491"
"Learning probabilistic models of cis-regulatory modules that represent logical and spatial aspects","Noto K., Craven M.","Bioinformatics","","MOTIVATION: The process of transcription is controlled by systems of factors which bind in specific arrangements called cis-regulatory modules (CRMs) in promoter regions. We present a discriminative learning algorithm which simultaneously learns the DNA binding site motifs as well as the logical structure and spatial aspects of CRMs.\\\\\\\\rRESULTS: Our results on yeast datasets show better predictive accuracy than a current state-of-the-art approach on the same datasets. Our results on yeast fly and human datasets show that the inclusion of logical and spatial aspects improves the predictive accuracy of our learned models.\\\\\\\\rAVAILABILITY: Source code is available at http://www.cs.wisc.edu/~noto/crm","","","2007","","","","medline-17237085.pdf","medline-17237085"
"On digitisation as a preservation measure","Vansnick, S. And Ntanos, K.","Studies In Conservation","","While access and engagement are usually the primary objectives of digitisation projects, they often also claim to benefit the long-term preservation of collection items due to reducing handling, one of the main risks to archival and library collections, making this a persuasive additional argument to invest in digitising a collection. Conservation intervention prior to digitisation, if done, is kept to minimum repair, cleaning and flattening of documents in order to achieve high-quality images, facilitate safe handling and ensure efficient workflow. Such preservation improvements may be negated by continued access to the physical records after digitisation has occurred. There is also a risk of damage during the digitisation process, especially for very fragile items, for which digitisation may nonetheless be the only way to provide future access. This paper assesses archival document request data before and after digitisation, and online access options, for a selection of digitisation projects from the national archives, uk, in order to review of the effectiveness of a number of digitisation programmes in reducing demand for handling of originals. It identifies procedural improvements post-digitisation that would further reduce access to original documents. © 2018, © the international institute for conservation of historic and artistic works 2018.","","","2018","10.1080/00393630.2018.1504451","","","scopus-2-s2.0-85053245697.pdf","scopus-2-s2.0-85053245697"
"Guilty as perceived: how opinions about states influence opinions about ngos","Guarrieri, T.r.","Review Of International Organizations","","Why do some people believe that ngos have a bad influence on their country? Building on the world polity literature, i hypothesize that opinions about western actors affect opinions about the influence of ngos because ngos can act as vehicles for the diffusion of western culture. Using pew research survey data, i find that the more unfavorable respondents’ opinions are of the united states, the european union, and the united nations, the more likely they are to believe that ngos have a bad influence on their country. While previous research finds evidence that a mechanism of “guilt by association” exists between opinions about states and opinions about igos (johnson, the review of international organizations, 6, 57–84, 2011), this manuscript expands on these findings by investigating the relationship between opinions about states and opinions about ngos. This research has important implications for ngo effectiveness because opinions about ngos can affect the willingness of local populations to work with such organizations. © 2017, springer science+business media, llc.","","","2018","10.1007/s11558-017-9291-2","","","scopus-2-s2.0-85030156880.pdf","scopus-2-s2.0-85030156880"
"Radical distrust: are economic policy attitudes tempered by social trust?","Pitlik, H. And Rode, M.","Social Indicators Research","","Debates about the appropriate role of markets and governments are often shaped by sharply contrasting opinions. Based on individual data from the world values survey and the european values study for up to 190,000 respondents in a sample of 68 democratic countries, we find that social trust is associated with tempered attitudes regarding government intervention and redistribution. Results corroborate ideas from socio-psychological research that trusting people have personality attributes which work towards a moderation on politically divisive topics. Complementary to the literature on political polarization, this opens the possibility that trusting societies may be superior at adapting polices to novel challenges because social trust reduces the probability of extreme attitude formation. © 2020, springer nature b.v.","","","2021","10.1007/s11205-020-02317-8","","","scopus-2-s2.0-85081978637.pdf","scopus-2-s2.0-85081978637"
"Effect of impact factor and discipline on journal data sharing policies","Resnik D.b. And Morales M. And Landrum R. And Shi M. And Minnier J. And Vasilevsky N.a. And Champieux R.e.","Account Res","","Data sharing is crucial to the advancement of science because it facilitates collaboration, transparency, reproducibility, criticism, and re-analysis. Publishers are well-positioned to promote sharing of research data by implementing data sharing policies. While there is an increasing trend toward requiring data sharing, not all journals mandate that data be shared at the time of publication. In this study, we extended previous work to analyze the data sharing policies of 447 journals across several scientific disciplines, including biology, clinical sciences, mathematics, physics, and social sciences. Our results showed that only a small percentage of journals require data sharing as a condition of publication, and that this varies across disciplines and impact factors. Both impact factors and discipline are associated with the presence of a data sharing policy. Our results suggest that journals with higher impact factors are more likely to have data sharing policies;  use shared data in peer review;  require deposit of specific data types into publicly available data banks;  and refer to reproducibility as a rationale for sharing data. Biological science journals are more likely than social science and mathematics journals to require data sharing.","","","2019","10.1080/08989621.2019.1591277","","","embase-627030068.pdf","embase-627030068"
"RAvariome: a genetic risk variants database for rheumatoid arthritis based on assessment of reproducibility between or within human populations","Nagai Y., Imanishi T.","Database: The Journal of Biological Databases and Curation","","Rheumatoid arthritis (RA) is a common autoimmune inflammatory disease of the joints and is caused by both genetic and environmental factors. In the past six years genome-wide association studies (GWASs) have identified many risk variants associated with RA. However not all associations reported from GWASs are reproduced when tested in follow-up studies. To establish a reliable set of RA risk variants we systematically classified common variants identified in GWASs by the degree of reproducibility among independent studies. We collected comprehensive genetic associations from 90 papers of GWASs and meta-analysis. The genetic variants were assessed according to the statistical significance and reproducibility between or within nine geographical populations. As a result 82 and 19 single nucleotide polymorphisms (SNPs) were confirmed as intra- and inter-population-reproduced variants respectively. Interestingly majority of the intra-population-reproduced variants from European and East Asian populations were not common in two populations but their nearby genes appeared to be the components of common pathways. Furthermore a tool to predict the individual's genetic risk of RA was developed to facilitate personalized medicine and preventive health care. For further clinical researches the list of reliable genetic variants of RA and the genetic risk prediction tool are provided by open access database RAvariome. DATABASE URL: http://hinv.jp/hinv/rav/.","","","2013","10.1093/database/bat073","","","medline-24158836.pdf","medline-24158836"
"Minimizing information loss in shared data: hiding frequent patterns with multiple sensitive support thresholds","Ergenç Bostanoǧlu, B. And Öztürk, A.c.","Statistical Analysis And Data Mining","","Privacy preserving data mining (ppdm) is the process of protecting sensitive knowledge from being discovered by data mining techniques in case of data sharing. Privacy preserving frequent itemset mining (ppfim) is a subtask and np-hard problem of ppdm. Its objective is to modify a given database in such a way that none of the sensitive itemsets of the database owner can be obtained by any frequent itemset mining technique from the modified database. The main challenge of ppfim is to minimize the distortion given to the data and nonsensitive knowledge while sanitizing all given sensitive itemsets. Distortion-based sensitive itemset hiding algorithms decrease the support of each sensitive itemset under a predefined sensitive threshold through sanitization. Most of the distortion-based itemset hiding algorithms allow database owner to define a single sensitive threshold for each sensitive itemset. However, this is a limitation to the database owner since the importance of each sensitive itemset varies. In this paper we propose a distortion-based itemset hiding algorithm that allows database owner to assign multiple sensitive thresholds, namely itemset oriented pseudo graph based sanitization (ipgbs) algorithm. The purpose of ipgbs algorithm is to give minimum distortion to the nonsensitive knowledge and data while hiding all sensitive itemsets. For this reason, the ipgbs algorithm modifies least amount of transaction and transaction content. The performance evaluation of the ipgbs algorithm is conducted by using two different counterparts on four different databases. The results show that the ipgbs algorithm is more efficient in terms of nonsensitive frequent itemset loss on both dense and sparse databases. It has considerable good results in terms of number of transactions modified, number of items deleted, execution time and total memory allocation as well. © 2020 wiley periodicals llc","","","2020","10.1002/sam.11458","","","scopus-2-s2.0-85083673180.pdf","scopus-2-s2.0-85083673180"
"Retinal nerve fiber layer thickness reproducibility using seven different OCT instruments","Pierro L., Gagliardi M., Iuliano L., Ambrosi A., Bandello F.","Investigative Ophthalmology & Visual Science","","PURPOSE: The clinical utility of new optical coherence tomography (OCT) instruments strongly depends on measurements reproducibility. The aim of this study was to assess retinal nerve fiber layer (RNFL) thickness reproducibility using six different spectral-domain OCTs (SD-OCTs) and one time-domain OCT.\\\\\\\\rMETHODS: RNFL thickness (average and four quadrant) from six SD-OCTs (Spectral OCT/SLO OPKO/OTI 3D-OCT 2000 Topcon RS-3000 NIDEK Cirrus HD-OCT Zeiss RTVue-100 Optovue and Spectralis Heidelberg) and one time-domain OCT (Stratus OCT Zeiss) was measured twice in 38 right eyes of 38 randomly chosen healthy volunteers by two masked operators. Inter- and intraoperator reproducibility was evaluated by the intraclass correlation coefficient (ICC) coefficient of variation (CV) and Bland-Altman test analysis. Instrument-to-instrument reproducibility was determined by ANOVA for repeated measures. We also tested how the devices disagree in terms of systemic bias and random error using a structural equation model.\\\\\\\\rRESULTS: Mean RNFL average thickness ranged from 90.08 mum to 106.51 mum. Cirrus and Heidelberg showed the thinnest RNFL values in all measurements Topcon the highest. ICC CV and Bland-Altman plots showed variable inter- and intraoperator agreement depending on the instrument. Heidelberg demonstrated the best interoperator (ICC 0.92; CV 1.56%) and intraoperator (ICC 0.94 and 0.95; CV 1.28% and 1.26% respectively for operator A and operator B) agreement for average RNFL thickness.\\\\\\\\rCONCLUSIONS: Heidelberg demonstrated the higher agreement in inter- and intraoperator reproducibility Optovue the worst. In light of our error analysis results we found that a scale bias among instruments could interfere with a thorough RNFL monitoring suggesting that best monitoring is obtained with the same operator and the same device.","","","2012","10.1167/iovs.11-8644","","","medline-22871835.pdf","medline-22871835"
"Hawaiian Fungal Amplicon Sequence Variants Reveal Otherwise Hidden Biogeography","Tipton L., Zahn G. L., Darcy J. L., Amend A. S., Hynson N. A.","Microbial Ecology","","To study biogeography and other ecological patterns of microorganisms including fungi scientists have been using operational taxonomic units (OTUs) as representations of species or species hypotheses. However when defined by 97% sequence similarity cutoff at an accepted barcode locus such as 16S in bacteria or ITS in fungi these OTUs can obscure biogeographic patterns mask taxonomic diversity and hinder meta-analyses. Amplicon sequence variants (ASVs) have been proposed to alleviate all of these issues and have been shown to do so in bacteria. Analyzing ASVs is just emerging as a common practice among fungal studies and it is unclear whether the benefits found in bacterial studies of using such an approach carryover to fungi. Here we conducted a meta-analysis of Hawaiian fungi by analyzing ITS1 amplicon sequencing data as ASVs and exploring ecological patterns. These surveys spanned three island groups and five ecosystems combined into the first comprehensive Hawaiian Mycobiome ASV Database. Our results show that ASVs can be used to combine fungal ITS surveys increase reproducibility and maintain the broad ecological patterns observed with OTUs including diversity orderings. Additionally the ASVs that comprise some of the most common OTUs in our database reveals some island specialists indicating that traditional OTU clustering can obscure important biogeographic patterns. We recommend that future fungal studies especially those aimed at assessing biogeography analyze ASVs rather than OTUs. We conclude that similar to bacterial studies ASVs improve reproducibility and data sharing for fungal studies. Copyright © 2021. The Author(s) under exclusive licence to Springer Science+Business Media LLC part of Springer Nature.","","","2022","10.1007/s00248-021-01730-x","","","medline-33742230.pdf","medline-33742230"
"Dynamic encrypted data sharing scheme based on conditional proxy broadcast re-encryption for cloud storage","Jiang, L. And Guo, D.","Ieee Access","","Since cloud service provider is a semi-trusted party in cloud storage, to protect data from being disclosed, users' data are encrypted before being uploaded to a cloud server. Undoubtedly, flexible encrypted data sharing is a very important demand required by cloud storage users, whereas few schemes have being designed to satisfy this demand. In this paper, based on conditional proxy broadcast re-encryption technology, an encrypted data sharing scheme for secure cloud storage is proposed. The scheme not only achieves broadcast data sharing by taking advantage of broadcast encryption, but also achieves dynamic sharing that enables adding a user to and removing a user from sharing groups dynamically without the need to change encryption public keys. Moreover, by using proxy re-encryption technology, our scheme enables the proxy (cloud server) to directly share encrypted data to the target users without the intervention of data owner while keeping data privacy, so that greatly improves the sharing performance. Meanwhile, the correctness and the security are proved;  the performance is analyzed, and the experimental results are shown to verify the feasibility and the efficiency of the proposed scheme. © 2013 ieee.","","","2017","10.1109/access.2017.2726584","","","scopus-2-s2.0-85028847775.pdf","scopus-2-s2.0-85028847775"
"Cloud-assisted ehr sharing with security and privacy preservation via consortium blockchain","Wang, Y. And Zhang, A. And Zhang, P. And Wang, H.","Ieee Access","","The sharing of electronic health records (ehrs) has great positive significance for research of disease and doctors' diagnosis. In recent years, cloud-based electronic medical record sharing scheme has brought a lot of conveniences, but the centralization of cloud exposes threats inevitably to data security and privacy preservation. Blockchain technology can be seen as a promising solution to address these problems on account of its unique propertis of decentration, anonymity, unforgeability and verifiability. In this paper, we propose a blockchain based secure and privacy-preserving ehr sharing protocol. Data requester can search desired keyword from data provider to find relevant ehrs on the ehr consortium blockchain and get the re-encryption ciphertext from cloud server after getting the data owner's authorization. The scheme mainly uses searchable encryption and conditional proxy re-encryption to realize data security, privacy preservation, and access control. Furthermore, proof of authorization is designed as the consensus mechanism for consortium blockchain to guarantee system's availability. Security analysis demonstrates that the proposed protocol can achieve security goals. Besides, we emulate the cryptographic primitives and implement the proposed scheme on ethereum platform. Performance evaluation shows that the proposed scheme has high computational efficiency. © 2013 ieee.","","","2019","10.1109/access.2019.2943153","","","scopus-2-s2.0-85077955751.pdf","scopus-2-s2.0-85077955751"
"Co-parenting and shared custody in catalonia","Solsona, M. And Brullet, C. And Spijker, J.","Documents D'analisi Geografica","","The paper addresses the issue of legal custody of minor children after divorce in a context of increasing diversity of parental practices. We present a socio-legal framework that currently exists in spain and catalonia around the legal entity and practice of shared custody. Judiciary data obtained from ine on ""decrees of annulments, separations and divorces"" are analyzed for catalonia and other spanish regions (2007-2012). The results highlight the uniqueness of catalonia in the context of the spanish state with the highest levels of divorce, fewer disputed judgements and higher rates of shared custody. We conclude that the sharp increase in shared custody could be due to the adaptation of the judicial practices to new models of co-parenting before divorce. This raises the need for qualitative research to study the real impact of shared custody on the daily lives of children and their parents, as we construe that shared custody agreements contain diverse and complex situations that are created after divorce.","","","2014","10.5565/rev/dag.137","","","scopus-2-s2.0-84902173125.pdf","scopus-2-s2.0-84902173125"
"On the possible tools for the prevention of non-performing loans. A case study of an italian bank","Bruno, E. And Iacoviello, G. And Lazzini, A.","Risk Governance And Control: Financial Markets And Institutions","","This work analyses the contribution of an information systems (is) to the implementation of credit monitoring as a new integrated process to prevent non-performing loans in a small bank. The study focuses on the process of active monitoring of the entire credit portfolio, aimed at guiding the best migration between risk classes. This is understood as a set of integrated activities, in which the quality of information becomes a major determinant of the outcome. Such tools support risk management in the decision-making process and aiding performance evaluation. The purpose of this work is to highlight the possibility of an is to support this new integrated process of credit monitoring, providing increasingly reliable data, availability on demand and real-time information. © 2015, virtus interpress. All rights reserved.","","","2015","10.22495/rgcv5i1art1","","","scopus-2-s2.0-84939506534.pdf","scopus-2-s2.0-84939506534"
"When good intentions-Open-Access Publishing-Take a wrong turn","Hinds Pamela S.","Cancer Nursing","","Discovering new knowledge in a trustworthy manner -so trustworthy that we would be willing to alter our care of the sick and injured-is precisely the purpose of research. Although infractions of credible research processes do occur adhering to established research strategies and to acknowledging infractions if they occur contributes to research findings being trustworthy. Such findings have the potential of (a) improving care and thereby care outcomes for children and adults with cancer and (b) sustaining support for the caregiving efforts of their family and professional care providers. Following the discovery of new knowledge and the acknowledgement of infractions that could have possibly influenced findings is the sharing of research findings. Sharing of findings also needs to occur in a trustworthy manner. Highly valued by researchers is sharing trustworthy findings as quickly as possible to benefit others as soon as possible. One approach to making credible research findings quickly available to all is open-access publishing. These motives for open-access publishing are respectable and important. The particularly concerning outcome of this wrong turn of good intentions is that peer review is commonly sacrificed. Peer review is one of the cornerstones of scientific publishing's services. Minus that review process trustworthiness of the overall publication process is immediately diminished. Academic systems have been described as overwhelmed by the sudden surge of publishing by faculty who did not understand the predatory nature of this business wrong turn and who relied on the claimed (fabricated) impact factors for their academic promotion. (PsycInfo Database Record (c) 2021 APA all rights reserved)","","","2015","10.1097/ncc.0000000000000219","","","medline-25479242.pdf","medline-25479242"
"Social media for global neurosurgery. Benefits and limitations of a groundbreaking approach to communication and education","Conti, A. And Magnani, M. And Zoli, M. And Kockro, R.a. And Tuleasca, C. And Peschillo, S. And Umana, G.e. And Tew, S.w. And Jallo, G. And Garg, K. And Spetzler, R.f. And Lafuente, J. And Chaurasia, B.","Brain And Spine","","Introduction: social media have become ubiquitous and their role in medicine is quickly growing. They provide an open platform by which members share educational material, clinical experiences, and collaborate with educational equity. Research question: to characterize the role of social media in neurosurgery, we analyzed metrics of the largest neurosurgical group (neurosurgery cocktail), collected relevant data about activities, impact and risks of this groundbreaking technology. Material and methods: we extracted facebook metrics from 60-day time sample, including users demographics and other platform-specific values such as active members and number of posts within 60 days. A quality assessment of the posted material (clinical case reports and second opinions) was obtained establishing four main quality-criteria: privacy violation;  quality of imaging;  clinical and follow up data. Results: by december 2022, the group included 29.524 members (79.8% male), most (29%) between 35 and 44 years of age. Over 100 countries were represented. A total of 787 posts were published in 60 days with an average of 12.7 per day. In 173 clinical cases presented through the platform, some issue with privacy was recorded in 50.9%. The imaging was considered insufficient in 39.3%, clinical data in 53.8%;  follow up data were missing in 60.7%. Discussion and conclusion: the study provided a quantitative evaluation of impact, flaws and limitations of social medial for healthcare. Flaws were mostly data breach and insufficient quality of case reports. There are actions to correct these flaws that can be easily taken to provide a greater credibility and efficacy to the system. © 2023 the authors","","","2023","10.1016/j.bas.2023.101728","","","scopus-2-s2.0-85152021369.pdf","scopus-2-s2.0-85152021369"
"[Depression and culture]","Stompe T., Ritter K., Schrank B.","Neuropsychiatrie","","It is well established knowledge that aside from biological and biographical factors socio-cultural patterns have a major impact in prevalence and phenomenology of depressive disorders. It is the aim of the authors (1) to clarify the different epistemological positions of transcultural research in depression (2) to present the most important findings of this research (3) to develop suggestions for culture-sensitive epidemiological research.","","","2009","","","","medline-19909697.pdf","medline-19909697"
"Comparison of radiosotopic T3 and T4 kits","Ravel R., Donnellan A. M.","Amer","","Reproducibility data on various T 3 and T 4 kits are presented. This information is useful in evaluating new kits and interpreting patient results. A plea is made for more attention to reproducibility studies by publications and by clinical or nuclear medicine laboratories.","","","1973","","","","unknown-2158.pdf","unknown-2158"
"Privacy-preserving credit evaluation system based on blockchain","Qiao, Y. And Lan, Q. And Zhou, Z. And Ma, C.","Expert Systems With Applications","","In digital intelligence era, the authenticity of data and the privacy protection of data sharing and multiparty collaborative computing are key factors in building a good credit evaluation system. Although blockchain-based credit evaluation system considered this point, more studies on data privacy protection are either only the design of the framework or the proposal of the concept, which is insufficient for privacy protection. To provide a more comprehensive and reliable privacy-preserving scheme, this paper proposes a novel credit evaluation system with secure sharing and multiparty computation based on blockchain. The system consists of five modules: data, access control, data encryption, secure computation and model storage modules. The hyperledger fabric blockchain-based data module ensures the authenticity and traceability of the data source. The raw data are encrypted by a linear transformation algorithm in the data encryption module, which minimizes the output and utilization of data when leaving local storage and prevents potential privacy leakage in data sharing to the greatest extent. The phillie homomorphic encryption-based secure computation algorithm in the secure computation module achieves secure data sharing while applying the secure multiparty computation, which makes it possible to data sharing and privacy protection in multiparty computing. The system obtains final summary statistical results without exposing the raw data. Additionally, the final statistical results of the raw data can be inferred from the encrypted data, and their results are consistent. The correctness and accuracy of the linear conversion encryption mechanism and homomorphic encryption algorithm are proven by theoretical analysis. Security analysis and calculation case show the security of the proposed credit evaluation system and the correctness and effectiveness of the proposed encryption scheme. © 2021","","","2022","10.1016/j.eswa.2021.115989","","","scopus-2-s2.0-85116898657.pdf","scopus-2-s2.0-85116898657"
"Practicing human resource strategy: understanding the relational dynamics in strategic hr work by means of a narrative approach","Kaudela-Baum, S. And Endrissat, N.","Zeitschrift Fur Personalforschung","","This article presents the results of a qualitative research project aimed at examining how human resource (hr) practitioners interpret hr strategy and strategic change. We will illustrate how they develop hr strategy by relying on a system of shared practices which, in turn, constitute the underlying relational dynamics. We argue that hr strategy is embedded in a (rhetorical) network of middle and top managers from hr departments and corresponding operational departments. This implies that hr strategy happens in a social process, more precisely in practices-in-use. Drawing on a systemic constructionist framework, the article discusses the nature of practices-in-use and presents findings from an inductive analysis of a qualitative hr study. The qualitative nature enabled us to shed light on previously neglected aspects of the field of strategic human resource management (shrm). We will outline our research approach and method in detail and discuss its suitability for studying shrm issues. The article concludes by proposing a new understanding of shrm that will hopefully prove to be fruitful both in theory and practice. © rainer hampp verlag.","","","2009","10.1688/1862-0000_zfp_2009_02_kaudela-baum","","","scopus-2-s2.0-76849092905.pdf","scopus-2-s2.0-76849092905"
"Developing participatory approaches for use in an action research project with teachers who support children with visual impairment in kenya and uganda: reflections on the relational praxis between participants and research institutions","Lynch, P. And Mclinden, M. And Douglas, G. And Mccall, S. And Muturi, M. And Bayo, A. And Mwaura, M. And Muga, J.","Research In Comparative And International Education","","Participatory research is a broad term covering a range of approaches that are characterised by a focus on 'action-oriented' research involving researchers and participants working in collaboration to bring about positive change. These approaches emphasise engagement with coresearchers and the development and implementation of context-appropriate strategies that seek to empower and transform at a number of levels. This article explores the dynamics of a multi-agency and multinational research programme that investigated the working practices of specialist teachers of children with visual impairment in uganda and kenya. The research utilised a range of participatory methods, including workshops and a dedicated practice journal, to provide opportunities for participants to record information about their practice and share their experiences with colleagues. The article analyses the effectiveness of the approach, with a particular focus on the 'relational praxis' between the project partners. This analysis highlights the complex nature of the collaborative relationships when research is transnational and operates across cultural, social and environmental contexts. Considerations are offered for research design in this area.","","","2012","10.2304/rcie.2012.7.3.282","","","scopus-2-s2.0-84867739419.pdf","scopus-2-s2.0-84867739419"
"Revticulate: an r framework for interaction with revbayes","Charpentier, C.p. And Wright, A.m.","Methods In Ecology And Evolution","","Phylogenetic methods are increasingly complex. Researchers need to make many choices about how to model different aspects of the data appropriately. It is increasingly common to deploy hierarchical bayesian models in which different data types may be described by different processes. This necessitates tools to help users understand model assumptions more clearly. We describe the package revticulate, which provides an r-based interface to the software revbayes. Revbayes is a bayesian phylogenetic program that implements an r-like computing language, but does not interface with r itself. Revticulate was designed to allow communication between an r session, and all of its associated capabilities, such as plotting and simulation, and a revbayes session. Revticulate can be used to copy objects from revbayes into r. We provide several usage examples demonstrating how objects, such as random variables drawn from probability distributions and phylogenetic trees, can be generated in revbayes. We then show how these objects can be used with r's phylogenetic ecosystem to plot a phylogenetic tree, or with base r functions to simulate the behaviour of a particular probability. Revticulate is a broadly useful software. Revticulate can be used alongside popular document preparation packages, such as knitr and pkgdown to generate attractive reports, tutorials and websites. This means that researchers who are looking to communicate their work in revbayes can do that very easily using revticulate, enabling rapid generation of reproducible research outputs. © 2022 the authors. Methods in ecology and evolution © 2022 british ecological society.","","","2022","10.1111/2041-210x.13852","","","scopus-2-s2.0-85128532307.pdf","scopus-2-s2.0-85128532307"
"Learning by doing: collaborative conceptual modelling as a path forward in ecosystem-based management","Depiper, G. And Gaichas, S. And Muffley, B. And Ardini, G. And Brust, J. And Coakley, J. And Dancy, K. And Elliott, G.w. And Leaning, D.c. And Lipton, D. And Mcnamee, J. And Perretti, C. And Rootes-Murdy, K. And Wilberg, M.j.","Ices Journal Of Marine Science","","Managers, stakeholders, and scientists recognize the need for collaborative, transparent, integrated approaches to complex resource management issues, and frameworks to address these complex issues are developing. Through the course of 2019, the mid-atlantic fishery management council developed a conceptual model of ecosystem linkages and risks for summer flounder, a species of recreational and commercial fisheries importance. The proximal aim of the model was to develop a list of integrated management questions that could be refined and addressed through a future quantitative management strategy evaluation. As such, this conceptual model served as a scoping tool. However, the true value of the conceptual model lays elsewhere: familiarizing resource managers historically focused on single-species management with the potential utility of an ecosystem approach to management. This paper details the goals and development of the conceptual model and situates this process in the broader context of best practices for collaborative open science and scientific reproducibility. Further, it highlights a successful path by which the shift towards ecosystem-based management can be actuated. © 2021 international council for the exploration of the sea 2021.","","","2021","10.1093/icesjms/fsab054","","","scopus-2-s2.0-85114145986.pdf","scopus-2-s2.0-85114145986"
"Conflict strength: measuring the tension between cooperative and competitive incentives in experimental negotiation tasks","Majer, J.m. And Schweinsberg, M. And Zhang, H. And Trötschel, R.","Collabra: Psychology","","Conflict management scholars study mixed-motive negotiation situations with cooperative and competitive incentives predominantly through multi-issue negotiation tasks in experimental studies. Intriguingly, experimenters currently lack an objective, generalizable, and continuous measure that precisely quantifies the incentives underlying these negotiation tasks. We present the conflict strength coefficient, which enables scholars to systematically quantify the incentive structures in these multi-issue negotiation tasks. By making the incentive structures accessible and numerically comparable, the conflict strength coefficient provides new insights into the central element of the experimental study of negotiation and conflict management, unmasks differences across existing tasks, facilitates research transparency, knowledge sharing, and open science practices. We demonstrate the coefficient’s benefits by providing a hands-on example from past research, by reviewing and quantitatively assessing the current literature, and by mapping conflict strength coefficients for the negotiation and conflict management research landscape and its subareas. Our analysis suggests that the conflict strength coefficient can enrich the understanding of cooperative and competitive incentives in the established tasks and directly guide and support an individual scholar’s process of knowledge creation. The conflict strength coefficient provides a methodological contribution to the experimental study of conflict management and negotiation with immediate benefits for the production of scientific knowledge, the experimental study of real-world phenomena, and theory development. © 2022 american institute of physics inc.. All rights reserved.","","","2022","10.1525/collabra.35330","","","scopus-2-s2.0-85130493762.pdf","scopus-2-s2.0-85130493762"
"Guidelines for improving the stringency of response shift research using the thentest","Schwartz C. E., Sprangers M. A.","Quality of Life Research","","OBJECTIVE: Health-state changes can lead to response shifts in internal standards. The most commonly used method for detecting such recalibration response shift is the retrospective pretest-posttest design here referred to as thentest. Since this design faces significant problems there is a pressing need to improve the stringency of studies using the thentest approach. Our objective is to provide guidelines for the optimal use of the thentest approach for detecting recalibration response shift.\\\\\\\\rMETHODS: Discussion of methods based on relevant literature.\\\\\\\\rRESULTS: A checklist is provided that includes recommendations for studies using the thentest approach focusing on: (1) designing the study; (2) formulating hypotheses; (3) constructing the thentest; (4) identifying change; (6) taking alternative explanations into account; (7) using analytic standards; and (8) interpreting results.\\\\\\\\rCONCLUSIONS: The guidelines-checklist has the potential to stimulate rigorous and replicable research using the thentest. This checklist might also be of use for journal editors and reviewers as 'gate keepers' of stringent research. Many of these suggestions also apply to other methods of detecting response shift.","","","2010","10.1007/s11136-010-9585-9","","","medline-20084465.pdf","medline-20084465"
"Effectiveness of One Health approach for control of Kyasanur Forest Disease in Wayanad Kerala India","Prejit, Hitziger M., Asha K.","Journal of Vector Borne Diseases","","BACKGROUND & OBJECTIVES: Kyasanur Forest Disease (KFD) is a vector borne haemorrhagic fever that is endemic in the Wayanad region located in Northern part of Kerala India. The region is managing the outbreak well ever since the major epidemic of 2015. This was because of the successful implementation of One Health (OH) initiative concentrating on multisectoral collaboration between regional institutions involved in public animal and environmental health domains. The article presents how OH was implemented for the first time in the district in the year 2015 and evaluates the degree OH-ness of the Initiative.\\\\\\\\rMETHODS: The OH approach involved trans-disciplinary stakeholder meetings and reviews outbreak management and integrated surveillance targeting ticks monkeys and humans. The degree of OH-ness used for addressing KFD during the year 2015 was evaluated following the protocol developed by the Network for Evaluation of One Health (NEOH). In detail we (i) described the OH initiative and its system (Aim stakeholders action strategy) and (ii) scored different aspects of this initiative (i.e. OH-thinking -planning -working -sharing -learning -organization) with values from 0 (=no OH approach) to 1 (=perfect OH approach).\\\\\\\\rRESULTS: We obtained a median score for each aspect evaluated. We reached high scores for OH systemic organization (1.0) OH thinking (0.83) and OH working (0.83). Lower scores were attributed to OH planning (0.58) OH sharing (0.50) and OH learning (0.33). The OH index was 0.36 and OH ratio was 0.95 indicating a balance between the OH operations and supporting infrastructures.\\\\\\\\rINTERPRETATION & CONCLUSION: With this we could high-light some critical issues related to communication on sharing data as well as learning gaps for consideration to control future outbreaks. The strengths and weaknesses detected may be used to refine the initiative aiming to provide a basis for the development of shared recommendations in a more OH-oriented perspective. This model of evaluation criteria will serve to create a database of OH success stories in India that will in turn help to institutionalize the approach at ministerial level. Future India is moving towards implementing a One Health hence this study data will provide an ideal opportunity for all sectors to control any vector borne diseases.","","","2022","10.4103/0972-9062.331407","","","medline-35708407.pdf","medline-35708407"
"Exploring synergistic interactions and catalysts in complex interventions: longitudinal, mixed methods case studies of an optimised multi-level suicide prevention intervention in four european countries (ospi-europe)","Harris, F.m. And Maxwell, M. And O'connor, R. And Coyne, J.c. And Arensman, E. And Coffey, C. And Koburger, N. And Gusmão, R. And Costa, S. And Székely, A. And Cserhati, Z. And Mcdaid, D. And Van Audenhove, C. And Hegerl, U.","Bmc Public Health","","Background: the medical research council (mrc) framework for complex interventions highlights the need to explore interactions between components of complex interventions, but this has not yet been fully explored within complex, non-pharmacological interventions. This paper draws on the process evaluation data of a suicide prevention programme implemented in four european countries to illustrate the synergistic interactions between intervention levels in a complex programme, and to present our method for exploring these. Methods: a realist evaluation approach informed the process evaluation, which drew on mixed methods, longitudinal case studies. Data collection consisted of 47 semi-structured interviews, 12 focus groups, one workshop, fieldnoted observations of six programme meetings and 20 questionnaires (delivered at six month intervals to each of the four intervention sites). Analysis drew on the framework approach, facilitated by the use of qsr nvivo (v10). Our qualitative approach to exploring synergistic interactions (quasic) also developed a matrix of hypothesised synergies that were explored within one workshop and two waves of data collection. Results: all four implementation countries provided examples of synergistic interactions that added value beyond the sum of individual intervention levels or components in isolation. For instance, the launch ceremony of the public health campaign (a level 3 intervention) in ireland had an impact on the community-based professional training, increasing uptake and visibility of training for journalists in particular. In turn, this led to increased media reporting of ospi activities (monitored as part of the public health campaign) and also led to wider dissemination of editorial guidelines for responsible reporting of suicidal acts. Analysis of the total process evaluation dataset also revealed the new phenomenon of the ospi programme acting as a catalyst for externally generated (and funded) activity that shared the goals of suicide prevention. Conclusions: the quasic approach enabled us to develop and refine our definition of synergistic interactions and add the innovative concept of catalytic effects. This represents a novel approach to the evaluation of complex interventions. By exploring synergies and catalytic interactions related to a complex intervention or programme, we reveal the added value to planned activities and how they might be maximised. © 2016 harris et al.","","","2016","10.1186/s12889-016-2942-z","","","scopus-2-s2.0-84962856551.pdf","scopus-2-s2.0-84962856551"
"Perceptions of self-care in East Germany: a cross-cultural empirical investigation","Whetstone W. R.","Journal of Advanced Nursing","","The purpose of this empirical investigation was replication for comparing self-care phenomena in a cross-cultural setting. Two self-reporting inventories were employed to measure perceptual dimensions of self-care agency and self-concept. Both inventories were translated into German and administered to a convenience sample of 17 adults living in an agricultural collective in East Germany. One research concern was the usability of American-constructed nursing assessment tools in another culture. Other research questions for cross-cultural comparisons of means were formulated. Self-care and self-concept were related in the East German sample. Self-care agency means for the East German sample were lower than for an American student sample. Study limitations are identified and cross-cultural implications of the findings for nursing are discussed.","","","1987","10.1111/j.1365-2648.1987.tb01317.x","","","medline-3646268.pdf","medline-3646268"
"Understanding and predicting web content credibility using the content credibility corpus","Kakol, M. And Nielek, R. And Wierzbicki, A.","Information Processing And Management","","The goal of our research is to create a predictive model of web content credibility evaluations, based on human evaluations. The model has to be based on a comprehensive set of independent factors that can be used to guide user's credibility evaluations in crowdsourced systems like wot, but also to design machine classifiers of web content credibility. The factors described in this article are based on empirical data. We have created a dataset obtained from an extensive crowdsourced web credibility assessment study (over 15 thousand evaluations of over 5000 web pages from over 2000 participants). First, online participants evaluated a multi-domain corpus of selected web pages. Using the acquired data and text mining techniques we have prepared a code book and conducted another crowdsourcing round to label textual justifications of the former responses. We have extended the list of significant credibility assessment factors described in previous research and analyzed their relationships to credibility evaluation scores. Discovered factors that affect web content credibility evaluations are also weakly correlated, which makes them more useful for modeling and predicting credibility evaluations. Based on the newly identified factors, we propose a predictive model for web content credibility. The model can be used to determine the significance and impact of discovered factors on credibility evaluations. These findings can guide future research on the design of automatic or semi-automatic systems for web content credibility evaluation support. This study also contributes the largest credibility dataset currently publicly available for research: the content credibility corpus (c3). © 2017 the authors","","","2017","10.1016/j.ipm.2017.04.003","","","scopus-2-s2.0-85018953320.pdf","scopus-2-s2.0-85018953320"
"Evidence-Based Medicine applied to the control of communicable disease incidents when evidence is scarce and the time is limited","Palmer S., Jansen A., Leitmeyer K., Murdoch H., Forland F.","Euro Surveillance: Bulletin Europeen sur les Maladies Transmissibles = European Communicable Disease Bulletin","","Control of acute communicable disease incidents demands rapid risk assessment often with minimal peer-reviewed literature available but conducted in the public's view. This paper explores how methods of evidence-based medicine (EBM) can be applied in this scenario to improve decision making and risk communication. A working group with members from EBM organisations public health institutions and the European Centre for Disease Prevention and Control used a six-stage framework for rapid risk assessments: preparation risk detection/verification risk assessment development of advice implementation and evaluation. It concluded that data from observational studies surveillance and modelling play a vital role in the evidence base. However there is a need to further develop protocols and standards to perform report and register outbreak investigations more systematically and rigorously and to allow rapid retrieval of the evidence in emergencies. Lack of evidence for risk assessment and advice (usual for new and emerging diseases) should be made explicit to policy makers and the public. Priorities are to improve templates for reporting and assessing the quality of case and outbreak reports apply grading systems to evidence generated from field investigations improve retrieval systems for incident reports internationally and assess how to communicate uncertainties of scientific evidence more explicitly.","","","2013","10.2807/1560-7917.es2013.18.25.20507","","","medline-23806298.pdf","medline-23806298"
"Validation of a new assessment tool for qualitative research articles","Schou, L. And Høstrup, H. And Lyngsø, E.e. And Larsen, S. And Poulsen, I.","Journal Of Advanced Nursing","","Aim. This paper presents the development and validation of a new assessment tool for qualitative research articles, which could assess trustworthiness of qualitative research articles as defined by guba and at the same time aid clinicians in their assessment. Background. There are more than 100 sets of proposals for quality criteria for qualitative research. However, we are not aware of an assessment tool that is validated and applicable, not only for researchers but also for clinicians with different levels of training and experience in reading research articles. Method. In three phases from 2007 to 2009 we delevoped and tested such an assessment tool called vaks, which is the danish acronym for appraisal of qualitative studies. Phase 1 was to develop the tool based on a literature review and on consultation with qualitative researchers. Phase 2 was an inter-rater reliability test in which 40 health professionals participated. Phase 3 was an inter-rater reliability test among the five authors by means of five qualitative articles. Results. The new assessment tool was based on guba's four criteria for assessing the trustworthiness of qualitative inquiries. The nurses found the assessment tool simple to use and helpful in assessing the quality of the articles. The inter-rater agreement was acceptable, but disagreement was seen for some items. Conclusion. We have developed an assessment tool for appraisal of qualitative research studies. Nurses with a range of formal education and experience in reading research articles are able to appraise, relatively consistently, articles based on different qualitative research designs. We hope that vaks will be used and further developed. © 2011 blackwell publishing ltd.","","","2012","10.1111/j.1365-2648.2011.05898.x","","","scopus-2-s2.0-84864304918.pdf","scopus-2-s2.0-84864304918"
"Notes of a review of the management of institutional repositories in sciencie, technology and innovation cuban entities","Cabrera-Gato, J.e. And Romero-Suárez, P.l.","Bibliotecas, Anales De Investigacion","","Objective. Characterization of the institutional repositories implemented in cuban entities focused on the intensive use of new or improved scientific and technological knowledge. Design/methodology/approach. The resiste-chs methodology allowed the identification, selection and analysis of information sources on the management of digital repositories and the reclassification of international records to define the sample of cuban institutional repositories;  the notions of its management are studied through the websites, the projections and purposes of its managers and previous studies contained in academic documents. Results/discussion. Seven cuban institutional repositories are identified in roar and nine in opendoar. 4.06% of all cuban institutions focused on the intensive use of new or improved knowledge participate in its management. Limitations related to functions, research data, integration of systems, performance evaluations. Conclusions. The number of institutional repositories in operation is scarce and the participation of cuban institutions focused on the intensive use of new or improved knowledge in their management is almost nil. The theoretical-practical limitations in the management of institutional repositories affect their assimilation of the new generation of repositories and open science. The adoption of conceptual, architectural and international role standards is urgently needed for its insertion in associations, networks and regional/international programs. Originality/value. Obtaining an updated and critical synthesis of the theoretical and practical experiences in the management of cuban institutional repositories and the contribution to raising their performance in cuban institutions focused on the intensive use of new or improved knowledge. © 2023 the author(s).","","","2023","","","","scopus-2-s2.0-85160565426.pdf","scopus-2-s2.0-85160565426"
"Data sharing privacy metrics model based on information entropy and group privacy preference","Guo, Y. And Zuo, J. And Guo, Z. And Qi, J. And Lu, Y.","Cryptography","","With the development of the mobile internet, service providers obtain data and resources through a large number of terminal user devices. They use private data for business empowerment, which improves the user experience while causing users’ privacy disclosure. Current research ignores the impact of disclosing user non-sensitive attributes under a single scenario of data sharing and lacks consideration of users’ privacy preferences. This paper constructs a data-sharing privacy metrics model based on information entropy and group privacy preferences. Use information theory to model the correlation of the privacy metrics problem, the improved entropy weight algorithm to measure the overall privacy of the data, and the analytic hierarchy process to correct user privacy preferences. Experiments show that this privacy metrics model can better quantify data privacy than conventional methods, provide a reliable evaluation mechanism for privacy security in data sharing and publishing scenarios, and help to enhance data privacy protection. © 2023 by the authors.","","","2023","10.3390/cryptography7010011","","","scopus-2-s2.0-85151086728.pdf","scopus-2-s2.0-85151086728"
"Design of open source framework for traffic and travel simulation","Tamminga, G. And Miska, M. And Santos, E. And Van Lint, H. And Nakasone, A. And Prendinger, H. And Hoogendoorn, S.","Transportation Research Record","","For the evaluation, design, and planning of traffic facilities and measures, traffic simulation packages are the de facto tools for consultants, policy makers, and researchers. However, the available commercial simulation packages do not always offer the desired work flow and flexibility for academic research. In many cases, researchers resort to designing and building their own dedicated models, without an intrinsic incentive (or the practical means) to make the results available in the public domain. To make matters worse, a substantial part of these efforts pertains to rebuilding basic functionality and, in many respects, reinventing the wheel. This problem not only affects the research community but adversely affects the entire traffic simulation community and frustrates the development of traffic simulation in general. For this problem to be addressed, this paper describes an open source approach, opentraffic, which is being developed as a collaborative effort between the queensland university of technology, australia;  the national institute of informatics, tokyo;  and the technical university of delft, the netherlands. The opentraffic simulation framework enables academies from geographic areas and disciplines within the traffic domain to work together and contribute to a specific topic of interest, ranging from travel choice behavior to car following, and from response to intelligent transportation systems to activity planning. The modular approach enables users of the software to focus on their area of interest, whereas other functional modules can be regarded as black boxes. Specific attention is paid to a standardization of data inputs and outputs for traffic simulations. Such standardization will allow the sharing of data with many existing commercial simulation packages.","","","2012","10.3141/2291-06","","","scopus-2-s2.0-84872259799.pdf","scopus-2-s2.0-84872259799"
"Analysis and Evaluation of Chinese Open Government Agricultural Data","Enbo J., Na L.","Journal of Library and Information Science in Agriculture","","[Purpose/Significance] The Ministry of Agriculture and Rural Affairs of China and the agricultural admin istrative departments of various provinces play a major role in promoting agricultural and rural big data develop-ment. This paper aims to learn analyze and evaluate the data publishing sharing standardization and applications by investigating the open governmental agricultural data in 31 provinces autonomous regions and municipalities in the mainland of China and propose suggestions for improvement accordingly. [Method/Process] We investigated the open government platforms built by 31 provinces (autonomous regions and municipalities) sorted out the content published in these platforms and standardized and summarized the investigation data. We made an analysis based on the update time of data license of data applications and download of data. Meanwhile combined with FAIR data principles we evaluated the data from the findability accessibility interoperability and reuse of the data. [Results/Conclusions] At present the management publishing and sharing of agricultural data in China is at an elementary stage. Although various governments formulated regulations and policies the implementation of these regulations and policies is unsatisfactory. The Ministry of Agriculture and Rural Affairs of China should join hands with the agricultural administrative departments of various provinces to promote the opening and use of government agricultural data. Meanwhile they should be in line with the construction mode of the international open government data and improve their capabilities in data publishing management and services. © 2020 Lithologic Reservoirs","","","2020","10.13998/j.cnki.issn1002-1248.2020.10.20-0454","","","scopus-2-s2.0-85150375309.pdf","scopus-2-s2.0-85150375309"
"A behavioral similarity metric for semantic workflows based on semantic task adjacency relations with importance","Sun, J. And Gu, T. And Qian, J.","Ieee Access","","For modern enterprises and organizations, new business workflow can be constructed by reusing already available similar workflows in the repository. Workflow reuse is an important method for implementing business workflow management. Semantic workflows contain control-flow, data-flow, and semantic information relevant to a domain, which facilitates workflow reuse and adaptation. A similarity metric for semantic workflows is important for achieving workflow reuse. However, the existing similarity metrics for semantic workflows focus on workflow structures while ignoring their behaviours, which affect the quality of retrieved similar semantic workflows. Therefore, this paper proposes a behavioral similarity metric for semantic workflows based on semantic task adjacency relations with importance (istars) that incorporate domain knowledge. First, istars that involve semantic tasks and importance of semantic task adjacency relations are defined, and the istars set is used to express the behaviour of the semantic workflow. The istar similarity proposal is based on the similarity between two istars sets and represents the similarity between semantic workflows. The istar distance deduced from istar similarity satisfies the properties of distance metrics. An experimental evaluation revealed that the proposed istar similarity resulted in more effective retrieval of similar semantic workflows than did existing popular behavioral similarity measures. © 2013 ieee.","","","2017","10.1109/access.2017.2731378","","","scopus-2-s2.0-85028913751.pdf","scopus-2-s2.0-85028913751"
"Wessim: a whole-exome sequencing simulator based on in silico exome capture","Kim S., Jeong K., Bafna V.","Bioinformatics","","SUMMARY: We propose a targeted re-sequencing simulator Wessim that generates synthetic exome sequencing reads from a given sample genome. Wessim emulates conventional exome capture technologies including Agilent's SureSelect and NimbleGen's SeqCap to generate DNA fragments from genomic target regions. The target regions can be either specified by genomic coordinates or inferred from in silico probe hybridization. Coupled with existing next-generation sequencing simulators Wessim generates a realistic artificial exome sequencing data which is essential for developing and evaluating exome-targeted variant callers.\\\\\\\\rAVAILABILITY: Source code and the packaged version of Wessim with manuals are available at http://sak042.github.com/Wessim/.\\\\\\\\rSUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.","","","2013","10.1093/bioinformatics/btt074","","","medline-23413434.pdf","medline-23413434"
"Elevating the quality of disability and rehabilitation research: mandatory use of the reporting guidelines","Chan L., Heinemann A. W., Roberts J.","American Journal of Occupational Therapy","","Note from the AJOT Editor-in-Chief: Since 2010 the American Journal of Occupational Therapy (AJOT) has adopted reporting standards based on the Consolidated Standards of Reporting Trials (CONSORT) Statement and American Psychological Association (APA) guidelines in an effort to publish transparent clinical research that can be easily evaluated for methodological and analytical rigor (APA Publications and Communications Board Working Group on Journal Article Reporting Standards 2008; Moher Schulz & Altman 2001). AJOT has now joined 28 other major rehabilitation and disability journals in a collaborative initiative to enhance clinical research reporting standards through adoption of the EQUATOR Network reporting guidelines described below. Authors will now be required to use these guidelines in the preparation of manuscripts that will be submitted to AJOT. Reviewers will also use these guidelines to evaluate the quality and rigor of all AJOT submissions. By adopting these standards we hope to further enhance the quality and clinical applicability of articles to our readers. Copyright © 2014 by the American Occupational Therapy Association Inc.","","","2014","10.5014/ajot.2014.682004","","","medline-24581397.pdf","medline-24581397"
"A case for ongoing structural support to maximise infectious disease modelling efficiency for future public health emergencies: A modelling perspective","Le Rutte E. A., Shattock A. J., Zhao C., Jagadesh S., Balac M., Muller S. A., Nagel K., Erath A. L., Axhausen K. W., Van Boeckel T. P., Penny M. A.","Epidemics","","This short communication reflects upon the challenges and recommendations of multiple COVID-19 modelling and data analytic groups that provided quantitative evidence to support health policy discussions in Switzerland and Germany during the SARS-CoV-2 pandemic. Capacity strengthening outside infectious disease emergencies will be required to enable an environment for a timely efficient and data-driven response to support decisions during any future infectious disease emergency. This will require 1) a critical mass of trained experts who continuously advance state-of-the-art methodological tools 2) the establishment of structural liaisons amongst scientists and decision-makers and 3) the foundation and management of data-sharing frameworks. Copyright © 2023 The Authors. Published by Elsevier B.V. All rights reserved.","","","2023","10.1016/j.epidem.2023.100734","","","medline-38118273.pdf","medline-38118273"
"Spatiotemporal analysis of bike mobility chain: a new perspective on mobility pattern discovery in urban bike-sharing system","Xin, R. And Yang, J. And Ai, B. And Ding, L. And Li, T. And Zhu, R.","Journal Of Transport Geography","","Bike-sharing data have been a valuable source for urban transport research. While most studies focus on origin-destination (od) data of users' bike trips in bike-sharing researches, little has been investigated on mobility patterns from the perspective of bikes. Bike mobility can not only reflect human mobility patterns but also provide practical insights for understanding the bike-sharing system and assisting bike management. In particular, continuous bike movement information can provide abundant spatiotemporal connection information for spatial context analysis in data without user id information. This paper studies bike mobility by shifting the perspective from od analysis to the new analysis primitive of bike mobility chain (bmc). First, bike-sharing od trip data are reconstructed to obtain bmcs. Second, the reconstructed bmcs are feature-augmented, based on which the spatiotemporal characteristics of bike mobility are analyzed. Finally, the word embedding model and the clustering algorithm are applied to the bmcs, which embody rich spatiotemporal inter-station connectivity, to facilitate mining stations with similar bike mobility. The methodology is applied for the comparative study of bike-sharing activities on workdays and holidays using data collected from new york citi-bike. The experimental results manifest locality patterns of bike mobility in both mobility chain indicators and multi-scale station embedding analysis results, and reveal disparities in bmc statistic indicators and spatial distribution mode of stations with similar bike mobility. These results can provide a new empirical reference for urban bike management in different time periods. As a more general implication, this study broadens the perspective for od-based data analysis and paves the path to leverage the thriving trajectory-based research for further investigations. © 2023 the authors","","","2023","10.1016/j.jtrangeo.2023.103606","","","scopus-2-s2.0-85159559457.pdf","scopus-2-s2.0-85159559457"
"Strengthening health care research and academics during and after COVID19 pandemic- an Indian perspective","Chowdhry A., Kapoor P., Popli D. B.","Journal of Oral Biology & Craniofacial Research","","The world-wide crisis of COVID-19 pandemic has disrupted daily lives global economies intra/inter-countries political outlook and educational systems. Schools and colleges in India and abroad are under lock-down to maximize social distancing and minimize the spread of infection amongst students and teaching staff. Health sciences related universities and researchers are forced to adopt non-contact teaching and research. Present article highlights the positive impact and opportunities provided by COVID-19 crisis to health care research and academic set-up. We have compiled ethical effective and practical guidelines to mitigate the impact on health care related research and academic front during these pandemic times in an Indian perspective. These guidelines and management suggestions can be modified to suit region based cases and can be applied in global perspective also. The suggestions in the current article provide a working collaboration of students and teachers to effectively connect on virtual platforms to strengthen their research output giving suggestions of data-sharing and rapid review of proposals by online review ethical boards. This time is proposed to be used for generating a positive impact on health and research sector to use each adversity as an opportunity. Copyright © 2020 Craniofacial Research Foundation. Published by Elsevier B.V. All rights reserved.","","","2020","10.1016/j.jobcr.2020.06.015","","","medline-32704469.pdf","medline-32704469"
"Development of an online morbidity mortality and near-miss reporting system to identify patterns of adverse events in surgical patients","Bilimoria K. Y., Kmiecik T. E., DaRosa D. A., Halverson A., Eskandari M. K., Bell R. H. Jr., Soper N. J., Wayne J. D.","Archives of Surgery","","OBJECTIVES: To design a Web-based system to track adverse and near-miss events to establish an automated method to identify patterns of events and to assess the adverse event reporting behavior of physicians.\\\\\\\\rDESIGN: A Web-based system was designed to collect physician-reported adverse events including weekly Morbidity and Mortality (M&M) entries and anonymous adverse/near-miss events. An automated system was set up to help identify event patterns. Adverse event frequency was compared with hospital databases to assess reporting completeness.\\\\\\\\rSETTING: A metropolitan tertiary care center.\\\\\\\\rMAIN OUTCOME MEASURES: Identification of adverse event patterns and completeness of reporting.\\\\\\\\rRESULTS: From September 2005 to August 2007 15524 surgical patients were reported including 957 (6.2%) adverse events and 34 (0.2%) anonymous reports. The automated pattern recognition system helped identify 4 event patterns from M&M reports and 3 patterns from anonymous/near-miss reporting. After multidisciplinary meetings and expert reviews the patterns were addressed with educational initiatives correction of systems issues and/or intensive quality monitoring. Only 25% of complications and 42% of inpatient deaths were reported. A total of 75.2% of adverse events resulting in permanent disability or death were attributed to the nature of the disease. Interventions to improve reporting were largely unsuccessful.\\\\\\\\rCONCLUSIONS: We have developed a user-friendly Web-based system to track complications and identify patterns of adverse events. Underreporting of adverse events and attributing the complication to the nature of the disease represent a problem in reporting culture among surgeons at our institution. Similar systems should be used by surgery departments particularly those affiliated with teaching hospitals to identify quality improvement opportunities.","","","2009","10.1001/archsurg.2009.5","","","medline-19380642.pdf","medline-19380642"
"Dynamics of cumulative advantage and threats to equity in open science: a scoping review","Ross-Hellauer T., Reichmann S., Cole N. L., Fessl A., Klebel T., Pontika N.","Royal Society Open Science","","Open Science holds the promise to make scientific endeavours more inclusive participatory understandable accessible and re-usable for large audiences. However making processes open will not per se drive wide reuse or participation unless also accompanied by the capacity (in terms of knowledge skills financial resources technological readiness and motivation) to do so. These capacities vary considerably across regions institutions and demographics. Those advantaged by such factors will remain potentially privileged putting Open Science's agenda of inclusivity at risk of propagating conditions of 'cumulative advantage'. With this paper we systematically scope existing research addressing the question: 'What evidence and discourse exists in the literature about the ways in which dynamics and structures of inequality could persist or be exacerbated in the transition to Open Science across disciplines regions and demographics?' Aiming to synthesize findings identify gaps in the literature and inform future research and policy our results identify threats to equity associated with all aspects of Open Science including Open Access Open and FAIR Data Open Methods Open Evaluation Citizen Science as well as its interfaces with society industry and policy. Key threats include: stratifications of publishing due to the exclusionary nature of the author-pays model of Open Access; potential widening of the digital divide due to the infrastructure-dependent highly situated nature of open data practices; risks of diminishing qualitative methodologies as 'reproducibility' becomes synonymous with quality; new risks of bias and exclusion in means of transparent evaluation; and crucial asymmetries in the Open Science relationships with industry and the public which privileges the former and fails to fully include the latter.","","","2022","10.1098/rsos.211032","","","pubmed-35116143.pdf","pubmed-35116143"
"A generic methodology for the statistically uniform & comparable evaluation of automated trading platform components","Sokolovsky, A. And Arnaboldi, L.","Expert Systems With Applications","","Introduction: although machine learning approaches have been widely used in the field of finance, to very successful degrees, these approaches remain bespoke to specific investigations and opaque in terms of explainability, comparability, and reproducibility. Objectives: the primary objective of this research was to shed light upon this field by providing a generic methodology that was investigation-agnostic and interpretable to a financial markets’ practitioner, thus enhancing their efficiency, reducing barriers to entry, and increasing the reproducibility of experiments. The proposed methodology is showcased on two automated trading platform components. Namely, price levels, a well-known trading pattern, and a novel 2-step feature extraction method. Methods: this proposed a generic methodology, useable across markets, the methodology relies on hypothesis testing, which is widely applied in other social and scientific disciplines to effectively evaluate the concrete results beyond simple classification accuracy. The first hypothesis was formulated to evaluate whether the selected trading pattern is suitable for use in the machine learning setting. The second hypothesis allows us to systematically assess whether the proposed feature extraction method leads to any statistically significant improvement in the automated trading platform performance. Results: experiments were conducted across, 10 contracts, 3 feature spaces, and 3 rebound configurations (for feature extraction), resulting in 90 experiments. Across the experiments we found that the use of the considered trading pattern in the machine learning setting is only partially supported by statistics, resulting in insignificant effect sizes (rebound 7 - 0.64±1.02, rebound 11 0.38±0.98, and rebound 15 - 1.05±1.16), but allowed the rejection of the null hypothesis based on the outcome of the statistical test. While the results of the proposed 2-step feature extraction looked promising at first sight, statistics did not support this, this demonstrated the usefulness of the proposed methodology. Additionally, we obtained shap values for the considered models, providing insights for adjustments to the feature space. Conclusion: we showcased the generic methodology on a us futures market instrument and provided evidence that with this methodology we could easily obtain informative metrics beyond the more traditional performance and profitability metrics. The interpretability of these results allows the practitioner to construct more effective automated trading pipelines by analysing their strategies using an intuitive and statistically sound methodology. This work is one of the first in applying this rigorous statistically-backed approach to the field of financial markets and we hope this may be a springboard for more research. A full reproducibility package is shared. © 2023 the author(s)","","","2023","10.1016/j.eswa.2023.119836","","","scopus-2-s2.0-85150249736.pdf","scopus-2-s2.0-85150249736"
"Insiders, outsiders, and credible visitors in research","Porisky, A. And Glas, A.","Ps - Political Science And Politics","","There is a growing consensus around both the importance of researcher positionality for the conduct of research and the intersectional and variable salience of positionality and its effects. However, at the same time, static assumptions of ""insider""and ""outsider""status prevail. This article presents a productive and two-fold intervention in these discussions. First, we show that the insider/outsider distinction is fraught on logistical and conceptual grounds. Relying on our experiences in conducting interview research from rural villages to diplomatic offices, we show that these elements of status are fluid and dynamic. Second, we suggest an alternative to this dichotomy through the aspirational status of a ""credible visitor.""We define this as a performative aspect of positionality founded on humility and reflexivity and enacted through showcasing competence and engaging in transparency. We describe how this approach to performing status may facilitate access as well as fruitful and ethical research interactions. © 2022 the author(s).","","","2023","10.1017/s1049096522001172","","","scopus-2-s2.0-85144531189.pdf","scopus-2-s2.0-85144531189"
"Data flows during public health emergencies in LMICs: A people-centered mapping of data flows during the 2018 ebola epidemic in Equateur DRC","Abramowitz S., Stevens L. A., Kyomba G., Mayaka S., Grepin K. A.","Social Science & Medicine","","In infectious outbreaks rapid case detection and reporting coordination and context-specific strategies are needed for rapid containment. Data sharing between actors and the speed and content of data flows is essential for expediting epidemic response. In this study researchers mapped data flows during the 2018 Ebola Virus Disease (EVD) outbreak in Equateur Province in the Democratic Republic of the Congo using semi-structured interviews ethnographic research and focus groups with EVD response actors. During this research we mapped and tracked data collection transmission storage sharing and use patterns. Target participants included: key organizational actors in the EVD outbreaks responses including local (primary health community-based hospital) provincial (MoPH DRC Red Cross) and international (WHO UN organizations international first-responders) stakeholders. We found that a community-based surveillance system enabled the rapid detection of a hemorrhagic fever outbreak resulting in the rapid laboratory confirmation of EVD. With the arrival of international organizations to provide support to the EVD response routine surveillance systems continued to function robustly. However the establishment of a vertical EVD response architecture created challenges for the response. Data flows during the Equateur outbreak were hampered by numerous challenges in the domains of early warning line lists of cases and contact tracing which impeded surveillance and data flows. We therefore argue that structuring health information systems for preparedness requires taking a person-centered approach to data production flow and analysis. Copyright © 2022. Published by Elsevier Ltd.","","","2023","10.1016/j.socscimed.2022.115116","","","medline-36610244.pdf","medline-36610244"
"Messing with Merton: The intersection between open science practices and Mertonian values","Hosseini M., Senabre Hidalgo E., Horbach Spjm, Guttinger S., Penders B.","Accountability in Research","","Although adherence to Mertonian values of science (i.e. communism universalism organized skepticism disinterestedness) is desired and promoted in academia such adherence can cause friction with the normative structures and practices of Open Science. Mertonian values and Open Science practices aim to improve the conduct and communication of research and are promoted by institutional actors. However Mertonian values remain mostly idealistic and contextualized in local and disciplinary cultures and Open Science practices rely heavily on third-party resources and technology that are not equally accessible to all parties. Furthermore although still popular Mertonian values were developed in a different institutional and political context. In this article we argue that new normative structures for science need to look beyond nostalgia and consider aspirations and outcomes of Open Science practices. To contribute to such a vision we explore the intersection of several Open Science practices with Mertonian values to flesh out challenges involved in upholding these values. We demonstrate that this intersection becomes complicated when the interests of numerous groups collide and contrast. Acknowledging and exploring such tensions informs our understanding of researchers' behavior and supports efforts that seek to improve researchers' interactions with other normative structures such as research ethics and integrity frameworks.","","","2022","10.1080/08989621.2022.2141625","","","medline-36303330.pdf","medline-36303330"
"A process-oriented service infrastructure for networked enterprises","Lukáč, G. And Sabol, T. And Tomášek, M. And Furdík, K.","Electronic Commerce Research And Applications","","The networked enterprise is a short-term partnership of business organizations aimed at sharing the partners’ services without restrictions on size or organizational structure. Our approach considers two software solutions developed for supporting the creation and maintenance of such business collaborations in interoperable networks. The first one addresses a business alliance formation based on combining competences, processes and services of several organizations into a single value chain. Our emphasis is mainly on the interoperability and security of the provided services. The second approach focuses on the collaboration between large enterprises with rich it ecosystems and smes with poor or missing it infrastructure. Interoperable data sharing is supported by light-weight semantics, while standard inter-sme communication is enriched to grant authentication among partners. Alternatives for enabling technologies for service orchestration, process modelling, and event routing are investigated for the solutions. Based on the evaluation results obtained from pilot testing of the system prototypes, we discuss the implications of the technologies on quality indicators such as usability, performance, and business applicability. © 2016 the authors","","","2017","10.1016/j.elerap.2016.11.003","","","scopus-2-s2.0-84998631596.pdf","scopus-2-s2.0-84998631596"
"When policy hits the ground. An empirical study of the communication practices of project managers of a water board in conversations for collaborative governance","Lems, P. And Aarts, N. And Van Woerkum, C.m.j.","Environmental Policy And Governance","","Civil servants organize collaborations with private actors with the aim of developing policy outcomes that fit environmental policy frameworks, shaping the course and outcome of collaborations through their communication practices. To investigate these practices and their effect, we conducted a case study, shadowing project managers from a dutch water board. We identified two distinct communication practices: frame incorporation and frame amplification. These practices respectively expanded or narrowed a process of collaborative governance, either purposefully by building social capital or unintentionally by distancing the conversation partner and his concern. The structural difference between these practices suggests that civil servants lack shared practices that foster collaboration. Interestingly, in neither practice do the civil servants discursively acknowledge their dependence on their conversation partner's support, and thus they deny that they are participating in a negotiation process: they claim that their conversation partner should cooperate. In effect, their conversation partners bypass the incorporation and amplification practices. The research suggests that, of the two practices identified, only incorporation builds the social capital that enables civil servants to switch to another approach in future interactions and start an integrative negotiation on problems and solutions. © 2013 john wiley & sons, ltd and erp environment.","","","2013","10.1002/eet.1618","","","scopus-2-s2.0-84882284833.pdf","scopus-2-s2.0-84882284833"
"The impact of quality culture and leadership on customer relationship in organizations from the romanian metal construction industry","Ilieş, L. And Sălăgean, H.c. And Beleiu, I.","Amfiteatru Economic","","The current paper is part of a wider research that has as general objective to develop an evaluation and analysis model for the total quality management (tqm) system to identify best practices that determine its' performance, in order to improve it. The research is focused on organizations from the metal construction industry. The sample consists of organizations from romania operating in the before mentioned area, which have a consolidated position in the market and conducted efforts in implementing tqm systems. The data analysis was conducted through quantitative research methods, based on statistical processing. Regarding the research tools used for data collection, a survey based on a questionnaire was employed. The designed and pre-tested questionnaire contains items based on factors considered important in analysing and evaluating the tqm system, based on the evaluation criteria of the efqm european excellence award (european foundation for quality management), which provides credibility to the research. The objective of the present research is analysing the components of the tqm system, leadership and quality culture, in companies from the romanian metal construction industry and their influence on customer relationship. The empirical research was conducted between september 2014 and august 2015, and the study is based on questioning 263 managers from 23 companies. The main research results show a very strong positive relation between the variables leadership, quality culture and customer relationship. It was also noticed that the management team of the analysed organizations is concerned with the continuous quality improvement process and that efforts are made for satisfying and exceeding customers' expectations, thus existing the premises for creating customers' dedicated organizations and achieving long term excellence. A surprising result concerning the leadership style favourable to quality culture's development was obtained. The managers from the analysed organizations which have an authoritarian leadership style favour the development of a quality culture more than managers who adopt a democratic style.","","","2017","","","","scopus-2-s2.0-85031708931.pdf","scopus-2-s2.0-85031708931"
"Study of data share in multiprocessor system based on dpram-idt7133","Yan, X.-F. And Ma, J.-H.","Dianzi Qijian/Journal Of Electron Devices","","This article introduced a dual-port random access memory monolithic chip-idt7133, including its external pin configurations and characteristic. As to data storage and share, it interprets two different examples of multiprocessor application;  one is based on normal single-port ram and the other is based on dpram-idt7133. The latter example has got the obvious advantage of data share and transmission in multiprocessor application compared with the former one. Data storage method inside idt7133 is fully described so as to ensure proper practical application.","","","2005","","","","scopus-2-s2.0-28244452540.pdf","scopus-2-s2.0-28244452540"
"Applied participatory priority setting in international agricultural research: making trade-offs transparent and explicit","Kelley, T.g. And Ryan, J.g. And Patel, B.k.","Agricultural Systems","","This paper describes an ex-ante multi-objective framework (economic efficiency, equity, internationality and sustainability) for assessing research priorities at an international agricultural research center. With its supplyside methodological orientation it complements the technical advisory committee/consultative group on international agricultural research demand-side analysis and thus represents a step forward in formulating research agendas. The distinct advantage of the framework described here is that at a time of intense competition for scarce funds, it makes explicit the benefits that would flow from additional investments to an institute as well as the opportunity costs corresponding to reductions. This kind of information is useful for the tac and the cgiar secretariat in making decisions about allocating scarce research resources across cgiar centers. The methodology used in setting research priorities for icrisat's (international crops research for the semi-arid tropics) 1994-1998 medium term plan provides clear criteria for establishing choices among competing research activities, is analytically rigorous, draws on scientists' empirical and intuitive knowledge base, and is transparent and interactive. Research themes identified are impact-oriented, projecting clear milestones against which progress can be measured and evaluated ex-post. Thus, assumptions about prospective yield increases, research lags, probabilities of success, and adoption lags and ceilings can be tested against actual delivery of a new research-induced technology. This forms an integral part of the research evaluation process and facilitates revising priorities in the light of such experiences. © 1995.","","","1995","10.1016/0308-521x(94)00030-u","","","scopus-2-s2.0-0028980631.pdf","scopus-2-s2.0-0028980631"
"The political fight over comparative effectiveness research","Etheredge, L.m.","Health Affairs","","Enactment of the federal stimulus and health reform legislation heralds the beginning of a national comparative effectiveness research program. This article suggests how the department of health and human services (hhs) can, with collaborators, build a highperforming comparative effectiveness research system. New policies and investments should exploit the rapid-learning potential of electronic health records, computerized databases, data sharing, and research networks. A national database for effectiveness research studies should be established by presidential order. Hhs will need to support all of these pieces and take the lead in creating a rapid-learning culture for the us health system. © 2010 project hope-the people-to-people health foundation, inc.","","","2010","10.1377/hlthaff.2010.0608","","","scopus-2-s2.0-84872250813.pdf","scopus-2-s2.0-84872250813"
"Dataset of wearable sensors with possibilities for data exchange","Muzny M., Henriksen A., Giordanengo A., Muzik J., Grottland A., Blixgard H., Hartvigsen G., Arsand E.","Data in Brief","","We performed a search to identify available wearable sensors systems that can collect patient health data and have data sharing capabilities. Findings available in ""Wearable sensors with possibilities for data exchange: Analyzing status and needs of different actors in mobile health monitoring systems"" [1]. We performed an initial search of the Vandrico wearable database and supplemented the resulting device list with an internet search. In addition to relevant meta-data (i.e. name description manufacturer web-link etc.) for each device we also collected data on 13 attributes related to data exchange. I.e. device type communication interface data transfer protocol smartphone and/or PC integration direct integration to open health platform 3rd platform integration with open health platform support for health care system/middleware connection recorded health data types integrated sensors medical device certification whether or not the use can access collected data device developer access and device availability on the market. In addition we grouped each device into three groups of actors that these devices are relevant for: electronic health record providers software developers and patients. The collected data can be used as an overview of available devices for future researchers with interest in the mobile health (mHealth) area. Copyright © 2019 The Author(s).","","","2020","10.1016/j.dib.2019.104978","","","medline-31890815.pdf","medline-31890815"
"Assessing the barriers to knowledge sharing practices in construction joint ventures through case studies","Bakri, A.s. And Shukor, A.s.a. And Khaderi, S.s.","Malaysian Construction Research Journal","","Joint ventures often used by construction companies as a strategic platform to enable learning and gain knowledge associated with their partner skills and capabilities and integrate the new knowledge into own system and structure. While many benefits of joint ventures were highlighted in previous studies, it does not work well in reality since people are often uncertain to share their knowledge and experience. Moreover, the nature of construction projects and temporary setting of joint venture organisations often results in difficulty to retain the knowledge of each project member once the project completed. These problems become more critical in a foreign-local joint ventures where knowledge must be shared across different organisations with different national cultures. The aim of this research paper is to assess the barriers for knowledge sharing practices by using cross-case analysis of joint venture projects as case studies. A qualitative approach with a multiple-case study method was adopted to perform exploratory case studies into selected construction joint ventures in malaysia. Qualitative data were collected from two case studies using the semi-structured interviews with 20 interviewees. Content analysis and cognitive mapping techniques were used to analysed the data. The research findings discovered several barriers to knowledge sharing practices within joint venture project settings such as the cultural barriers, lack of loyalty and project continuity, language barriers, unwilling to share and learn;  and lack of time. As outlined in cidb construction revolution 4.0 (cr4.0), the malaysian construction industry is taking initiatives to improve its current project performance through capacity development by encouraging the collaboration between construction participants. It gives a very substantial explanation for undertaking this research concentrating on cultivating the collaboration and project performance of joint venture project settings through effective knowledge sharing. © 2022, construction research institute of malaysia. All rights reserved.","","","2022","","","","scopus-2-s2.0-85136308295.pdf","scopus-2-s2.0-85136308295"
"Millennial attitudes towards sharing mobile phone location data with health agencies: a qualitative study","Murphy, H. And Keahey, L. And Bennett, E. And Drake, A. And Brooks, S.k. And Rubin, G.j.","Information Communication And Society","","The use of mobile phone devices leaves digital traces which include personal data of the user’s location and can be used to produce aggregated and anonymised location data. There is widespread interest in utilising different types of mobile phone location data to optimise emergency health responses within a range of settings, however until now there has been no qualitative research exploring public opinions on sharing such data. A qualitative study with 40 millennials (born between 1981–2000) across six focus groups were conducted before and after widespread news reports about the leaking of personal data on social media and a major public health incident in the uk. Thematic analysis was used to identify themes in the data. Analysis identified four main themes and five subthemes suggesting the main concepts related to attitudes and concerns were ‘control’, ‘trust’, ‘risks to sharing’ and ‘pros and cons of data sharing’. Millennials were generally accepting of sharing different types of location data with ambulance services and a public health agency if they were able to give explicit consent and retain some personal control towards how their data would be used. The results suggest that policymakers who wish to use aggregated and anonymized mobile phone location data to improve healthcare services should focus on reassurance about how data will be used and promoting public trust. © 2020 informa uk limited, trading as taylor & francis group.","","","2021","10.1080/1369118x.2020.1753798","","","scopus-2-s2.0-85083703593.pdf","scopus-2-s2.0-85083703593"
"Reproducibility of data collected by patient interview","Lim L. L. Y., Dobbins T.","Australian and New Zealand Journal of Public Health","","This study examined the reproducibility of data not generally considered at risk for poor patient recall obtained on two separate occasions. Our study used data collected for a register of heart attacks in the Lower Hunter Region of New South Wales and included 1675 patients who were registered at least twice. Reporting inconsistencies between occasions were assessed for eight data items. We found that the sex of five patients had been recorded differently on the two occasions. Among patients interviewed on both occasions between 0.5 per cent and 2.0 per cent of patients had inconsistent reports for marital status country of birth smoking status and height 2.7 per cent for date of birth 13 per cent for education level and between 1.6 per cent and 9.6 per cent for the history of various medical conditions. Patients not from an English-speaking background over 60 years of age or without tertiary education tended to have higher rates of inconsistent reporting. Time between occasions marital status and sex were not associated with increased rates of inconsistent reporting. We concluded that apparently straightforward data items such as date of birth and education level were not perfectly reproducible when obtained by patient interview on separate occasions. Our results provide a starting point for sensitivity analysis in other studies if the potential inaccuracies in reporting of such data should be of concern.","","","1996","10.1111/j.1467-842x.1996.tb01632.x","","","medline-8987223.pdf","medline-8987223"
"Data trust framework using blockchain technology and adaptive transaction validation","Rouhani, S. And Deters, R.","Ieee Access","","Trust is the main barrier preventing widespread data sharing. The lack of transparent infrastructures for implementing data trust prevents many data owners from sharing their data and concerns data users regarding the quality of the shared data. Data trust is a paradigm that facilitates data sharing by forcing data users to be transparent about the process of sharing and reusing data. Blockchain technology proposes a distributed and transparent administration by employing multiple parties to maintain consensus on an immutable ledger. This paper presents an end-to-end framework for data trust to enhance trustworthy data sharing utilizing blockchain technology. The framework promotes data quality by assessing input data sets, effectively manages access control, and presents data provenance and activity monitoring. We introduce an assessment model that includes reputation, endorsement, and confidence factors to evaluate data quality. We also suggest an adaptive solution to determine the number of transaction validators based on the computed trust value. The proposed data trust framework addresses both data owners' and data users' concerns by ensuring the trustworthiness and quality of the data at origin and ethical and secure usage of the data at the end. A comprehensive experimental study indicates the presented system effectively handles a large number of transactions with low latency. © 2013 ieee.","","","2021","10.1109/access.2021.3091327","","","scopus-2-s2.0-85117585209.pdf","scopus-2-s2.0-85117585209"
"A portable parallel implementation of a boundary element elastostatic code for shared and distributed memory systems","Cunha, M.t.f. And Telles, J.c.f. And Coutinho, A.l.g.a.","Advances In Engineering Software","","This paper presents the parallel implementation of a boundary element code for the solution of 2d elastostatic problems using linear elements. The original code is described in detail in a reference text in the area [boundary elements techniques: theory and applications in engineering, 1984]. The fortran code is reviewed and rewritten to run on shared and distributed memory systems using standard and portable libraries: openmp, lapack and scalapack. The implementation process provides guidelines to develop parallel applications of the boundary element method, applicable to many science and engineering problems. Numerical experiments on a sgi origin 2000 shows the effectiveness of the proposed approach. © 2004 elsevier ltd. All rights reserved.","","","2004","10.1016/j.advengsoft.2004.05.007","","","scopus-2-s2.0-3242716730.pdf","scopus-2-s2.0-3242716730"
"Automation of fluorous solid-phase extraction for parallel synthesis","Zhang W., Lu Y.","Journal of Combinatorial Chemistry","","An automatic fluorous solid-phase extraction (F-SPE) technique is developed by using FluoroFlash SPE cartridges on the RapidTrace workstation. A 10-module workstation has the capability to complete a maximum of 100 SPEs each round in 1-2 h. Another important feature of the RapidTrace system is that it has the capability to load slurry samples onto the F-SPE cartridges. The F-SPE cartridge charged with 2 g of fluorous silica gel is used to purify up to 200 mg of crude sample. Sample loading elution solvent cartridge reuse and SPE reproducibility are evaluated. The automatic SPE system is used for purification of a small urea library generated from amine-scavenging reactions using fluorous dichlorotriazine a 96-membered amide library generated using 2-chloro-46-bis[(perfluorohexyl)propyloxy]-135-triazine as the coupling agent and another 96-membered library generated from fluorous Mitsunobu reactions. Approximately 90% of the products have > 90% purity after F-SPE.","","","2006","10.1021/cc0601130","","","medline-17096578.pdf","medline-17096578"
"Computational systems biology as an animal-free approach to characterize toxicological effects of persistent organic pollutants","Wu, Q. And Achebouche, R. And Audouze, K.","Altex","","Exposure to persistent organic pollutants (pops), as defined by the stockholm convention, may alter biological systems and cause toxic effects. Computational studies appear to be a relevant approach to increase our understanding of the molecular mechanisms triggered by pops. We investigated the use of a systems toxicology approach to explore the effects of pops on human health. A protein-protein association network (ppan) was developed based on known pop-protein interactions. This model was used to predict protein complexes for several candidate pops, including dicofol, methoxychlor, and perfluorooctanoic acid (pfoa), that are listed or proposed to be listed as pops by the stockholm convention. Integration of multiple data sources (pathways, disease annotations, adverse outcome pathways) involving the identified protein complexes was performed independently in order to reveal putative risk factors for human health. This approach revealed that several systems may be disturbed by these candidate pops, mainly the reproductive, metabolic and nervous systems. This study highlights that a computational systems toxicology approach may help to decipher putative biological mechanisms of poorly studied chemicals and link them to possible adverse effects with the aim to support regulatory assessment and trigger new epidemiological and experimental studies. In order to develop more accurate computational models as alternative methods to animal testing, the next challenge will be to integrate more data according to the findable, accessible, interoperable and reusable (fair) data principles. © the authors, 2020.","","","2020","10.14573/altex.1910161","","","scopus-2-s2.0-85082979276.pdf","scopus-2-s2.0-85082979276"
"EUA Roadmap on Research Assessment in the Transition to Open Science","","European University Association","","The European University Association (EUA) has continuously supported European universities in the transition towards Open Science and in particular to Open Access. Upon recommendation of its Expert Group on Science 2.0/Open Science EUA has developed a variety of initiatives in this area as outlined in the ""EUA Roadmap on Open Access to Research Publications."" That roadmap mainly focused on introducing Open Access as the main model of accessing research publications. Looking ahead to the more global transition towards Open Science with its broader framework beyond accessing research publications the Expert Group is starting to address new models of research assessment and evaluation at all levels as these are instrumental to achieving a fairer more open and transparent system driven by researchers. The present EUA roadmap addresses a selection of topics related to new approaches in research assessment including the assessment of research outcomes researchers and research units and organisations (laboratories research centers and universities). With this document EUA aims to raise awareness and support institutions in the development of research assessment approaches that focus on research quality potential and future impact and that take into account Open Science practices. (ERIC)","","","2018","","","","unknown-1012.pdf","unknown-1012"
"Application of occupational justice concepts to children who are born preterm or admitted to neonatal intensive care and their parents: a scoping review protocol","Carruthers K., Robinson J., Armstrong A., Hannis D.","JBI Evidence Synthesis","","OBJECTIVE: This review aims to identify and map the usage application and context of occupational justice concepts and related terms by occupational therapists and occupational scientists in relation to parents and children when children are born preterm or admitted to a neonatal intensive care unit.\\\\\\\\rINTRODUCTION: Occupational justice concepts and related terms can inform occupational therapy practice at the individual level or as a wider social approach. However the extent to which these concepts have been applied to parents and children when children are born preterm or admitted to neonatal intensive care is unknown.\\\\\\\\rINCLUSION CRITERIA: Studies must include 1 or more occupational justice concepts or associated terms in relation to the named population groups. Sources must be related to occupational therapy or occupational science.\\\\\\\\rMETHODS: The review will follow the JBI methodology for scoping reviews and will be reported according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR) and the PRISMA-S extension for reporting literature searches in systematic reviews. Several electronic databases and sources of gray literature will be searched limited by publication year (2000 till the present day). The review will only include human studies and studies with a title or abstract in English. Book chapters will be excluded. Reference lists of included studies will be searched against pre-determined criteria. Evidence sources will be independently screened by a minimum of 2 authors and evidence will be mapped on a pre-determined template.\\\\\\\\rDETAILS OF THE REVIEW AVAILABLE AT: Open Science Framework https://osf.io/fgd7n. Copyright © 2022 JBI.","","","2023","10.11124/jbies-22-00203","","","medline-36728721.pdf","medline-36728721"
"Auto-FedRL: Federated Hyperparameter Optimization for Multi-institutional Medical Image Segmentation","Guo P., Yang D., Hatamizadeh A., Xu A., Xu Z., Li W., Zhao C., Xu D., Harmon S., Turkbey E., Turkbey B., Wood B., Patella F., Stellato E., Carrafiello G., Patel V. M., Roth H. R., Avidan S., Brostow G., Cissé M., Farinella G. M., Hassner T.","","","Federated learning (FL) is a distributed machine learning technique that enables collaborative model training while avoiding explicit data sharing. The inherent privacy-preserving property of FL algorithms makes them especially attractive to the medical field. However in case of heterogeneous client data distributions standard FL methods are unstable and require intensive hyperparameter tuning to achieve optimal performance. Conventional hyperparameter optimization algorithms are impractical in real-world FL applications as they involve numerous training trials which are often not affordable with limited compute budgets. In this work we propose an efficient reinforcement learning (RL)-based federated hyperparameter optimization algorithm termed Auto-FedRL in which an online RL agent can dynamically adjust hyperparameters of each client based on the current training progress. Extensive experiments are conducted to investigate different search strategies and RL agents. The effectiveness of the proposed method is validated on a heterogeneous data split of the CIFAR-10 dataset as well as two real-world medical image segmentation datasets for COVID-19 lesion segmentation in chest CT and pancreas segmentation in abdominal CT. © 2022 The Author(s) under exclusive license to Springer Nature Switzerland AG.","","","2022","10.1007/978-3-031-19803-8_26","","","scopus-2-s2.0-85142677131.pdf","scopus-2-s2.0-85142677131"
"A privacy-preserving technique for incremental dataset on cloud by synthetic data perturbation","Vigneswari, D. And Komal Kumar, N. And Lakshmi Tulasi, R.","International Journal Of Engineering And Technology(Uae)","","Cloud is an impetus technology revolution, allowing data providers to store their privatized electronic health record (ehr) for further analysis and outlook with a compromised privacy, where the shared data being exposed to various adversary attacks and malware threats. There are several masking and randomization techniques that provide hints of privacy. In this paper, the electronic health record (ehr) values are perturbed using logarithmic data perturbation and outsourced to the cloud. Aims.to develop a privacy-preserving technique for effective sharing ofelectronic health record (ehr) on a cloud by logarithmic data perturbation. Methods.synthetic logarithmic transformation is applied to the sensitive values in a record before they are outsourced and for better privacy. Results. Synthetic logarithmic transformation along with the incremental anonymization produces effective result compared to classical anonymization. © 2018 authors.","","","2018","","","","scopus-2-s2.0-85081999938.pdf","scopus-2-s2.0-85081999938"
"Loss of heterozygosity at the BRCA1 and BRCA2 loci detected in ductal lavage fluid from BRCA gene mutation carriers and controls","Locke I., Kote-Jarai Z., Bancroft E., Bullock S., Jugurnauth S., Osin P., Nerurkar A., Izatt L., Pichert G., Gui G. P., Eeles R. A.","Cancer Epidemiology Biomarkers & Prevention","","Female BRCA gene mutation carriers are at increased risk for developing breast cancer. Ductal lavage is a novel method for sampling breast ductal fluid providing epithelial cells for cytologic assessment and a source of free DNA for molecular analyses. Loss of heterozygosity (LOH) at the BRCA loci in ductal lavage fluid is a potential biomarker of breast cancer risk. The LOH rate was measured at the BRCA1/2 loci and compared with that at a control locus (APC) using free DNA from the ductal lavage fluid of BRCA carriers and predictive test negative controls. We evaluated the reproducibility of these analyses. Free DNA sufficient for PCR amplification was obtained from 33 ductal lavage samples of 17 healthy women of known BRCA status (14 BRCA carriers and 3 controls). LOH rates of 36.4% to 56.3% at the BRCA1 locus and 45% to 61.5% at the BRCA2 locus were found among BRCA carriers. The LOH rate at the APC locus was lower (18.5%). The interaliquot reproducibility for the D17S855 marker of the BRCA1 locus was 66.7%. Intraaliquot reproducibility was 90%. Although we successfully isolated sufficient free DNA from ductal lavage fluid for PCR amplification the degree of reproducibility of these LOH studies raises questions about the robustness of this technique as a risk assessment tool in the evaluation of high-risk women. Further studies are required to evaluate the specificity and predictive value of LOH in ductal lavage fluid for breast cancer development.","","","2006","10.1158/1055-9965.epi-05-0971","","","medline-16835343.pdf","medline-16835343"
"Creating connections: an implementation study of promising practices for mentoring in california charter schools","Maxwell, Melanie Sue","Dissertation Abstracts International Section A: Humanities And Social Sciences","","The purpose of the present study was to uncover promising practices in the area of mentoring, specifically implementation of one-on-one adult mentoring with students within the california charter school setting. A case study approach formed the theoretical framework for this study. Research questions guiding the study included: how do charter schools use adult mentoring to improve student achievement? How are resources used to implement adult mentoring for students successfully? What challenges have charter schools faced when implementing adult mentoring and how were the challenges addressed? How do key adults perceive the impact of the mentoring program on mentees and mentors? What other evidence exists to support these perceptions? This study was conducted using a selected sample of two mentoring programs within california charter schools. The selection process utilized the following criteria: the mentoring program must have been implemented for more than one year;  it should demonstrate innovativeness;  it should show evidence of a positive change for student outcomes;  and it should contain a potential for replicability. Data sources, which were qualitative in nature, included interviews with charter school administrators and mentors, a document analysis, and mentoring session observations. The study results showed similarities and differences in the promising practice each charter school performed. A promising practice was defined as a strategy demonstrating the promise, or potential, of improved student achievement. The research provided evidence that one-on-one adult mentoring has the potential to increase student achievement through improving student attendance, grade-to-grade promotion, and decreased discipline referrals. This study's findings and conclusions offer meaningful information regarding implementation of school-based mentoring programs. By publicizing these findings and conclusions through usc's web-based compendium of promising practices, this information has the potential to inspire and guide educators to implement mentoring programs that connect students to school and lead to improved student achievement. (Psycinfo database record (c) 2022 apa, all rights reserved)","","","2009","","","","psychinfo-2009-99210-595.pdf","psychinfo-2009-99210-595"
"Lessons Learned from Large-Scale First-Tier Clinical Exome Sequencing in a Highly Consanguineous Population","Monies D., Abouelhoda M., Assoum M., Moghrabi N., Rafiullah R., Almontashiri N., Alowain M., Alzaidan H., Alsayed M., Subhani S., Cupler E., Faden M., Alhashem A., Qari A., Chedrawi A., Aldhalaan H., Kurdi W., Khan S., Rahbeeni Z., Alotaibi M., Goljan E., Elbardisy H., ElKalioby M., Shah Z., Alruwaili H., Jaafar A., Albar R., Akilan A., Tayeb H., Tahir A., Fawzy M., Nasr M., Makki S., Alfaifi A., Akleh H., Yamani S., Bubshait D., Mahnashi M., Basha T., Alsagheir A., Abu Khaled M., Alsaleem K., Almugbel M., Badawi M., Bashiri F., Bohlega S., Sulaiman R., Tous E., Ahmed S., Algoufi T., Al-Mousa H., Alaki E., Alhumaidi S., Alghamdi H., Alghamdi M., Sahly A., Nahrir S., Al-Ahmari A., Alkuraya H., Almehaidib A., Abanemai M., Alsohaibaini F., Alsaud B., Arnaout R., Abdel-Salam G. M. H., Aldhekri H., AlKhater S., Alqadi K., Alsabban E., Alshareef T., Awartani K., Banjar H., Alsahan N., Abosoudah I., Alashwal A., Aldekhail W., Alhajjar S., Al-Mayouf S., Alsemari A., Alshuaibi W., Altala S., Altalhi A., Baz S., Hamad M., Abalkhail T., Alenazi B., Alkaff A., Almohareb F., Al Mutairi F., Alsaleh M., Alsonbul A., Alzelaye S., Bahzad S., Manee A. B., Jarrad O., Meriki N., Albeirouti B., Alqasmi A., AlBalwi M., Makhseed N., Hassan S., Salih I., Salih M. A., Shaheen M., Sermin S., Shahrukh S., Hashmi S., Shawli A., Tajuddin A., Tamim A., Alnahari A., Ghemlas I., Hussein M., Wali S., Murad H., Meyer B. F., Alkuraya F. S.","American Journal of Human Genetics","","We report the results of clinical exome sequencing (CES) on >2200 previously unpublished Saudi families as a first-tier test. The predominance of autosomal-recessive causes allowed us to make several key observations. We highlight 155 genes that we propose to be recessive disease-related candidates. We report additional mutational events in 64 previously reported candidates (40 recessive) and these events support their candidacy. We report recessive forms of genes that were previously associated only with dominant disorders and that have phenotypes ranging from consistent with to conspicuously distinct from the known dominant phenotypes. We also report homozygous loss-of-function events that can inform the genetics of complex diseases. We were also able to deduce the likely causal variant in most couples who presented after the loss of one or more children but we lack samples from those children. Although a similar pattern of mostly recessive causes was observed in the prenatal setting the higher proportion of loss-of-function events in these cases was notable. The allelic series presented by the wealth of recessive variants greatly expanded the phenotypic expression of the respective genes. We also make important observations about dominant disorders; these observations include the pattern of de novo variants the identification of 74 candidate dominant disease-related genes and the potential confirmation of 21 previously reported candidates. Finally we describe the influence of a predominantly autosomal-recessive landscape on the clinical utility of rapid sequencing (Flash Exome). Our cohort's genotypic and phenotypic data represent a unique resource that can contribute to improved variant interpretation through data sharing. Copyright © 2019 American Society of Human Genetics. Published by Elsevier Inc. All rights reserved.","","","2019","10.1016/j.ajhg.2019.04.011","","","medline-31130284.pdf","medline-31130284"
"Evaluation of the research methodology in genetic, molecular and proteomic tests","Lumbreras, B. And Jarrín, I. And Aguado, I.h.","Gaceta Sanitaria","","Introduction: advances in genomic analysis technologies have led to the development of new diagnostic tests with clinical application. Therefore, as in other diagnostic fields, awareness of the methodological limitations of genetic investigation will facilitate the application of the results. Methods: 44 articles which studied the diagnostic accuracy of genetic, molecular and proteomic tests, and published in jama, lancet, new england journal of medicine, cancer research y clinical cancer research from 2002 to june 2005 were analysed. 24 methodological criteria of the stard guide (standards for reporting of diagnostic accuracy) were applied. Results: the mean number of methodological criteria satisfied was 9.8 (95%, ci 8.8-10.6), with the greatest deficiencies observed in the aspects related to the description of patient selection, 9 (20%), the treatment of indeterminate results, 5 (11%), and the determination of the technique's reproducibility, 6 (13%). In contrast, a high frequency was observed in the description of the reference standard, 39 (87%), and the method used, 28 (62%). Discussion: the articles evaluated fail to fulfil many of the quality requirements laid out in the stard proposal, with the methodological quality being lower than in other diagnostic fields. The aspects most in need of improvement are those related to the description of patient selection and the determination of reproducibility. Research and progress in new genetic-molecular technologies require improved fulfilment of the epidemiological and clinical standards which are already applied by other diagnostic fields.","","","2006","10.1157/13093205","","","scopus-2-s2.0-34547756498.pdf","scopus-2-s2.0-34547756498"
"Calibrating building energy simulation models: A review of the basics to guide future work","Chong A., Gu Y., Jia H.","Energy and Buildings","","Building energy simulation (BES) plays a significant role in buildings with applications such as architectural design retrofit analysis and optimizing building operation and controls. There is a recognized need for model calibration to improve the simulations’ credibility especially with building data becoming increasingly available and the promises that a digital twin brings. However BES calibration remains challenging due to the lack of clear guidelines and best practices. This study aims to provide the foundation for future research through a detailed systematic review of the vital aspects of BES calibration. Specifically we conducted a meta-analysis and categorization of the simulation inputs and outputs data type and resolution key calibration methods and calibration performance evaluation. This study also identified reproducible simulations as a critical issue and proposes an incremental approach to encourage future research's reproducibility. © 2021 Elsevier B.V.","","","2021","10.1016/j.enbuild.2021.111533","","","scopus-2-s2.0-85117208567.pdf","scopus-2-s2.0-85117208567"
"Assessing coastal management case studies around europe using an indicator based tool","Karnauskaitė, D. And Schernewski, G. And Schumacher, J. And Grunert, R. And Povilanskas, R.","Journal Of Coastal Conservation","","Over 350 european integrated coastal zone management (iczm) ‘best practice’ case studies are documented in the ourcoast online public database, to ensure that lessons learned from experiences and practices are shared and improve coastal management practices. However, concrete criteria for ‘best practice’ are missing and a critical evaluation of the success of these case studies did not take place. We present an indicator-based tool and methodology that allows assessing the progress towards sustainability of iczm measures. An indicator-based tool was applied to 18 thematically different coastal case studies using two different methods: a fast screening and an analysis in-depth assessment. Both methods used help to identify strengths and weaknesses of iczm and their contribution to sustainable development. However, indicator scores were highly affected by evaluators’ background and perception. The tool is user-friendly and easy to apply, it indicates what progress has made towards sustainability and to which extent targets have been met. © 2018, the author(s).","","","2018","10.1007/s11852-018-0597-x","","","scopus-2-s2.0-85042938048.pdf","scopus-2-s2.0-85042938048"
"Exploring COVID-19 research credibility among Spanish scientists","Garcia-Garzon E., Angulo-Brunet A., Lecuona O., Barrada J. R., Corradi G.","Current Psychology","","Amidst a worldwide vaccination campaign trust in science plays a significant role when addressing the COVID-19 pandemic. Given current concerns regarding research standards we were interested in how Spanish scholars perceived COVID-19 research and the extent to which questionable research practices and potentially problematic academic incentives are commonplace. We asked researchers to evaluate the expected quality of their COVID-19 projects and other peers' research and compared these assessments with those from scholars not involved in COVID-19 research. We investigated self-admitting and estimated rates of questionable research practices and attitudes towards current research status. Responses from 131 researchers suggested that COVID-19 evaluations followed partisan lines with scholars being more pessimistic about others' colleagues' research than their own. Additionallyresearchers not involved in COVID-19 projects were more negative than their participating peers. These differences were particularly notable for areas such as the expected theoretical foundations or overall quality of the research among others. Most Spanish scholars expected questionable research practices and inadequate incentives to be widespread. In these two aspects researchers tended to agree regardless of their involvement in COVID-19 research. We provide specific recommendations for improving future meta-science studies such as redefining QRPs as inadequate research practices (IRP). This change could help avoid key controversies regarding QRPs' definition while highlighting their detrimental impact. Lastly we join previous calls to improve transparency and academic career incentives as a cornerstone for generating trust in science.\\\\\\\\rSUPPLEMENTARY INFORMATION: The online version contains supplementary material available at 10.1007/s12144-022-02797-6. Copyright © The Author(s) under exclusive licence to Springer Science+Business Media LLC part of Springer Nature 2022.","","","2022","10.1007/s12144-022-02797-6","","","medline-35250242.pdf","medline-35250242"
"Optimization of Revision Hip Arthroplasty Workflow by Means of Detailed Pre-Surgical Planning Using Computed Tomography Data Open-Source Software and Three-Dimensional-Printed Models","Andrzejewski K., Domzalski M., Komorowski P., Poszepczynski J., Rokita B., Elgalal M.","Diagnostics","","BACKGROUND: In revision hip arthroplasty (RHA) establishing the center of rotation (COR) can be technically challenging due to the acetabular bone destruction that is usually present particularly in severe cases such as Paprosky type II and III defects. The aim of this study was to demonstrate the use of open-source medical image reconstruction software and low-cost 3D anatomical models in pre-surgical planning of RHA.\\\\\\\\rMETHODS: A total of 10 patients underwent RHA and were included in the study. Computed tomography (CT) scans were performed for all cases before surgery and approximately 1 week after the procedure. The reconstruction of CT data 3D virtual planning of the COR and positioning of acetabular cups including their inclination and anteversion angles was carried out using the free open source software platform 3D Slicer. In addition anatomical models of the pelvis were built on a desktop 3D printer from polylactic acid (PLA). Preoperative and postoperative reconstructed imaging data were compared for each patient and the position of the acetabular cups as well as the COR were evaluated for each case.\\\\\\\\rRESULTS: Analysis of the pre- and post-op center of rotation position data indicated statistically insignificant differences for the location of the COR on the X-axis (1.5 mm t = 0.5741 p = 0.5868) with a fairly strong correlation of the results (r = -0.672 p = 0.0982) whilst for the location of the COR in the Y and Z-axes there was statistical dependence (Y axis 4.7 mm t = 3.168 and p = 0.0194; Z axis 1.9 mm t = 1.887 and p = 0.1081). A strong correlation for both axes was also observed (Y and Z) (Y-axis r = 0.9438 and p = 0.0014; Z-axis r = 0.8829 and p = 0.0084). Analysis of inclination angle values showed a statistically insignificant difference between mean values (3.9 degrees t = 1.111 p = 0.3092) and a moderate correlation was found between mean values (r = -0.4042 p = 0.3685). Analysis of the anteversion angle showed a statistically insignificant difference between mean values (1.9 degrees t = 0.8671 p = 0.4192) while a moderate correlation between mean values was found (r = -0.4782 p = 0.2777).\\\\\\\\rCONCLUSIONS: Three-dimensional reconstruction software together with low-cost anatomical models are very effective tools for pre-surgical planning which have great potential use in orthopedic surgery particularly RHA. In up and in- and up and out-type defects it is essential to establish a new COR and to identify three support points within the revision acetabulum in order to correctly position acetabular cups.","","","2023","10.3390/diagnostics13152516","","","medline-37568878.pdf","medline-37568878"
"Promoting respectful maternity care: challenges and prospects from the perspectives of midwives at a tertiary health facility in Ghana","Dzomeku V. M., Mensah A. B. B., Nakua E. K., Agbadi P., Okyere J., Donkor P., Lori J. R.","BMC Pregnancy & Childbirth","","BACKGROUND: Evidence shows that women in Ghana experience disrespectful care (slapping pinching being shouted at etc.) from midwives during childbirth. Hence evidence-based research is needed to advance the adoption of respectful maternity care (RMC) by midwives. We therefore sought to explore and document midwives' perspectives concerning challenges faced and prospects available for promoting RMC in a tertiary health facility.\\\\\\\\rMETHODS: We employed an exploratory descriptive qualitative study design. In total we conducted 12 interviews with midwives educated on RMC. All audio data were transcribed verbatim and exported to NVivo-12 for data management and analyses. We relied on the Consolidated Criteria for Reporting Qualitative Research guideline in reporting this study.\\\\\\\\rRESULTS: The findings were broadly categorised into three themes: emotional support dignified care and respectful communication which is consistent with the WHO's quality of care framework. For each theme the current actions that were undertaken to promote RMC the challenges and recommendations to improve RMC promotion were captured. Overall the current actions that promoted RMC included provision of sacral massages and reassurance ensuring confidentiality and consented care and referring clients who cannot pay to the social welfare unit. The challenges to providing RMC were logistical constraints for ensuring privacy free movement of clients and alternative birthing positions. Poor attitudes from some midwives workload and language barrier were other challenges that emerged. The midwives recommended the appointment of more midwives as well as the provision of logistics to support alternative birthing positions and privacy. Also they recommended the implementation of continuous training and capacity building.\\\\\\\\rCONCLUSION: We conclude that in order for midwives to deliver RMC services that include emotional support dignified care and respectful communication the government and hospital administration must make the required adjustments to resolve existing challenges while improving the current supporting activities. Copyright © 2022. The Author(s).","","","2022","10.1186/s12884-022-04786-w","","","medline-35641939.pdf","medline-35641939"
"Ontology based natural language queries transformation into sparql queries","Askar, M. And Algergawy, A. And Soliman, T.h.a. And König-Ries, B. And Sewisy, A.a.","Baltic Journal Of Modern Computing","","Ontology-based data access (obda) enables semantic access to a set of heterogamous data sources, supporting data sharing, exchanging, and integration across these data sources. In the obda scheme, normally formal query languages, such as sparql, are used to represent the user questions, which limits end users from defining their requests. To cope with this problem a layer that accepts the user request in her own language and transforms it into one of these formal languages has become a necessity. To this end, we introduce a new and interactive method that guides the user during the translation. The proposed approach makes use of the capabilities of natural language processing and the semantic information embedded in the domain ontology. Furthermore, the proposed approach considers user involvement during the translation process. To demonstrate the effectiveness, we implemented the proposed approach and validated it against a query benchmark assessing the query accuracy and efficiency. © 2020 university of latvia. All rights reserved.","","","2021","10.22364/bjmc.2020.8.4.14","","","scopus-2-s2.0-85099190543.pdf","scopus-2-s2.0-85099190543"
"The future of interdisciplinary research in the digital era: obstacles and perspectives of collaboration in social and data sciences - an empirical study","Parti, K. And Szigeti, A.","Cogent Social Sciences","","In the last decade, a transition in research design and methodology is identified in social research methodology;  however, the high entry threshold (i.e., technical knowledge) to utilize computational methods and the ethical concerns seem to slow down the process. A possible way out is that social sciences collaborate with computational or data scientists in interdisciplinary research projects to rely on each other’s skills and to develop jointly accepted ethical principles. In this exploratory study, we collected data from researchers with a variety of academic backgrounds to find out their views of interdisciplinary projects and related methodological or ethical issues. Our findings derived from one-on-one interviews (n = 22) reinforce the importance of interdisciplinary collaboration and highlight the significance of “interpreters,” i.e., individuals able to communicate with and connect various areas of science, education, and academic institutions’ role in enhancing interdisciplinary collaborations of sciences. Additional concerns of participants emerged in terms of research methodology applied in the digital world (i.e., data validity, credibility and research ethics). Finally, participants identified open science and the transparency of research as the key to the future development of social sciences. © 2021 the author(s). This open access article is distributed under a creative commons attribution (cc-by) 4.0 license.","","","2021","10.1080/23311886.2021.1970880","","","scopus-2-s2.0-85114307563.pdf","scopus-2-s2.0-85114307563"
"A Decade of GigaScience: GigaDB and the Open Data Movement","Armit C., Tuli M. A., Hunter C. I.","GigaScience","","The increasingly multidisciplinary nature of scientific research necessitates a need for Open Data repositories that can archive data in support of publications in scientific journals. Recognising this need even before GigaScience launched in 2012 GigaDB was already in place and taking data for a year before (making it 11 this year). Since GigaDB launched there has been a consistent growth in this resource in terms of data volume data discoverability and data re-use. In this commentary we provide a retrospective of key changes over the last decade and the role of Data Curation in enhancing the user experience. Furthermore we explore a much needed emphasis on enabling researchers to interact with and explore datasets prior to data download. Copyright © The Author(s) 2022. Published by Oxford University Press GigaScience.","","","2022","10.1093/gigascience/giac053","","","medline-35701374.pdf","medline-35701374"
"Trust vulnerable populations and genetic data sharing","Arias J. J., Pham-Kanter G., Gonzalez R., Campbell E. G.","Journal of Law and the Biosciences","","Recent policies and proposed regulations including the Notice of Proposed Rulemaking for the Common Rule and the 2014 NIH Genetic Data Sharing Policy seek to improve research subject protections. Protections for subjects whose genetic data is shared are critical to reduce risks such as loss of confidentiality stigma and discrimination. In the article 'It depends whose data are being shared: considerations for genomic data sharing policies' Robinson et al. provide a response to our article 'The Growth and Gaps of Genetic Data Sharing Policies'. Robinson et al. highlight the importance of individual and group preferences. In this article we extend the conversation on models for improving protections which will mitigate consequences for individuals and groups that are vulnerable to stigma and discrimination.","","","2015","10.1093/jlb/lsv044","","","medline-27774227.pdf","medline-27774227"
"PhageBox: An Open Source Digital Microfluidic Extension With Applications for Phage Discovery","Albin D., Buecherl L., Kochavi E., Niehaus E., Novack S., Uragoda S., Myers C. J., Alistar M.","IEEE Transactions on Biomedical Engineering","","OBJECTIVE: Recent advancements demonstrate the significant role of digital microfluidics in automating laboratory work with DNA and on-site viral testing. However since commercially available instruments are limited to droplet manipulation our work addresses the need for accelerated integration of other components such as temperature control that can expand the application domain.\\\\\\\\rMETHODS: We developed PhageBox-an accessible device that can be used as a biochip extension. At hardware level PhageBox integrates temperature and electromagnetic control modules. At software level PhageBox is controlled by embedded software containing a unique model for bio-protocol programming and a graphical user interface for visual device feedback and operation.\\\\\\\\rRESULTS: To evaluate PhageBox's efficacy for biomedical applications we performed functional testing. Similarly we validated the temperature control using thermography obtaining a range of +/-0.2[Formula: see text]. The electromagnets produced a magnetic force of 15 milliTesla demonstrating precise immobilization of magnetic beads. We show the potential of PhageBox for bacteriophage research through three initial protocols: a universal framework for PCR T7 bacteriophage restriction enzyme digestion and concentrating phiX174 RF genomic DNA.\\\\\\\\rCONCLUSION: Our work presents an open-source hardware and software extension for digital microfluidics devices. This extension integrates temperature and electromagnetic modules demonstrating efficacy in biomedical applications and potential for bacteriophage research.\\\\\\\\rSIGNIFICANCE: We developed PhageBox to be accessible: the components are off-the-shelf at a low cost ( <= $200) and the hardware designs and software code are open-source. With the long aim of ensuring reproducibility and accelerating collaboration we also provide a DIY-build document.","","","2024","10.1109/tbme.2023.3295418","","","medline-37450356.pdf","medline-37450356"
"Celebrating biodiversity science 30th anniversary: a retrospective evaluation","Zhou, Y. And Li, H. And Ma, K.","Biodiversity Science","","Aims: we have examined the major advancements in biodiversity science from 2013 to 2022 in order to celebrate its 30th anniversary and improve its capacity to serve the development of biodiversity science in china. Progress: over the past 10 years, a total of 58 special issues/features have been published to achieve a high quality and to advance the development in biodiversity research and conservation in china. With the development and needs of the subject, new categories have been established, including editorial, bioinventory, data paper, conservation and governance, and biocultural diversity. Among them, categories like data paper and bioinventory are to encourage data sharing, editorial to introduce hot topics, and forum to encourage academic contending. Over this time, the number of research areas of the journal has increased from 61 to 78. Approximately 90% of the papers in the journal focus on biodiversity conservation, environmental sciences/ecology. The papers of botany, zoology and microbiology accounted for 41.79%, 47.48% and 4.61% of the total, respectively. The keywords of the published articles were grouped into nine subfields according to a bibliometric analysis. These subfields included genetic diversity, community structure, camera-trapping, the convention on biological diversity, national parks, plant diversity, taxonomy, and geographical distribution. A significant amount of biodiversity talent has contributed to the journal, with 4,665 authors. The top 20 authors are mainly from associated institutes of the chinese academy of sciences, chinese academy of environmental sciences, peking university, etc. There are 1,525 papers published in the journal during 2013 and 2022. Of these, 1,211 papers have been cited 13,507 times by journal papers (excluding thesis papers and conference papers) in total, with an average of more than 11 times of each article. They were also widely downloaded and the download capacity increased from 66.4 thousand times in 2012 to 238.5 thousand times in 2021. Five articles have been honored as “the excellent research article award” from china association for science and technology (cast) or “the 100 most influential domestic academic papers” in china. The highly cited and downloaded papers mainly focus on national parks, camera-trapping, the red list, multifunctionality, and biological invasion. The impact factor and citation frequency of the journal have ranked highly in the field of biology. According to the world journal clout index (wjci) report of scientific and technological periodicals, the journal is the only chinese journal among global conservation biology journals, ranked 23/48 in 2019 and 25/49 in 2020, respectively. Prospects: biodiversity science has made a great contribution to the development of biodiversity science in china and become one of the most important journals in biodiversity conservation. Finally, we discuss how to continuously lead china’s biodiversity research and conservation in the future, challenges and countermeasures for creating a world first class journal, as well as how to improve science communication. © 2022, chinese academy of sciences. All rights reserved.","","","2022","10.17520/biods.2022618","","","scopus-2-s2.0-85142037536.pdf","scopus-2-s2.0-85142037536"
"Moving sport and exercise science forward: a call for the adoption of more transparent research practices","Caldwell A.r. And Vigotsky A.d. And Tenan M.s. And Radel R. And Mellor D.t. And Kreutzer A. And Lahart I.m. And Mills J.p. And Boisgontier M.p.","Sports Med","","The primary means of disseminating sport and exercise science research is currently through journal articles. However, not all studies, especially those with null findings, make it to formal publication. This publication bias towards positive findings may contribute to questionable research practices. Preregistration is a solution to prevent the publication of distorted evidence resulting from this system. This process asks authors to register their hypotheses and methods before data collection on a publicly available repository or by submitting a registered report. In the registered report format, authors submit a stage 1 manuscript to a participating journal that includes an introduction, methods, and any pilot data indicating the exploratory or confirmatory nature of the study. After a stage 1 peer review, the manuscript can then be offered in-principle acceptance, rejected, or sent back for revisions to improve the quality of the study. If accepted, the project is guaranteed publication, assuming the authors follow the data collection and analysis protocol. After data collection, authors re-submit a stage 2 manuscript that includes the results and discussion, and the study is evaluated on clarity and conformity with the planned analysis. In its final form, registered reports appear almost identical to a typical publication, but give readers confidence that the hypotheses and main analyses are less susceptible to bias from questionable research practices. From this perspective, we argue that inclusion of registered reports by researchers and journals will improve the transparency, replicability, and trust in sport and exercise science research. The preprint version of this work is available on sportr[formula: see text]iv: https://osf.io/preprints/sportrxiv/fxe7a/.","","","2020","10.1007/s40279-019-01227-1","","","embase-630830108.pdf","embase-630830108"
"Big data begin in psychiatry","Weissman, M.m.","Jama Psychiatry","","The last 40 years of jama psychiatry are reviewed as a celebration of its achievements. The focus of this article is on the evolution of big data as reflected in key journal articles. The review begins in 1984 with the introduction of the epidemiology catchment area (eca) study and freedman's editorial ""psychiatric epidemiology counts."" The eca study (n = 17000), for the first time in a survey, used clinical diagnosis in 5 urban communities, thus linking research and care to population rates of psychiatric diagnosis. The review then traces the subsequent evolution of big data to 5 overlapping phases, other population surveys in the us and globally, cohort studies, administrative claims, large genetic data sets, and electronic health records. Each of these topics are illustrated in articles in jama psychiatry. The many caveats to these choices, the historical roots before 1984, as well as the controversy around the choice of topics and the term big data are acknowledged. The foundation for big data in psychiatry was built on the development of defined and reliable diagnosis, assessment tools that could be used in large samples, the computational evolution for handling large data sets, hypothesis generated by smaller studies of humans and animals with carefully crafted phenotypes, the welcoming of investigators from all over the world with calls for broader diversity, open access and the sharing of data, and introduction of electronic health records more recently. Future directions as well as the opportunities for the complementary roles of big and little data are described. Jama psychiatry will continue to be a rich resource of these publications.. © 2020 american medical association. All rights reserved.","","","2020","10.1001/jamapsychiatry.2020.0954","","","scopus-2-s2.0-85085305234.pdf","scopus-2-s2.0-85085305234"
"Regions of interest selection and thermal imaging data analysis in sports and exercise science: a narrative review","Perpetuini, D. And Formenti, D. And Cardone, D. And Filippini, C. And Merla, A.","Physiological Measurement","","Objective: infrared thermography (irt) is a non-invasive, contactless and low-cost technology that allows recording of the radiating energy that is released from a body, providing an estimate of its superficial temperature. Thanks to the improvement of infrared thermal detectors, this technique is widely used in the biomedical field to monitor the skin temperature for different purposes (e.g. assessing circulatory diseases, psychophysiological state, affective computing). Particularly, in sports and exercise science, thermography is extensively used to assess sports performance, to investigate superficial vascular changes induced by physical exercise, and to monitor injuries. However, the methods of analysis employed to treat irt data are not standardized, and hence introduce variability in the results. Approach: this review focuses on the methods of analysis currently used for thermal imaging in sports and exercise science. Main results: firstly, the procedures employed for the selection of regions of interest (rois) from anatomical body districts are reviewed, paying attention also to the potentialities of morphing algorithms to increase the reproducibility of thermal results. Secondly, the statistical approaches utilized to characterize the temperature frequency and spatial distributions within rois are investigated, showing their strengths and weaknesses. Moreover, the importance of employing tracking methods to analyze the temporal thermal oscillations within rois is discussed. Thirdly, the capability of employing procedures of investigation based on machine learning frameworks on thermal imaging in sports science is examined. Significance: finally, some proposals to improve the standardization and the reproducibility of irt data analysis are provided, in order to facilitate the development of a common database of thermal images and to improve the effectiveness of irt in sports science. © 2021 institute of physics and engineering in medicine","","","2021","10.1088/1361-6579/ac0fbd","","","scopus-2-s2.0-85113381244.pdf","scopus-2-s2.0-85113381244"
"Current ecology not ancestral dispersal patterns influences menopause symptom severity","Yang Y., Arnot M., Mace R.","Ecology and Evolution","","All human females who reach midlife experience menopause however it is currently unclear why women experience this period of infertility and why it is accompanied by many unpleasant symptoms. Using primary data from four ethnic groups in China we test an existing theory that age of menopause and its symptoms are the result of intragenomic conflict between maternally and paternally inherited genes with the outcome of such conflict predicted to be contingent on the ancestral postmarital residence pattern of the female (Ubeda Ohtsuki & Gardner Ecology Letters 17 2014 165). The model predicts that being ancestrally patrilocal results in less intragenomic conflict causing a shorter less symptomatic perimenopause that terminates in a later menopause. Our findings show no support for this hypothesis and suggest current rather than ancestral residence patterns better predict aspects of the menopausal transition. Furthermore current patrilocality when compared to duolocality is associated with more severe menopause symptoms which may be due to sexual rather than intragenomic conflict.\\\\\\\\rOPEN RESEARCH BADGES: This article has earned an Open Data Badge for making publicly available the digitally-shareable data necessary to reproduce the reported results. The data is available at https://doi.org/10.5061/dryad.27s8k0p. Copyright © 2019 The Authors. Ecology and Evolution published by John Wiley & Sons Ltd.","","","2019","10.1002/ece3.5705","","","medline-31788193.pdf","medline-31788193"
"Event-based awareness services for p2p groupware systems","Poulovassilis, A. And Xhafa, F. And O'hagan, T.","Informatica (Netherlands)","","P2p systems enable decentralised applications for supporting collaborating groups and communities, where the collaboration may involve both sharing of data and sharing of group processes among group members. In such applications, monitoring and awareness are critical functionalities required for an effective collaboration. However, to date there has been little research into providing generic, application-independent awareness in p2p groupware systems.we present a distributed event-based awareness approach for such systems that provides different forms of awareness through a set of interoperating, low-level awareness services. The user and technical requirements for the approach are motivated with reference to project-based learning in a p2p environment. We describe the implementation of a superpeer p2p network on a cloud platform and the provision of reliable awareness services (aaas awareness as a service) from the cloud. We report on the outcomes of an empirical evaluation of the performance and scalability of the approach. © 2015 vilnius university.","","","2015","10.15388/informatica.2015.42","","","scopus-2-s2.0-84948123183.pdf","scopus-2-s2.0-84948123183"
"Transparency in fisheries conservation and management measures","Davis, R.a. And Hanich, Q.","Marine Policy","","The adoption of effective fisheries conservation and management measures (‘cmm’) represents a critical stage in the process of sustainably managing global fishing stocks. It represents the point at which scientific data is integrated with law and policy considerations to generate concrete rules designed to constrain the behaviour of fishers and other stakeholders in order to promote desired conservation goals within a fishery. This paper will examine the fisheries cmm process within the broader framework of international law and policy for marine resource governance. It will consider transparency aspects at key stages of the cmm process including the gathering and sharing of data upon which measures are based, the tabling and negotiation of new measures in rfmo meetings, through to the monitoring and enforcement of cmm to ensure their implementation. At each stage, the paper will seek to explore the potential for transparency initiatives to improve the effectiveness of fisheries cmm in promoting desired conservation and management goals within a fishery. © 2020 the authors","","","2022","10.1016/j.marpol.2020.104088","","","scopus-unknown-accession-4032544.pdf","scopus-unknown-accession-4032544"
"Endorsement of guidelines for reporting economic evaluation studies by spanish biomedical journals","Catalá-López, F. And Ridao, M. And Bernal-Delgado, E. And Moher, D. And Repullo, J.r.","Gaceta Sanitaria","","Objective: to examine the endorsement of reporting guidelines for economic evaluation studies, such as the cheers (consolidated health economic evaluation reporting standards) statement, by spanish biomedical journals. Method: cross-sectional analysis of the instructions to authors of spanish biomedical journals included in the journal citation reports 2017. Two authors examined and extracted the following information: mention of any reporting guideline, the cheers statement, the recommendations of the international committee of medical journal directors (icmje) and the enhancing the quality and transparency of health research (equator) network. Results: of the 28 journals included, 23 (82.1%;  95% confidence interval [95%ci]: 63.1-93.9%) mentioned at least one reporting guideline in the instructions to authors. Only one journal mentioned the cheers statement for health economic evaluations. Twenty-four journals (85.7%;  95%ci: 67.3-96.0%) mentioned the icmje recommendations and 8 (28.6%;  95%ci: 13.2-48.7%) mentioned the equator network. The consort (consolidated standards of reporting trials) statement for clinical trials was the most- mentioned reporting guideline (n = 21;  75.0%;  95%ci: 55.1-89.3%). Discussion: most of the instructions to authors do not provide guidance on how to report economic evaluations. Journals should support compliance with reporting guidelines by authors and peer-reviewers. © 2019 sespas","","","2019","10.1016/j.gaceta.2018.12.006","","","scopus-2-s2.0-85062721470.pdf","scopus-2-s2.0-85062721470"
"Atom probe tomography analysis of the reference zircon gj-1: an interlaboratory study","Exertier, F. And La Fontaine, A. And Corcoran, C. And Piazolo, S. And Belousova, E. And Peng, Z. And Gault, B. And Saxey, D.w. And Fougerouse, D. And Reddy, S.m. And Pedrazzini, S. And Bagot, P.a.j. And Moody, M.p. And Langelier, B. And Moser, D.e. And Botton, G.a. And Vogel, F. And Thompson, G.b. And Blanchard, P.t. And Chiaramonti, A.n. And Reinhard, D.a. And Rice, K.p. And Schreiber, D.k. And Kruska, K. And Wang, J. And Cairney, J.m.","Chemical Geology","","In recent years, atom probe tomography (apt) has been increasingly used to study minerals, and in particular the mineral zircon. Zircon (zrsio4) is ideally suited for geochronology by utilising the u-th-pb isotope systems, and trace element compositions are also widely used to constrain petrogenetic processes. However, while standard geoanalytical techniques provide information at micrometer scale lengths, the unique combination of chemical/isotopic sensitivity and spatial resolution of apt allows compositional and textural measurements at the nanoscale. This interlaboratory study aims to define the reproducibility of apt data across research facilities and assess the role of different aspects of the atom probe workflow on reproducibility. This is essential to allow correct evaluation of apt results and full utilization of this emerging technique within the geoscience community. In this study, nine samples from the same homogeneous, gj-1/87 zircon reference grain were sent to nine apt institutes in germany, the uk, usa, canada and australia. After preparing the sample out of a selectioned slab, each institute conducted three different rounds of apt analyses: using (i) unconstrained analysis parameters, (ii) pre-defined analysis parameters, and (iii) interpreting and quantifying a provided dataset. Data such as the measured elemental composition, acquisition parameters, or mass spectrum peak identifications, were recorded and analyzed. We observe a significant variation in the measured composition across this interlaboratory study as well as the number of trace elements identified. These differences are thought to directly result from the user's choice of atom probe data analysis parameters. The type of instrument does not seem to be a critical factor. Consequently, comparison of absolute trace element concentrations on zircon using apt between laboratories is only valid if the same workflow has been ensured. © 2018 elsevier b.v.","","","2018","10.1016/j.chemgeo.2018.07.031","","","scopus-2-s2.0-85051058690.pdf","scopus-2-s2.0-85051058690"
"Multicenter data banking in management of dizzy patients: first results from the dizzynet registry project","Grill, E. And Akdal, G. And Becker-Bense, S. And Hübinger, S. And Huppert, D. And Kentala, E. And Strobl, R. And Zwergal, A. And Celebisoy, N.","Journal Of Neurology","","Purpose: comprehensive phenotypical data across countries is needed to understand the determinants, prognosis and consequences of vestibular disease. The registry is a data repository for the members of the european dizzynet. We report results from a pilot study using data from turkey and germany. Methods: the pilot study included a convenience sample of patients aged 18 or above referred to ege university medical school hospital, dokuz eylül university hospital, izmir, turkey, and the german center for german center for vertigo and balance disorders, university on munich, germany, with symptoms of vertigo or dizziness. Health-related quality of life was assessed with the eq5-d and the dizziness handicap inventory (dhi). To obtain comparable groups we matched data from the two countries for age, sex and diagnosis by propensity score. Results: we included 80 adult patients, 40 from each country (60% female, mean age 54.1, sd 12.4). Matching was successful. Vestibular migraine (34%) was the most frequent diagnosis, followed by benign paroxysmal positional vertigo (29%) and menière’s disease (12%). Clinical signs and symptoms were comparable in both countries. Patients from turkey were more likely to report headaches (65 vs. 32%) and to show gait unsteadiness (51 vs. 5%). Patients from germany reported significantly higher quality of life and lower values of the dhi score. Conclusions: sharing data facilitates research, enhances translation from basic science into clinical applications, and increases transparency. The dizzynet registry is a first step to data sharing in vestibular research across europe. © 2018, springer-verlag gmbh germany, part of springer nature.","","","2018","10.1007/s00415-018-8864-1","","","scopus-2-s2.0-85045481769.pdf","scopus-2-s2.0-85045481769"
"Efficient and secure transfer, synchronization, and sharing of big data","Chard, K. And Tuecke, S. And Foster, I.","Ieee Cloud Computing","","Cloud computing provides a scalable computing platform through which large datasets can be stored and analyzed. However, because of the number of storage models used and rapidly increasing data sizes, it is often difficult to efficiently and securely access, transfer, synchronize, and share data. The authors describe the approaches taken by globus to create standard data interfaces and common security models for performing these actions on large quantities of data. These approaches are general, allowing users to access different types of cloud storage with the same ease with which they access local storage. Through an existing network of more than 8,000 active storage endpoints and support for direct access to cloud storage, globus has demonstrated both the effectiveness and scalability of the approaches presented. © 2014 ieee.","","","2014","10.1109/mcc.2014.52","","","scopus-2-s2.0-84923228424.pdf","scopus-2-s2.0-84923228424"
"EDGE(3): a web-based solution for management and analysis of Agilent two color microarray experiments","Vollrath A. L., Smith A. A., Craven M., Bradfield C. A.","BMC Bioinformatics","","BACKGROUND: The ability to generate transcriptional data on the scale of entire genomes has been a boon both in the improvement of biological understanding and in the amount of data generated. The latter the amount of data generated has implications when it comes to effective storage analysis and sharing of these data. A number of software tools have been developed to store analyze and share microarray data. However a majority of these tools do not offer all of these features nor do they specifically target the commonly used two color Agilent DNA microarray platform. Thus the motivating factor for the development of EDGE(3) was to incorporate the storage analysis and sharing of microarray data in a manner that would provide a means for research groups to collaborate on Agilent-based microarray experiments without a large investment in software-related expenditures or extensive training of end-users.\\\\\\\\rRESULTS: EDGE(3) has been developed with two major functions in mind. The first function is to provide a workflow process for the generation of microarray data by a research laboratory or a microarray facility. The second is to store analyze and share microarray data in a manner that doesn't require complicated software. To satisfy the first function EDGE3 has been developed as a means to establish a well defined experimental workflow and information system for microarray generation. To satisfy the second function the software application utilized as the user interface of EDGE(3) is a web browser. Within the web browser a user is able to access the entire functionality including but not limited to the ability to perform a number of bioinformatics based analyses collaborate between research groups through a user-based security model and access to the raw data files and quality control files generated by the software used to extract the signals from an array image.\\\\\\\\rCONCLUSION: Here we present EDGE(3) an open-source web-based application that allows for the storage analysis and controlled sharing of transcription-based microarray data generated on the Agilent DNA platform. In addition EDGE(3) provides a means for managing RNA samples and arrays during the hybridization process. EDGE(3) is freely available for download at http://edge.oncology.wisc.edu/.","","","2009","10.1186/1471-2105-10-280","","","medline-19732451.pdf","medline-19732451"
"Enabling collaboration and communication across law enforcement jurisdictions: data sharing in a multiagency partnership","Pickering, J.c. And Fox, A.m.","Criminal Justice Policy Review","","Offenders do not always operate within jurisdictional boundaries and, as such, neighboring law enforcement agencies can benefit from sharing crime data and other investigation-related information with one another, with the shared goal of reducing crime throughout their region. In 2016, one such partnership was formed with seven law enforcement agencies, the district attorney’s office, and public health officials in king county, washington. As part of a larger evaluation of this regional collaboration, the authors assessed the data and intelligence-sharing behaviors of key personnel from each participating agency over an 18-month period. This was done through a series of interviews with key personnel and the use of social network analysis. Results suggest that, although data-sharing networks increased in size and project personnel were able to identify benefits to sharing crime data with one another (e.g., seeing the “bigger picture” regarding crime in their region, using shared crime data to track and combat violent crime), they also identified a number of obstacles associated with cross-jurisdictional data sharing. Findings from this evaluation contribute to the collective understanding and implementation of a regional approach to crime control. If criminal justice agencies plan to work together to reduce crime, data and information sharing are essential. Therefore, it is imperative that agencies are aware of the positive outcomes associated with regional data sharing and the challenges that can arise throughout this collaborative effort. © the author(s) 2021.","","","2022","10.1177/08874034211066756","","","scopus-2-s2.0-85122086395.pdf","scopus-2-s2.0-85122086395"
"Towards quantitative evaluation of privacy protection schemes for electricity usage data sharing","Mashima, D. And Serikova, A. And Cheng, Y. And Chen, B.","Ict Express","","Thanks to the roll-out of smart meters, availability of fine-grained electricity usage data has rapidly grown. Such data has enabled utility companies to perform robust and efficient grid operations. However, at the same time, privacy concerns associated with sharing and disclosure of such data have been raised. In this paper, we first demonstrate the feasibility of estimating privacy-sensitive household attributes based solely on the energy usage data of residential customers. We then discuss a framework to measure privacy gain and evaluate the effectiveness of customer-centric privacy-protection schemes, namely redaction of data irrelevant to services and addition of bounded artificial noise. © 2018 the korean institute of communications information sciences","","","2018","10.1016/j.icte.2018.01.006","","","scopus-2-s2.0-85044870766.pdf","scopus-2-s2.0-85044870766"
"Hybrid approach for data publishing using privacy preservation techniques","Saranya, N. And Karpagam, M. And Muruganandham, N.","Arpn Journal Of Engineering And Applied Sciences","","Now a day's governmental and nongovernmental organization wants to share their information for the purpose of knowledge discovery. When the data's are shared individuals personal data or sensitive data which should not be known to others. E.g. Medical record, voters list, census data. This may leads a latest research field called privacy preserving data mining. To address these issues, released datasets must be modified to preserve privacy. This article proposes hiding sensitive medical information by using first randomizes the original data and then applying k-anonymity method for sensitive data for preserving the privacy. Here data fly algorithm is used to implement k-anonymity to anonymize the medical dataset for research purpose. © 2006-2017 asian research publishing network (arpn). All rights reserved.","","","2017","","","","scopus-2-s2.0-85011116068.pdf","scopus-2-s2.0-85011116068"
"Goseed: optimal seeding plan for deduplicated storage","Nachman, A. And Sheinvald, S. And Kolikant, A. And Yadgar, G.","Acm Transactions On Storage","","Deduplication decreases the physical occupancy of files in a storage volume by removing duplicate copies of data chunks, but creates data-sharing dependencies that complicate standard storage management tasks. Specifically, data migration plans must consider the dependencies between files that are remapped to new volumes and files that are not. Thus far, only greedy approaches have been suggested for constructing such plans, and it is unclear how they compare to one another and how much they can be improved. We set to bridge this gap for seeding - migration in which the target volume is initially empty. We prove that even this basic instance of data migration is np-hard in the presence of deduplication. We then present goseed, a formulation of seeding as an integer linear programming (ilp) problem, and three acceleration methods for applying it to real-sized storage volumes. Our experimental evaluation shows that, while the greedy approaches perform well on ""easy""problem instances, the cost of their solution can be significantly higher than that of goseed's solution on ""hard""instances, for which they are sometimes unable to find a solution at all. © 2021 association for computing machinery.","","","2021","10.1145/3453301","","","scopus-2-s2.0-85122582518.pdf","scopus-2-s2.0-85122582518"
"Resolving the data debacle in commercial property: are property practitioners in opaque markets ready for data sharing and assemblage","Olapade, D.t. And Olaleye, A.","Journal Of Property Investment And Finance","","Purpose: with a focus on lagos, nigeria property market, the purpose of this paper is to examine the willingness of property practitioners towards property data sharing and assemblage with a view to improving accessibility to commercial property data in nigerian property market. Design/methodology/approach: primary data were sourced through the use of questionnaire administered on property practitioners (referred as estate surveying and valuation (esv) firms) in lagos property market. In total, 190 esv firms were selected using stratified random sampling based on their geographical location, frequency distribution, percentage, and cross-tabulation were employed for data analysis. Findings: the results showed that majority of the practitioners (68.1 per cent) were willing to share property data among themselves while 52.6 per cent of the practitioners were in support of data assemblage. The result also revealed the higher the experience of the practitioners, the more they are averse to data sharing. It was also revealed that the bigger firm are more averse to data assemblage than the smaller firms. Meanwhile, majority of the practitioners (93.3 per cent) were in support of creation of a central database. Practical implications: the study concluded that without the willingness of practitioners to support data assemblage, the data debacle in property market might not be resolved. Originality/value: the paper is an attempt towards the possibility of creating database of concluded transactions, which will improve accessibility to property data in opaque property market. © 2018, emerald publishing limited.","","","2018","10.1108/jpif-07-2017-0054","","","scopus-2-s2.0-85044224070.pdf","scopus-2-s2.0-85044224070"
"Relationships between change management, knowledge sharing, curriculum coherence and school impact in national curriculum reform: a longitudinal approach","Sullanmaa, J. And Pyhältö, K. And Pietarinen, J. And Soini, T.","International Journal Of Leadership In Education","","It has been suggested that the outcomes of curriculum reform depend on the implementation strategy and coherence making between the reform and school practice. This study examined how teachers perceived a national core curriculum reform implementation in terms of change management and knowledge sharing, and how these contributed to the perceived curriculum coherence and to school-level impact of the reform process over time. Survey data (n = 2447) were collected from teachers during the recent core curriculum reform in finnish basic education. The longitudinal data were collected at three time points during the first three years of curriculum implementation. A cross-lagged path model was utilized to explore longitudinal relations between the variables. The results showed that knowledge sharing practices and perceived curriculum coherence had reciprocal effects over the first year. Moreover, both predicted the extent to which the reform process was considered to promote school impact in terms of meaningful development and teacher commitment, which facilitated higher levels of curriculum coherence and knowledge sharing later on. Change management did not seem to predict the other constructs–yet, knowledge sharing facilitated evaluations of successful change management. The results provide new insights on supporting meaningful school development in large-scale curriculum reform. © 2021 the author(s). Published by informa uk limited, trading as taylor & francis group.","","","2021","10.1080/13603124.2021.1972165","","","scopus-2-s2.0-85113967791.pdf","scopus-2-s2.0-85113967791"
"Accessibility of environmental data for sharing: the role of ux in large cyberinfrastructure projects","Volentine, R. And Specht, A. And Allard, S. And Frame, M. And Hu, R. And Zolly, L.","Ecological Informatics","","Incorporating user experience (ux) testing when creating research cyberinfrastructure is often overlooked, but if left too late, the cost of retrofitting is considerable, and the very clients the cyberinfrastructure was built to serve may be lost. Successfully integrating ux testing into the product development cycle can be difficult but rewarding. This paper describes how ux evaluations were incorporated over ten years of operation of dataone (www.dataone.org), a multi-sector science research cyberinfrastructure project created to support the discovery, access, and sustainability of data about life on earth and the environment that sustains it. The diverse stakeholders in dataone include data creators and users such as researchers and government workers across the broad scope of the earth and environmental sciences as well as those who hold and manage data such as libraries and data repositories. Between 2009 and 2019 dataone members designed and constructed data management tools and services to fulfill the dataone objectives. To assist in achieving its goals, a participatory design approach was used by establishing several largely volunteer and stakeholder-representative working groups, including the usability and assessment working group. This working group conducted over forty ux evaluations to assess the usability of dataone products and websites at various stages of the development process. In addition to improving the usability of dataone products, the ux evaluations fostered community involvement by building trust and engagement with the products being developed. The dataone ux experience yields several important lessons which will improve the success of other projects. It is our conclusion that ux testing should be a mandatory part of the design of any cyberinfrastructure project. © 2021 the authors","","","2021","10.1016/j.ecoinf.2021.101317","","","scopus-2-s2.0-85105843912.pdf","scopus-2-s2.0-85105843912"
"Open science approaches to covid-19","Todd M.h. And Tse E.g. And Klug D.m.","F1000 Res","","In only a matter of months, the coronavirus disease of 2019 (covid-19) has spread around the world. The global impact of the disease has caused significant and repeated calls for quick action towards new medicines and vaccines. In response, researchers have adopted open science methods to begin to combat this disease via global collaborative efforts. We summarise here some of those initiatives, and have created an updateable list to which others may be added. Though open science has previously been shown as an accelerator of biomedical research, the covid-19 crisis has made openness seem the logical choice. Will openness persist in the discovery of new medicines, after the crisis has receded?Copyright © 2020 tse eg et al.","","","2020","10.12688/f1000research.26084.1","","","embase-633408405.pdf","embase-633408405"
"Implementation of GenePattern within the Stanford Microarray Database","Hubble J., Demeter J., Jin H., Mao M., Nitzberg M., Reddy T. B., Wymore F., Zachariah Z. K., Sherlock G., Ball C. A.","Nucleic Acids Research","","Hundreds of researchers across the world use the Stanford Microarray Database (SMD; http://smd.stanford.edu/) to store annotate view analyze and share microarray data. In addition to providing registered users at Stanford access to their own data SMD also provides access to public data and tools with which to analyze those data to any public user anywhere in the world. Previously the addition of new microarray data analysis tools to SMD has been limited by available engineering resources and in addition the existing suite of tools did not provide a simple way to design execute and share analysis pipelines or to document such pipelines for the purposes of publication. To address this we have incorporated the GenePattern software package directly into SMD providing access to many new analysis tools as well as a plug-in architecture that allows users to directly integrate and share additional tools through SMD. In this article we describe our implementation of the GenePattern microarray analysis software package into the SMD code base. This extension is available with the SMD source code that is fully and freely available to others under an Open Source license enabling other groups to create a local installation of SMD with an enriched data analysis capability.","","","2009","10.1093/nar/gkn786","","","medline-18953035.pdf","medline-18953035"
"Industrial methodology for process verification in research (IMPROVER): toward systems biology verification. [Review]","Meyer P., Hoeng J., Rice J. J., Norel R., Sprengel J., Stolle K., Bonk T., Corthesy S., Royyuru A., Peitsch M. C., Stolovitzky G.","","","MOTIVATION: Analyses and algorithmic predictions based on high-throughput data are essential for the success of systems biology in academic and industrial settings. Organizations such as companies and academic consortia conduct large multi-year scientific studies that entail the collection and analysis of thousands of individual experiments often over many physical sites and with internal and outsourced components. To extract maximum value the interested parties need to verify the accuracy and reproducibility of data and methods before the initiation of such large multi-year studies. However systematic and well-established verification procedures do not exist for automated collection and analysis workflows in systems biology which could lead to inaccurate conclusions. RESULTS: We present here a review of the current state of systems biology verification and a detailed methodology to address its shortcomings. This methodology named 'Industrial Methodology for Process Verification in Research' or IMPROVER consists on evaluating a research program by dividing a workflow into smaller building blocks that are individually verified. The verification of each building block can be done internally by members of the research program or externally by 'crowd-sourcing' to an interested community. www.sbvimprover.com IMPLEMENTATION: This methodology could become the preferred choice to verify systems biology research workflows that are becoming increasingly complex and sophisticated in industrial and academic settings.","","","2012","","","","unknown-1954.pdf","unknown-1954"
"Harnessing the Biologics and Biosimilars Collective Intelligence Consortium to Evaluate Patterns of Care","McMahill-Walraven C. N., Kent D. J., Panozzo C. A., Pawloski P. A., Haynes K., Marshall J., Brown J., Eichelberger B., Lockhart C. M.","Journal of Managed Care & Specialty Pharmacy","","INTRODUCTION: As clinical trials test efficacy rather than effectiveness of medications real-world effectiveness data often vary from clinical trial data. Given the recent market entry of multiple biologics and biosimilars a dedicated assessment of these diverse agents is needed to build the evidence base regarding efficacy and safety of innovator biologics and biosimilars.\\\\\\\\rPROGRAM DESCRIPTION: The Academy of Managed Care Pharmacy's Biologics and Biosimilars Collective Intelligence Consortium (BBCIC) was convened to address the lack of real-world postmarket outcome evidence generation for innovator biologics and corresponding biosimilars. The BBCIC is a multistakeholder scientific research consortium whose participants prioritize topics and collaboratively conduct research studies. The BBCIC conducts a wide range of analyses including population characterization epidemiologic studies and active observational studies and develops best practices for conducting large-scale studies to provide real-world evidence.\\\\\\\\rOBSERVATIONS: Over the past 3 years we undertook multiple descriptive analyses with the goal of characterizing data availability and demonstrating the feasibility and efficacy of using the BBCIC distributed research network (DRN) which includes commercial claims data from 2008-2018 covering approximately 100 million lives with approximately 20 million active members in 2017 from 2 major U.S. health plans and 3 regional integrated delivery networks. We analyzed 4 medication classes of particular interest to biologics and biosimilars development: insulins granulocyte colony-stimulating factors erythropoietic-stimulating agents and anti-inflammatories. We were able to identify exposures and user characteristics in all 4 categories. Herein we describe the successes and challenges of conducting some of our analyses specifically among insulin users with type 1 diabetes mellitus.\\\\\\\\rIMPLICATIONS: Our results demonstrate the BBCIC DRN's ability to identify and characterize exposures cohorts and outcomes that can contribute to more sophisticated comparative surveillance of biosimilars and innovator biologics in the future. Additional linkages to laboratory data and a wider range of insurance carriers will further strengthen the BBCIC DRN.\\\\\\\\rDISCLOSURES: This study was coordinated and funded by the Biologics and Biosimilars Collective Intelligence Consortium (BBCIC) and represents the independent findings of the BBCIC Insulins Principal Investigator and the BBCIC Insulins Research Team. Lockhart is employed by the BBCIC; Eichelberger was employed by the BBCIC at the time of this study. McMahill-Walraven is employed by Aetna a CVS Health business. Panozzo Marshall and Brown are employed by Harvard Pilgrim Healthcare Institute. Aetna receives external funding through research grants and subcontracts with Harvard Pilgrim Healthcare Institute which are funded by the FDA NIH PCORI BBCIC Pfizer and GSK; the Reagan-Udall Foundation for IMEDS; and PCORI for the ADAPTABLE Study. Aetna was reimbursed for data and analytic support from Harvard Pilgrim Healthcare Institute and the Reagan Udall Foundation for the U.S. Food and Drug Administration. This work was presented as a poster at AMCP Nexus 2018; October 22-25 2018; in Orlando FL.","","","2019","10.18553/jmcp.2019.19041","","","medline-31397619.pdf","medline-31397619"
"Doing comparative case study research in urban and regional studies: what can be learnt from practice?","Krehl, A. And Weck, S.","European Planning Studies","","Recent years have seen a vivid debate on the epistemological foundations of comparative urban research. Remarkably, comparative case study research practice has remained unaffected by these wider debates and empirical research processes often stay a ‘black box’. Thus, we identify an unmet need for a critical and transparent reflection of conceptual foundations and empirical processes. Based on a review of eu-funded projects in the field of territorial cohesion, we discuss minimum standards of comparative case study research. These standards encompass the theoretical framework of the study, the objective of comparison, questions regarding the ambition to generalize, the case study selection strategy, and potential trade-offs. We conclude that researchers should be more explicit in their way of carrying out comparative research. Eventually, this transparency supports both a fruitful debate on comparative case study designs and the soundness of academic and policy conclusions. © 2019 the author(s). Published by informa uk limited, trading as taylor & francis group.","","","2020","10.1080/09654313.2019.1699909","","","scopus-2-s2.0-85076435481.pdf","scopus-2-s2.0-85076435481"
"About the improvement of production and evaluation of scientific journals in brazil","Ponce, B.j. And De Almeida, M.e.b. And Freitas, S.a. And Da Silva, C.b. And Anjos, D. And De Pietri, E. And Prieto, R.g. And Dias, É.s.a.c. And Camargo, E. And Branco, J.c. And Souza, J.s. And Bizelli, J.l. And Siman, L.m.c. And Muzzeti, L.r. And Dos Reis, M. And Martins, E. And Rosito, M.m.b. And Bissoto, M.l. And De Castro, M.r. And Gimenes, N. And Gualtieri, R. And Silva, R. And Ribeiro, R. And Lemes, S.s.","Ensaio","","The document we presented is the result of the reflection of editors of scientific journals connected to fepae southeast and expresses concrete concerns about the material conditions for the realization of its work and about the evaluation criteria that have been used to qualify its journals. Cheaper budgets, dismantling of university structures that supported many academic journals and indicators which everytime complicate even more the operational procedures involved in editorial production, undermine the national journals. Lack of visibility about the evaluation procedures, absence of dialogue about results and questions connected to the qualis frequency bring uncertainty for the authors who have in the journals a vehicle for sharing its practices and theories. This way we want to deepen the discussion with the scientific community and the regulatory governmental agency - capes - about the destinations reserved to brazilian scientific journals.","","","2017","10.1590/s0104-40362017002501032","","","scopus-2-s2.0-85032014563.pdf","scopus-2-s2.0-85032014563"
"Effect of drying on the quality of leaves of plants used in the traditional brazilian medicine: a review of the period 2007-2017","De Oliveira, M.i.s. And Barbosa Junior, J.l. And Mancini, M.c. And Jacintho Barbosa, M.i.m.","Revista Brasileira De Plantas Medicinais","","The quality of the leaves, in terms of the preservation of compounds of interest, such as active principles, nutrients, vitamins, natural pigments, essential oils, among others, is directly related to the water content. Therefore, drying is one of the most used processes in the conservation of these biological materials that can be applied for therapeutic purposes. Many studies have evaluated the kinetics and the mathematical models that describe the drying, but few had as their purpose the evaluation of the quality of the dehydrated plants during and after the process. In this context, this review article aimed to discuss the most pertinent works of the last decade, which evaluated the effect of the drying process on the quality of leaves of plants used in the traditional brazilian medicine. Regarding the method used, drying is still very restricted to traditional processes, such as: convective dryers, with and without forced air circulation, and natural convection oven. The use of alternative technologies seeking efficiency and improvement of the quality of the dehydrated product was not observed. It is difficult to obtain homogeneous samples and obtain reproducibility of the data in modeling and kinetics. Thus, further studies of the processes and quality parameters are necessary to enable the improvement and efficiency of the drying of the brazilian medicinal plants. © 2018, instituto de biociencias. All rights reserved.","","","2018","","","","scopus-2-s2.0-85149389162.pdf","scopus-2-s2.0-85149389162"
"Public and biobank participant attitudes toward genetic research participation and data sharing","Lemke A. A., Wolf W. A., Hebert-Beirne J., Smith M. E.","Public Health Genomics","","Research assessing attitudes toward consent processes for high-throughput genomic-wide technologies and widespread sharing of data is limited. In order to develop a better understanding of stakeholder views toward these issues this cross-sectional study assessed public and biorepository participant attitudes toward research participation and sharing of genetic research data. Forty-nine individuals participated in 6 focus groups; 28 in 3 public focus groups and 21 in 3 NUgene biorepository participant focus groups. In the public focus groups 75% of participants were women 75% had some college education or more 46% were African-American and 29% were Hispanic. In the NUgene focus groups 67% of participants were women 95% had some college education or more and the majority (76%) of participants was Caucasian. Five major themes were identified in the focus group data: (a) a wide spectrum of understanding of genetic research; (b) pros and cons of participation in genetic research; (c) influence of credibility and trust of the research institution; (d) concerns about sharing genetic research data and need for transparency in the Policy for Sharing of Data in National Institutes of Health-Supported or Conducted Genome-Wide Association Studies; (e) a need for more information and education about genetic research. In order to increase public understanding and address potential concerns about genetic research future efforts should be aimed at involving the public in genetic research policy development and in identifying or developing appropriate educational strategies to meet the public's needs.","","","2010","10.1159/000276767","","","medline-20805700.pdf","medline-20805700"
"Automated Sholl analysis of digitized neuronal morphology at multiple scales: Whole cell Sholl analysis versus Sholl analysis of arbor subregions","Langhammer C. G., Previtera M. L., Sweet E. S., Sran S. S., Chen M., Firestein B. L.","Cytometry Part A: The Journal of the International Society for Analytical Cytology","","The morphology of dendrites and the axon determines how a neuron processes and transmits information. Neurite morphology is frequently analyzed by Sholl analysis or by counting the total number of neurites and branch tips. However the time and resources required to perform such analysis by hand is prohibitive for the processing of large data sets and introduces problems with data auditing and reproducibility. Furthermore analyses performed by hand or using course-grained morphometric data extraction tools can obscure subtle differences in data sets because they do not store the data in a form that facilitates the application of multiple analytical tools. To address these shortcomings we have developed a program (titled ""Bonfire"") to facilitate digitization of neurite morphology and subsequent Sholl analysis. Our program builds upon other available open-source morphological analysis tools by performing Sholl analysis on subregions of the neuritic arbor enabling the detection of local level changes in dendrite and axon branching behavior. To validate this new tool we applied Bonfire analysis to images of hippocampal neurons treated with 25 ng/ml brain-derived neurotrophic factor (BDNF) and untreated control neurons. Consistent with prior findings conventional Sholl analysis revealed that global exposure to BDNF increases the number of neuritic intersections proximal to the soma. Bonfire analysis additionally uncovers that BDNF treatment affects both root processes and terminal processes with no effect on intermediate neurites. Taken together our data suggest that global exposure of hippocampal neurons to BDNF results in a reorganization of neuritic segments within their arbors but not necessarily a change in their number or length. These findings were only made possible by the neurite-specific Sholl data returned by Bonfire analysis. Copyright © 2010 International Society for Advancement of Cytometry.","","","2010","10.1002/cyto.a.20954","","","medline-20687200.pdf","medline-20687200"
"Analysis of hyperspectral reflectance for disease classification of soybean frogeye leaf spot using knime analytics","Ang, Y. And Shafri, H.z.m.","Malaysian Journal Of Analytical Sciences","","The feasibility of classifying soybean frogeye leaf spot (fls) has been investigated with the advance of hyperspectral technology. Hyperspectral reflectance data of healthy and fls disease soybeans were used. The first step was to smooth out the data by using a filtering technique namely savitzky-golay to eliminate the noise of the spectrum. In order to select the most significant wavelengths, genetic algorithm (ga) was used as a forward feature selection technique. This analysis involved the implementation of machine learning (ml) algorithms, including decision trees, random forests, and stacking, to classify soybean fls severity levels. Preprocessing ml steps including converting class numbers to strings, identifying and removing missing values, partitioning and normalizing data were implemented prior to the development of the model. Overall accuracy and the receiver operating characteristic curve measure were used to assess the performance of this analysis. All of these steps were carried out through knime analytical platform. Based on the results of the analysis, ga-stacking and random forest algorithms achieved the best overall accuracy of 85.9% and 84.3%, respectively. In terms of reproducibility, data flow control, data exploration, analysis and visualization, knime analytics platform provided great convenience in connecting tools graphically and ensuring the same results on different operating systems. The rapid implementation of workflow in knime analytics platform provided the opportunity to process hyperspectral reflectance data to classify crop diseases. © 2023, malaysian society of analytical sciences. All rights reserved.","","","2023","","","","scopus-2-s2.0-85164116942.pdf","scopus-2-s2.0-85164116942"
"Behaviour-based short-term invoice probability of default evaluation","Perko, I.","European Journal Of Operational Research","","In this paper, the effect of behavioural analytics on short-term default predictions at the invoice level is addressed by answering a question that slightly diverges from the traditional probability of default definition: ‘what is the probability that this invoice will be paid within the next 30 days?’ Resultantly improving short-term liquidity planning accuracy and supporting financial management in companies. To provide a valid answer to the research question, a set of issues needs to be resolved, including identifying an appropriate data set, increasing the data predictive power, and creating and testing predictive models. Since the appropriate data set is not yet presented, we primarily focus on the first two issues: identifying appropriate data and raising its predictive power. In this paper, we propose to build predictive models upon a new data source from multiple companies, acquired by business partners' data sharing concept. Furthermore, we upgrade these data with behavioural analysis to test the assumption that the probability of default depends not only on payment capability but also on payment preparedness. The predictive power of shared invoice data and the effects of behavioural analysis are tested in a two-phase experiment: first, basic shared data are used to predict short-term invoice defaults, and in the second phase, the behavioural analysis results are included in the dataset. Lastly, the predictive models’ test results are compared. Both results are positive: the already high accuracy of models, build upon basic data is significantly upgraded in models, using the behaviour analysis extended data set. © 2016 elsevier b.v.","","","2017","10.1016/j.ejor.2016.08.039","","","scopus-2-s2.0-84995493558.pdf","scopus-2-s2.0-84995493558"
"Faircs—blockchain-based fair crowdsensing scheme using trusted execution environment","Liang, Y. And Li, Y. And Shin, B.-S.","Sensors (Switzerland)","","Crowdsensing applications provide platforms for sharing sensing data collected by mobile devices. A blockchain system has the potential to replace a traditional centralized trusted third party for crowdsensing services to perform operations that involve evaluating the quality of sensing data, finishing payment, and storing sensing data and so forth. The requirements which are codified as smart contracts are executed to evaluate the quality of sensing data in a blockchain. However, regardless of the fact that the quality of sensing data may actually be sufficient, one key challenge is that malicious requesters can deliberately publish abnormal requirements that cause failure to occur in the quality evaluation process. If requesters control a miner node or full node, they can access the data without making payment;  this is because of the transparency of data stored in the blockchain. This issue promotes unfair dealing and severely lowers the motivation of workers to participate in crowdsensing tasks. We (i) propose a novel crowdsensing scheme to address this issue using trusted execution environments;  (ii) offer a solution for the confidentiality and integrity of sensing data, which is only accessible by the worker and corresponding requester;  (iii) and finally, report on the implementation of a prototype and evaluate its performance. Our results demonstrate that the proposed solution can guarantee fairness without a significant increase in overhead. © 2020 by the authors. Licensee mdpi, basel, switzerland.","","","2020","10.3390/s20113172","","","scopus-unknown-accession-3197953.pdf","scopus-unknown-accession-3197953"
"Improving data interpretation of fragmentary data-sets on invertebrate dispersal with permutation tests","Jopp, F. And Lange, C.","Acta Oecologica","","Biological data often tend to have heterogeneous, discontinuous non-normal distributions. Statistical non-parametric tests, like the mann-whitney u-test or the extension for more than two samples, the kruskal-wallis test, are often used in these cases, although they assume certain preconditions which are often ignored. We developed a permutation test procedure that uses the ratio of the interquartile distances and the median differences of the original non-classified data to assess the properties of the real distribution more appropriately than the classical methods. We used this test on a heterogeneous, skewed biological data set on invertebrate dispersal and showed how different the reactions of the kruskal-wallis test and the permutation approach are. We then evaluated the new testing procedure with reproducible data that were generated from the normal distribution. Here, we tested the influence of four different experimental trials on the new testing procedure in comparison to the kruskal-wallis test. These trials showed the impact of data that were varying in terms of (a) negative correlation between variances and means of the samples, (b) changing variances that were not correlated with the means of the samples, (c) constant variances and means, but different sample sizes and in trials (d) we evaluated the testing power of the new procedure. Due to the different test statistics, the permutation test reacted more sensibly to the data presented in trials (a) and c) and non-uniformly in trial (b). In the evaluation of the testing power, no significant differences between the kruskal-wallis test and the new permutation testing procedure could be detected. We consider this test to be an alternative for working on heterogeneous data where the preconditions of the classical non-parametric tests are not met. © 2006 elsevier masson sas. All rights reserved.","","","2007","10.1016/j.actao.2006.10.002","","","scopus-2-s2.0-33847324446.pdf","scopus-2-s2.0-33847324446"
"Efficient secure data publishing algorithms for supporting information sharing","Yang, X. And Wang, B. And Yu, G.","Science In China, Series F: Information Sciences","","Many data sharing applications require that publishing data should protect sensitive information pertaining to individuals, such as diseases of patients, the credit rating of a customer, and the salary of an employee. Meanwhile, certain information is required to be published. In this paper, we consider data-publishing applications where the publisher specifies both sensitive information and shared information. An adversary can infer the real value of a sensitive entry with a high confidence by using publishing data. The goal is to protect sensitive information in the presence of data inference using derived association rules on publishing data. We formulate the inference attack framework, and develop complexity results. We show that computing a safe partial table is an np-hard problem. We classify the general problem into subcases based on the requirements of publishing information, and propose algorithms for finding a safe partial table to publish. We have conducted an empirical study to evaluate these algorithms on real data. The test results show that the proposed algorithms can produce approximate maximal published data and improve the performance of existing algorithms. © 2009 science in china press and springer-verlag gmbh.","","","2009","10.1007/s11432-009-0023-y","","","scopus-2-s2.0-64249154174.pdf","scopus-2-s2.0-64249154174"
"Proficiency Testing in a Laboratory Accreditation Program for the Bacterial Ring Rot Pathogen of Potato","De Boer S. H., Hall J. W.","Plant Disease","","Variability of enzyme-linked immunosorbent assay (ELISA) and immunofluorescence tests for the detection of Clavibacter michiganensis subsp. sepedonicus in potato tissue was analyzed to determine the magnitude of repeatability (within analyst variation) and reproducibility (among analyst variation) components. The analysis was based on data generated by analysts in eight laboratories testing proficiency panel samples distributed under a laboratory accreditation program. The standard deviation for repeatability of the ELISA test was small but increased at higher absorbance readings while the standard deviation for reproducibility was larger and also increased at high absorbances. For immunofluorescence the standard deviation for repeatability and reproducibility were similar to one another and increased with increasing bacterial concentration as might be expected for count data and the inherent subjectivity of the test. The reproducibility standard deviation provided the basis for calculating ""z-scores"" by the Association of Official Analytical Chemists' procedure to evaluate proficiency of chemical analyses. More than 90 and 80% of the z-scores for samples tested in this study by ELISA and immunofluorescence respectively were in the acceptable range. The rescaled sums of z-scores for individual analysts were used as single combination scores to evaluate each analyst's results over all samples of a proficiency panel. This measure may be useful for tracking analyst performance on process control charts as part of a quality control system.","","","2000","10.1094/pdis.2000.84.6.649","","","medline-30841105.pdf","medline-30841105"
"Global academic response to covid-19: cross-sectional study","Helliwell, J.a. And Bolton, W.s. And Burke, J.r. And Tiernan, J.p. And Jayne, D.g. And Chapman, S.j.","Learned Publishing","","This study explores the response to covid-19 from investigators, editors, and publishers and seeks to define challenges during the early stages of the pandemic. A cross-sectional bibliometric review of covid-19 literature was undertaken between 1 november 2019 and 24 march 2020, along with a comparative review of middle east respiratory syndrome (mers) literature. Investigator responsiveness was assessed by measuring the volume and type of research published. Editorial responsiveness was assessed by measuring the submission-to-acceptance time and availability of original data. Publisher-responsiveness was assessed by measuring the acceptance-to-publication time and the provision of open access. Three hundred and ninety-eight of 2,835 covid-19 and 55 of 1,513 mers search results were eligible. Most covid-19 studies were clinical reports (n = 242;  60.8%). The submission-to-acceptance [median: 5 days (iqr: 3–11) versus 71.5 days (38–106);  p <.001] and acceptance-to-publication [median: 5 days (iqr: 2–8) versus 22.5 days (4–48·5-;  p <.001] times were strikingly shorter for covid-19. Almost all covid-19 (n = 396;  99.5%) and mers (n = 55;  100%) studies were open-access. Data sharing was infrequent, with original data available for 104 (26.1%) covid-19 and 10 (18.2%) mers studies (p =.203). The early academic response was characterized by investigators aiming to define the disease. Studies were made rapidly and openly available. Only one-in-four were published alongside original data, which is a key target for improvement. Key points: covid-19 publications show rapid response from investigators, specifically aiming to define the disease. Median time between submission and acceptance of covid-19 articles is 5 days demonstrating rapid decision-making compared with the median of 71.5 days for mers articles. Median time from acceptance to publication of covid-19 articles is 5 days, confirming the ability to introduce rapid increases at times of crisis, such as during the sars outbreak. The majority of both covid-19 and mers articles are available open-access. © 2020 the author(s). Learned publishing published by john wiley & sons ltd on behalf of alpsp.","","","2020","10.1002/leap.1317","","","scopus-2-s2.0-85087152224.pdf","scopus-2-s2.0-85087152224"
"Disclosure of researcher allegiance in meta-analyses and randomised controlled trials of psychotherapy: a systematic appraisal","Dragioti E., Dimoliatis I., Evangelou E.","BMJ Open","","OBJECTIVE: Psychotherapy research may suffer from factors such as a researcher's own therapy allegiance. The aim of this study was to evaluate if researcher allegiance (RA) was reported in meta-analyses and randomised controlled trials (RCTs) of psychotherapeutic treatments.\\\\\\\\rDESIGN: Systematic approach using meta-analyses of different types of psychotherapies.\\\\\\\\rDATA SOURCES: Medline PsycINFO and Cochrane Database of Systematic Reviews.\\\\\\\\rMETHODS: We evaluated meta-analyses of RCTs regarding various types of psychotherapies. Meta-analyses were eligible if they included at least one RCT with RA and they were published in journals in Medline PsycINFO and Cochrane Database of Systematic Reviews with an impact factor larger than 5.\\\\\\\\rRESULTS: We identified 146 eligible meta-analyses that synthesised data from a total of 1198 unique RCTs. Only 25 of the meta-analyses (17.2%) reported allegiance and only 6 (4.1%) used a proper method to control its effect. Of the 1198 eligible primary RCTs 793 (66.3%) were allegiant. Authors in 25 of these 793 RCTs (3.2%) reported their allegiance while only one study (0.2%) controlled for its effect.\\\\\\\\rCONCLUSIONS: The vast majority among a group of published meta-analyses and RCTs of psychotherapeutic treatments seldom reported and evaluated the allegiance effect. The results of the present study highlight a major lack of this information in meta-analyses and their included studies though meta-analyses perform slightly better than RCTs. Stringent guidelines should be adopted by journals in order to improve reporting and attenuate possible effects of RA in future research. Copyright Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions.","","","2015","10.1136/bmjopen-2014-007206","","","medline-26033943.pdf","medline-26033943"
"Psychometric Properties of Instruments that Measure Vaping Outcome Expectancies: A Systematic Review","Wall N., Fox S., Mirza N., Ralph J.","Nicotine & Tobacco Research","","INTRODUCTION: Vaping is a growing public health concern. Interventions that address vaping must build upon rigorous research that uses psychometrically sound instruments to measure vaping-associated outcome expectancies. The primary aim was to appraise the reporting of psychometric properties of instruments used to measure vaping outcome expectancies. Secondary aims were to distinguish the different types of outcome expectancies assessed across the measures the conceptual underpinnings and the evidence explaining e-cigarette use etiology.\\\\\\\\rMETHODS: This systematic review was guided by an adapted version of the COnsensus-based Standards for the selection of health Measurement INstruments (COSMIN) guideline and Risk of Bias Checklist. Five electronic databases were searched for peer-reviewed studies dissertations and theses that psychometrically evaluated instruments that measure vaping outcome expectancies. Studies that met the inclusion criteria were appraised based on their reporting of nine psychometric properties outlined in the COSMIN checklist.\\\\\\\\rRESULTS: The review included 11 studies that described eight instruments and reported on two to five of nine pre-determined psychometric properties. Structural validity construct validity and internal consistency were the most commonly reported properties. No studies reported test-retest intra-rater or inter-rater reliability measurement error or responsiveness. Content validity and measurement invariance were only reported by two and four studies respectively. The most commonly included subscales in the instruments were affect regulation positive sensory experience and negative health consequences. Many of the outcome expectancy subscales were associated with e-cigarette behaviors.\\\\\\\\rCONCLUSIONS: There is limited reporting of psychometric testing of instruments that measure vaping outcome expectancies; however utilization of the COSMIN guideline could enhance the quality of such reporting.\\\\\\\\rIMPLICATIONS: Appraising the reporting of psychometric properties of instruments that measure vaping outcome expectancies is a first step to ensuring valid and reliable instruments are used to support rigorous research and build evidence-based knowledge. Future research should focus on testing for responsiveness measurement error and reliability and on quality appraisal of the instruments. Studying vaping outcome expectancies may improve understanding of factors that influence and deter vaping. This may contribute to the development of effective interventions aimed at vaping cessation and prevention. Copyright © The Author(s) 2024. Published by Oxford University Press on behalf of the Society for Research on Nicotine and Tobacco. All rights reserved. For permissions please e-mail: journals.permissions@oup.com.","","","2024","10.1093/ntr/ntad261","","","medline-38165692.pdf","medline-38165692"
"Challenges and opportunities for the space radiobiology research in china","Hu, W. And Zhou, G.","Kexue Tongbao/Chinese Science Bulletin","","Advancing the interdisciplinary research of space radiobiology, as well as establishing a space radiation risk assessment system to provide astronauts with health risk prediction, early warning, and protection strategies are several approaches that meet the needs of long-term manned space exploration in china. At the 561st xiangshan science conference, scientists engaged in relevant planning and research in the field of space life sciences in china, together with colleagues from the united states and germany, discussed research opportunities, key research directions, planning and layout in the interdisciplinary space radiobiology research in china. The participants further proposed that a ten-year plan for china's space radiobiology and interdisciplinary research be formulated, as well as providing sustained and stable financial support and establishing scientific systems of management and operation. To maximize the utilization efficiency of research resources, the participants advocated the establishment of the china alliance for space radiobiology and interdisciplinary research with the purpose of integrating resources, strengthening team building, discipline construction and international cooperation, developing popular science education, and training reserve talents. Other proposals include integration of astronauts, aircraft design and basic issues of space radiobiology, strengthening ground-based platform construction, simulation research with an emphasis in both experimental study and theory development, and finally, construction of the data sharing platform. This paper highlights advances in the space radiation field and proposes several major scientific issues faced by long-term manned space exploration. Space radiation-induced carcinogenesis, cardiovascular disease, central nervous system injury, reproductive system and immune-system damage are considered to be the most serious health challenges confronted by astronauts. Besides the traditional space radiation protection strategy, the meeting participants proposed some innovative strategies including choice of appropriate time window for extravehicular activities, development of chinese herbal medicine for radioprotection, selection of astronauts based on individual radiosensitivity. The panel regarded the up-and-coming chinese space station as the most important opportunity for the development of the radiobiology research in china and all over the world. However, some weaknesses in the current status of chinese space radiobiological research have been identified by the panel including insufficient financial support, lack of international cooperation, and poor innovative capacity. Furthermore, the panel summarized the key space radiobiological issues, including: (1) understanding of the mechanisms of the space radiation-induced carcinogenesis and screening of biomarkers for the early diagnosis of related tumors;  (2) optimization of the health risk assessment model for astronauts;  (3) research of individual radiosensitivity to space radiations;  (4) research and development of effective radioprotection measures;  (5) design and development of space radiation shielding materials and devices, and real-time radiation detection system. Finally, the panel provided several recommendations in advancing the chinese space radiobiological research program, including increasing funding support to provide a sustained and stable financial support structure, developing team cooperation to improve the utilization efficiency of space research resources, strengthening ground-based platform construction and simulation research. In conclusion, this paper described both the current challenges and opportunities for space radiobiology research in china. It also provides considerable information for the chinese science and technology program managers. © 2019, science press. All right reserved.","","","2019","10.1360/n972019-00187","","","scopus-2-s2.0-85080103955.pdf","scopus-2-s2.0-85080103955"
"Efficient and hra secure universal conditional proxy re-encryption for cloud-based data sharing","Hu, H. And Zhou, Y. And Cao, Z. And Dong, X.","Applied Sciences (Switzerland)","","Cloud computing has become popular in data sharing mainly because it has huge storage capacity and computing power. Securing the privacy of sensitive data for cloud-based data sharing is vital. Currently, there are various conditional proxy re-encryption (upre) schemes that have been proposed to resolve the privacy issue. Nevertheless, the existing upre schemes cannot allow the proxy (e.g., the cloud server) to transfer the outsourced encrypted data under the data owner’s public key of any homomorphic encryption scheme into the encrypted data under the data user’s public key of a homomorphic encryption scheme (possibly different from the data owner). The transformation of outsourced encrypted data between homomorphic encryption schemes is more suitable for the real data sharing in clouds. Consequently, we present the notion of universal conditional proxy re-encryption (ucpre) to solve the issue of flexible transformation of outsourced encrypted data between homomorphic encryption schemes in cloud-based data sharing. Ucpre is lightweight in the sense that it only requires the re-encrypted key generation and re-encryption algorithms. We give the definition of ucpre and prove that it is hra secure without random oracle. Finally, we show that our ucpre is efficient and rational compared to other existing cpre schemes by instantiating our ucpre. © 2022 by the authors.","","","2022","10.3390/app12199586","","","scopus-2-s2.0-85139960887.pdf","scopus-2-s2.0-85139960887"
"Separating fact from fiction in software architecture","Medvidovic, Nenad And Taylor, Richard N.","Proceedings Of The 1998 3rd International Software Architecture Workshop, Isaw-3","","Explicit focus on architecture has shown tremendous potential to improve the current state-of-the-art in software development. Relatively quickly, software architecture research has produced credible results. However, some of this initial success has also resulted in unrealistic expectations and failure to recognize the limits of this line of research, which can result in backlash when the unrealistic expectations are not met. One solution is to attempt to clearly delineate the boundaries of applicability and effectiveness of software architectures. This paper represents a step in that direction: it dispels some common misconceptions about architectures and discusses problem areas for which architecture is well suited and those for which it is not.","","","1998","10.1145/288408.288435","","","scopus-2-s2.0-0031607109.pdf","scopus-2-s2.0-0031607109"
"Multi-task learning for analyzing and sorting large databases of sequential data","Ni, K. And Paisley, J. And Carin, L. And Dunson, D.","Ieee Transactions On Signal Processing","","A new hierarchical nonparametric bayesian framework is proposed for the problem of multi-task learning (mtl) with sequential data. The models for multiple tasks, each characterized by sequential data, are learned jointly, and the intertask relationships are obtained simultaneously. This mtl setting is used to analyze and sort large databases composed of sequential data, such as music clips. Within each data set, we represent the sequential data with an infinite hidden markov model (ihmm), avoiding the problem of model selection (selecting a number of states). Across the data sets, the multiple ihmms are learned jointly in a mtl setting, employing a nested dirichlet process (ndp). The ndp-ihmm mtl method allows simultaneous task-level and data-level clustering, with which the individual ihmms are enhanced and the between-task similarities are learned. Therefore, in addition to improved learning of each of the models via appropriate data sharing, the learned sharing mechanisms are used to infer interdata relationships of interest for data search. Specifically, the mtl-learned task-level sharing mechanisms are used to define the affinity matrix in a graph-diffusion sorting framework. To speed up the mcmc inference for large databases, the ndp-ihmm is truncated to yield a nested dirichlet-distribution based hmm representation, which accommodates fast variational bayesian (vb) analysis for large-scale inference, and the effectiveness of the framework is demonstrated using a database composed of 2500 digital music pieces. © 2008 ieee.","","","2008","10.1109/tsp.2008.924798","","","scopus-2-s2.0-48849102964.pdf","scopus-2-s2.0-48849102964"
"Multiple security anti-counterfeit applications to qr code payment based on visual secret sharing and qr code","Wan, S. And Yang, G. And Qi, L. And Li, L. And Yan, X. And Lu, Y.","Mathematical Biosciences And Engineering","","In this paper, we propose a novel mechanism for qr code security anti-counterfeit based on the fusion of visual secret sharing (vss) and qr code (called vssqr scheme), which can greatly improve the security of qr code payment. Due to different application scenarios, the background security anti-counterfeit application and the prospects security anti-counterfeit application are shown for qr code payment authentication. The basic idea of the two applications can be characterized as follows. First, two qr code shares that contain the information of the merchant can be generated based on vssqr scheme with an original secret image. Second, the secret image can be revealed by stacking two qr code shares to obtain the original information. Finally, whether the stacking result is the same as the original secret image or not can determine the authenticity of qr code share used for payment. The analyses show the security of our method. The applications are conducted to show the effectiveness and practicability. © 2019 the author(s), licensee aims press. This is an open access article distributed under the terms of the creative commons attribution license (http://creativecommons.org/licenses/by/4.0)","","","2019","10.3934/mbe.2019318","","","scopus-2-s2.0-85069597412.pdf","scopus-2-s2.0-85069597412"
"Availability of Clinical Trial Data From Industry-Sponsored Cardiovascular Trials","Murugiah K., Ritchie J. D., Desai N. R., Ross J. S., Krumholz H. M.","Journal of the American Heart Association","","BACKGROUND: Industry-sponsored clinical trials produce high-quality data sets that can be used by researchers to generate new knowledge. We assessed the availability of individual participant-level data (IPD) from large cardiovascular trials conducted by major pharmaceutical companies and compiled a list of available trials.\\\\\\\\rMETHODS AND RESULTS: We identified all randomized cardiovascular interventional trials registered on ClinicalTrials.gov with >5000 enrollment sponsored by 1 of the top 20 pharmaceutical companies by 2014 global sales. Availability of IPD for each trial was ascertained by searching each company's website/data-sharing portal. If availability could not be determined each company was contacted electronically. Of 60 included trials IPD are available for 15 trials (25%) consisting of 204 452 patients. IPD are unavailable for 15 trials (25%). Reasons for unavailability were: cosponsor did not agree to make IPD available (4 trials) and trials were not conducted within a specific time (5 trials); for the remaining 6 trials no specific reason was provided. For 30 trials (50%) availability of IPD could not be definitively determined either because of no response or requirements for a full proposal (23 trials).\\\\\\\\rCONCLUSIONS: IPD from 1 in 4 large cardiovascular trials conducted by major pharmaceutical companies are confirmed available to researchers for secondary research a valuable opportunity to enhance science. However IPD from 1 in 4 trials are not available and data availability could not be definitively determined for half of our sample. For several of these trials companies require a full proposal to determine availability making use of the IPD by researchers less certain. Copyright © 2016 The Authors. Published on behalf of the American Heart Association Inc. by Wiley Blackwell.","","","2016","10.1161/jaha.116.003307","","","medline-27098969.pdf","medline-27098969"
"Hardness and fracture toughness of semiconducting materials studied by indentation and erosion techniques","Ericson, F. And Johansson, S. And Schweitz, J.a.","","","In recent years, the growing field of semiconductor micromechanics has created an increasing demand for strength data on semiconductors and for adequate tests and evaluations of their mechanical properties. Previously the authors demonstrated that the solid particle erosion rate can be taken as a simple and highly reproducible statistical measure of the susceptibility of si and gaas to contact damage in the micron range. In the present work the scope is broadened to include several new crystal orientations (and one new doping level), as well as three new materials: ge, inp and inas, for which hardness and fracture toughness (kic) values are determined.","","","1987","","","","scopus-2-s2.0-85040895580.pdf","scopus-2-s2.0-85040895580"
"Randomized Clinical Trials of Machine Learning Interventions in Health Care: A Systematic Review","Plana D., Shung D. L., Grimshaw A. A., Saraf A., Sung J. J. Y., Kann B. H.","JAMA Network Open","","Importance: Despite the potential of machine learning to improve multiple aspects of patient care barriers to clinical adoption remain. Randomized clinical trials (RCTs) are often a prerequisite to large-scale clinical adoption of an intervention and important questions remain regarding how machine learning interventions are being incorporated into clinical trials in health care.\\\\\\\\rObjective: To systematically examine the design reporting standards risk of bias and inclusivity of RCTs for medical machine learning interventions.\\\\\\\\rEvidence Review: In this systematic review the Cochrane Library Google Scholar Ovid Embase Ovid MEDLINE PubMed Scopus and Web of Science Core Collection online databases were searched and citation chasing was done to find relevant articles published from the inception of each database to October 15 2021. Search terms for machine learning clinical decision-making and RCTs were used. Exclusion criteria included implementation of a non-RCT design absence of original data and evaluation of nonclinical interventions. Data were extracted from published articles. Trial characteristics including primary intervention demographics adherence to the CONSORT-AI reporting guideline and Cochrane risk of bias were analyzed.\\\\\\\\rFindings: Literature search yielded 19737 articles of which 41 RCTs involved a median of 294 participants (range 17-2488 participants). A total of 16 RCTS (39%) were published in 2021 21 (51%) were conducted at single sites and 15 (37%) involved endoscopy. No trials adhered to all CONSORT-AI standards. Common reasons for nonadherence were not assessing poor-quality or unavailable input data (38 trials [93%]) not analyzing performance errors (38 [93%]) and not including a statement regarding code or algorithm availability (37 [90%]). Overall risk of bias was high in 7 trials (17%). Of 11 trials (27%) that reported race and ethnicity data the median proportion of participants from underrepresented minority groups was 21% (range 0%-51%).\\\\\\\\rConclusions and Relevance: This systematic review found that despite the large number of medical machine learning-based algorithms in development few RCTs for these technologies have been conducted. Among published RCTs there was high variability in adherence to reporting standards and risk of bias and a lack of participants from underrepresented minority groups. These findings merit attention and should be considered in future RCT design and reporting.","","","2022","10.1001/jamanetworkopen.2022.33946","","","medline-36173632.pdf","medline-36173632"
"Microgrid data security sharing method based on blockchain under internet of things architecture","Shang, J. And Guan, R. And Tong, Y.","Wireless Communications And Mobile Computing","","The efficient and secure data sharing mechanism can support the microgrid to achieve more accurate business control, while the current data processing methods have the problems of large computing overhead and low data sharing security. Aiming at the current problems, this paper proposes a microgrid data sharing method based on blockchain technology based on the processing mode of cloud-edge-terminal architecture. Firstly, the elliptic curve encryption algorithm is used on the edge side to encrypt the data collected by the terminal equipment reliably, so as to improve the security and efficiency of microgrid key management. Then, in the cloud, the reputation-evaluation practical byzantine fault tolerant mechanism (repbft) based on smart contract and reputation evaluation can effectively manage the data sharing of edge computing devices, avoid the waste of network computing resources, and further improve the efficiency of microgrid data sharing. The simulation results show that when the number of edge devices reaches 25, the calculation and communication overhead of the proposed method are 63.46 ms and 2.66 kb, respectively, and when the processing data reaches 1024 kb, the security of the microgrid system is still 95%, which can realize safe and reliable data sharing and interaction, and can stably support the optimal operation of the microgrid. © 2022 jian shang et al.","","","2022","10.1155/2022/9623934","","","scopus-2-s2.0-85128599463.pdf","scopus-2-s2.0-85128599463"
"Creating context for the experiment record. User-defined metadata: investigations into metadata usage in the LabTrove ELN","Willoughby C., Bird C. L., Coles S. J., Frey J. G.","Journal of Chemical Information & Modeling","","The drive toward more transparency in research the growing willingness to make data openly available and the reuse of data to maximize the return on research investment all increase the importance of being able to find information and make links to the underlying data. The use of metadata in Electronic Laboratory Notebooks (ELNs) to curate experiment data is an essential ingredient for facilitating discovery. The University of Southampton has developed a Web browser-based ELN that enables users to add their own metadata to notebook entries. A survey of these notebooks was completed to assess user behavior and patterns of metadata usage within ELNs while user perceptions and expectations were gathered through interviews and user-testing activities within the community. The findings indicate that while some groups are comfortable with metadata and are able to design a metadata structure that works effectively many users are making little attempts to use it thereby endangering their ability to recover data in the future. A survey of patterns of metadata use in these notebooks together with feedback from the user community indicated that while a few groups are comfortable with metadata and are able to design a metadata structure that works effectively many users adopt a ""minimum required"" approach to metadata. To investigate whether the patterns of metadata use in LabTrove were unusual a series of surveys were undertaken to investigate metadata usage in a variety of platforms supporting user-defined metadata. These surveys also provided the opportunity to investigate whether interface designs in these other environments might inform strategies for encouraging metadata creation and more effective use of metadata in LabTrove.","","","2014","10.1021/ci500469f","","","medline-25405258.pdf","medline-25405258"
"Web-based data model conversion for power system","Cheng, P. And Wang, J.-Y. And Huang, W.-Z. And Lin, L.-Y.","Dianli Zidonghua Shebei / Electric Power Automation Equipment","","To improve the application effectiveness of power system planning simulation software packages from different vendors and realize power grid model data sharing in electric power enterprises, an approach, webcps (web-based data model conversion for power system), is designed to convert the data model among different systems. Its technical approach is discussed. It has three tiers: client, web server and database server. The database is constructed on yh-dm data model and the software is implemented with component technology. The constitution of ui (user interface) and data conversion components is analyzed. When the data file of cim model is uploaded, the ntp (network topology process) component is called to analyze the model, the topology islands are created and the result is mapped into the corresponding computing model. System performance, response time and maximum file size are discussed. The system performance could be improved through data model tuning and merging functions.","","","2006","","","","scopus-2-s2.0-33751099328.pdf","scopus-2-s2.0-33751099328"
"National surveys must be allowed to compete. Open market for value-added products and services","Groot, R.","Geomatics Info Magazine","","Many enterprises are recognising the efficiencies to be gained in reducing time searching for data and information and are facilitating access to, and use of, company information by means of enterprise wide (geospatial) data infrastructures. Immediate benefits would thus seem possible if governments would also increase the efficiency and effectiveness of their own information and data use. This might be realised by sharing data and information through appropriate domain and enterprise geospatial data infrastructures (gdi), all part of the national geospatial data infrastructure (ngdi), between government ministries and departments/agencies.","","","2001","","","","scopus-2-s2.0-0034989082.pdf","scopus-2-s2.0-0034989082"
"Reporting Research","Simera I., Altman D. G.","","","This chapter provides a brief overview of general principles of reporting medical research studies with a particular focus on the following study designs: randomised controlled trials analytical observational studies and systematic reviews and meta-analyses. Health-related research can be divided into two broad groups: experimental and observational. A typical example of experimental research design is a randomised controlled trial (RCT). Reporting guidelines provide structured advice on the minimum information to be included in an article reporting a particular type of medical research. There are three main types of observational design: cohort studies case-control studies and cross-sectional surveys. A minimum set of recommendations for reporting these studies is specified in the STROBE Statement. Similar to the CONSORT Statement. The Enhancing the Quality and Transparency of Health Research (EQUATOR) Network is an international initiative that aims to improve the reliability and value of the medical research literature by promoting transparent and accurate reporting of research studies. © 2016 John Wiley & Sons Ltd. All rights reserved.","","","2012","10.1002/9781118763025.ch39","","","scopus-2-s2.0-85028842848.pdf","scopus-2-s2.0-85028842848"
"Local cinema history at scale: data and methods for comparative exhibition studies","Aronson, M. And Hayden, G. And Peterson, E.","Iluminace","","Digital tools and digitized sources have expanded our ability to research and present regional film histories, along with the hope of conducting comparative work across both place and time. Along-side these projects are increasing calls for more deliberate coordination of tools, methods, and sources to create more meaningful comparisons. However, it remains difficult for researchers to know what digital projects exist for comparative work, and the methods, points of comparison, data structure, and sources used all considerably vary. Utilizing research data management principles, we conducted an exploratory survey of local film exhibition digital projects to document the current historiographic landscape, and to assess existing coverage of geography, time, sources, data struc-tures, metadata schema, data accessibility and reproducibility. The dataset from the survey results can be shared by researchers to better discover each other’s work, but also to serve as a guide to best practices going forward. © 2022, national film archive. All rights reserved.","","","2022","","","","scopus-2-s2.0-85142611760.pdf","scopus-2-s2.0-85142611760"
"Insertion torque recordings for the diagnosis of contact between orthodontic mini-implants and dental roots: protocol for a systematic review","Meursinge Reynders R., Ladu L., Ronchi L., Di Girolamo N., de Lange J., Roberts N., Pluddemann A.","Systematic Reviews","","BACKGROUND: Hitting a dental root during the insertion of orthodontic mini-implants (OMIs) is a common adverse effect of this intervention. This condition can permanently damage these structures and can cause implant instability. Increased torque levels (index test) recorded during the insertion of OMIs may provide a more accurate and immediate diagnosis of implant-root contact (target condition) than radiographic imaging (reference standard). An accurate index test could reduce or eliminate X-ray exposure. These issues the common use of OMIs the high prevalence of the target condition and because most OMIs are placed between roots warrant a systematic review. We will assess 1) the diagnostic accuracy and the adverse effects of the index test 2) whether OMIs with root contact have higher insertion torque values than those without and 3) whether intermediate torque values have clinical diagnostic utility.\\\\\\\\rMETHODS: The Preferred Reporting Items for Systematic review and Meta-Analysis Protocols (PRISMA-P) 2015 statement was used as a the guideline for reporting this protocol. Inserting implants deliberately into dental roots of human participants would not be approved by ethical review boards and adverse effects of interventions are generally underreported. We will therefore apply broad spectrum eligibility criteria which will include clinical animal and cadaver models. Not including these models could slow down knowledge translation. Both randomized and non-randomized research studies will be included. Comparisons of interest and subgroups are pre-specified. We will conduct searches in MEDLINE and more than 40 other electronic databases. We will search the grey literature and reference lists and hand-search ten journals. All methodological procedures will be conducted by three reviewers. Study selection data extraction and analyses and protocols for contacting authors and resolving conflicts between reviewers are described. Designed specific risk of bias tools will be tailored to the research question. Different research models will be analysed separately. Parameters for exploring statistical heterogeneity and conducting meta-analyses are pre-specified. The quality of evidence for outcomes will be assessed through the Grading of Recommendations Assessment Development and Evaluation (GRADE) approach.\\\\\\\\rDISCUSSION: The findings of this systematic review will be useful for patients clinicians researchers guideline developers policymakers and surgical companies.","","","2015","10.1186/s13643-015-0014-6","","","medline-25875916.pdf","medline-25875916"
"A criminological study of women in the south african police service","Morrison, Cherita Jeanne","Dissertation Abstracts International Section A: Humanities And Social Sciences","","In order to gain a better understanding of the position of women in the field of policing, it was necessary to study the attitudes of the policewomen, which presently exist with regard to the role of the woman in the south african police service. Although some studies have been done on policewomen world-wide, none have been done in the rural areas of the vaalrand and this is where the research took place. Only women formed part of this survey. Detailed questions were asked concerning their role in policing. This was an empirical qualitative study. The research procedures as stipulated for a descriptive study were followed, as the main objective of the research was to describe the circumstances of women in the predominantly male environment of policing. A survey interview was drawn up, containing semi-structured in-depth questions regarding their recruitment, motivation for joining and job-related satisfaction and other issues including discrimination and domination by men. Qualitative methods were applied not only for data collection but also for data analysis. The coding consisted of conceptualising the raw data. Open coding was used in this qualitative research. The researcher read through all the collected data and then assigned initial codes to condense the mass of data collected. The following main issues were found: that discrimination still exists in the saps, as well as resentment, a lack of recognition, misunderstanding and unfulfilled challenges which relate to conflict being experienced. These respondents have aspirations in their work and aspire to better positions in the saps, as there have been major contributions by women in the police. They have also had an impact on policing, as they have become major role players in the field where victims are concerned. The presence of policewomen in the saps is an important asset to modern law enforcement and their present day role in policing should be explored and expanded. Qualified women could also be utilised in important staff service units such as planning and research, training, intelligence, inspection, public information, community relations, and as legal advisors instead of being utilised only in administrative work. Recommendations are made for further research on aspects highlighted by the findings. (Psycinfo database record (c) 2021 apa, all rights reserved)","","","2007","","","","psychinfo-2007-99211-283.pdf","psychinfo-2007-99211-283"
"A lamus-based flight data sharing model on consortium blockchain","Li, F. And Cui, Y. And Huang, B. And Yu, S. And Liu, P. And Wang, Y. And Li, T.","Security And Communication Networks","","Currently, traditional flight data sharing models cannot resist quantum attacks, which poses the risk of data leakage. The research on the flight data sharing model against quantum attack has become one of the research hotspots. Lattice-based cryptography is recognized as an effective way to resist quantum attacks. A flight data sharing model on consortium blockchain is proposed in this paper to resolve data leakage during data sharing. First, a new lattice-based multisignature scheme (lamus) is proposed, capable of resisting quantum attacks. We prove the security of the proposed lamus scheme in the random oracle model. Moreover, a flight data sharing model on consortium blockchain is proposed by applying the proposed lamus scheme to resist quantum attacks. Security and performance analysis show that the model guarantees antiquantum security, and it achieves good performance in terms of storage efficiency and operating efficiency. © 2022 fengyin li et al.","","","2022","10.1155/2022/5717185","","","scopus-2-s2.0-85130882254.pdf","scopus-2-s2.0-85130882254"
"Whole blood titanium metal ion measurement reproducibility of two laboratories","Barry, J. And Eichler, D. And Robitaille, R. And Vendittoli, P.-A.","Practical Laboratory Medicine","","Background: metal ion blood concentrations evaluation can be useful in monitoring wear and corrosion of orthopedic implants. Elevated metal ion level may help detecting defective hip arthroplasty implants and serve as an indicator for revision surgery. Our objective was to evaluate the reproducibility of titanium metal ion level measurements by two different laboratories. Methods: seventy-one whole blood samples were collected from 64 patients with unilateral ceramic-on-ceramic hip arthroplasty. For each patient, two whole blood samples were collected and analyzed in two different laboratories. Results: for each case, laboratory 1 had significantly higher values than laboratory 2. There was a clinically significant absolute difference between the two laboratories, above the predetermined threshold, for 90% of samples. A mean variation ratio of 410% between the two laboratories was found. Conclusion: not all laboratories use the same techniques and calibrations to perform these measurements. Therefore, their results should be interpreted with caution and clinical decision should rely on metal ion trends provided by the same laboratory. © 2020 the authors","","","2020","10.1016/j.plabm.2020.e00167","","","scopus-2-s2.0-85084489772.pdf","scopus-2-s2.0-85084489772"
"Corporate governance disclosures in the annual reports of nigerian banks","Olowosegun, O. And Moloi, T.","Acta Commercii","","Orientation: several breaches continue to occur in nigeria’s banking sector even with the litany of regulation put in place. These regulations require that banks disclose certain types of information, for accountability and transparency. Research purpose: to determine the extent of corporate governance disclosures in annual reports of nigerian banks taking into cognisance the provisions of laws and codes applicable to nigerian banks as well as acclaimed national codes and international guiding principles on corporate governance. Motivation for the study: disclosures of corporate governance practices in the annual reports are a subtle indication of the level of compliance with provisions of relevant laws and codes. Research design, approach, and method: the study employed the qualitative content analysis that included a checklist based on the provisions of the central bank of nigeria (cbn) code and acclaimed national codes and guiding principles to test the level of compliance disclosed by commercial banks in their annual reports. Main findings: the results show substantial corporate governance disclosures by all the banks except for two corporate governance pillar scores rights and functions of shareholders and engagement with shareholders’ associations that received little or no attention in the annual reports of the assessed banks. Practical/managerial implications: disclosures do not necessarily imply that preparers comply with the spirit of corporate governance. A governance code that is based on ethics as a foundation should be considered rather than the current comply or else regime. Contribution/value-add: the article identifies the gap that the comply or else regimes do not necessarily succeed as preparers of report tend to tick the box to comply with the regulation rather than buying into the spirit of that regulation. © 2021. The authors.","","","2021","10.4102/ac.v21i1.857","","","scopus-2-s2.0-85121120505.pdf","scopus-2-s2.0-85121120505"
"Variational bayes for the estimation of conditional bivariate copulas","Qing, X.","Journal Of Computational Information Systems","","A probabilistic graphical model of conditional bivariate copulas is presented in this paper. Variational inference is employed to estimate the parameters of the proposed model. A detailed calculation process is provided for the reproducible research. Experimental results on a simulated data set illustrate the effectiveness of the methodology. Copyright © 2014 binary information press.","","","2014","10.12733/jcis8888","","","scopus-2-s2.0-84892884650.pdf","scopus-2-s2.0-84892884650"
"Improving privacy-preserving healthcare data sharing in a cloud environment using hybrid encryption","Boumezbeur, I. And Zarour, K.","Acta Informatica Pragensia","","In recent years, cloud computing has been widely used in various fields and is gaining importance in healthcare systems. Patients’ health data are outsourced to cloud storage, enabling healthcare professionals to easily access health information from anywhere and at any time to improve health services. Once patient data are stored in the cloud, they are vulnerable to attacks such as data loss, denial of service (dos), distributed denial of service (ddos) and other sorts of cyberattacks. Data confidentiality and patient privacy are more of a problem in the cloud computing context due to their public availability. If a patient's personal information is stolen, he or she may face a range of problems. These are concerns that necessitate more security. The transmission of this sensitive information over the internet is always susceptible to hacking. Therefore, the privacy of patients’ data is considered one of healthcare organizations’ main issues. To overcome this problem, encryption mechanisms that place a significant emphasis on securing data within the cloud environment are used to preserve sensitive health data. A hybrid cryptography approach is employed in this paper to ensure the secure sharing of health data over the cloud. To maintain data privacy and secrecy, a hybrid cryptography mechanism for storing and transporting data to and from the cloud is used. To protect data from malevolent insiders, the encryption key is separated into two halves, controlling access to patient records via a specific technique. This paper shows the implementation and performance evaluation of the proposal as a functional system prototype. The evaluation is based on the key generation time, the record encryption time, the record decryption time, the record upload time and the record download time for different user numbers and different file sizes varying from 0.1 mb to 500 mb. The findings show that the proposal performs better than other state-of-the-art systems and can practically share secure health data in cloud environments. © 2022 by the author(s).","","","2022","10.18267/j.aip.182","","","scopus-2-s2.0-85145354772.pdf","scopus-2-s2.0-85145354772"
"How usability of policy transparency promotes citizen compliance: evidence from a survey experiment","Liu, B. And He, S. And Lin, S. And Zhang, J. And Xue, B.","Journal Of Chinese Governance","","Although policy transparency is praised highly to promote citizen compliance, it sometimes loses its effect in practice due to the lack of scientific design. To better exploit policy transparency, this study examined how the usability of policy transparency promotes citizen compliance, and the role of perceived benefit and descriptive social norms in this mechanism. The results of an online survey experiment conducted in the urban renewal policy domain revealed that, in the implementation of the house expropriation policy, easy-to-understand policy transparency encourages citizen compliance better, since it promotes more perceived benefits. Furthermore, descriptive social norms were found to influence the way perceived benefits promote citizen compliance;  more in detail, negative norms were found to increase, and positive norms to decrease, the role of perceived benefit, eventually influencing the effectiveness of policy transparency. This research is a breakthrough for the effectiveness of policy transparency, emphasizing the role of perceived benefit and descriptive social norms in policy compliance. © 2023 zhejiang university.","","","2023","10.1080/23812346.2023.2166568","","","scopus-2-s2.0-85146988033.pdf","scopus-2-s2.0-85146988033"
"Enhancing stock market prediction with extended coupled hidden markov model over multi-sourced data","Zhang, X. And Li, Y. And Wang, S. And Fang, B. And Yu, P.s.","Knowledge And Information Systems","","Traditional stock market prediction methods commonly only utilize the historical trading data, ignoring the fact that stock market fluctuations can be impacted by various other information sources such as stock-related events. Although some recent works propose event-driven prediction approaches by considering the event data, how to leverage the joint impacts of multiple data sources still remains an open research problem. In this work, we study how to explore multiple data sources to improve the performance of the stock prediction. We introduce an extended coupled hidden markov model incorporating the news events with the historical trading data. To address the data sparsity issue of news events for each single stock, we further study the fluctuation correlations between the stocks and incorporate the correlations into the model to facilitate the prediction task. Evaluations on china a-share market data in 2016 show the superior performance of our model against previous methods. © 2018, springer-verlag london ltd., part of springer nature.","","","2019","10.1007/s10115-018-1315-6","","","scopus-2-s2.0-85058681044.pdf","scopus-2-s2.0-85058681044"
"Policy-based broadcast access authorization for flexible data sharing in clouds","Deng, H. And Zhang, J. And Qin, Z. And Wu, Q. And Yin, H. And Castiglione, A.","Ieee Transactions On Dependable And Secure Computing","","Cloud storage services allow data owners to outsource their potentially sensitive data (e.g., private genome data) to remote cloud servers in a ciphertext form. To enable data owners to further share the data encrypted in ciphertexts, many proxy re-encryption (pre) schemes are proposed. However, most schemes only support single-recipient or coarse-grained re-encryption, which may limit the flexibility for data sharing. To address this issue, we propose a policy-based broadcast access authorization (pbaa) scheme by introducing the well-established identity-based broadcast encryption (ibbe) and key-policy attribute-based encryption into pre. In our pbaa scheme, a data owner can apply ibbe to encrypt his data to a group of recipients. More importantly, the data owner can generate a delegation key with an access policy, and send this key to the cloud such that it can convert any initial ciphertext satisfying the access policy into a new ciphertext for a new group of recipients. With these features, cloud users can share their remote data in a secure and flexible way. Security analysis and performance evaluation show that the pbaa scheme is secure and efficient, respectively. © 2004-2012 ieee.","","","2022","10.1109/tdsc.2021.3080282","","","scopus-2-s2.0-85105884493.pdf","scopus-2-s2.0-85105884493"
"Performance evaluation and enhancement of process-based parallel loop execution","Lu, X. And Chen, L. And Li, Z.","International Journal Of Parallel Programming","","Parallel programming is known to be difficult and error-prone. Thread-based parallel execution has particular difficulties due to the tendency for the program to contain errors such as incorrect operation ordering, atomicity violation, and others. Worse yet, as many of such erroneous behaviors tend to be non-deterministic, the programmer is often unable to reproduce the exact event sequence that causes the program failure, which makes diagnosis difficult. In contrast, with process-based parallel execution, unintended data sharing can be avoided, thanks to the isolated address spaces among processes, which greatly simplifies the run-time program states, making it easier to reproduce and diagnose an error. Nonetheless, parallel loop execution on multicore has been dominated by parallel threads and thread-based language extensions and tools. This seems to be due to a long-held common wisdom that process-based parallel execution incurs much higher overhead. This paper reports experimental results that show the competitiveness of process-based parallel loop execution. Several benchmark programs of process-based parallel execution achieved speedups ranging from 6.73 to 20.24 on a 32 cores machine. © 2015, springer science+business media new york.","","","2017","10.1007/s10766-015-0394-1","","","scopus-2-s2.0-84944706473.pdf","scopus-2-s2.0-84944706473"
"The use of x-ray computed tomography for paper analysis: proposed solution for automated segmentation","","Professional Papermaking","","Today, the use of x-ray computed tomography (ct) is gaining a broader acceptance in paper analysis. Compared to large-scale synchrotron facilities modern laboratory computed tomography can provide the necessary image quality, which is suitable for further data analysis. Nevertheless, to date, the analysis of fibrous materials and in particular, natural fibers remains a major challenge. The approach presented in this article uses new workflow modules, by creating a cylinder correlation field of paper pattern capable of segmenting this automatically and reliably. The subsequent analysis and evaluation of four sub-volumes of a paper sample exhibits a good reproducibility of the data obtained. Thus, it is possible, among other things, for example, to determine the fiber-fiber intersections, the specific fiber surface or the number of intersections. The workflow works very well for unrefined fibers but reaches its limit in the analysis of intensively refined fiber patterns.","","","2015","","","","scopus-2-s2.0-84954539637.pdf","scopus-2-s2.0-84954539637"
"Learning ahead of time: how evaluation of foresight may add to increased trust, organizational learning and future oriented policy and strategy","Van Der Steen, M. And Van Der Duin, P.","Futures","","Evaluation of futures research (foresight) consists of three elements: . quality, . success, and . impact of a study. Futures research ought to be methodologically and professionally sound, should to a certain extent be accurate, and should have a degree of impact on strategic decision making and policy-making. However, in the case of futures studies, the one does not automatically lead to the other. Quality of method does not ensure success, just as quality and success do not guarantee impact. This article explores the new paths for understanding evaluating of futures studies that are provided by the various articles in this special issue and sets out an agenda for next steps with regard to evaluation of futures research. The more structural and systematic evaluation can result in an increased level of trust in futures research, which may in turn lead to more future oriented strategy, policy and decision making. Therefore, evaluation should be seen as more than a burden of accountability - albeit important as accountability is - but as an investment in the credibility and impact of the profession. It may set in motion a cycle of mutual learning that will not only improve the capacity of futures-researchers but will also enhance the capacity and likeliness of decision-makers to apply insight from futures research. © 2012 elsevier ltd.","","","2012","10.1016/j.futures.2012.03.010","","","scopus-2-s2.0-84860592580.pdf","scopus-2-s2.0-84860592580"
"Adopting a photo-sharing site as a library tool: a web-based survey","De Sarkar, T.","Information And Learning Science","","Purpose: the article demonstrates how libraries are incorporating photo-sharing applications into the collection development and service provision to encourage improved user participation around digital inclusion. Investigating the steps to increase accessibility to photo-sharing sites and current photo-sharing practices, the paper seeks to highlight the extent of implementation across the world. Design/methodology/approach: stratified sampling method was employed to select libraries from four continents. Content analysis was used to collect data from 160 libraries along the lines of evaluation models prepared for the purpose. Findings: with the comparative account of implementation of photo-sharing apps, the study showcases the relevance of different approaches adopted by libraries and also presents an overview of the implementation with supportive examples. Research limitations/implications: the present investigation is limited to selected libraries of four continents and restricted to english websites only. The study may further be extended to include other types of libraries in different areas, including libraries using non-english websites, to get a fuller picture of implementation. Originality/value: the paper makes an attempt to improve the understanding of the budding library professionals towards the usage pattern of photo-sharing sites. The guidelines, based on a brief synthesis of the functions/ purposes of photo-sharing sites, will make a stronger case for the implications of this research to future photo-sharing practices. © 2017, © emerald publishing limited.","","","2017","10.1108/ils-12-2016-0085","","","scopus-2-s2.0-85018905288.pdf","scopus-2-s2.0-85018905288"
"Citation and co-citation analysis to identify core and emerging knowledge in electronic commerce research","Shiau, W.-L. And Dwivedi, Y.k.","Scientometrics","","The purpose of this paper is to explore the core and emerging knowledge of electronic commerce (e-commerce) research. Data was collected from the top six e-commerce journals from 2006-2010. A total of 1,064 electronic commerce related articles and 33,173 references were identified. There were 48 high value research articles identified using a citation and co-citation analysis. Using statistical analysis including factor analysis, multidimensional scaling, and cluster analysis, we identified five research areas: trust, technology acceptance and technology application, e-commerce task-related application, e-markets, and identity and evaluation. We also identified emerging core knowledge, information systems success. The findings of this study provide core knowledge and directions for researchers and practitioners interested in the electronic commerce field. © 2012 akadémiai kiadó, budapest, hungary.","","","2013","10.1007/s11192-012-0807-5","","","scopus-2-s2.0-84873749454.pdf","scopus-2-s2.0-84873749454"
"Cluster failure revisited: impact of first level design and physiological noise on cluster false positive rates","Eklund, A. And Knutsson, H. And Nichols, T.e.","Human Brain Mapping","","Methodological research rarely generates a broad interest, yet our work on the validity of cluster inference methods for functional magnetic resonance imaging (fmri) created intense discussion on both the minutia of our approach and its implications for the discipline. In the present work, we take on various critiques of our work and further explore the limitations of our original work. We address issues about the particular event-related designs we used, considering multiple event types and randomization of events between subjects. We consider the lack of validity found with one-sample permutation (sign flipping) tests, investigating a number of approaches to improve the false positive control of this widely used procedure. We found that the combination of a two-sided test and cleaning the data using ica fix resulted in nominal false positive rates for all data sets, meaning that data cleaning is not only important for resting state fmri, but also for task fmri. Finally, we discuss the implications of our work on the fmri literature as a whole, estimating that at least 10% of the fmri studies have used the most problematic cluster inference method (p =.01 cluster defining threshold), and how individual studies can be interpreted in light of our findings. These additional results underscore our original conclusions, on the importance of data sharing and thorough evaluation of statistical methods on realistic null data. © 2018 the authors. Human brain mapping published by wiley periodicals, inc.","","","2019","10.1002/hbm.24350","","","scopus-2-s2.0-85054926704.pdf","scopus-2-s2.0-85054926704"
"An opportunity evaluation framework for introductory courses in entrepreneurship","Winsor, B. And Hanlon, D.","Journal Of Entrepreneurship Education","","We present a robust framework for opportunity evaluation especially suitable for introductory entrepreneurship courses where an important learning goal is the ability to evaluate business opportunities. The framework is divided into three main elements: opportunity, resource requirements, and entrepreneur(s). We have used it to guide first-year business students through the business opportunity review process during our introductory entrepreneurship course in a systematic and thorough manner. It is particularly useful when making sense of typically complex entrepreneurial situations. The framework should interest entrepreneurship educators and practitioners engaged in the design and delivery of entrepreneurship curriculum. It specifically addresses two key learning goals recommended for future entrepreneurs: it assists them acquire an understanding for action based on the main entrepreneurial behaviors and ensures they are able to apply entrepreneurial heuristics valuable in start-up and other contexts. The framework underpins a significant portion of a required introduction to entrepreneurship course at our university and has been successfully employed in nearly 150 iterations of the course over the past number of years. It was recently adopted by a canadian provincial department of education for use at the secondary school level. The experience of both students and instructors has tended to be highly positive. Business educators outside the entrepreneurship domain who often deal with small firm contexts (e.g. marketing, retail management) have also expressed interest in the framework. The paper is primarily qualitative in nature, relying on description, critical discussion and logical development of our story. It addresses the concern over the lack of paradigms available to guide curriculum development through the sharing of practice and by stimulating critique and discussion to improve the tools and models available to entrepreneurship educators. At another level we contribute to the wider debate in entrepreneurship education (ee) on what is appropriate entrepreneurship curriculum. We begin by examining the relevant literature and then proceed to describe the history, development, and framework’s use at our university, which leads to reflections on its implementation and effectiveness as a tool for ee. We conclude that the framework is suited for students in an introductory entrepreneurship course, entrepreneurs, and a wider audience who wish to understand how an entrepreneurial opportunity can be evaluated. Future work could usefully focus on further empirical validation of the framework. © 2016 by jordan whitney enterprises, inc., usa.","","","2016","","","","scopus-2-s2.0-84995572308.pdf","scopus-2-s2.0-84995572308"
"Design and realization of a sharing oriented web database of polymer materials","Yufeng, L. And Yong, Z. And Lina, L. And Zhiyong, L. And Jing, C. And Changcheng, H. And Yizhuang, X. And Dujin, W.","Chemistry Bulletin / Huaxue Tongbao","","A polymer database was established as a part of the national materials science data sharing network (nmsdsn) of china and opened to the public recently. The database is designed to share detailed data of commercially available polymer materials, serving for academic and industrial users. It covers most of the common material types in the area of polymer science including plastics, rubbers, fibers, coatings, adhesives, as well as additive agents, which give rise to over 50000 items of data from more than 7000 polymer materials currently. Materials are organized with a network classification system, so that complex materials could be reached through different paths, aiming to offer more convenient browse experiences. Data quality and reliability are guaranteed all through the production, collection and integration processes. The property data is described with a multi-dimensional model, where the source reference, evaluation and modification records are included in the schema.","","","2012","","","","scopus-2-s2.0-84865688536.pdf","scopus-2-s2.0-84865688536"
"Multidimensional study on users’ evaluation of the kraken personal data sharing platform","Gabrielli, S. And Rizzi, S. And Mayora, O. And More, S. And Baun, J.c.p. And Vandevelde, W.","Applied Sciences (Switzerland)","","Background: recent advances in the design of blockchain-based personal data sharing platforms bring the benefit of empowering users with more control and privacy-preserving measures in sharing data products. However, so far very little is known about users’ intentions to adopt such platforms for providing or consuming data products. Objective: this study aims to investigate users’ main expectations, preferences, and concerns regarding the adoption of blockchain-based personal data sharing platforms in the health and education domains. Methods: fifteen participants were involved in a multidimensional evaluation of a prototyped release of the kraken blockchain-based data sharing platform and asked to assess it in the health or education pilot domains. Data collected during online group interviews with participants were analyzed by applying the micro interlocutor technique to provide a descriptive overview of participant responses. Results: participants showed a marginal acceptance of the prototype usability, asking for some improvements of the user experience and for a more transparent presentation of the platform security and privacy preserving capabilities. Participants expressed interest in using the platform as data providers and consumers as well as setting privacy policies for sharing data products with third parties, including the possibility of revoking access to data. Conclusions: blockchain-based data sharing platforms are more likely to engage target users when technical design is informed by a deeper knowledge of their needs, expectations, and relevant concerns. © 2022 by the authors. Licensee mdpi, basel, switzerland.","","","2022","10.3390/app12073270","","","scopus-2-s2.0-85127516542.pdf","scopus-2-s2.0-85127516542"
"Clinical trial transparency and data sharing among biopharmaceutical companies and the role of company size, location and product type: a cross-sectional descriptive analysis","Axson S. And Mello M.m. And Lincow D. And Yang C. And Gross C. And Ross J.s. And Miller J.","Bmj Open","","Objectives to examine company characteristics associated with better transparency and to apply a tool used to measure and improve clinical trial transparency among large companies and drugs, to smaller companies and biologics. Design cross-sectional descriptive analysis. Setting and participants novel drugs and biologics food and drug administration (fda) approved in 2016 and 2017 and their company sponsors. Main outcome measures using established good pharma scorecard (gps) measures, companies and products were evaluated on their clinical trial registration, results dissemination and fda amendments act (fdaaa) implementation;  companies were ranked using these measures and a multicomponent data sharing measure. Associations between company transparency scores with company size (large vs non-large), location (us vs non-us) and sponsored product type (drug vs biologic) were also examined. Results 26% of products (16/62) had publicly available results for all clinical trials supporting their fda approval and 67% (39/58) had public results for trials in patients by 6 months after their fda approval;  58% (32/55) were fdaaa compliant. Large companies were significantly more transparent than non-large companies (overall median transparency score of 95% (iqr 91-100) vs 59% (iqr 41-70), p<0.001), attributable to higher fdaaa compliance (median of 100% (iqr 88-100) vs 57% (0-100), p=0.01) and better data sharing (median of 100% (iqr 80-100) vs 20% (iqr 20-40), p<0.01). No significant differences were observed by company location or product type. Conclusions it was feasible to apply the gps transparency measures and ranking tool to non-large companies and biologics. Large companies are significantly more transparent than non-large companies, driven by better data sharing procedures and implementation of fdaaa trial reporting requirements. Greater research transparency is needed, particularly among non-large companies, to maximise the benefits of research for patient care and scientific innovation.copyright © author(s) (or their employer(s)) 2021. Re-use permitted under cc by-nc. No commercial re-use. See rights and permissions. Published by bmj.","","","2021","10.1136/bmjopen-2021-053248","","","embase-635520592.pdf","embase-635520592"
"The problem of irreproducible bioscience research","Flier, J.s.","Perspectives In Biology And Medicine","","Over recent decades, progress in bioscience research has been remarkable, but alongside the many transformative advances is a growing concern that a surprisingly high fraction of published research cannot be reproduced by the scientific community. Though experimental and interpretive errors are unavoidable features of the scientific process, recent evidence suggests that irreproducibility is a serious issue requiring analysis, understanding, and remediation. This article reviews the meaning of research reproducibility, examines ongoing efforts to estimate its prevalence, and considers the factors that contribute to it. Two recent case studies illustrate the disparate responses that researchers may take when facing serious claims that a high-profile research finding is irreproducible and may be false. Finally, the article examines potential interventions to counter the current level of irreproducibility, aimed at increasing the efficiency and impact of society’s substantial and critically important investment in bioscience research. © 2022 by johns hopkins university press.","","","2022","10.1353/pbm.2022.0032","","","scopus-2-s2.0-85137714947.pdf","scopus-2-s2.0-85137714947"
"St-elevation myocardial infarction in a young adult secondary to giant coronary aneurysm thrombosis: an important sequela of kawasaki disease and a management challenge","Potter, E.l. And Meredith, I.t. And Psaltis, P.j.","Bmj Case Reports","","Thrombosis of a coronary artery aneurysm (caa) is a rare trigger for st-elevation myocardial infarction (stemi) and an important cause of stemi in young adults previously affected by kawasaki disease. Initial management should proceed in line with standard stemi-management guidelines advocating antiplatelet medication and emergency coronary angiography. Acute caa thrombosis presents the interventional cardiologist with unique challenges during attempted percutaneous revascularisation. In the absence of consensus guidelines, experiential reporting can therefore be of great value. We report on a 36-year-old vietnamese woman presenting with an inferior stemi secondary to two giant thrombosed aneurysms of the right coronary artery. Coronary wiring and thrombus aspiration temporarily improved coronary flow but recurrent thrombus with distal embolisation resulted in ventricular fibrillation and cardiogenic shock. Emergency surgical revascularisation subsequently provided a definitive and successful outcome. We discuss the challenges of percutaneous coronary intervention in this scenario and review previous reports to give an overview of principles of decision-making and management. Copyright 2016 bmj publishing group. All rights reserved.","","","2016","10.1136/bcr-2015-213622","","","scopus-2-s2.0-84959298288.pdf","scopus-2-s2.0-84959298288"
"Privacy-preserving public auditing and data dynamics for secure cloud storage based on exact regenerated code","Pasupuleti, S.k.","International Journal Of Cloud Applications And Computing","","Cloud storage allows users to store their data in the cloud to avoid local storage and management costs. Since the cloud is untrusted, the integrity of stored data in the cloud has become an issue. To address this problem, several public auditing schemes have been designed to verify integrity of the data in the cloud. However, these schemes have two drawbacks: public auditing may reveal sensitive data to verifier and does not address the data recovery problem efficiently. This article proposes a new privacy-preserving public auditing scheme with data dynamics to secure the data in the cloud based on an exact regenerated code. This scheme encodes the data for availability, then masks the encoded blocks with randomness for privacy of data and enables a public auditor to verify the integrity of the data. Further, this scheme also supports dynamic data updates. In addition, security and performance analysis proves that proposed scheme is provably secure and efficient. Copyright © 2019, igi global.","","","2019","10.4018/ijcac.2019100101","","","scopus-2-s2.0-85112822573.pdf","scopus-2-s2.0-85112822573"
"Testing the prisma-equity 2012 reporting guideline: the perspectives of systematic review authors","Burford B.j. And Welch V. And Waters E. And Tugwell P. And Moher D. And O'neill J. And Koehlmoos T. And Petticrew M.","Plos One","","Reporting guidelines can be used to encourage standardised and comprehensive reporting of health research. In light of the global commitment to health equity, we have previously developed and published a reporting guideline for equity-focused systematic reviews (prisma-e 2012). The objectives of this study were to explore the utility of the equity extension items included in prisma-e 2012 from a systematic review author perspective, including facilitators and barriers to its use. This will assist in designing dissemination and knowledge translation strategies. We conducted a survey of systematic review authors to expose them to the new items in prisma-e 2012, establish the extent to which they had historically addressed those items in their own reviews, and gather feedback on the usefulness of the new items. Data were analysed using microsoft excel 2008 and stata (version 11.2 for mac). Of 151 respondents completing the survey, 18.5% (95% ci: 12.7% to 25.7%) had not heard of the prisma statement before, although 83.4% (95% ci: 77.5% to 89.3%) indicated that they plan to use prisma-e 2012 in the future, depending on the focus of their review. Most (68.9%;  95% ci: 60.8% to 76.2%) thought that using prisma-e 2012 would lead them to conduct their reviews differently. Important facilitators to using prisma-e 2012 identified by respondents were journal endorsement and incorporation of the elements of the guideline into systematic review software. Barriers identified were lack of time, word limits and the availability of equity data in primary research. This study has been the first to 'road-test' the new prisma-e 2012 reporting guideline and the findings are encouraging. They confirm the acceptability and potential utility of the guideline to assist review authors in reporting on equity in their reviews. The uptake and impact of prisma-e 2012 over time on design, conduct and reporting of primary research and systematic reviews should continue to be examined. © 2013 burford et al.","","","2013","10.1371/journal.pone.0075122","","","embase-370004465.pdf","embase-370004465"
"The linkage between knowledge management practices and company performance: empirical evidence","Syed, N. And Lin, X.","Journal Of Industrial Engineering And Management","","Purpose: this study explores the linkage between knowledge management practices and company performance. Keeping in view the theoretical and empirical importance, the present study examines the predicting linkage of knowledge management practices (sharing of best practices and building of consistent process, continues employee learning, effective management of knowledge, innovative culture development, and management of core competencies) with company performance. Methodology: the study was carried out on purposively selected sample of 412 employees at different managerial positions. They were administered questionnaires including knowledge management practices and company performance. Data was operated by using spss version 20.Correlation and regression analysis was done to establish the relationship between various knowledge management practices and company performance. Findings: results of this study illustrated that all selected knowledge management were positively related to company performance. Based on the findings, and management of core competencies was the strongest predictor of company performance, followed by innovative culture development, effective management of knowledge and sharing of best practices and building of consistent process, continues employee learning. Research limitations/implications: the paper focuses on examining the perceptual impacts of knowledge management (km) practices on company performance. The interpretation of results should be taken with caution. Value: the aim of this research is to investigate the relationship between knowledge management and company performance, study the importance of knowledge management as a source of sustainable competitive advantages for companies and to investigate how the introduction of knowledge management practices facilitates company performance to improve. The practices that have a more positive influence on company performance are also discussed.","","","2013","10.3926/jiem.656","","","scopus-2-s2.0-84875517161.pdf","scopus-2-s2.0-84875517161"
"Neutrality and satisfaction in the mediation session: party and mediator perspectives","Szejda, K. And Ebesu Hubbard, A.s.","International Journal Of Conflict Management","","Purpose: this study aims to investigate the relationship between perceptions of mediators acting symmetrically (treating parties equally) and transparently (providing an explanation of past or future behavior) with parties’ assessments of the neutrality of their mediator and satisfaction with the mediation process. Design/methodology/approach: this mixed-method study surveyed parties and mediators from 35 naturally occurring mediation sessions at community mediation centers about their perceptions of neutrality, symmetry, transparency and satisfaction. Findings: the results showed that parties overwhelmingly assessed their mediators as acting neutrally. Compared to parties’ assessments of mediator neutrality, mediators rated their own neutrality even higher. Symmetry and transparency were both positively correlated with parties’ assessment of mediator neutrality and also emerged as qualitative themes. Speaking order and talk time did not significantly correlate with perception of symmetry. Overall, symmetry appeared to be a more salient factor in parties’ assessment of mediator neutrality than transparency. Both neutrality and symmetry were positively correlated with party satisfaction with the mediation process, but transparency was not. Research limitations/implications: the present study provides a foundation for future research in understanding neutrality from both parties and mediators’ perspectives. The primary limitation was a small sample size and possible selection bias in achieving the sample. Practical implications: the study found that symmetry and transparency are useful strategies for managing party perceptions of mediator neutrality and party satisfaction with the mediation process. Originality/value: this study is one of only a few empirical research studies that investigated the parties’ perspective of mediator neutrality. The study provides a foundation for future research in understanding neutrality from both parties and mediators’ perspectives. © 2019, emerald publishing limited.","","","2019","10.1108/ijcma-04-2018-0054","","","scopus-2-s2.0-85071589169.pdf","scopus-2-s2.0-85071589169"
"Biomarkers, designs, and interpretations of resting-state fmri in translational pharmacological research: a review of state-of-the-art, challenges, and opportunities for studying brain chemistry","Khalili-Mahani, N. And Rombouts, S.a.r.b. And Van Osch, M.j.p. And Duff, E.p. And Carbonell, F. And Nickerson, L.d. And Becerra, L. And Dahan, A. And Evans, A.c. And Soucy, J.-P. And Wise, R. And Zijdenbos, A.p. And Van Gerven, J.m.","Human Brain Mapping","","A decade of research and development in resting-state functional mri (rsfmri) has opened new translational and clinical research frontiers. This review aims to bridge between technical and clinical researchers who seek reliable neuroimaging biomarkers for studying drug interactions with the brain. About 85 pharma-rsfmri studies using bold signal (75% of all) or arterial spin labeling (asl) were surveyed to investigate the acute effects of psychoactive drugs. Experimental designs and objectives include drug fingerprinting dose-response evaluation, biomarker validation and calibration, and translational studies. Common biomarkers in these studies include functional connectivity, graph metrics, cerebral blood flow and the amplitude and spectrum of bold fluctuations. Overall, rsfmriderived biomarkers seem to be sensitive to spatiotemporal dynamics of drug interactions with the brain. However, drugs cause both central and peripheral effects, thus exacerbate difficulties related to biological confounds, structured noise from motion and physiological confounds, as well as modeling and inference testing. Currently, these issues are not well explored, and heterogeneities in experimental design, data acquisition and preprocessing make comparative or meta-analysis of existing reports impossible. A unifying collaborative framework for data-sharing and data-mining is thus necessary for investigating the commonalities and differences in biomarker sensitivity and specificity, and establishing guidelines. Multimodal datasets including sham-placebo or active control sessions and repeated measurements of various psychometric, physiological, metabolic and neuroimaging phenotypes are essential for pharmacokinetic/pharmacodynamic modeling and interpretation of the findings. We provide a list of basic minimum and advanced options that can be considered in design and analyses of future pharma-rsfmri studies. © 2017 the authors human brain mapping published by wiley periodicals, inc.","","","2017","10.1002/hbm.23516","","","scopus-2-s2.0-85011601344.pdf","scopus-2-s2.0-85011601344"
"Reporting guidelines: Doing better for readers","Moher D.","BMC Medicine","","There is clear guidance on the responsibilities of editors to ensure that the research they publish is of the highest possible quality. Poor reporting is unethical and directly impacts patient care. Reporting guidelines are a relatively recent development to help improve the accuracy clarity and transparency of biomedical publications. They have caught on with hundreds of reporting guidelines now available. Some journals endorse reporting guidelines while a smaller number have used various approaches to implement them. Yet challenges remain - biomedical research is still not optimally reported despite the abundance of reporting guidelines. Electronic algorithms are now being developed to facilitate the choice of correct reporting guideline(s) while other tools are being integrated into journal editorial management processes. Universities need to consider whether it is responsible to advance careers of faculty based on poorly reported research which is of little societal value. If journals embraced auditing of the quality of articles they publish this would give them and their readers essential feedback from which to improve their product. Copyright © 2018 The Author(s).","","","2018","10.1186/s12916-018-1226-0","","","medline-30545364.pdf","medline-30545364"
"Optimizing privacy-accuracy tradeoff for privacy preserving distance-based classification","Kim, D. And Chen, Z. And Gangopadhyay, A.","International Journal Of Information Security And Privacy","","Privacy concerns often prevent organizations from sharing data for data mining purposes. There has been a rich literature on privacy preserving data mining techniques that can protect privacy and still allow accurate mining. Many such techniques have some parameters that need to be set correctly to achieve the desired balance between privacy protection and quality of mining results. However, there has been little research on how to tune these parameters effectively. This paper studies the problem of tuning the group size parameter for a popular privacy preserving distance-based mining technique: the condensation method. The contributions include: 1) a class-wise condensation method that selects an appropriate group size based on heuristics and avoids generating groups with mixed classes, 2) a rule-based approach that uses binary search and several rules to further optimize the setting for the group size parameter. The experimental results demonstrate the effectiveness of the authors' approach. Copyright © 2012, igi global.","","","2012","10.4018/jisp.2012040102","","","scopus-2-s2.0-84870266287.pdf","scopus-2-s2.0-84870266287"
"Reproducibility of extracranial carotid atherosclerotic lesions assessed by B-mode ultrasound: the Atherosclerosis Risk in Communities Study","Li R., Cai J., Tegeler C., Sorlie P., Metcalf P. A., Heiss G.","Ultrasound in Medicine & Biology","","The reproducibility in the identification of carotid artery lesions using B-mode ultrasound was studied in a large random sample selected from the Atherosclerosis Risk in Communities (ARIC) Study. Carotid lesions were defined as plaque with or without acoustic shadowing (indicative of mineralization). A weighted kappa (kappa w) statistic was used as a chance-adjusted measure of repeatability. In the ARIC baseline survey the kappa w values for the assessment of lesions on repeat reading were 0.47 0.60 and 0.69 in the left common carotid artery the carotid bifurcation and the internal carotid artery respectively. In a repeat scanning the kappa w values ranged from 0.59 to 0.79 in the left carotid segments. The results were similar in the left and right carotid arteries. Covariates (age race gender body mass index study center) did not influence the reproducibility. Similar results were also found in both the baseline survey and the first follow-up examination. In conclusion reproducibility in the assessment of carotid lesions by B-mode ultrasound can be achieved in multicenter studies at fair to good levels of agreement.","","","1996","10.1016/0301-5629(96)00084-1","","","medline-8923698.pdf","medline-8923698"
"Validation and reproducibility of pressure-corrected aortic distensibility measurements using pulse-wave-velocity Doppler ultrasound","Lehmann E. D., Parker J. R., Hopkins K. D., Taylor M. G., Gosling R. G.","Journal of Biomedical Engineering","","A non-invasive Doppler ultrasound technique is described for the assessment of aortic compliance based on the in vivo measurement of pulse wave velocity along the thoraco-abdominal aortic pathway. A structured protocol which has been developed to improve the reproducibility of the technique is validated. A method of correcting for the effect of non-chronic changes in blood pressure on arterial elasticity is considered and applied to compliance measurements performed on 66 normal healthy volunteers. The results of a study to ascertain the overall reproducibility of the method are provided and problems associated with the technique are discussed. Medical disorders such as atherosclerosis diabetes mellitus familial hypercholesterolaemia and growth hormone deficiency have all been shown to affect arterial wall compliance. It is suggested that the in vivo measurement of pressure-corrected aortic distensibility may be a useful non-invasive tool for assessing such patients' susceptibility to atheromatous arterial disease and for monitoring their response to therapy. Measurements in the aorta may be especially pertinent since the natural history of fatty streaks there tends to parallel that in coronary arteries thereby potentially affording a convenient surrogate estimate of coronary heart disease.","","","1993","","","","medline-8320981.pdf","medline-8320981"
"Ra: research assistant for the computational sciences","Ramage, D. And Oliner, A.j.","2007 Workshop On Experimental Computer Science","","Computational experiments often discard large amounts of valuable data, such as invocation parameters and the lineage of output. Our goal is to identify, manage, capture, and organize this information. These data can be used to make the scientific process simpler and more efficient, and to increase the value of the research by making it more rigorous and reproducible. Research assistant (ra) is an open source java programming tool that helps to plug this information leak. Ra ensures that all console output is valid xml;  saves invocation parameters, the random seed, and code version information;  automatically checkpoints intermediate results;  creates runnable experiment packages;  and keeps meticulous notes. This paper presents the design and implementation of ra, and shows how ra easily scales to make complex experiments repeatable. Copyright 2007 acm.","","","2007","10.1145/1281700.1281719","","","scopus-2-s2.0-37849027509.pdf","scopus-2-s2.0-37849027509"
"A heterogeneous data sharing approach based on ontology and metadata","Li, X. And Hu, X. And Lu, W. And Liu, X.","Journal Of Computational Information Systems","","To overcome the problem of sharing multi-sourced, multi-class, heterogeneous data, an information sharing solution is proposed based on ontology and a two-layer metadata standard. Firstly, the framework of the information sharing system is presented. Secondly, the architecture of the two-layer metadata is introduced. Finally, with the lack of semantic information, an ontology layer is built on the metadata layer for describing metadata and reasoning. In the aspect of information retrieval, an improved method combining lucene full-text search engine with sparql query is proposed, which improves the recall rate and optimizes the retrieval time. The experiment results illustrate the effectiveness of the approach and the conclusion is given. ©, 2015, binary information press. All right reserved.","","","2015","10.12733/jcis12958","","","scopus-2-s2.0-84930526215.pdf","scopus-2-s2.0-84930526215"
"Attitudes of research participants and the general public towards genomic data sharing: A systematic literature review","Shabani M., Bezuidenhout L., Borry P.","Expert Review of Molecular Diagnostics","","Aim: Introducing data sharing practices into the genomic research arena has challenged the current mechanisms established to protect rights of individuals and triggered policy considerations. To inform such policy deliberations soliciting public and research participants' attitudes with respect to genomic data sharing is a necessity. Method: The main electronic databases were searched in order to retrieve empirical studies investigating the attitudes of research participants and the public towards genomic data sharing through public databases. Results: In the 15 included studies participants' attitudes towards genomic data sharing revealed the influence of a constellation of interrelated factors including the personal perceptions of controllability and sensitivity of data potential risks and benefits of data sharing at individual and social level and also governance level considerations. Conclusion: This analysis indicates that future policy responses and recruitment practices should be attentive to a wide variety of concerns in order to promote both responsible and progressive research. Copyright © 2014 Informa UK Ltd.","","","2014","10.1586/14737159.2014.961917","","","medline-25260013.pdf","medline-25260013"
"Review of Research Reporting Guidelines for Radiology Researchers","Cronin P., Rawson J. V.","Academic Radiology","","Prior articles have reviewed reporting guidelines and study evaluation tools for clinical research. However only some of the many available accepted reporting guidelines at the Enhancing the QUAlity and Transparency Of health Research Network have been discussed in previous reports. In this paper we review the key Enhancing the QUAlity and Transparency Of health Research reporting guidelines that have not been previously discussed. The study types include diagnostic and prognostic studies reliability and agreement studies observational studies analytical and descriptive experimental studies quality improvement studies qualitative research health informatics systematic reviews and meta-analyses economic evaluations and mixed methods studies. There are also sections on study protocols and statistical analyses and methods. In each section there is a brief overview of the study type and then the reporting guideline(s) that are most applicable to radiology researchers including radiologists involved in health services research are discussed.","","","2016","10.1016/j.acra.2016.01.004","","","medline-26928069.pdf","medline-26928069"
"A meta-research study of randomized controlled trials found infrequent and delayed availability of protocols","Schonenberger C. M., Griessbach A., Taji Heravi, Gryaznov D., Gloy V. L., Lohner S., Klatte K., Ghosh N., Lee H., Mansouri A., Marian I. R., Saccilotto R., Nury E., Busse J. W., von Niederhausern B., Mertz D., Blumle A., Odutayo A., Hopewell S., Speich B., Briel M.","Journal of Clinical Epidemiology","","OBJECTIVES: Availability of randomized controlled trial (RCT) protocols is essential for the interpretation of trial results and research transparency. STUDY DESIGN AND SETTING: In this study we determined the availability of RCT protocols approved in Switzerland Canada Germany and the United Kingdom in 2012. For these RCTs we searched PubMed Google Scholar Scopus and trial registries for publicly available protocols and corresponding full-text publications of results. We determined the proportion of RCTs with (1) publicly available protocols (2) publications citing the protocol and (3) registries providing a link to the protocol. A multivariable logistic regression model explored factors associated with protocol availability. RESULTS: Three hundred twenty-six RCTs were included of which 118 (36.2%) made their protocol publicly available; 56 (47.6% 56 of 118) provided as a peer-reviewed publication and 48 (40.7% 48 of 118) provided as supplementary material. A total of 90.9% (100 of 110) of the protocols were cited in the main publication and 55.9% (66 of 118) were linked in the clinical trial registry. Larger sample size (>500; odds ratio [OR] = 5.90 95% confidence interval [CI] 2.75-13.31) and investigator sponsorship (OR = 1.99 95% CI 1.11-3.59) were associated with increased protocol availability. Most protocols were made available shortly before the publication of the main results. CONCLUSION: RCT protocols should be made available at an early stage of the trial.","","","2022","10.1016/j.jclinepi.2022.05.014","","","medline-35654268.pdf","medline-35654268"
"Clap-pre: certificateless autonomous path proxy re-encryption for data sharing in the cloud","Ren, C. And Dong, X. And Shen, J. And Cao, Z. And Zhou, Y.","Applied Sciences (Switzerland)","","In e-health systems, patients encrypt their personal health data for privacy purposes and upload them to the cloud. There exists a need for sharing patient health data with doctors for healing purposes in one’s own preferred order. To achieve this fine-gained access control to delegation paths, some researchers have designed a new proxy re-encryption (pre) scheme called autonomous path proxy re-encryption (ap-pre), where the delegator can control the whole delegation path in a multi-hop delegation process. In this paper, we introduce a certificateless autonomous path proxy re-encryption (clap-pre) using multilinear maps, which holds both the properties (i.e., certificateless, autonomous path) of certificateless encryption and autonomous path proxy re-encryption. In the proposed scheme, (a) each user has two public keys (user’s identity and traditional public key) with corresponding private keys, and (b) each ciphertext is first re-encrypted from a public key encryption (pke) scheme to an identity-based encryption (ibe) scheme and then transformed in the ibe scheme. Our scheme is an ind-cpa secure clap-pre scheme under the k-multilinear decisional diffie–hellman (k-mddh) assumption in the random oracle model. © 2022 by the authors. Licensee mdpi, basel, switzerland.","","","2022","10.3390/app12094353","","","scopus-2-s2.0-85129001034.pdf","scopus-2-s2.0-85129001034"
"Assessing the application of focus groups as a method for collecting data in logistics","Rodrigues, V.s. And Piecyk, M. And Potter, A. And Mckinnon, A. And Naim, M. And Edwards, J.","International Journal Of Logistics Research And Applications","","Relatively little attention has been given to methodological issues in the logistics literature. In logistics, 'we need to take more account of the views of practitioners in the field by supporting quantitative data with qualitative data' [new, s j. and payne, p. (1995). Research frameworks in logistics: three models, seven dinners and a survey. International journal of physical distribution & logistics management, 25(10), 60-77]. The aim of this paper is to provide a guide on how to deploy focus groups as a supportive method to achieve industrial relevance without compromising the academic rigour of logistics research. We develop a framework that highlights the factors influencing focus groups' effectiveness in the logistics discipline. Our analysis is based on previous focus groups research applied in logistics and on focus group cases discussed in the paper. We conclude that the focus group method for data collection can be used as a supporting method in logistics research, enabling methodological triangulation that improves the credibility of research results. © 2010 taylor & francis.","","","2010","10.1080/13675560903224970","","","scopus-2-s2.0-76649085854.pdf","scopus-2-s2.0-76649085854"
"Verifiable inner product computation on outsourced database for authenticated multi-user data sharing","Yang, H. And Su, Y. And Qin, J. And Wang, H. And Song, Y.","Information Sciences","","With the rapid development of cloud computing, the practical applications such as the machine learning based on the outsourced data have been investigated in the data sharing setting. In machine learning, the inner product is a necessary primitive to analyze the description statistics. However, the inner product computation in selective data sharing setting has not been fully considered. For this fact, we propose a verifiable inner product computation scheme based on inner product functional encryption (ipfe). Ipfe is employed to preserve the outsourced data privacy and restrict the computation on the outsourced data to be inner product. To achieve the key privacy and result privacy, we transform the secret key into blinded form, which in turn results in a blinded result. With the aim of implementing access control over the data user and outsourced data, we design to let cloud server perform the authentication procedures before computing inner product. This can also eliminate most computational overhead resulting from the unauthorized data user and undesired data. As a result, only the authorized data user can obtain the inner product computed on the designated outsourced data. The proposed scheme is proved to be secure under the authentication model and the result unforgeability model. The performance evaluation shows that the proposed scheme is feasible. To achieve a better security level, the proposed scheme is extended to be secure against the corrupted cloud server. © 2020 elsevier inc.","","","2020","10.1016/j.ins.2020.05.118","","","scopus-2-s2.0-85086828688.pdf","scopus-2-s2.0-85086828688"
"Detecting localized homogeneous anomalies over spatio-temporal data","Telang, A. And Deepak, P. And Joshi, S. And Deshpande, P. And Rajendran, R.","Data Mining And Knowledge Discovery","","The last decade has witnessed an unprecedented growth in availability of data having spatio-temporal characteristics. Given the scale and richness of such data, finding spatio-temporal patterns that demonstrate significantly different behavior from their neighbors could be of interest for various application scenarios such as - weather modeling, analyzing spread of disease outbreaks, monitoring traffic congestions, and so on. In this paper, we propose an automated approach of exploring and discovering such anomalous patterns irrespective of the underlying domain from which the data is recovered. Our approach differs significantly from traditional methods of spatial outlier detection, and employs two phases - (i) discovering homogeneous regions, and (ii) evaluating these regions as anomalies based on their statistical difference from a generalized neighborhood. We evaluate the quality of our approach and distinguish it from existing techniques via an extensive experimental evaluation. © 2014 the author(s).","","","2014","10.1007/s10618-014-0366-x","","","scopus-2-s2.0-84906548499.pdf","scopus-2-s2.0-84906548499"
"A computational study of floyd's algorithm","Shier, D.r.","Computers And Operations Research","","This paper studies the empirical computational complexity of five different computer codes for realizing floyd's shortest path algorithm, using classes of randomly generated test problems. The present work investigates objective and reproducible measures of computational effort, and indicates how rather substantial reductions in this computational effort (as much as 30%, asymptotically) can be achieved. Both actual cpu time and predicted computation time are discussed and compared. Results indicate a strong interaction between code, computer, compiler, and several empirical measures of computational effort. © 1981.","","","1981","10.1016/0305-0548(81)90015-0","","","scopus-2-s2.0-0019703044.pdf","scopus-2-s2.0-0019703044"
"2010 International Conference on Computational Intelligence and Software Engineering CiSE 2010","","","","The proceedings contain 561 papers. The topics discussed include: a benchmarking framework for domain specific software; a broker-based architecture for quality-driven web services composition; a clustering query algorithm based on particle swarm in wireless sensor networks; a combined prediction method for network security situation; a conservative prefix delegation policy for nested mobile networks based on paging mechanism; a contour-based method on image retrieval; a cross-platform supported technique for embedded software generation; a data-driven software testing tools integration system; a digital fingerprinting scheme of digital image; a distributed spatial data sharing and management system for forest farms; a enhanced trust model based on social network and online behavior analysis for recommendation; a general framework for fuzzy data mining; a global efficiency optimization model of service evaluation and selection; and a high energy efficiency link layer adaptive error control mechanism for wireless sensor networks.","","","2010","","","","scopus-2-s2.0-79951592085.pdf","scopus-2-s2.0-79951592085"
"Observed data of extreme rainfall events over the West African Sahel","Salack S., Saley I. A., Bliefernicht J.","Data in Brief","","The data described in this article are sets of daily rainfall values derived from observed station records. The data was recorded by 72 in-situ rain gauges spread over the West African Sahel. The daily rainfall time series from synoptic climate agro-meteorological and rainfall stations are assessed for quality and consistency before extreme values are extracted based on 90th 95th and 99th percentile thresholds. This data is free for use as part of the study ""Scales for rating heavy rainfall events in West African Sahel"" [1] (Salack et al. 2018). Complementary and up to date time series can be taken from WASCAL data infrastructure (WADI) geoportal https://wascal-dataportal.org/wascal_searchportal2/. This is a derived product (DP) made public in line with WASCAL's ""3rd party data sharing policy"" signed by the WASCAL member countries.","","","2018","10.1016/j.dib.2018.09.001","","","medline-30238039.pdf","medline-30238039"
"A tentative evaluation framework for digital archaeological data sites","Freeman, M.a. And Zhu, X.","Proceedings Of The Association For Information Science And Technology","","In this poster presentation, we describe a tentative evaluation framework for digital archaeological data sites and a test of this framework using 148 virginia archaeological websites. Archaeological data dissemination situates in the overlapping demands of openness, scholarship and outreach. This analysis suggests that, while there are some exemplary websites, much of the archaeological record remains publicly inaccessible. These websites did provide many supporting characteristics for public outreach, but concerns about preservation, data “openness” and limited datasets remain. ©2017 mark antony freeman and xiaohua zhu","","","2017","10.1002/pra2.2017.14505401112","","","scopus-2-s2.0-85040797714.pdf","scopus-2-s2.0-85040797714"
"A methodological assessment of studies that use voxel-based morphometry to study neural changes in tinnitus patients","Scott-Wittenborn N., Karadaghy O. A., Piccirillo J. F., Peelle J. E.","Hearing Research","","BACKGROUND: The scientific understanding of tinnitus and its etiology has transitioned from thinking of tinnitus as solely a peripheral auditory problem to an increasing awareness that cortical networks may play a critical role in tinnitus percept or bother. With this change studies that seek to use structural brain imaging techniques to better characterize tinnitus patients have become more common. These studies include using voxel-based morphometry (VBM) to determine if there are differences in regional gray matter volume in individuals who suffer from tinnitus and those who do not. However studies using VBM in patients with tinnitus have produced inconsistent and sometimes contradictory results. OBJECTIVE: This paper is a systematic review of all of the studies to date that have used VBM to study regional gray matter volume in people with tinnitus and explores ways in which methodological differences in these studies may account for their heterogeneous results. We also aim to provide guidance on how to conduct future studies using VBM to produce more reproducible results to further our understanding of disease processes such as tinnitus. METHODS: Studies about tinnitus and VBM were searched for using PubMed and Embase. These returned 15 and 25 results respectively. Of these nine met the study criteria and were included for review. An additional 5 studies were identified in the literature as pertinent to the topic at hand and were added to the review for a total of 13 studies. RESULTS: There was significant heterogeneity among the studies in several areas including inclusion and exclusion criteria software programs and statistical analysis. We were not able to find publicly shared data or code for any study. DISCUSSION: The differences in study design software analysis and statistical methodology make direct comparisons between the different studies difficult. Especially problematic are the differences in the inclusion and exclusion criteria of the study and the statistical design of the studies both of which could radically alter findings. Thus heterogeneity has complicated efforts to explore the etiology of tinnitus using structural MRI. CONCLUSION: There is a pressing need to standardize the use of VBM when evaluating tinnitus patients. While some heterogeneity is expected given the rapid advances in the field more can be done to ensure that there is internal validity between studies.","","","2017","10.1016/j.heares.2017.09.002","","","medline-28951023.pdf","medline-28951023"
"Intraobserver and interobserver variation in the sonographic grading of placental maturity","Sau A., Seed P., Langford K.","Ultrasound in Obstetrics & Gynecology","","OBJECTIVES: The appearance of Grannum Grade III changes in the placenta at around 34-36 weeks is a predictor of adverse perinatal outcome which may be reduced by reporting to the clinician. This has led to the suggestion that the placental grade should be noted during any third-trimester scan. There are no published data on the reproducibility of sonographic Grannum grading of the placenta; the objective of this study was to evaluate intra- and interobserver variation.\\\\\\\\rMETHODS: Fifty-five placental images from normal and complicated pregnancies of several different gestational ages were collected between April and October 2001. Three fetal medicine consultants and three experienced sonographers graded the images as 0 I II III or ungradeable. They then regraded the same images presented in a different order and with different codes 4-6 weeks later. Observers were blinded to their previous grading and to each others'. Weighted kappa (kappa) with linear weights was used to look for strength of agreement.\\\\\\\\rRESULTS: There was good agreement between the two observations of each placental image for five observers (kappa = 0.61 to 0.90) and moderate agreement for one observer (kappa = 0.56). However the kappa-values for comparisons between the 15 pairs of observers ranged from 0.24 to 0.69 with six values below 0.41 indicating only fair agreement. This was confirmed by the overall kappa-value of 0.24 between all six observers. The agreement between the observers for Grade III placenta was poor with an overall kappa-value of 0.09.\\\\\\\\rCONCLUSIONS: Although intraobserver agreement was generally good interobserver agreement was only fair for all grades and poor for Grade III placenta. This may be an indication that Grannum grading is not reproducible or it may reflect a need for training in those performing grading. Such variation may limit the effectiveness of reporting Grannum grades in clinical practice. Copyright 2004 ISUOG.","","","2004","10.1002/uog.1004","","","medline-15065188.pdf","medline-15065188"
"An integrated framework for de-identifying unstructured medical data","Gardner, J. And Xiong, L.","Data And Knowledge Engineering","","While there is an increasing need to share medical information for public health research, such data sharing must preserve patient privacy without disclosing any information that can be used to identify a patient. A considerable amount of research in data privacy community has been devoted to formalizing the notion of identifiability and developing techniques for anonymization but are focused exclusively on structured data. On the other hand, efforts on de-identifying medical text documents in medical informatics community rely on simple identifier removal or grouping techniques without taking advantage of the research developments in the data privacy community. This paper attempts to fill the above gaps and presents a framework and prototype system for de-identifying health information including both structured and unstructured data. We empirically study a simple bayesian classifier, a bayesian classifier with a sampling based technique, and a conditional random field based classifier for extracting identifying attributes from unstructured data. We deploy a k-anonymization based technique for de-identifying the extracted data to preserve maximum data utility. We present a set of preliminary evaluations showing the effectiveness of our approach. © 2009 elsevier b.v. All rights reserved.","","","2009","10.1016/j.datak.2009.07.006","","","scopus-2-s2.0-71749103414.pdf","scopus-2-s2.0-71749103414"
"Impact of pelvic floor ultrasound in diagnosis of postpartum pelvic floor dysfunction: A protocol of systematic review","Wang F. B., Rong R., Xu J. J., Yang G., Xin T. Y., Wang X. H., Tang H. B.","Medicine","","BACKGROUND: This study will appraise the impact of pelvic floor ultrasound (PFU) in diagnosis of postpartum pelvic floor dysfunction (PPPFD).\\\\\\\\rMETHODS: Studies that report the impact of PFU in diagnosis of PPPFD will be examined in Cochrane Library MEDLINE EMBASE PSYCINFO Scopus Web of Science Allied and Complementary Medicine Database CNKI and WANGFANG up to June 1 2020. Grey literature sources will also be searched. All potential case-controlled studies (CCSs) exploring the impact of PFU in diagnosis of PPPFD will be considered for inclusion in this study. Data will be extracted from eligible CCSs for data pooling and meta-analysis. Whenever necessary we will also perform summary effect size heterogeneity across studies study quality assessment and reporting bias.\\\\\\\\rRESULTS: The present study will estimate pooled outcome effects regarding the impact of PFU in diagnosis of PPPFD.\\\\\\\\rCONCLUSION: This study may provide robust evidence to judge the impact of PFU on PPPFD SYSTEMATIC REVIEW REGISTRATION:: PROSPERO CRD42020187623.","","","2020","10.1097/md.0000000000021582","","","medline-32769908.pdf","medline-32769908"
"Reproducibility of arterial stiffness and wave reflections in chronic obstructive pulmonary disease: the contribution of lung hyperinflation and a comparison of techniques","Stone I. S., John L., Petersen S. E., Barnes N. C.","Respiratory Medicine","","Significant cardiovascular morbidity and mortality exists in chronic obstructive pulmonary disease (COPD). Arterial stiffness is raised in COPD and may be a mechanistic link. Non-invasive assessment of arterial stiffness has the potential to be a surrogate outcome measure although no reproducibility data exists in COPD patients. Two studies (23 and 33 COPD patients) were undertaken to 1) assess the Vicorder reproducibility of carotid-femoral pulse wave velocity and Augmentation index in COPD; 2) compare it to SphygmoCor; and 3) assess the contribution of lung hyperinflation to measurement variability. There were excellent correlations and good agreement between repeat Vicorder measurements for carotid-femoral pulse wave velocity (r = 0.96 (p < 0.001); mean difference +/-SD = -0.03 +/- 0.36 m/s (p = 0.65); co-efficient of reproducibility = 4.02%; limits of agreement = -0.68-0.75 m/s). Augmentation index significantly correlated (r = 0.736 (p < 0.001); mean difference +/-SD = 0.72 +/- 4.86% (p = 0.48) however limits of agreement were only 10.42-9.02% with co-efficient of reproducibility of 27.93%. Comparing devices Vicorder values were lower but there was satisfactory agreement. There were no correlation between lung hyperinflation (as measured by residual volume percent predicted total lung capacity percent predicted or the ratio of inspiratory capacity to residual volume) and variability of measurements in either study. In COPD measurement of carotid-femoral pulse wave velocity is highly reproducible not affected by lung hyperinflation and suitable as a surrogate endpoint in research studies. Day-to-day variation in augmentation index highlights the importance of such studies prior to the planning and undertaking of clinical COPD research. Copyright © 2013 Elsevier Ltd. All rights reserved.","","","2013","10.1016/j.rmed.2013.06.008","","","medline-23920329.pdf","medline-23920329"
"Comparing social media data and survey data in assessing the attractiveness of beijing olympic forest park","Wang, Z. And Jin, Y. And Liu, Y. And Li, D. And Zhang, B.","Sustainability (Switzerland)","","Together with the emerging popularity of big data in numerous studies, increasing theoretical discussions of the challenges and limitations of such data sources exist. However, there is a clear research gap in the empirical comparison studies on different data sources. The goal of this paper is to use ""attractiveness"" as a medium to examine the similarity and differences of social media data (smd) and survey data in academic research, based on a case study of the beijing olympic forest park, in beijing, china. Smd was extracted from two social media platforms and two surveys were conducted to assess the attractiveness of various locations and landscape elements. Data collection, keyword extraction and keyword prioritization were used and compared in the data gathering and analysis process. The findings revealed that smd and survey data share many similarities. Both data sources confirm that natural ambience is more appreciated than cultural elements, particularly the naturalness of the park. Spaces of practical utility are more appreciated than facilities designed to have cultural meanings and iconic significance. Despite perceived similarities, this study concludes that smd exhibits exaggerated and aggregated bias. This resulted from the intrinsic character of smd as volunteered and unstructured data selected through an emotional process rather than from a rational synthesis. Exciting events were reported more often than daily experiences. Reflecting upon the strength and weakness of smd and survey data, this study would recommend a combined landscape assessment process, which first utilizes smd to build up an assessment framework, then applies conventional surveys for supplementary and detailed information. This would ultimately result in comprehensive understanding. © 2018 by the authors.","","","2018","10.3390/su10020382","","","scopus-2-s2.0-85041520105.pdf","scopus-2-s2.0-85041520105"
"Improving clinical productivity in an academic surgical practice through transparency","Scoggins C. R., Crockett T., Wafford L., Cannon R. M., McMasters K. M.","Journal of the American College of Surgeons","","BACKGROUND: Patient care revenue is becoming an increasingly important source of funding to support the academic surgery department missions of research and education. Transparency regarding productivity metrics will improve clinical productivity among members of an academic surgical practice.\\\\\\\\rSTUDY DESIGN: Clinical productivity-related data were collected and compared between 2 time periods. Data were stratified by pretransparency and post-transparency time periods. Comparisons were made using the Wilcoxon-Mann-Whitney test and p values <=0.05 were considered significant.\\\\\\\\rRESULTS: The faculty compensation plan remained the same across both time periods; faculty members were paid a base salary plus practice plan income based on individual collections minus practice overhead and academic program support taxes. Before 2006 clinical productivity data were not made public among faculty members. In 2006 the departmental leadership developed a physician scorecard that led to transparency with regard to productivity. After publication of the scorecard clinical productivity increased as did the number of partners producing a threshold number of work relative value units (RVU) (6415 wRVU = 1.0 full time equivalent [FTE]). This occurred during a time of reduced collections per RVU. There was no change in the work assignments (percent effort for clinical service research and teaching) for the physicians between the 2 time periods or the overall effort assigned to the Veterans Affairs hospital.\\\\\\\\rCONCLUSIONS: Clinical productivity can be improved by making productivity metrics transparent among faculty members. Additional measures must be taken to ensure that research and teaching activities are appropriately incentivized. Copyright © 2013 American College of Surgeons. Published by Elsevier Inc. All rights reserved.","","","2013","10.1016/j.jamcollsurg.2013.01.066","","","medline-23628228.pdf","medline-23628228"
"School leadership and educational change: tools and practices in shared school leadership development","Hauge, T.e. And Norenes, S.o. And Vedøy, G.","Journal Of Educational Change","","This study examines the features of school leadership as it evolved in an upper secondary school attempting to enhance school improvement through a dedicated team of developmental leaders. We study the team leadership’s tools and design over one school year and report on the evolution of a collective approach to leadership for school improvement. Researchers in a formative intervention research project supported the change process. Cultural-historical activity theory and a set of new technologies inspired the intervention design. The study describes how conceptions and practices of leadership gradually emerged as a collective and distributed approach to leading educational change and school improvement. In particular, new tools and designs for school team leadership were explored and implemented. The study addresses the need to develop shared and collaborative conceptions of leadership in schools. The study concludes that careful planning and skilful orchestration of human, cultural and technological resources are needed in order to make sustainable improvements in schools. © 2014, springer science+business media dordrecht.","","","2014","10.1007/s10833-014-9228-y","","","scopus-2-s2.0-84894230363.pdf","scopus-2-s2.0-84894230363"
"Critical appraisal of the design and reporting of studies of imaging and measurement of carotid stenosis","Rothwell, P.m. And Pendlebury, S.t. And Wardlaw, J. And Warlow, C.p.","Stroke","","Background and purpose - several hundred studies have been published over the last few years on imaging and measurement of carotid stenosis. Despite all this research, there is still no consensus about how best to image and measure stenosis. One possible explanation for this is that many of the studies have not been large enough or methodologically sound enough to allow useful conclusions to be drawn. We aimed to assess the design and methods of a random sample of published studies of imaging and measurement of carotid stenosis using 9 simple criteria. Methods - a formal literature search was performed for studies of imaging and measurement of carotid stenosis. Two subsets were randomly selected for detailed assessment: 20 studies published before 1991 and 20 published between 1993 and 1997 (some years after the initial publication of the ecst and nascet trials). The criteria used to assess the selected studies were as follows: prospective rather than retrospective study design;  patient selection based on a consecutive series or a random sample;  adequate detail of study population;  adequate detail of imaging techniques;  inclusion of all investigations, ie, patients with poor-quality imaging were not excluded;  blinded assessment of images;  adequate detail of derivation of measurement of stenosis from images or data;  adequate data on the reproducibility of measurements of stenosis;  and study powered according to a sample-size calculation. Results - there were many basic methodological deficiencies in both subsets of studies, with relatively little evidence of improvement with time. For example, only 33% of studies were prospective, only 45% studied a consecutive or random selection of patients, and only 38% reported any data on the reproducibility of measurements. More than half of the studies satisfied ≤4 of the 9 quality criteria. However, there was considerable variation between studies, with 7 studies satisfying ≥7 criteria and 10 studies satisfying ≤2. No study was based on a sample-size calculation. The number of patients studied was often small, particularly in the more recent studies: median sample size was 100 in the 1970-1990 studies and 58 in the 1993-1997 studies (p<0.0001). Conclusions - the design and reporting of published studies of imaging and measurement of carotid stenosis are poor and have not improved much in recent years. The majority of published studies are not of a sufficient standard to enable the results to be used to inform clinical practice. The utility of future studies could be improved considerably by better adherence to 9 simple methodological guidelines.","","","2000","10.1161/01.str.31.6.1444","","","scopus-2-s2.0-0034074733.pdf","scopus-2-s2.0-0034074733"
"Patient-powered research networks: building capacity for conducting patient-centered clinical outcomes research","Daugherty S. E., Wahba S., Fleurence R.","Journal of the American Medical Informatics Association","","The Patient-Centered Outcomes Research Institute (PCORI) recently launched PCORnet to establish a single inter-operable multicenter data research network that will support observational research and randomized clinical trials. This paper provides an overview of the patient-powered research networks (PPRNs) networks of patient organizations focused on a particular health condition that are interested in sharing health information and engaging in research. PPRNs will build on their foundation of trust within the patient communities and draw on their expertise working with participants to identify true patient-centered outcomes and direct a patient-centered research agenda. The PPRNs will overcome common challenges including enrolling a diverse and representative patient population; engaging patients in governance; designing the data infrastructure; sharing data securely while protecting privacy; prioritizing research questions; scaling small networks into a larger network; and identifying pathways to sustainability. PCORnet will be the first distributed research network to bring PCOR to national scale. Copyright Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions.","","","2014","10.1136/amiajnl-2014-002758","","","medline-24821741.pdf","medline-24821741"
"Is repeated reading evidence-based? A review of the literature","Petersen-Brown, S. And Johnson, M.e. And Bowen, J. And Lundberg, A.r. And Nelson, J.d. And Williamson, A.a. And Wiswell, J.m.","Preventing School Failure","","Repeated reading (rr) is an established and extensively researched intervention which has been shown to improve reading fluency and comprehension. However, past reviews have found the rigor of the rr research insufficient for it to be considered evidence-based. Previous review of the rr research were updated and expanded. Forty-four group designs and 63 scd studies were evaluated using criteria proposed in the literature. Four group designs and four scd studies met criteria for high-quality or acceptable research. Rr can be considered a promising practice based on group design research;  it cannot be considered an evidence-based practice based on scd research. Additional rigorous research is needed on rr, and criteria used to evaluate rigor should be considered. © 2021 taylor & francis group, llc.","","","2021","10.1080/1045988x.2021.1934376","","","scopus-2-s2.0-85108290252.pdf","scopus-2-s2.0-85108290252"
"The handbook for standardized field and laboratory measurements in terrestrial climate change experiments and observational studies (climex)","Halbritter, A.h. And De Boeck, H.j. And Eycott, A.e. And Reinsch, S. And Robinson, D.a. And Vicca, S. And Berauer, B. And Christiansen, C.t. And Estiarte, M. And Grünzweig, J.m. And Gya, R. And Hansen, K. And Jentsch, A. And Lee, H. And Linder, S. And Marshall, J. And Peñuelas, J. And Kappel Schmidt, I. And Stuart-Haëntjens, E. And Wilfahrt, P. And Vandvik, V. And Abrantes, N. And Almagro, M. And Althuizen, I.h.j. And Barrio, I.c. And Te Beest, M. And Beier, C. And Beil, I. And Carter Berry, Z. And Birkemoe, T. And Bjerke, J.w. And Blonder, B. And Blume-Werry, G. And Bohrer, G. And Campos, I. And Cernusak, L.a. And Chojnicki, B.h. And Cosby, B.j. And Dickman, L.t. And Djukic, I. And Filella, I. And Fuchslueger, L. And Gargallo-Garriga, A. And Gillespie, M.a.k. And Goldsmith, G.r. And Gough, C. And Halliday, F.w. And Hegland, S.j. And Hoch, G. And Holub, P. And Jaroszynska, F. And Johnson, D.m. And Jones, S.b. And Kardol, P. And Keizer, J.j. And Klem, K. And Konestabo, H.s. And Kreyling, J. And Kröel-Dulay, G. And Landhäusser, S.m. And Larsen, K.s. And Leblans, N. And Lebron, I. And Lehmann, M.m. And Lembrechts, J.j. And Lenz, A. And Linstädter, A. And Llusià, J. And Macias-Fauria, M. And Malyshev, A.v. And Mänd, P. And Marshall, M. And Matheny, A.m. And Mcdowell, N. And Meier, I.c. And Meinzer, F.c. And Michaletz, S.t. And Miller, M.l. And Muffler, L. And Oravec, M. And Ostonen, I. And Porcar-Castell, A. And Preece, C. And Prentice, I.c. And Radujković, D. And Ravolainen, V. And Ribbons, R. And Ruppert, J.c. And Sack, L. And Sardans, J. And Schindlbacher, A. And Scoffoni, C. And Sigurdsson, B.d. And Smart, S. And Smith, S.w. And Soper, F. And Speed, J.d.m. And Sverdrup-Thygeson, A. And Sydenham, M.a.k. And Taghizadeh-Toosi, A. And Telford, R.j. And Tielbörger, K. And Töpper, J.p. And Urban, O. And Van Der Ploeg, M. And Van Langenhove, L. And Večeřová, K. And Ven, A. And Verbruggen, E. And Vik, U. And Weigel, R. And Wohlgemuth, T. And Wood, L.k. And Zinnert, J. And Zurba, K. And The Climmani Working Group","Methods In Ecology And Evolution","","Climate change is a world-wide threat to biodiversity and ecosystem structure, functioning and services. To understand the underlying drivers and mechanisms, and to predict the consequences for nature and people, we urgently need better understanding of the direction and magnitude of climate change impacts across the soil–plant–atmosphere continuum. An increasing number of climate change studies are creating new opportunities for meaningful and high-quality generalizations and improved process understanding. However, significant challenges exist related to data availability and/or compatibility across studies, compromising opportunities for data re-use, synthesis and upscaling. Many of these challenges relate to a lack of an established ‘best practice’ for measuring key impacts and responses. This restrains our current understanding of complex processes and mechanisms in terrestrial ecosystems related to climate change. To overcome these challenges, we collected best-practice methods emerging from major ecological research networks and experiments, as synthesized by 115 experts from across a wide range of scientific disciplines. Our handbook contains guidance on the selection of response variables for different purposes, protocols for standardized measurements of 66 such response variables and advice on data management. Specifically, we recommend a minimum subset of variables that should be collected in all climate change studies to allow data re-use and synthesis, and give guidance on additional variables critical for different types of synthesis and upscaling. The goal of this community effort is to facilitate awareness of the importance and broader application of standardized methods to promote data re-use, availability, compatibility and transparency. We envision improved research practices that will increase returns on investments in individual research projects, facilitate second-order research outputs and create opportunities for collaboration across scientific communities. Ultimately, this should significantly improve the quality and impact of the science, which is required to fulfil society's needs in a changing world. © 2019 the authors. Methods in ecology and evolution published by john wiley & sons ltd on behalf of british ecological society.","","","2020","10.1111/2041-210x.13331","","","scopus-2-s2.0-85076341782.pdf","scopus-2-s2.0-85076341782"
"Shrimpdb: a new geoanalytical database for u-th-pb geochronological data from shrimp measurements","He, Y. And Tian, D. And Gao, R. And Fan, R. And Yao, L. And Chen, P.","Earth Science Informatics","","This paper introduces a novel web-based database, shrimpdb, to support the efficient reutilization of u-th-pb geochronological data from sensitive high-resolution ion microprobe (shrimp) measurements. In order to provide complete data content that can be reutilized by earth scientists, a new data model containing analytical data and relevant sample metadata is proposed according to analyses of measurement procedures and the data characteristics of shrimp. Vivid data visualization, real-time data query interfaces (including a novel and intuitive polygonal region search), and a pragmatic data management module are designed and implemented using web-based and cloud gis-based technologies, which provide a platform for earth scientists to efficiently curate and share shrimp data on the internet. An incentive that encourages geochronologists to contribute data is suggested through cooperation between shrimpdb and the beijing shrimp center. The database is currently under evaluation at the beijing shrimp center. Shrimpdb is globally available online at http://202.198.17.27/shrimpdb/home. © 2018, springer-verlag gmbh germany, part of springer nature.","","","2018","10.1007/s12145-018-0353-7","","","scopus-2-s2.0-85049587941.pdf","scopus-2-s2.0-85049587941"
"Developing standards for a national spatial data infrastructure","Wortman, K.c.","Cartography And Geographic Information Systems","","The concept of a framework for data and information linkages among producers and users, known as a national spatial data infrastructure (nsdi), is built upon four corners: data, technology, institutions, and standards. Standards are paramount to increase the efficiency and effectiveness of the nsdi. Historically, data standards and specifications have been developed with a very limited scope - they were parochial, and even competitive in nature, and promoted the sharing of data and information within only a small community at the expense of more open sharing across many communities. Today, an approach is needed to grow and evolve standards to support open systems and provide consistency and uniformity among data producers. There are several significant ongoing activities in geospatial data standards: transfer or exchange, metadata, and data content. In addition, standards in other areas are under discussion, including data quality, data models, and data collection. © 1994 taylor & francis group, llc.","","","1994","10.1080/152304094782602872","","","scopus-2-s2.0-0028477937.pdf","scopus-2-s2.0-0028477937"
"User involvement in adolescents' mental healthcare: protocol for a systematic review","Viksveen P., Bjonness S. E., Berg S. H., Cardenas N. E., Game J. R., Aase K., Storm M.","BMJ Open","","INTRODUCTION: User involvement has become a growing importance in healthcare. The United Nations state that adolescents have a right to be heard and user involvement in healthcare is a legal right in many countries. Some research provides an insight into the field of user involvement in somatic and mental healthcare for adults but little is known about user involvement in adolescents' mental healthcare and no overview of the existing research evidence exists.\\\\\\\\rMETHODS AND ANALYSIS: The aim of this systematic review is to provide an overview of existing research reporting on experiences with and the effectiveness and safety issues associated with user involvement for adolescents' mental healthcare at the individual and organisational level. A systematic literature search and assessment of published research in the field of user involvement in adolescents' mental healthcare will be carried out. Established guidelines will be used for data extraction (Cochrane Collaboration guidelines Strengthening the Reporting of Observational studies in Epidemiology and Critical Appraisal Skills Programme (CASP)) critical appraisal (Cochrane Collaboration guidelines and Pragmatic-Explanatory Continuum Indicator Summary) and reporting of results (Preferred Reporting Items for Systematic reviews and Meta-Analyses Consolidated Standards of Reporting Trials and CASP). Confidence in the research evidence will be assessed using the Grading of Recommendations Assessment Development and Evaluation approach. Adolescents are included as coresearchers for the planning and carrying out of this systematic review. This systematic review will provide an overview of the existing research literature and thereby fill a knowledge gap. It may provide various stakeholders including decision-makers professionals individuals and their families with an overview of existing knowledge in an underexplored field of research.\\\\\\\\rETHICS AND DISSEMINATION: Ethics approval is not required for this systematic review as we are not collecting primary data. The results will be published in a peer-reviewed journal and at conference presentations and will be shared with stakeholder groups. Copyright © Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2017. All rights reserved. No commercial use is permitted unless otherwise expressly granted.","","","2017","10.1136/bmjopen-2017-018800","","","medline-29273667.pdf","medline-29273667"
"METACOHORTS for the study of vascular disease and its contribution to cognitive decline and neurodegeneration: An initiative of the Joint Programme for Neurodegenerative Disease Research","Anonymous","Alzheimer's & Dementia","","Dementia is a global problem and major target for health care providers. Although up to 45% of cases are primarily or partly due to cerebrovascular disease little is known of these mechanisms or treatments because most dementia research still focuses on pure Alzheimer's disease. An improved understanding of the vascular contributions to neurodegeneration and dementia particularly by small vessel disease is hampered by imprecise data including the incidence and prevalence of symptomatic and clinically ""silent"" cerebrovascular disease long-term outcomes (cognitive stroke or functional) and risk factors. New large collaborative studies with long follow-up are expensive and time consuming yet substantial data to advance the field are available. In an initiative funded by the Joint Programme for Neurodegenerative Disease Research 55 international experts surveyed and assessed available data starting with European cohorts to promote data sharing to advance understanding of how vascular disease affects brain structure and function optimize methods for cerebrovascular disease in neurodegeneration research and focus future research on gaps in knowledge. Here we summarize the results and recommendations from this initiative. We identified data from over 90 studies including over 660000 participants many being additional to neurodegeneration data initiatives. The enthusiastic response means that cohorts from North America Australasia and the Asia Pacific Region are included creating a truly global collaborative data sharing platform linked to major national dementia initiatives. Furthermore the revised World Health Organization International Classification of Diseases version 11 should facilitate recognition of vascular-related brain damage by creating one category for all cerebrovascular disease presentations and thus accelerate identification of targets for dementia prevention. Copyright © 2016 The Authors. Published by Elsevier Inc. All rights reserved.","","","2016","10.1016/j.jalz.2016.06.004","","","medline-27490018.pdf","medline-27490018"
"Local differential privately anonymizing online social networks under hrg-based model","Gao, T. And Li, F. And Chen, Y. And Zou, X.","Ieee Transactions On Computational Social Systems","","Following the trend of online social networks (osns) data sharing and publishing, users raise serious concerns on osn privacy. Differential privacy is a mechanism to anonymize sensitive data. It employs graph abstraction models, such as the hierarchical random graph (hrg) model, to extract graph features and then add sufficient noise. However, the noise amount, determined by the sensitivity, is usually proportional to the size of the whole network. Therefore, achieving global differential privacy may harm the utility of releasing graphs. In this paper, we define the notion of group-based local differential privacy. In particular, by resolving the network into 1-neighborhood graphs and applying hrg-based methods, our scheme preserves differential privacy and reduces the noise scale on the local graphs. By deploying the grouping algorithm, our scheme abandons the attempt to anonymize every relationship to be ordinary, but we focus on the similarities in hrg models. In the final released graph, each individual user in one group is not distinguishable, which greatly enhances the osn privacy. We experimentally evaluate our approach on three real-world osns. It produces synthetic graphs that are more closely matched with the originals compared with the existing differential-privacy results. © 2014 ieee.","","","2018","10.1109/tcss.2018.2877045","","","scopus-2-s2.0-85056611254.pdf","scopus-2-s2.0-85056611254"
"Research on privacy-preserving keyword retrieval technology in cloud storage","Huang, R.-W. And Gui, X.-L. And Yu, S. And Zhuang, W.","Tongxin Xuebao/Journal On Communications","","Cloud storage provides scalable storage resources which are available everywhere. Privacy has become the key problem of cloud storage. Encryption is a well established technology for protecting sensitive data. But it makes effective data utilization and sharing a very challenging task. To solve the problem, a privacy-preserving framework of cloud storage was proposed, and a bilinear map-based search scheme on encrypted keyword (bmsek) was constructed. The performance evaluation and security analysis show that the running overhead of bmsek is smaller, and bmsek is se-mantic security and can support privacy protection and data sharing well while realizing encypted keywords retrieval.","","","2011","","","","scopus-2-s2.0-81355136267.pdf","scopus-2-s2.0-81355136267"
"Improving performance: does performance-oriented management really matter?","Lee, J.w. And Cho, Y.j. And Kim, S.e.","International Review Of Public Administration","","The last two decades have witnessed the emergence of “performance-oriented management” (pom) as a major approach to public management reform in the united states. Pom refers to management practices that share a common assumption that effective goal setting, and proper design and implementation of performance management systems are the key to high performance. Despite the prominence of pom in the practice of public management today, very little large-n empirical research has investigated the effectiveness of pom as a management reform strategy. This study seeks to fill this void by drawing on the merit principles survey 2000 data to test whether pom actually ensures the results envisioned by its advocates. The regression results show that the two core elements of pom goal setting, and performance management design and implementation are positively associated with performance dimensions such as productivity and quality of work, providing support for the idea that pom can be a performance driver in governmental settings. This study also examines whether the effect of pom is mitigated by the presence of intensive external political influences as pom skeptics suggest. The results are mixed: the effect of goal setting on performance was found to be smaller in federal agencies with high political salience than in federal agencies with low political salience;  on the other hand, the effect of performance management design and implementation was not significantly different across the two groups. Implications of these findings are discussed in relation to the issue of administrative reform and the research on governmental performance. © 2009, taylor & francis group, llc. All rights reserved.","","","2009","10.1080/12294659.2009.10805128","","","scopus-2-s2.0-77954168684.pdf","scopus-2-s2.0-77954168684"
"Mentoring clinical nurses to write for publication: strategies for success","Oman, K.s. And Mancuso, M.p. And Ceballos, K. And Makic, M.f. And Fink, R.m.","American Journal Of Nursing","","Clinical nurses often find writing a challenge, but it's important to disseminate clinical practice initiatives that result in notable patient outcomes. Nurses have a responsibility to share what they do to improve patient care. The increased emphasis on the development and evaluation of evidence-based practice has made it necessary for nurses to share best practices that are associated with improved patient outcomes. We developed a six-month writing for publication workshop series designed to teach clinical nurses about the writing process and mentor them through the stages of preparing a manuscript to submit for publication. This successful program helped novice nurse authors become published professionals and had a great impact on our organization. Copyright © 2016 wolters kluwer health, inc. All rights reserved.","","","2016","10.1097/01.naj.0000482966.46919.0f","","","scopus-2-s2.0-84964955472.pdf","scopus-2-s2.0-84964955472"
"Scientific journal portals: an investigation based on its content","Anna, J.s.","Ciencia Da Informacao","","This text intends to present the content of the journal portals and the relations of this content with the institutional and scientific development, specifically regarding the free access to knowledge movement. It is hoped that by knowing the content of the portals, it will be possible to highlight possible relations with the democratization of access, reinforcing the role of research institutions, especially universities, in this process of strengthening the philosophy of open science. The study is characterized as descriptive, as inherent characteristics of journal portals are raised, given that these environments are related to the process of free access to knowledge. The approach is mixed, since, along the methodological path, information from the literature is identified and contextualized and, at the same time, quantitative data are described, such as the number of journals in the portal, knowledge areas and qualis evaluation of journals. As for the technical investigation procedures, literature review and documentary study are adopted. The literature review used scientific articles published in the information science database (brapci). The documentary study, in turn, was conducted by consulting the websites of the portals of journals of the federal universities of the state of minas gerais: federal university of minas gerais, ouro preto, juiz de fora, sao joao del rei and triangulo mineiro. These universities were selected because they are, in this state, which provide on their institutional websites, access to the portals of journals they maintain. Also worth mentioning in the documentary research was the consultation of the sucupira platform, with the purpose of confirming the information on the qualis evaluation, considering the highest stratum obtained by the journal, in the last year of evaluation (2016). The results revealed that the constitutive elements of the five portals are disparate, although this differentiation is related to other factors not contemplated in this study, such as university size as the number of courses;  resources made available;  numbers of students, teachers and linked servers;  number of undergraduate and postgraduate courses;  partnership with funding institutions and funders, among other details and specific occurrences of the institutional context. It can be concluded that the portals of the investigated journals manifest themselves as facilitating instruments for the dissemination of the scientific knowledge produced, further expanding the flow of communication and dissemination of science among peers and with society. It was also possible to infer that these information environments are adept at the movement to open access, since the inserted journals allow access to the full text of published works, without any kind of restriction. Considering the content of the analyzed portals (number of existing journals, areas of knowledge and qualis evaluation of these journals), regarding the number of journals, the results indicated disparity between the portals, some contemplating a small number of journals, such as the ufsj portal. and uftm, which house seven and nine magazines, respectively;  and others with higher numbers, such as ufjf, with 30, and ufmg, with 62 journals. This heterogeneity may be related to the size of institutions, based on the number of courses offered, since the portals with the largest number of journals belong to institutions with the largest number of courses. This same disparity was found regarding the areas of knowledge of the journals and the qualis assessment. The portals have journals linked to different areas of knowledge, most of them with qualis evaluation. Although this evaluation has covered the journals of almost all portals, there is a predominance of the best strata in the institutions with the largest number of postgraduate courses. It is likely that this difference between the portals reflects the reality of each institution, considering, mainly, the number of courses offered, with emphasis mainly on the courses that emphasize the research process, such as the master and doctorate courses. © 2019, brazilian institute for information in science and technology. All rights reserved.","","","2019","","","","scopus-2-s2.0-85086028886.pdf","scopus-2-s2.0-85086028886"
"Using science and psychology to improve the dissemination and evaluation of scientific work","Buttliere B. T.","Frontiers in Computational Neuroscience","","Here I outline some of what science can tell us about the problems in psychological publishing and how to best address those problems. First the motivation behind questionable research practices is examined (the desire to get ahead or at least not fall behind). Next behavior modification strategies are discussed pointing out that reward works better than punishment. Humans are utility seekers and the implementation of current change initiatives is hindered by high initial buy-in costs and insufficient expected utility. Open science tools interested in improving science should team up to increase utility while lowering the cost and risk associated with engagement. The best way to realign individual and group motives will probably be to create one centralized easy to use platform with a profile a feed of targeted science stories based upon previous system interaction a sophisticated (public) discussion section and impact metrics which use the associated data. These measures encourage high quality review and other prosocial activities while inhibiting self-serving behavior. Some advantages of centrally digitizing communications are outlined including ways the data could be used to improve the peer review process. Most generally it seems that decisions about change design and implementation should be theory and data driven.","","","2014","10.3389/fncom.2014.00082","","","medline-25191261.pdf","medline-25191261"
"Data sharing between home care professionals: a feasibility study using the RAI Home Care instrument","Guthrie D. M., Pitman R., Fletcher P. C., Hirdes J. P., Stolee P., Poss J. W., Papaioannou A., Berg K., Ezekiel H. J.","BMC Geriatrics","","BACKGROUND: Across Ontario home care professionals collect standardized information on each client using the Resident Assessment for Home Care (RAI-HC). However this information is not consistently shared with those professionals who provide services in the client's home. In this pilot study we examined the feasibility of sharing data from the RAI-HC between care coordinators and service providers.\\\\\\\\rMETHODS: All participants were involved in a one-day training session on the RAI-HC. The care coordinators shared specific outputs from the RAI-HC including the embedded health index scales with their contracted physiotherapy and occupational therapy service providers. Two focus groups were held one with care coordinators (n = 4) and one with contracted service providers (n = 6). They were asked for their opinions on the positive aspects of the project and areas for improvement.\\\\\\\\rRESULTS: The focus groups revealed a number of positive outcomes related to the project including the use of a falls prevention brochure and an increased level of communication between professionals. The participants also cited multiple areas for improvement related to data sharing (e.g. time constraints data being sent in a timely fashion) and to their standard practices in the community (e.g. busy workloads difficulties in data sharing duplication of assessments between professionals).\\\\\\\\rCONCLUSIONS: Home care professionals were able to share select pieces of information generated from the RAI-HC system and this project enhanced the level of communication between the two groups of professionals. However a single information session was not adequate training for the rehabilitation professionals who do not use the RAI-HC as part of normal practice. Better education ongoing support and timely access to the RAI-HC data are some ways to improve the usefulness of this information for busy home care providers.","","","2014","10.1186/1471-2318-14-81","","","medline-24975375.pdf","medline-24975375"
"A model for an undergraduate research experience program in quantitative sciences","Tan K. S., Elkin E. B., Satagopan J. M.","Journal of Statistics & Data Science Education","","We developed a summer research experience program within a freestanding comprehensive cancer center to cultivate undergraduate students with an interest in and an aptitude for quantitative sciences focused on oncology. This unconventional location for an undergraduate program is an ideal setting for interdisciplinary training in the intersection of oncology statistics and epidemiology. This paper describes the development and implementation of a hands-on research experience program in this unique environment. Core components of the program include faculty-mentored projects instructional programs to improve research skills and domain knowledge and professional development activities. We discuss key considerations such as effective partnership between research and administrative units recruiting students and identifying faculty mentors with quantitative projects. We describe evaluation approaches and discuss post-program outcomes and lessons learned. In its initial two years the program successfully improved students' perception of competence gained in research skills and statistical knowledge across several knowledge domains. The majority of students also went on to pursue graduate degrees in a quantitative field or work in oncology-centric academic research roles. Our research-based training model can be adapted by a variety of organizations motivated to develop a summer research experience program in quantitative sciences for undergraduate students.","","","2022","10.1080/26939169.2021.2016036","","","medline-35722171.pdf","medline-35722171"
"Guidelines for reporting the results of experiments on fish","Brattelid T., Smith A. J.","Laboratory Animals","","A detailed account of experimental design including an accurate description of the animals used is an essential part of good research practice. Without these details the reader will be unable not only to form an opinion on the significance of the findings but also to repeat the experiment in another laboratory. This paper presents suggested guidelines for reporting experimental studies using fish.","","","2000","10.1258/002367700780457590","","","medline-10817451.pdf","medline-10817451"
"Geoinformatics: toward an integrative view of earth as a system","Sinha, A.k. And Thessen, A.e. And Barnes, C.g.","Special Paper Of The Geological Society Of America","","Synergy between science and informatics is required to develop a more robust understanding of the earth as a system of systems. Interaction of earth systems is recorded in both geological and biological data, yet the capability to integrate across disciplines is hampered by diverse social and technological approaches to research and communication. Ontology-based informatics provides the ability to share, access, and discover data across disciplines. This ability will lead to data integration and new models that enable evaluation of past, present, and future changes associated with earth systems. Signifi cant challenges that must be met in order to promote such an understanding encompass social and technical considerations, such as professional credit for data sharing, development of data registration services for ready access to heterogeneous and distributed data, and development of new approaches for evaluating trust and security in a web environment. Integration of data from different scientific disciplines will require development and management of new earth system ontologies. If done properly, this development will not only enable but engage the next generation workforce. © 2013 the geological society of america. All rights reserved.","","","2013","10.1130/2013.2500(19)","","","scopus-2-s2.0-84887705726.pdf","scopus-2-s2.0-84887705726"
"Leveraging the electronic medical record to measure fidelity to the primary care behavioral health model: implications for clinical and research pursuits","Dueweke, A.r. And Tolliver, M. And Archer, A. And Polaha, J.","Families, Systems And Health","","Introduction: the primary care behavioral health (pcbh) model of integration has been widely implemented across a number of noteworthy health care systems. However, lack of consistent measurement and reporting of the degree to which the pcbh model has been implemented as developers intended has resulted in two disadvantages in the field. First, clinical quality improvement efforts are hampered by lack of clear guidance on what elements are central to pcbh implementation. Second, the dearth of empirical studies reporting model fidelity impedes cross-study comparisons and limits the rigor of pcbhfocused research. Efforts to expand measurement of pcbh model fidelity would benefit from identification of accessible, unbiased metrics that could complement existing selfreport measures. Method: in this article, we describe how we partnered with our clinical informatics team to incorporate pcbh fidelity metrics into the electronic medical record (emr), allowing for monthly extraction and review of these data. Results: next, we describe how we have used monthly fidelity monitoring to inform clinical quality improvement efforts in the context of a developing integrated care program and provide an example of how pcbh fidelity data might be reported in a research article. Discussion: leveraging emr data to support pcbh fidelity measurement has the potential to strengthen clinical quality improvement efforts and enable more consistent measurement and reporting of pcbh fidelity data in research. Future efforts should aim to parse out the relative contribution of different variables to the success of pcbh integration and evaluate the effectiveness of implementation strategies at supporting high fidelity © 2023 american psychological association","","","2023","10.1037/fsh0000778","","","scopus-2-s2.0-85147037116.pdf","scopus-2-s2.0-85147037116"
"Patients' experiences towards the donation of their residual biological samples and the impact of these experiences on the type of consent given for secondary use: A systematic review","Wai C. T., Mackey S. J., Hegney D. G.","JBI Library of Systematic Reviewis","","EXECUTIVE SUMMARY: Background Residual or leftover clinical tissues are valuable resources for biomedical research. There is on-going discussion about the methodological legal and ethical issues on the collection storage and use of these tissues for future research. This systematic review will consider qualitative studies previously conducted which report on patients' preferences experiences and willingness to donate their tissues.Objectives The aim of this review was to critically appraise synthesize and present the best available evidence related to the experiences of patients toward consent when donating their leftover tissue for research. Search strategy The search strategy aimed to find both published and unpublished studies. A three-step search strategy was utilized. An initial limited search of MEDLINE and CINAHL was undertaken followed by analysis of text words contained in the title and abstract and of the index terms used to describe the article. A second search using all identified keywords and index terms was then undertaken across all included databases. Thirdly the reference lists of all identified reports and articles were searched for additional studies.Data collection & analysis The standardised data extraction tool from the Joanna Briggs Institute Qualitative Assessment and Review Instrument (JBI-QARI) was used to extract data from each paper. The qualitative research findings were presented as thematic pooling using the JBI-QARI approach in a narrative form. During the analysis 131 study findings from 18 publications were aggregated into 19 categories to form four synthesized findings.Main results The synthesized findings generated were: (1) Healthcare professionals should be aware that patients' consent to the use of their left-over tissues are influenced by many and varied factors. Primarily these factors included: benefits to self and other and trust in research and researchers; (2) Healthcare institutions and regulatory authorities must provide strict safeguards and controls in order to maintain privacy and confidentiality of the patients; (3) Healthcare professionals should be aware that the views on ownership and rights to the tissues will vary between individual patients; (4) Healthcare professionals institutions and regulatory authorities should be aware that patients have different views on the commercial use of their tissues.Discussion Patients would prefer that institutions requesting donation of leftover tissues establish a good governance system for the collection and storage of tissues as well as a system for protecting the rights and confidentiality of patients. Most patients prefer to have an ethical and effective system which decides the future use of their tissues especially when a full informed consent is not obtained from the patients at time of donation and subsequent use.Implications for Practice The results from this review can assist researchers and policy makers to understand the experiences of patients and their attitudes and preferences on the collection storage distribution and use of their leftover tissue for research. This is especially so when designing a prospective model of consent regimen to respect patients' needs and make recommendations for the use of existing and previously collected biological samples with no consent taken.Implications for Research Further qualitative research can be undertaken to ascertain patients' expectations when they donate their tissues; the type of consent model to be used; the perceived risks of genetic and stem cells research; and the effects of culture religion and age on patients' willingness to donate their leftover tissues for future research.","","","2011","","","","medline-27820581.pdf","medline-27820581"
"Comparative evaluation of mass spectrometry platforms used in large-scale proteomics investigations","Elias J. E., Haas W., Faherty B. K., Gygi S. P.","Nature Methods","","Researchers have several options when designing proteomics experiments. Primary among these are choices of experimental method instrumentation and spectral interpretation software. To evaluate these choices on a proteome scale we compared triplicate measurements of the yeast proteome by liquid chromatography tandem mass spectrometry (LC-MS/MS) using linear ion trap (LTQ) and hybrid quadrupole time-of-flight (QqTOF; QSTAR) mass spectrometers. Acquired MS/MS spectra were interpreted with Mascot and SEQUEST algorithms with and without the requirement that all returned peptides be tryptic. Using a composite target decoy database strategy we selected scoring criteria yielding 1% estimated false positive identifications at maximum sensitivity for all data sets allowing reasonable comparisons between them. These comparisons indicate that Mascot and SEQUEST yield similar results for LTQ-acquired spectra but less so for QSTAR spectra. Furthermore low reproducibility between replicate data acquisitions made on one or both instrument platforms can be exploited to increase sensitivity and confidence in large-scale protein identifications.","","","2005","10.1038/nmeth785","","","medline-16118637.pdf","medline-16118637"
"Status reporting completeness and methodological quality of pilot randomised controlled trials in acupuncture: protocol for a systematic review","Zhang Y., Hu H., Li X., Lou J., He X., Jiang Y., Fang J.","BMJ Open","","INTRODUCTION: To date there has been a lack of knowledge about the status reporting completeness and methodological quality of pilot trials in the acupuncture field. Thus this systematic review protocol aims to: (1) investigate publication trends and aspects of feasibility evaluated in acupuncture pilot trials; (2) identify the proportion of acupuncture pilot trials that lead to definitive trials and (3) assess the reporting completeness and methodological quality of pilot trials in acupuncture.\\\\\\\\rMETHODS AND ANALYSIS: Studies of acupuncture pilot randomised controlled trials published from 2011 to 2021 will be retrieved in seven databases in January 2022 including PubMed Web of Science EMBASE Cochrane Library Chinese National Knowledge Infrastructure Wanfang Database and Chinese Biomedical Literature Database. The methodological quality and reporting completeness of all included studies will be assessed using the risk of bias 2.0 tool (RoB 2) and the Consolidated Standards of Reporting Trials (CONSORT) extension to randomised pilot and feasibility trials respectively. For the primary analysis publication trends aspects of feasibility and the proportion of pilot trials that lead to definitive trials will be analysed. A quantitative analysis of the methodological quality and reporting completeness of the included trials will be implemented by calculating the percentage of items reported in each domain of RoB 2 and CONSORT. The secondary analysis will adopt a regression analysis to identify factors associated with the reporting completeness.\\\\\\\\rETHICS AND DISSEMINATION: Ethical approval is not required for this study. This study is planned to be submitted to a peer-reviewed academic journal. Copyright © Author(s) (or their employer(s)) 2021. Re-use permitted under CC BY. Published by BMJ.","","","2021","10.1136/bmjopen-2021-052528","","","medline-34862291.pdf","medline-34862291"
"Random disclosure in confidential statistical databases","Lenz, R. And Hochgürtel, T.","Statistical Journal Of The Iaos","","As part of statistical disclosure control national statistical offices can only deliver confidential data being sufficiently protected meeting national legislation. When releasing confidential microdata to users, data holders usually apply what are called anonymisation methods to the data. In order to fulfil the privacy requirements, it is possible to measure the level of privacy of some confidential data file by simulating potential data intrusion scenarios matching publicly or commercially available data with the entire set of confidential data, both sharing a non-empty set of variables (quasi-identifiers). According to real world microdata, incompatibility between data sets and not unique combinations of quasi-identifiers are very likely. In this situation, it is nearly impossible to decide whether or not two records refer to the same underlying statistical unit. Even a successful assignment of records may be a fruitless disclosure attempt, if a rationale data intruder would keep distance from that match. The paper lines out that disclosure risks estimated thus far are overrated in the sense that revealed information is always a combination of both, systematically derived results and non-negligible random assignment. © 2021 - ios press. All rights reserved.","","","2021","10.3233/sji-200704","","","scopus-2-s2.0-85103497873.pdf","scopus-2-s2.0-85103497873"
"Randomized controlled trials in the journal of sexual medicine: a quality assessment and relevant clinical impact","Jo J. K., Chung J. H., Kim K. S., Lee J. W., Lee S. W.","Journal of Sexual Medicine","","INTRODUCTION: Quality assessment of randomized clinical trials (RCTs) is important to prevent the adoption of findings of low-quality trials into clinical practice.\\\\\\\\rAIM: The aim if this study was to analyze the quality of studies reporting RCTs in the Journal of Sexual Medicine (JSM) and to find relevant clinical impact.\\\\\\\\rMETHODS: A quality assessment was conducted in all studies identified as RCTs published in the JSM from 2004 to 2012. The review period was divided into three periods: early (2004-2006) mid (2007-2009) and late (2010-2012).\\\\\\\\rMAIN OUTCOME MEASURES: The Jadad scale van Tulder scale and the Cochrane Collaboration Risk of Bias Tool (CCRBT) quality scoring instruments were used. The RCTs were also categorized by country of origin topic the inclusion of institutional review board (IRB) approval funding citation rate and impact factor.\\\\\\\\rRESULTS: A total of 2418 original articles were published in the JSM during the review period and 188 were reports of RCTs. There were 39 (14.89%) 70 (7.77%) and 76 (6.29%) RCTs published during the early mid and late terms respectively (P < 0.001). No significant increases in Jadad or van Tulder scale scores were found over time nor were there any significant changes in the number of low-risk articles as assessed by the CCRBT. However significant differences in quality analysis were found in funding and IRB approval. Citation rates and impact factor were not correlated with RCT quality using any of the tools.\\\\\\\\rCONCLUSIONS: The number of original articles and RCTs published in the JSM increased over time. However the ratio of RCTs to original articles did not increase significantly. Adequate randomization and blinding methods IRB review and financial support are required for the conduct of high-quality RCTs. Copyright © 2014 International Society for Sexual Medicine.","","","2014","10.1111/jsm.12455","","","medline-24548282.pdf","medline-24548282"
"The prevalence of and factors influencing statistical testing of baseline characteristics in randomized controlled trials published in high-impact orthodontic journals","Alduwaisan A., Hirst L., Cobourne M. T., Pandis N., Seehra J.","American Journal of Orthodontics & Dentofacial Orthopedics","","INTRODUCTION: When proper randomization has been undertaken statistical testing of baseline characteristics between participants in trial arms in randomized controlled trials (RCTs) is not required. This investigation aimed to assess the prevalence of statistical testing of baseline differences in orthodontic RCTs. Factors influencing the undertaking of this analysis were explored.\\\\\\\\rMETHODS: Orthodontic RCTs published between January 1 2017 and December 31 2021 in 5 orthodontic journals were identified. To determine if statistical testing of baseline differences had been undertaken each article was reviewed in detail to identify the reporting of P values and the term ""significant difference"" in the table of characteristics the table legends and the results section of each included RCT. Trial characteristics at the RCT level were extracted. Frequency distributions were calculated for the included trial characteristics. Significant predictors from the univariate analysis were used to construct a multivariable Bayesian logistic regression model.\\\\\\\\rRESULTS: One hundred and thirty-two RCTs were analyzed. Significance testing of baseline characteristics was undertaken in 50% (66/132) of RCTs. At a journal level significance testing at baseline was infrequently undertaken in RCTs published in the American Journal of Orthodontics and Dentofacial Orthopedics (AJODO). Compared with 2017 RCTs published in 2018 (odds ratio [OR] 5.57; 95% credible interval [CrI] 1.33-25.69) 2019 (OR 17.82; 95% CrI 4.41-82.11) 2020 (OR 6.48; 95% CrI 1.72-27.12) and 2021 (OR 3.24 95% CrI 0.81-14.01) had higher odds of significance testing at baseline. RCTs published in the European Journal of Orthodontics (OR 5.31; 95% CrI 1.79-17.04) Progress in Orthodontics (OR 5.00; 95% CrI 0.97-28.43) Orthodontics and Craniofacial Research (OR 6.49; 95% CrI 1.04-46.10) and Angle Orthodontist (OR 12.30; 95% CrI 3.27-51.44) had higher odds of significant testing at baseline testing compared with AJODO.\\\\\\\\rCONCLUSIONS: Statistical testing of baseline differences is common in orthodontic RCTs. Trials published in AJODO had the lowest incidence of statistical testing of baseline differences. RCTs published between 2018-2021 had higher odds of significance testing at baseline than in 2017. Per the consolidated standards of reporting trials guidelines this practice should be discouraged as it can be misleading and unnecessary. Copyright © 2022 American Association of Orthodontists. Published by Elsevier Inc. All rights reserved.","","","2023","10.1016/j.ajodo.2022.12.005","","","medline-36599785.pdf","medline-36599785"
"Timely access to trial data in the context of a pandemic: the time is now","Li R. And Wood J. And Baskaran A. And Neumann S. And Graham E. And Levenstein M. And Sim I.","Bmj Open","","Objective clinical trial data sharing has the potential to accelerate scientific progress, answer new lines of scientific inquiry, support reproducibility and prevent redundancy. Vivli, a non-profit organisation, operates a global platform for sharing of individual participant-level trial data and associated documents. Sharing of these data collected from each trial participant enables combining of these data to drive new scientific insights or assess reproducibility-not possible with the aggregate or summary data tables historically made available. We report on our initial experience including key metrics, lessons learned and how we see our role in the data sharing ecosystem. We also describe how vivli is addressing the needs of the covid-19 challenge through a new dedicated portal that provides a direct search function for covid-19 studies, availability for fast-tracked request review and data sharing. Data summary the vivli platform was established in 2018 and has partnered with 28 diverse members from industry, academic institutions, government platforms and non-profit foundations. Currently, 5400 trials representing 3.6 million participants are shared on the platform. From july 2018 to september 2020, vivli received 201 requests. To date, 106 of 201 requests received approval, 5 have been declined, 27 withdrew and 27 are in the revision stage. Conclusions the pandemic has only magnified the necessity for data sharing. If most data are shared and in a manner that allows interoperability, then we have hope of moving towards a cohesive scientific understanding more quickly not only for covid-19 but also for all diseases. Conversely, if only isolated pockets of data are shared then society loses the opportunity to close vital gaps in our understanding of this rapidly evolving epidemic. This current challenge serves to highlight the value of data sharing platforms-critical enablers that help researchers build on prior knowledge.copyright © 2020 author(s) (or their employer(s)). Re-use permitted under cc by-nc. No commercial re-use. See rights and permissions. Published by bmj.","","","2020","10.1136/bmjopen-2020-039326","","","embase-633256439.pdf","embase-633256439"
"The myth of academics’ non-interference in legislatures","Zelizer, A.","Political Studies Review","","This essay discusses the history and ethics of academics’ intervention in the legislative process. Academics, and even our professional associations, have explicitly worked to change legislative operations through advocacy and consulting. I argue that subjecting such interventions to the research process to evaluate their effects makes them more ethical and transparent. Research is monitored and guided by professional associations, institutional review boards, and journals in ways that advocacy and consulting are not. If academics are already intervening in legislative processes, such efforts will be more fruitful if conducted as part of a research program. This program, which i call “evidence-based legislating,” aims to improve the evaluation of legislative processes just as the movement for evidence-based policymaking reshaped academics’ and lawmakers’ approach to policy evaluation. © the author(s) 2022.","","","2022","10.1177/14789299221076700","","","scopus-2-s2.0-85126056257.pdf","scopus-2-s2.0-85126056257"
"Retrofittar: supporting hardware-centered expertise sharing in manufacturing settings through augmented reality","Hoffmann, S. And Ludwig, T. And Jasche, F. And Wulf, V. And Randall, D.","Computer Supported Cooperative Work: Cscw: An International Journal","","Since almost the onset of computer-supported cooperative work (cscw), the community has been concerned with how expertise sharing can be supported in different settings. Here, the complex handling of machines based on experience and knowledge is increasingly becoming a challenge. In our study, we investigated expertise sharing in a medium-sized manufacturing company in an effort to support the fostering of hardware-based expertise sharing by using augmented reality (ar) to ‘retrofit’ machines. We, therefore, conducted a preliminary empirical study to understand how expertise is shared in practice and what current support is available. Based on the findings, we derived design challenges and implications for the design of ar systems in manufacturing settings. The main challenges, we found, had to do with existing socio-technical infrastructure and the contextual nature of expertise. We implemented a hololens application called retrofittar that supports learning on the production machine during actual use. We evaluated the system during the company’s actual production process. The results show which data types are necessary to support expertise sharing and how our design supports the retrofitting of old machines. We contribute to the current state of research in two ways. First, we present the knowledge-intensive practice of operating older production machines through novel ar interfaces. Second, we outline how retrofitting measures with new visualisation technologies can support knowledge-intensive production processes. © 2022, the author(s).","","","2023","10.1007/s10606-022-09430-x","","","scopus-2-s2.0-85133172083.pdf","scopus-2-s2.0-85133172083"
"NVStream: Accelerating HPC workflows with NVRAM-based transport for streaming objects","Fernando P., Gavrilovska A., Kannan S., Eisenhauer G.","","","Nonvolatile memory technologies (NVRAM) with larger capacity relative to DRAM and faster persistence relative to block-based storage technologies are expected to play a crucial role in accelerating I/O performance for HPC scientific workflows. Typically a scientific workflow includes a simulation process (producer of data) and an analytics application process (consumer of data) that stream share and exchange data supported by an underlying OS-level file system. However using an OS-level file system for data sharing adds substantial software overheads due to frequent system calls journaling (for crash-consistency) cost and file-system metadata update cost. To overcome these challenges we design NVStream– a lightweight user-level data management system that exploits NVRAMs byte addressability and fast persistence to support streaming I/O in scientific workflows. First NVStream reduces I/O-related software overheads by designing a memory-based persistent object store and log-structured heap manager that exploit NVRAM’s large capacity. Second NVStream incorporates a hardware-assisted non-temporal stores for crash-consistent updates at near hardware data copy (memory copy) speeds. Finally NVStream reduces data written to NVRAM with a delta compression which further reduces I/O cost for workflows with higher write locality. The evaluation of NVStream using I/O benchmarks and scientific applications demonstrates 10× reduction in I/O compared to NVRAM-optimized file systems and also guaranteeing crash-consistent data movement. © 2018 Copyright held by the owner/author(s).","","","2018","10.1145/3208040.3208061","","","scopus-2-s2.0-85050080679.pdf","scopus-2-s2.0-85050080679"
"A portable application for supporting aba intervention","Manduchi, R. And Coughlan, J. And Miesenberger, K. And Artoni, S. And Mencarini, S. And Claudia Buzzi, M. And Buzzi, M. And Fenili, C. And Leporini, B. And Senette, C.","Journal Of Assistive Technologies","","Applied behavior analysis (aba) is a scientific method for modelling human behavior, successfully applied in the context of autism. Recording and sharing measurable data (on subjects’ performance) between caregivers guarantees consistency of learning programs and allows monitoring the learning enhancements. Data are usually recorded on paper, which requires considerable effort and is subject to error. The purpose of this paper is to describe a portable application developed to support aba tutors in their work with autistic subjects. It allows gathering data from aba sessions, giving tutors rapid access to information, also in graphical formats. The tool was designed via participatory design. Various aba team members were involved, in order to make the application respond perfectly to their needs. The approach aims to ensure maximum usability, while minimizing errors and ambient interference. The use of mobile devices (i.e. tablets or smartphones) allows mobility and ease of interaction, enabling efficient data collection and processing. Data plotting allows one to easily interpret gathered data. The proposed application, free open source software, can be a valuable aid for supporting the aba intervention and favor the inclusion of children with autism. Available software to assist tutors during therapy sessions is often proprietary, and research prototypes are not freely available, so paper forms are still widespread. Besides, without attention to usability requirements, assisting tools would be comparable in efficiency with data insertion on paper. Our software was specifically designed following aba principles and favors efficient data entry allowing natural interaction with touch screen interfaces: drag and drop, taps and gestures. Furthermore, it is shared in the public domain. © 2013, emerald group publishing limited. All rights reserved.","","","2013","10.1108/17549451311328763","","","scopus-2-s2.0-84879707167.pdf","scopus-2-s2.0-84879707167"
"Length matters: Improved high field EEG-fMRI recordings using shorter EEG cables","Assecondi S., Lavallee C., Ferrari P., Jovicich J.","Journal of Neuroscience Methods","","BACKGROUND: The use of concurrent EEG-fMRI recordings has increased in recent years allowing new avenues of medical and cognitive neuroscience research; however currently used setups present problems with data quality and reproducibility.\\\\\\\\rNEW METHOD: We propose a compact experimental setup for concurrent EEG-fMRI at 4T and compare it to a more standard reference setup. The compact setup uses short EEG cables connecting to the amplifiers which are placed right at the back of the head RF coil on a form-fitting extension force-locked to the patient MR bed. We compare the two setups in terms of sensitivity to MR-room environmental noise interferences between measuring devices (EEG or fMRI) and sensitivity to functional responses in a visual stimulation paradigm.\\\\\\\\rRESULTS: The compact setup reduces the system sensitivity to both external noise and MR-induced artefacts by at least 60% with negligible EEG noise induced from the mechanical vibrations of the cryogenic cooling compression pump.\\\\\\\\rCOMPARISON WITH EXISTING METHODS: The compact setup improved EEG data quality and the overall performance of MR-artifact correction techniques. Both setups were similar in terms of the fMRI data with higher reproducibility for cable placement within the scanner in the compact setup.\\\\\\\\rCONCLUSIONS: This improved compact setup may be relevant to MR laboratories interested in reducing the sensitivity of their EEG-fMRI experimental setup to external noise sources setting up an EEG-fMRI workplace for the first time or for creating a more reproducible configuration of equipment and cables. Implications for safety and ergonomics are discussed. Copyright © 2016 Elsevier B.V. All rights reserved.","","","2016","10.1016/j.jneumeth.2016.05.014","","","medline-27222442.pdf","medline-27222442"
"All smoke, no fire? Sharing practices and political investment in two italian cities","Polizzi, E. And Bassoli, M.","Rivista Italiana Di Scienza Politica","","The practice of sharing products, services, and other activities among people living in the same city has emerged as one of the most important waves of social innovation in recent years. However, the public and scientific debate have, to date, been mostly rhetoric and rarely relied on empirical evidence. A study of the role played by local institutions in governing the phenomenon is still lacking. This paper addresses the issue of the relationship between local governments and private actors in the sharing economy sector, exploiting the 'political exchange' approach. Departing from this governance perspective, it appraises the political exchange-and its outputs in terms of co-operation-underlying the governing structures in two italian cases between 2014 and 2018. We thus bridge the gap between a theoretical understanding of the sharing economy and empirical cases, providing scholars with a framework to study this phenomenon which highlights the crucial impact of the political investment of public institutions. Copyright © 2019 società italiana di scienza politica.","","","2020","10.1017/ipo.2019.12","","","scopus-2-s2.0-85080127628.pdf","scopus-2-s2.0-85080127628"
"Reproducibility of a test for the functional evaluation of dynamic balance and agility in elderly people","Fonseca, A.a. And García, C.l.a. And Collante, M.c.b. And Patiño, J.p. And Santisteban, R.n.r. And Carrascal, Y.t.a.","Iatreia","","Background: the 8 foot up & go test assesses the dynamic balance and agility in elderly people. Its reproducibility has been evaluated in american population, but it is unknown whether it would work similarly in a different population like the colombian. Objective: to evaluate the test-retest reliability and agreement level of the 8 foot up & go test in a sample of older adults from bucaramanga, colombia. Materials and methods: an evaluation of diagnostic tests was done in 114 elderly individuals. In the analysis, we assessed the test-retest reliability of the 8 foot up & go test by the intraclass correlation coefficient (icc 2.1) with their respective confidence intervals at 95% (95% ci). The agreement level was established by the bland-altman method. Results: the test-retest reliability of the 8 foot up & go test was very good (icc: 0.98;  95% ci: 0.98- 0.99). The agreement was good in females (mean difference [md] = 0.04 seconds and limits of agreement [la]: -1.27;  1.36 seconds), and in elderly institutionalized (md = 0.04 seconds [la]: -3.18;  3.27 seconds). Conclusion: the 8 foot up & go test has very good reliability and good agreement in colombian local elderly population.","","","2014","","","","scopus-2-s2.0-84903194024.pdf","scopus-2-s2.0-84903194024"
"Characterizing Mystery Cell Lines: Student-driven Research Projects in an Undergraduate Neuroscience Laboratory Course","Lemons M. L.","Journal of Undergraduate Neuroscience Education : JUNE : A Publication of FUN Faculty for Undergraduate Neuroscience","","Inquiry-based projects promote discovery and retention of key concepts increase student engagement and stimulate interest in research. Described here are a series of lab exercises within an undergraduate upper level neuroscience course that train students to design execute and analyze their own hypothesis-driven research project. Prior to developing their own projects students learn several research techniques including aseptic cell culture cell line maintenance immunocytochemistry and fluorescent microscopy. Working in groups students choose how to use these techniques to characterize and identify a ""mystery"" cell line. Each lab group is given a unique cell line with either a neural astrocyte or Schwann cell origin. Working together students plan and execute experiments to determine the cellular origin and other unique characteristics of their mystery cell line. Students generate testable hypotheses design interpretable experiments generate and analyze data and report their findings in both oral and written formats. Students receive instructor and peer feedback throughout the entire project. In summary these labs train students the process of scientific research. This series of lab exercises received very strong positive feedback from the students. Reflections on student feedback and plans for future improvements are discussed.","","","2012","","","","medline-23504583.pdf","medline-23504583"
"""You Measure Us and You Depress Us"": Healthism and the Subjective Impact of Body Measurements on Secondary School Students","Beltran-Carrillo V. J., Jimenez-Loaisa A., Gonzalez-Cutre D., Sierra A. C., Valenciano-Valcarcel J.","Qualitative Health Research","","This study explores adolescents' subjective experiences when facing body measurements at school performed to evaluate the effects of a school-based intervention to promote physical activity. Three semi-structured interviews (n = 3) and two focus groups (n = 7 and 3) were conducted with adolescents after measuring some variables related to their weight and adiposity. Observational data (n = 88) collected by the two researchers in charge of the measurements were also obtained. Findings derived from our thematic analysis question the suitability of body measurements as social contexts where the core ideas of healthism emerge. Some adolescents lived body measurements as negative social experiences promoting body dissatisfaction social comparison embarrassment and simplistic associations between health and body shape which could hinder their adherence to healthy habits. We emphasize the role of qualitative research when evaluating pre/posttests of school-based intervention studies not just the interventions themselves to generate knowledge to improve research protocols and prevent unwanted psychological outcomes in participants.","","","2023","10.1177/10497323231152155","","","medline-36715082.pdf","medline-36715082"
"Interrelationships Between Patients' Data Tracking Practices Data Sharing Practices and Health Literacy: Onsite Survey Study","Luo Y., Oh C. Y., Jean B. S., Choe E. K.","Journal of Medical Internet Research","","BACKGROUND: Although the use of patient-generated data (PGD) in the optimization of patient care shows great promise little is known about whether patients who track their PGD necessarily share the data with their clinicians. Meanwhile health literacy-an important construct that captures an individual's ability to manage their health and to engage with their health care providers-has often been neglected in prior studies focused on PGD tracking and sharing. To leverage the full potential of PGD it is necessary to bridge the gap between patients' data tracking and data sharing practices by first understanding the interrelationships between these practices and the factors contributing to these practices.\\\\\\\\rOBJECTIVE: This study aims to systematically examine the interrelationships between PGD tracking practices data sharing practices and health literacy among individual patients.\\\\\\\\rMETHODS: We surveyed 109 patients at the time they met with a clinician at a university health center unlike prior research that often examined patients' retrospective experience after some time had passed since their clinic visit. The survey consisted of 39 questions asking patients about their PGD tracking and sharing practices based on their current clinical encounter. The survey also contained questions related to the participants' health literacy. All the participants completed the survey on a tablet device. The onsite survey study enabled us to collect ecologically valid data based on patients' immediate experiences situated within their clinic visit.\\\\\\\\rRESULTS: We found no evidence that tracking PGD was related to self-reports of having sufficient information to manage one's health; however the number of data types participants tracked positively related to their self-assessed ability to actively engage with health care providers. Participants ' data tracking practices and their health literacy did not relate to their data sharing practices; however their ability to engage with health care providers positively related to their willingness to share their data with clinicians in the future. Participants reported several benefits of and barriers to sharing their PGD with clinicians.\\\\\\\\rCONCLUSIONS: Although tracking PGD could help patients better engage with health care providers it may not provide patients with sufficient information to manage their health. The gaps between tracking and sharing PGD with health care providers call for efforts to inform patients of how their data relate to their health and to facilitate efficient clinician-patient communication. To realize the full potential of PGD and to promote individuals' health literacy empowering patients to effectively track and share their PGD is important-both technologies and health care providers can play important roles. Copyright ©Yuhan Luo Chi Young Oh Beth St Jean Eun Kyoung Choe. Originally published in the Journal of Medical Internet Research (http://www.jmir.org) 22.12.2020.","","","2020","10.2196/18937","","","medline-33350960.pdf","medline-33350960"
"Impacts of data synthesis: a metric for quantifiable data standards and performances","Chandra, G. And Siirtola, P. And Tamminen, S. And Knip, M.j. And Veijola, R. And Röning, J.","Data","","Clinical data analysis could lead to breakthroughs. However, clinical data contain sensitive information about participants that could be utilized for unethical activities, such as blackmailing, identity theft, mass surveillance, or social engineering. Data anonymization is a standard step during data collection, before sharing, to overcome the risk of disclosure. However, conventional data anonymization techniques are not foolproof and also hinder the opportunity for personalized evaluations. Much research has been done for synthetic data generation using generative adversarial networks and many other machine learning methods;  however, these methods are either not free to use or are limited in capacity. This study evaluates the performance of an emerging tool named synthpop, an r package producing synthetic data as an alternative approach for data anonymization. This paper establishes data standards derived from the original data set based on the utilities and quality of information and measures variations in the synthetic data set to evaluate the performance of the data synthesis process. The methods to assess the utility of the synthetic data set can be broadly divided into two approaches: general utility and specific utility. General utility assesses whether synthetic data have overall similarities in the statistical properties and multivariate relationships with the original data set. Simultaneously, the specific utility assesses the similarity of a fitted model’s performance on the synthetic data to its performance on the original data. The quality of information is assessed by comparing variations in entropy bits and mutual information to response variables within the original and synthetic data sets. The study reveals that synthetic data succeeded at all utility tests with a statistically non-significant difference and not only preserved the utilities but also preserved the complexity of the original data set according to the data standard established in this study. Therefore, synthpop fulfills all the necessities and unfolds a wide range of opportunities for the research community, including easy data sharing and information protection. © 2022 by the authors.","","","2022","10.3390/data7120178","","","scopus-2-s2.0-85144599100.pdf","scopus-2-s2.0-85144599100"
"Cross-lingual acoustic modeling for under-resourced languages","Song, M. And Zhang, Q. And Pan, J. And Yan, Y.","Journal Of Computational Information Systems","","This paper presents our work on acoustic modeling for under-resourced languages. We focus on crosslingual data sharing to overcome the data scarcity problem. The cross-lingual data are shared at two levels: phone-level and model-level. Through the use of a universal phone set, we accomplish the phone-level data sharing at monophone bootstrap stage. Furthermore, by using shared-hidden-layer multilingual deep neural networks (shl-mdnn), we accomplish the model-level data sharing in deep neural networks (dnns) training for acoustic modeling. In this paper, the effectiveness of this twolevel cross-lingual data sharing is verified on conversational speech recognition task for under-resourced japanese. With only 5 hours japanese speech data, the character error rates (cers) for the conventional monolingual hmm/gmm (hidden markov model/gaussian mixture model) and hmm/dnn (hidden markov model/deep neural network) systems are 82.9% and 71.0%. With the two-level cross-lingual sharing of about 300 hours speech data comes from three source languages (chinese, english and korean), the cers are significantly reduced to 78.1% and 52.1% respectively. ©, 2015, journal of computational information systems. All right reserved.","","","2015","10.12733/jcis14543","","","scopus-2-s2.0-84940755538.pdf","scopus-2-s2.0-84940755538"
"How statistical concepts facilitate evaluation of corrosion inhibitors","Nathan Cc And Dulaney Cl","Mater Prot Performance","","For years it has been difficult for those working in the field of corrosion to obtain reproducible corrosion test data. Often systems using inhibitors presented particular problems with interpretation. This paper discusses equations which can be useful in calculating reproducibility of test data. A mathematical treatment based on probability concepts has been found to give a good approximation to the observed parabolic relation. The requirement of 90% inhibitor effectiveness with good reproducibility may be considered a safety factor in measurement and application in order to increase the probability of developing useful information. As such, additional costs of the methods suggested are believed to be well justified.","","","1971","","","","scopus-2-s2.0-0015009337.pdf","scopus-2-s2.0-0015009337"
"Extracting enhanced artificial intelligence model metadata from software repositories","Tsay, J. And Braz, A. And Hirzel, M. And Shinnar, A. And Mummert, T.","Empirical Software Engineering","","While artificial intelligence (ai) models have improved at understanding large-scale data, understanding ai models themselves at any scale is difficult. For example, even two models that implement the same network architecture may differ in frameworks, datasets, or even domains. Furthermore, attempting to use either model often requires much manual effort to understand it. As software engineering and ai development share many of the same languages and tools, techniques in mining software repositories should enable more scalable insights into ai models and ai development. However, much of the relevant metadata around models are not easily extractable. This paper (an extension of our msr 2020 paper) presents a library called aimmx for ai model metadata extraction from software repositories into enhanced metadata that conforms to a flexible metadata schema. We evaluated aimmx against 7,998 open-source models from three sources: model zoos, arxiv ai papers, and state-of-the-art ai papers. We also explored how aimmx can enable studies and tools to advance engineering support for ai development. As preliminary examples, we present an exploratory analysis for data and method reproducibility over the models in the evaluation dataset and a catalog tool for discovering and managing models. We also demonstrate the flexibility of extracted metadata by using the evaluation dataset in an existing natural language processing (nlp) analysis platform to identify trends in the dataset. Overall, we hope aimmx fosters research towards better ai development. © 2022, the author(s), under exclusive licence to springer science+business media, llc, part of springer nature.","","","2022","10.1007/s10664-022-10206-6","","","scopus-2-s2.0-85138474182.pdf","scopus-2-s2.0-85138474182"
"Discovery and integrative neuroscience. [Review] [71 refs]","Koslow S. H.","","","Hypothesis driven research has been shown to be an excellent model for pursuing investigations in neuroscience. The Human Genome Project demonstrated the added value of discovery research especially in areas where large amounts of data are produced. Neuroscience has become a data rich field and one that would be enhanced by incorporating the discovery approach. Databases as well as analytical modeling and simulation tools will have to be developed and they will need to be interoperable and federated. This paper presents an overview of the development of the field of neuroscience databases and associate tools: Neuroinformatics. The primary focus is on the impact of NIH funding of this process. The important issues of data sharing as viewed from the perspective of the scientist and private and public funding organizations are discussed. Neuroinformatics will provide more than just a sophisticated array of information technologies to help scientists understand and integrate nervous system data. It will make available powerful models of neural functions and facilitate discovery hypothesis formulation and electronic collaboration. [References: 71]","","","2005","","","","unknown-1787.pdf","unknown-1787"
"Low-fidelity prototyping with simple collaborative tabletop computer-aided design systems","Kaya, E. And Alacam, S. And Findik, Y. And Balcisoy, S.","Computers And Graphics (Pergamon)","","Design processes encompass iterative elaboration and elimination of new and many ideas gathered from a wide range of resources. The higher the diversity of the resources, the higher the chances that the design process will bear expected outcomes. Following that idea, immense amount of effort has been devoted to the development of collaborative computer-aided design (cad) systems, and process frameworks that drive those systems. We infer from the existing literature that collaborative cad solution attempts involve holistic approaches in which all aspects of the problem (social and technical) are being addressed. As an attempt to address social and physical aspects of the problem, tabletop systems with complex structures have been proposed by the previous work. Unfortunately, such complexity comes with the lack of reproducibility of the research work, and high evaluation overhead per prototype imposing a low limit on the number of design ideas to be investigated. Sophisticated systems might be required to solve the real-world problems, however, we argue that, with simple setups, rapid collaborative iterative prototyping could be achieved. Such simple setups could lead to high number of good ideas ready to be fed into off-the-shelf cad systems lacking adequate support for collaborative design. We realized and evaluated this idea by implementing a tangible tabletop collaborative design system that facilitates fast and iterative prototype production for residential area design. Based on the case studies conducted with this setup, we show that synchronous collaboration for rapid prototyping could be achieved with lean setups, provide a list of design recommendations for such systems that we derive from our case study observations and existing literature, and finally contribute to the community with an open source tangible tabletop installation tool kit. © 2017 elsevier ltd","","","2018","10.1016/j.cag.2017.07.026","","","scopus-2-s2.0-85026490565.pdf","scopus-2-s2.0-85026490565"
"Reporting quality of social and psychological intervention trials: A systematic review of reporting guidelines and trial publications","Grant Sean P., Mayo-Wilson Evan, Melendez-Torres G., Montgomery Paul","PLoS ONE Vol 8(5) 2013 ArtID e65442","","Background: Previous reviews show that reporting guidelines have improved the quality of trial reports in medicine yet existing guidelines may not be fully suited for social and psychological intervention trials. Objective/Design: We conducted a two-part study that reviewed (1) reporting guidelines for and (2) the reporting quality of social and psychological intervention trials.","","","2013","10.1371/journal.pone.0065442","","","medline-23734256.pdf","medline-23734256"
"Leveraging proteomics in orphan disease research: pitfalls and potential","Braconi, D. And Bernardini, G. And Spiga, O. And Santucci, A.","Expert Review Of Proteomics","","Introduction: the term ‘orphan diseases’ includes conditions meeting prevalence-based or commercial viability criteria: they affect a small number of individuals and are considered an unviable market for drug development. Proteomics is an important technology to study them, providing information on mechanisms and evolution, biomarkers, and effects of therapeutic interventions. Areas covered: herein, we review how proteomics and bioinformatic tools could be applied to the study of rare diseases and discuss pitfalls and potential. Expert opinion: research in the field of rare diseases has to face many challenges, and implementation plans should foresee highly specialized collaborative consortia to create multidisciplinary frameworks for data sharing, advancing research, supporting clinical studies, and accelerating drug development. The integration of different technologies will allow better knowledge of disease pathophysiology, and the inclusion of proteomics and other omics technologies in this context will be pivotal to this aim. Several aspects of rare diseases, often perceived as limiting factors, might actually be advantages for a precision medicine approach: the limited number of patients, the collaboration with patient societies, and the availability of curated clinical registries could allow the development of homogeneous clinical databases and ultimately a better control over the data to be analyzed. © 2021 informa uk limited, trading as taylor & francis group.","","","2021","10.1080/14789450.2021.1918549","","","scopus-2-s2.0-85105241126.pdf","scopus-2-s2.0-85105241126"
"Payer reimbursement practices and incentives for improving interpretation of germline genetic testing","Deverka, P. And Geary, J. And Mathews, C. And Cohen, M. And Hooker, G. And Majumder, M. And Skvarkova, Z. And Cook-Deegan, R.","Journal Of Law And The Biosciences","","Germline genetic testing for inherited cancer risk has shifted to multi-gene panel tests (mgpts). While mgpts detect more pathogenic variants, they also detect more variants of uncertain significance (vuss) that increase the possibility of harms such as unnecessary surgery. Data sharing by laboratories is critical to addressing the vus problem. However, barriers to sharing and an absence of incentives have limited laboratory contributions to the clinvar database. Payers can play a crucial role in the expansion of knowledge and effectiveness of genetic testing. Current policies affecting mgpt reimbursement are complex and create perverse incentives. Trends in utilization and coverage for private payers and medicare illustrate opportunities and challenges for data sharing to close knowledge gaps and improve clinical utility. Policy options include making data sharing (i) a condition of payment, and (ii) a metric of laboratory quality in payment contracts, yielding preferred coverage or enhanced reimbursement. Mandating data sharing sufficient to verify interpretations and resolve discordance among labs under medicare and federal health programs is an option for the us congress. Such policies can reduce the current waste of valuable data needed for precision oncology and improved patient outcomes, enabling a learning health system. © 2023 the author(s).","","","2023","10.1093/jlb/lsad020","","","scopus-unknown-accession-4872757.pdf","scopus-unknown-accession-4872757"
"National institute of neurological disorders and stroke and department of defense sport-related concussion common data elements version 1.0 recommendations","Broglio, S.p. And Kontos, A.p. And Levin, H. And Schneider, K. And Wilde, E.a. And Cantu, R.c. And Feddermann-Demont, N. And Fuller, G.w. And Gagnon, I. And Gioia, G.a. And Giza, C. And Griesbach, G.s. And Leddy, J.j. And Lipton, M.l. And Mayer, A.r. And Mcallister, T.w. And Mccrea, M. And Mckenzie, L.b. And Putukian, M. And Signoretti, S. And Suskauer, S.j. And Tamburro, R. And Turner, M. And Yeates, K.o. And Zemek, R. And Ala'i, S. And Esterlitz, J. And Gay, K. And Bellgowan, P.s.f. And Joseph, K.","Journal Of Neurotrauma","","Through a partnership with the national institute of neurological disorders and stroke (ninds), national institutes of health, and department of defense, the development of sport-related concussion (src) common data elements (cdes) was initiated. The aim of this collaboration was to increase the efficiency and effectiveness of clinical research studies and clinical treatment outcomes, increase data quality, facilitate data sharing across studies, reduce study start-up time, more effectively aggregate information into metadata results, and educate new clinical investigators. The src cde working group consisted of 32 worldwide experts in concussion from varied fields of related expertise divided into three subgroups: acute (<72 h post-concussion), subacute (3 days-3 months post-concussion) and persistent/chronic (>3 months post-concussion). To develop cdes, the subgroups reviewed various domains, then selected from, refined, and added to existing cdes, case report forms and field-tested data elements from national registries and funded research studies. Recommendations were posted to the ninds cde website for public review from february 2017 to april 2017. Following an internal working group review of recommendations, along with consideration of comments received from the public review period, the first iteration (version 1.0) of the ninds src cdes was completed in june 2017. The recommendations include core and supplemental-highly recommended cdes for cognitive data elements and symptom checklists, as well as other outcomes and end-points (e.g., vestibular, oculomotor, balance, anxiety, depression), and sample case report forms (e.g., injury reporting, demographics, concussion history) for domains typically included in clinical research studies. The ninds src cdes and supporting documents are publicly available on the ninds cde website www.commondataelements.ninds.nih.gov. Widespread use of cdes by researchers and clinicians will facilitate consistent src clinical research and trial design, data sharing, and metadata retrospective analysis. © copyright 2018, mary ann liebert, inc., publishers.","","","2018","10.1089/neu.2018.5643","","","scopus-2-s2.0-85053208756.pdf","scopus-2-s2.0-85053208756"
"Digital contents as a tool to address research reproducibility crisis in psychology: a case study on sexual attraction under conditions of high arousal","Pizzoli, S.f.m. And Monzani, D. And Mazzocco, K. And Masiero, M. And Pravettoni, G.","Annual Review Of Cybertherapy And Telemedicine","","In the field of behavioral sciences, a crisis of the replicability of data took place. Among the reasons of the crisis, there is the difficulty of replicating some classical experimental settings and the lack of reproduced studies. Nowadays, digital contents might provide valuable opportunities to re-create specific environmental situations and manipulations in a safe and cost-saving way. The present study is a preliminary attempt to replicate the relationship between arousal manipulation and sexual attraction as it was assessed in the classical study by dutton and aron in 1974. Here, 30 male subjects will be randomly assigned to high or low arousal condition (induced with digital contents) and then asked to rate attractiveness of a female brief video. The objective of this preliminary study is to assess whether the same pattern of results from the classical study of dutton and aron will be confirmed with a virtual reprise of the experiment. Theoretical and practical implications will be discussed. © 2020, interactive media institute. All rights reserved.","","","2020","","","","scopus-2-s2.0-85113476226.pdf","scopus-2-s2.0-85113476226"
"Using blockchain and distributed machine learning to manage decentralized but trustworthy disease data","Hiwale, M. And Phanasalkar, S. And Kotecha, K.","Science And Technology Libraries","","Public health surveillance systems for infectious diseases, that can turn pandemic, need a regular intervention for diagnosis, treatment and control. For an effective disease monitoring and control system, there is a need to model a solution for organizing, sharing and analyzing the disease data with trusted, privacy-preserving and interoperable methodologies to improve the outreach, time and cost-effectiveness for disease-control and treatment interventions. Blockchain has emerged as one of the promising technologies owing to its unique features like decentralization, transparency, immutability, data provenance and cryptography. The primary aim of this study is to perform a bibliometric analysis of literature on the applications of blockchain in disease data management systems. Secondly, it is aimed to survey the suitability of existing blockchain platforms for disease data storage, sharing and analytics. This study also explored literature on the design of privacy-preserving machine learning models on blockchain applications for collaborative learning. Conclusively, the presented survey opens opportunities to the building of privacy-preserving, trusted, interoperable and inferring disease data management systems with blockchain and machine learning. © 2020 the author(s). Published with license by taylor & francis group, llc.","","","2021","10.1080/0194262x.2020.1859046","","","scopus-2-s2.0-85098713786.pdf","scopus-2-s2.0-85098713786"
"A fair and rational data sharing strategy toward two-stage industrial internet of things","Zheng, X. And Tian, L. And Cai, Z.","Ieee Transactions On Industrial Informatics","","The easy and pervasive involvement of devices in industrial internet of things has greatly benefited the implementation and adoption of various smart services. One prominent prerequisite of such trends is the extensive and continuous support and sharing of data and resources among devices. However, previous efforts usually treat the data sharing as one-time task among devices, which are incapable when the data are applied for the distributed and iterative training task of machine learning models. Therefore, this article proposes a novel framework for continuous data sharing in industrial internet of things. The system consists of different system owners, each brings devices and participate the distributed training of models. Specifically, system owners hold different scales of devices, data, and resources, while devices own heterogeneous availability in different time periods. In this case, the goal is to properly assign devices for qualified model training process in different rounds, such that no devices will devote unlimited resources and the overall efforts and consumptions among different owners are balanced. Accordingly, three algorithms for device allocation are proposed, based on whether the availability of devices in each training round are known at the beginning of the training procedure. The analysis shows that all algorithms can achieve a rational allocation for devices and balance the performance among system owners. Finally, evaluation results reveal that the proposed solutions outperform baseline methods in providing better data sharing plans. © 2005-2012 ieee.","","","2023","10.1109/tii.2022.3179361","","","scopus-2-s2.0-85131724144.pdf","scopus-2-s2.0-85131724144"
"Oruta: privacy-preserving public auditing for shared data in the cloud","Wang, B. And Li, B. And Li, H.","Ieee Transactions On Cloud Computing","","With cloud data services, it is commonplace for data to be not only stored in the cloud, but also shared across multiple users. Unfortunately, the integrity of cloud data is subject to skepticism due to the existence of hardware/software failures and human errors. Several mechanisms have been designed to allow both data owners and public verifiers to efficiently audit cloud data integrity without retrieving the entire data from the cloud server. However, public auditing on the integrity of shared data with these existing mechanisms will inevitably reveal confidential information - identity privacy - to public verifiers. In this paper, we propose a novel privacy-preserving mechanism that supports public auditing on shared data stored in the cloud. In particular, we exploit ring signatures to compute verification metadata needed to audit the correctness of shared data. With our mechanism, the identity of the signer on each block in shared data is kept private from public verifiers, who are able to efficiently verify shared data integrity without retrieving the entire file. In addition, our mechanism is able to perform multiple auditing tasks simultaneously instead of verifying them one by one. Our experimental results demonstrate the effectiveness and efficiency of our mechanism when auditing shared data integrity. © 2014 ieee.","","","2014","10.1109/tcc.2014.2299807","","","scopus-2-s2.0-84922271700.pdf","scopus-2-s2.0-84922271700"
"Analysis of publications by authors of ukrainian institutes in scopus-delisted titles","Nazarovets, S.","Learned Publishing","","In ukraine, scopus data are used to evaluate academics. Existing shortcomings in the ukrainian evaluation system allow them to publish in titles that have been delisted from scopus, and continue to use those papers as credible research output for evaluation. The purpose of this study was to analyse the publishing activity of ukrainian institutions in scopus-delisted titles (as of september 2021) in different fields between 2011 and 2020 and to attempt to appreciate how common this practice is among ukrainian authors. Scopus was sourced to collect bibliographic and citations-related data, while scival was used to analyse these data. The findings suggest that for 17 ukrainian institutions, papers from titles that have been delisted from scopus still play an important part of the publication achievement of their employees. In particular, in the field of economics, econometrics and finance, 46.92% of ukrainian papers were published in a title that was excluded from scopus. Moreover, the analysis indicated that in two ukrainian institutions, the level of citation of such papers significantly exceeds the average number of citations to scopus-indexed papers in the same year and in the same field. Given that bibliometric indicators are also used for research assessment in other eastern european countries, the results of this paper are applicable to a wider geographic context. © 2022 the author. Learned publishing © 2022 alpsp.","","","2022","10.1002/leap.1464","","","scopus-2-s2.0-85130602996.pdf","scopus-2-s2.0-85130602996"
"Toward establishing scientific credibility in acupuncture research","Riscalla, L.m.","Medical Hypotheses","","While the effectiveness of acupuncture has been established clinically, research methods and tools which are basic for establishing objective scientific credibility in medicine have been a problem in acupuncture research. Research methods developed in other areas and reported in the literature are presented which could, if applied to acupuncture research, contribute toward establishing scientific credibility in medicine. © 1979.","","","1979","10.1016/0306-9877(79)90121-x","","","scopus-2-s2.0-0018287277.pdf","scopus-2-s2.0-0018287277"
"Psychological assessment of intimate partner violence","Yaxley, R. And Norris, K. And Haines, J.","Psychiatry, Psychology And Law","","Risk assessment is a controversial area of forensic practice, yet it has become an integral part of responding to intimate partner violence (ipv). Given lethal consequences can arise from judicial decisions based on poorly executed risk assessments, it is incumbent on mental health practitioners to utilise best-practice methods and form evidence-based determinations of risk and intervention strategies. This article provides a best-practice guide to ipv risk assessment and summarises available information on the most prevalent ipv risk assessment measures for male and female offenders. The research indicates that caution is warranted as most risk assessment measures have not been normed for use outside north america or for female offenders, have small to moderate effect sizes, and a lack of adherence to administrative procedures and methodical rigour has undermined research findings. Nevertheless, structured risk assessment enhances the defensibility of expert opinion and is recommended. © 2017 the australian and new zealand association of psychiatry, psychology and law.","","","2018","10.1080/13218719.2017.1356211","","","scopus-2-s2.0-85028555975.pdf","scopus-2-s2.0-85028555975"
"Reproducibility and reliability of hypoglycaemic episodes recorded with Continuous Glucose Monitoring System (CGMS) in daily life","Hoi-Hansen T., Pedersen-Bjergaard U., Thorsteinsson B.","Diabetic Medicine","","AIM: Continuous glucose monitoring may reveal episodes of unrecognized hypoglycaemia. We evaluated reproducibility and reliability of hypoglycaemic episodes recorded in daily life by the Medtronic MiniMed Continuous Glucose Monitoring System (CGMS).\\\\\\\\rMETHODS: Twenty-nine adult patients with Type 1 diabetes underwent 6 days of continuous subcutaneous glucose monitoring applying one CGMS on each side of the abdomen. Blood glucose was measured by HemoCue B-Glucose Analyzers six times daily and two different 4-point calibration sets were generated (set A and B). Using these calibration sets CGMS raw data were recalibrated generating four different CGMS data sets [left-A (left side of abdomen calibration set A) left-B right-A and right-B]. Agreement between CGMS data sets was evaluated during hypoglycaemic events comparing CGMS readings = 2.2 mmol/l with nadir values from corresponding CGMS data sets. CGMS readings were also compared with independent self-monitored blood glucose (SMBG) values.\\\\\\\\rRESULTS: With hypoglycaemia (CGMS readings = 2.2 mmol/l) in calibration set left-A values below 3.5 mmol/l were present in 99% (95% CI: 95-100%) of samples in left-B 91% (95% CI: 84-96%) of samples in right-A and 90% (95% CI: 83-95%) of samples in right B. In 84% of these episodes (95% CI: 59-96%) independent SMBG values were below 3.5 mmol/l. Difference in duration was observed with a median difference of 20 min; (left-A vs. right-B).\\\\\\\\rCONCLUSION: Hypoglycaemic episodes recorded by CGMS are reproducible and agreement with independent SMBG values is acceptable for retrospective recording of hypoglycaemic events with CGMS.","","","2005","10.1111/j.1464-5491.2005.01552.x","","","medline-15975099.pdf","medline-15975099"
"The development and electronic delivery of case-based learning using a fast healthcare interoperability resource system","Braunstein, M.l. And Oancea, I. And Barry, B.k. And Darlington, S. And Steel, J. And Hansen, D.p. And Battock, J. And Cheung, D. And Gan, G. And Hooper, B. And Lundin, R. And Nicol, D. And O'brien, J. And Whittington, S. And Wilkinson, C. And Wong, T.t.","Jamia Open","","Hl7 international's fast healthcare interoperability resources (fhir) standard provides a common format for sharing health data (eg, fhir resources) and a restful application programming interface (eg, fhir api) for accessing those resources via a fhir server connected to an electronic health record system or any other system storing clinical data. Substitutable medical applications and reusable technologies (smart) leverages fhir to create an electronic health record (ehr) agnostic app platform. It utilizes the oauth standard to provide for authorization and authentication. This paper describes the development and informal evaluation of case based learning on fhir (cbl on fhir), a prototype ehr-connected fhir/smart platform to provide interactive digital cases for use in medical education. The project goals were to provide a more interactive form of cbl than is possible on paper to more realistically simulate clinical decision making and to expose medical students to modern informatics systems and tools for use in patient care. © the author(s) 2019. Published by oxford university press on behalf of the american medical informatics association. This is an open access article distributed under the terms of the creative commons attribution non-commercial license (http://creativecommons.org/licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited.","","","2019","10.1093/jamiaopen/ooz055","","","scopus-2-s2.0-85103742844.pdf","scopus-2-s2.0-85103742844"
"Information management in beef cow-calf operations: data priorities, recording, and sharing","Hefley, J.m. And Schroeder, T.c. And Larson, R.l. And Kopp, D.","Applied Animal Science","","The objective of this study was to identify and prioritize animal information gathered in cow-calf op- erations and identify producer willingness to share animal information to guide design of a mobile, electronic, ani- mal information recordkeeping and sharing tool known as calfdex. The program is designed to support improved management practices and streamline data sharing to downstream customers. Materials and methods: the functionality and inter- face of calfdex is designed based on input collected from cow-calf and feedlot producers. Surveys and interviews were conducted with cow-calf producers to analyze their information management practices, identify animal infor- mation they found important to record, and assess their willingness to share information downstream in the supply chain. Additionally, surveys were conducted with feedlot producers to determine information they wish to receive from upstream producers. Results and discussion: highlighting the potential benefit of calfdex, survey results together with prior re- search reveal a lack of uniformity in the way beef cattle records are recorded and maintained as well little data sharing between vertical supply chain participants. Gen- eral calf management and health information were the 2 most important categories cow-calf producers indicated they wish to record and retain. Additionally, surveys sug- gest cow-calf producers are generally willing to share data wanted by feedlot producers. Implications and applications: the surveys pro- vided enhanced understanding of prioritized information needs of cow-calf producers and willingness to share spe- cific information with downstream producers. This information informed the design structure of the calfdex app to streamline functionality and ensure the program met producer needs. Currently, calfdex is undergoing β test- ing trials with producers to evaluate the effectiveness of the program to manage animal information and facilitate information sharing in the beef cattle supply chain. © 2023","","","2023","10.15232/aas.2022-02381","","","scopus-2-s2.0-85165996656.pdf","scopus-2-s2.0-85165996656"
"Ontology mapping using description logic and bridging axioms","Kumar, S.k. And Harding, J.a.","Computers In Industry","","In the last decade various proposals have been made to promote fruitful and efficient collaboration among small and medium sized enterprises (smes) in the form of virtual enterprises (ves). The success of ves depends on seamless interoperability of knowledge and data sharing. Ontology implementation is becoming an essential and successful tool for ve operation but commonly ontology mapping is also required to achieve interoperability. The current state of the art in ontology mapping indicates that mapping systems require a great deal of human intervention as mapping brings various types of conflicts and inconsistencies. The ontology mapping method proposed in this paper uses description logic (dl) based bridging axioms between the ontologies. Atomic concept level similarity has been taken as input to establish the complex concepts and roles level mapping. Manufacturing and marketing enterprise ontologies are considered and their mapping has been demonstrated as an example of the proposed mapping process. © 2012 elsevier b.v.","","","2013","10.1016/j.compind.2012.09.004","","","scopus-2-s2.0-84870292217.pdf","scopus-2-s2.0-84870292217"
"Observations on the uk transformational government strategy relative to citizen data sharing and privacy","Combe, C.","Transforming Government: People, Process And Policy","","Purpose - one of the key aims of the uk's transformational government strategy is to create a ""joined-up"" government where communications within and between public organisations is improved by the use of information technology. Data sharing is a key enabler of ""joined-up"" government but the implementation of the strategy presents a series of risks. The purpose of this paper is to articulate and assess the nature of those risks in relation to violations of existing laws using the national pupil database (npd) in england as a case study. Design/methodology/approach - the paper investigates examples of violations of eu law relating to rights to privacy of data sharing practices within the uk public sector using an interpretive approach to existing published information. The case of the npd illustrates how certain identified data sharing practices contravene existing laws and exposes this aspect of the transformational government strategy to heightened risk of a legal challenge. Findings - four examples of violations of existing eu laws on privacy are identified from an investigation into the npd for schools in england. The analysis exposes the imbalance between the data sharing practices underpinning the transformational government strategy in the uk and the requirements for fulfilling privacy protection rights to citizens enshrined in eu law. The findings reveal that data sharing practices as a key enabler of the transformational government strategy risks violating existing laws designed to protect privacy. The uk government risks a legal challenge, the outcome of which may seriously undermine the prospects for achieving the stated aim of improving efficiency and effectiveness across the public sector. Research limitations/implications - the paper is largely restricted to the npd for schools in england. The findings would be strengthened by expanding the research into other areas of the public sector where data sharing practices have been implemented. Originality/value - the findings are a significant and timely contribution to understanding the data sharing/privacy tension that ministers and legislators need to address. The work provides an insight into where weaknesses exist within current arrangements that is of value to policymakers, legislators, human rights advocates and government authorities at both central and local levels. © emerald group publishing limited.","","","2009","10.1108/17506160910997892","","","scopus-2-s2.0-70350362715.pdf","scopus-2-s2.0-70350362715"
"The impact of social capital on successful ageing of empty nesters: A cross-sectional study","Chang H., Zhou J., Wang Z.","Journal of Advanced Nursing","","AIM: To explore the impact of social capital on successful ageing among empty nesters in China.\\\\\\\\rDESIGN: A cross-sectional study.\\\\\\\\rMETHODS: The data for this study came from the survey of the China Health and Retirement Longitudinal Study (CHARLS) in 2018. Overall 6098 empty nesters aged 60 years and over were included. Successful ageing was defined according to Rowe and Kahn's model. Social capital includes social trust social support reciprocity and social networks. Multivariable logistic regression and a classification and regression tree model were applied to estimate the impact of social capital on successful ageing. For this study we followed the Reporting of Studies Conducted Using Observational Routinely Collected Health Data (RECORD) reporting guidelines an extension of Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) guidelines.\\\\\\\\rRESULTS: The successful ageing rate of empty nesters in China was 9.2%. Empty nesters who had a higher level of reciprocal behaviour and caregiving support in several dimensions of social capital and who were members of organizations in their social networks have had higher odds of achieving successful ageing. We also observed interactions with social capital associated with successful ageing suggesting that special attention should be given to empty nesters who are less educated have no caregiving support live in rural areas have worse self-rated health are older do not have reciprocal behaviours and are unmarried.\\\\\\\\rCONCLUSIONS: The results of this study show that social capital especially in terms of reciprocity caregiving support and organizational membership in a social network can contribute to the achievement of successful ageing among empty nesters.\\\\\\\\rIMPACT: This study confirms the impact of social capital on the successful ageing of empty nesters for the first time and provides new ideas for state community and health care workers to address ageing issues.\\\\\\\\rNO PATIENT OR PUBLIC CONTRIBUTION: Because of the public database data used in this study all data were collected by survey agency personnel so this section is not applicable to this study. Copyright © 2022 John Wiley & Sons Ltd.","","","2023","10.1111/jan.15509","","","medline-36416380.pdf","medline-36416380"
"Indirect treatment comparison/network meta-analysis study questionnaire to assess relevance and credibility to inform health care decision making: an ISPOR-AMCP-NPC Good Practice Task Force report","Jansen J. P., Trikalinos T., Cappelleri J. C., Daw J., Andes S., Eldessouki R., Salanti G.","Value in Health","","Despite the great realized or potential value of network meta-analysis of randomized controlled trial evidence to inform health care decision making many decision makers might not be familiar with these techniques. The Task Force developed a consensus-based 26-item questionnaire to help decision makers assess the relevance and credibility of indirect treatment comparisons and network meta-analysis to help inform health care decision making. The relevance domain of the questionnaire (4 questions) calls for assessments about the applicability of network meta-analysis results to the setting of interest to the decision maker. The remaining 22 questions belong to an overall credibility domain and pertain to assessments about whether the network meta-analysis results provide a valid answer to the question they are designed to answer by examining 1) the used evidence base 2) analysis methods 3) reporting quality and transparency 4) interpretation of findings and 5) conflicts of interest. The questionnaire aims to help readers of network meta-analysis opine about their confidence in the credibility and applicability of the results of a network meta-analysis and help make decision makers aware of the subtleties involved in the analysis of networks of randomized trial evidence. It is anticipated that user feedback will permit periodic evaluation and modification of the questionnaire. Copyright © 2014 International Society for Pharmacoeconomics and Outcomes Research (ISPOR). Published by Elsevier Inc. All rights reserved.","","","2014","10.1016/j.jval.2014.01.004","","","medline-24636374.pdf","medline-24636374"
"Perspectives regarding privacy in clinical research among research professionals from the arab region: an exploratory qualitative study","Adarmouch, L. And Felaefel, M. And Wachbroit, R. And Silverman, H.","Bmc Medical Ethics","","Background: protecting the privacy of research participants is widely recognized as one of the standard ethical requirements for clinical research. It is unknown, however, how research professionals regard concepts of privacy as well as the situations in the research setting that require privacy protections. The aim of this study was to explore the views of research professionals from arab countries regarding concepts and scope of privacy that occur in clinical research. Methods: we adopted an exploratory qualitative approach by the use of focus group discussions. We recruited individuals involved in research from egypt and morocco. We analyzed focus group data via a constant comparison approach, which consisted of close reading of the transcribed interviews followed by coding and then determining themes and subthemes. Results: between august 2016 and july 2018, we conducted nine focus group discussions. Respondents discussed several privacy issues that occurred before the research began (e.g., recruitment practices);  during research (e.g., data collection and physical exams), and after the research (e.g., secondary use of data and data sharing). Respondents revealed their perspectives of patients towards privacy in the clinical and research settings and mentioned that patients are more likely to permit access to their privacy in the clinical setting compared with research setting due to the existence of benefits and trust in clinical care. Respondents also recommended training regarding data protections for individuals involved in research. Conclusions: our study shows that research professionals discussed a range of privacy issues that are present during the different stages of research. We recommend 1) development of standards regarding privacy protections during recruitment efforts;  2) additional training for individuals involved in research regarding best practices with data security in secondary research;  3) a quantitative study involving investigators and rec members to determine their knowledge, attitudes and practices regarding privacy issues that occur in research;  and 4) a quantitative study involving patients to elicit their views regarding their privacy concerns in research. © 2020 the author(s).","","","2020","10.1186/s12910-020-0456-9","","","scopus-2-s2.0-85083412191.pdf","scopus-2-s2.0-85083412191"
"Deriving Weight From Big Data: Comparison of Body Weight Measurement-Cleaning Algorithms","Evans R., Burns J., Damschroder L., Annis A., Freitag M. B., Raffa S., Wiitala W.","JMIR Medical Informatics","","BACKGROUND: Patient body weight is a frequently used measure in biomedical studies yet there are no standard methods for processing and cleaning weight data. Conflicting documentation on constructing body weight measurements presents challenges for research and program evaluation.\\\\\\\\rOBJECTIVE: In this study we aim to describe and compare methods for extracting and cleaning weight data from electronic health record databases to develop guidelines for standardized approaches that promote reproducibility.\\\\\\\\rMETHODS: We conducted a systematic review of studies published from 2008 to 2018 that used Veterans Health Administration electronic health record weight data and documented the algorithms for constructing patient weight. We applied these algorithms to a cohort of veterans with at least one primary care visit in 2016. The resulting weight measures were compared at the patient and site levels.\\\\\\\\rRESULTS: We identified 496 studies and included 62 (12.5%) that used weight as an outcome. Approximately 48% (27/62) included a replicable algorithm. Algorithms varied from cutoffs of implausible weights to complex models using measures within patients over time. We found differences in the number of weight values after applying the algorithms (71961/1175995 6.12% to 1175177/1175995 99.93% of raw data) but little difference in average weights across methods (93.3 SD 21.0 kg to 94.8 SD 21.8 kg). The percentage of patients with at least 5% weight loss over 1 year ranged from 9.37% (4933/52642) to 13.99% (3355/23987).\\\\\\\\rCONCLUSIONS: Contrasting algorithms provide similar results and in some cases the results are not different from using raw unprocessed data despite algorithm complexity. Studies using point estimates of weight may benefit from a simple cleaning rule based on cutoffs of implausible values; however research questions involving weight trajectories and other more complex scenarios may benefit from a more nuanced algorithm that considers all available weight data. Copyright ©Richard Evans Jennifer Burns Laura Damschroder Ann Annis Michelle B Freitag Susan Raffa Wyndy Wiitala. Originally published in JMIR Medical Informatics (https://medinform.jmir.org) 09.03.2022.","","","2022","10.2196/30328","","","medline-35262492.pdf","medline-35262492"
"Comparison of quantification of target-specific accumulation of [18f]f-sipsma-14 in the het-cam model and in mice using pet/mri","Löffler, J. And Hamp, C. And Scheidhauer, E. And Di Carlo, D. And Solbach, C. And Abaei, A. And Hao, L. And Glatting, G. And Beer, A.j. And Rasche, V. And Winter, G.","Cancers","","Assessment of biodistribution and specific tumor accumulation is essential for the development of new radiopharmaceuticals and requires animal experiments. The het-cam (hens-egg test—chorioallantoic membrane) model can be used in combination with the non-invasive imaging modalities pet and mri for pre-selection during radiopharmaceutical development to reduce the number of animal experiments required. Critical to the acceptance of this model is the demonstration of the quantifiability and reproducibility of these data compared to the standard animal model. Tumor accumulation and biodistribution of the psma-specific radiotracer [18f]f-sipsma-14 was analyzed in the chick embryo and in an immunodeficient mouse model. Evaluation was based on mri and pet data in both models. γ-counter measurements and histopathological analyses comple-mented these data. Psma-specific accumulation of [18f]f-sipsma-14 was successfully demonstrated in the het-cam model, similar to the results obtained by mouse model studies. The combination of mr and pet imaging allowed precise quantification of peptide accumulation, initial assessment of biodistribution, and accurate determination of tumor volume. Thus, the use of the het-cam model is suitable for the pre-selection of new radiopharmaceuticals and potentially reduces animal testing in line with the 3rs principles of animal welfare. © 2021 by the authors. Licensee mdpi, basel, switzerland.","","","2021","10.3390/cancers13164007","","","scopus-2-s2.0-85112643634.pdf","scopus-2-s2.0-85112643634"
"Multi-user searchable symmetric encryption with dynamic updates for cloud computing","Guo, C. And Fu, X. And Mao, Y. And Wu, G. And Li, F. And Wu, T.","Information (Switzerland)","","With the advent of cloud computing, more and more users begin to outsource encrypted files to cloud servers to provide convenient access and obtain security guarantees. Searchable encryption (se) allows a user to search the encrypted files without leaking information related to the contents of the files. Searchable symmetric encryption (sse) is an important branch of se. Most of the existing sse schemes considered single-user settings, which cannot meet the requirements for data sharing. In this work, we propose a multi-user searchable symmetric encryption scheme with dynamic updates. This scheme is applicable to the usage scenario where one data owner encrypts sensitive files and shares them among multiple users, and it allows secure and efficient searches/updates. We use key distribution and re-encryption to achieve multi-user access while avoiding a series of issues caused by key sharing. Our scheme is constructed based on the index structure where a bit matrix is combined with two static hash tables, pseudorandom functions and hash functions. Our scheme is proven secure in the random oracle model. © 2018 by the authors.","","","2018","10.3390/info9100242","","","scopus-2-s2.0-85054344976.pdf","scopus-2-s2.0-85054344976"
"Greetings as social action in finland swedish and sweden swedish service encounters- a pluricentric perspective","Nilsson, J. And Norrthon, S. And Lindström, J. And Wide, C.","Intercultural Pragmatics","","While greetings are performed in all cultures and open most conversations, previous studies suggest that there are cross-cultural differences between different languages in greeting behavior. But do speakers of different national varieties of the same language organize and perform their greeting behavior in similar ways? In this study, we investigate the sequential organization of greetings in relation to gaze behavior in the two national varieties of swedish: sweden swedish spoken in sweden and finland swedish spoken in finland. In recent years, the importance of studying pluricentric languages from a pragmatic perspective has been foregrounded, not least within the framework of variational pragmatics. To date, most studies have focused on structural differences between national varieties of pluricentric languages. With this study, we extend the scope of variational pragmatics through adding an interactional, micro perspective to the broader macro analysis typical of this field. For this study, we have analyzed patterns for greetings in 297 video-recorded service encounters, where staff and customers interact at theatre box offices and event booking venues in sweden and finland. The study shows that there are similarities and differences in greeting behavior between varieties. There is a strong preference for exchanging reciprocal verbal greetings, one at a time, in both. There is also a similar organization of the greeting sequence, where customer and staff establish mutual gaze prior to the verbal greetings, thus signaling availability for interaction. The duration of mutual gaze and the timing of the greeting, however, differ between the two varieties. We have also conducted a multi modal analysis of gaze behavior in correlation to the greeting. We found that the customers and staff in the finland swedish data share mutual gaze before and during the verbal greeting, and often avert gaze after the verbal greetings. However, in the sweden swedish data, the participants often avert gaze before the verbal greetings. Our results thus indicate that both similarities and differences in pragmatic routines and bodily behavior exist between the two national varieties of swedish. The present study on greeting practices in finland swedish and sweden swedish should contribute to the field of variational pragmatics and to the development of pluricentric theory. © 2018 walter de gruyter gmbh, berlin/boston.","","","2018","10.1515/ip-2017-0030","","","scopus-2-s2.0-85046274170.pdf","scopus-2-s2.0-85046274170"
"Analysis of critical success factors for blockchain technology implementation in healthcare sector","Bali, S. And Bali, V. And Mohanty, R.p. And Gaur, D.","Benchmarking","","Purpose: recently, blockchain technology (bt) has resolved healthcare data management challenges. It helps healthcare providers automate medical records and mining to aid in data sharing and making more accurate diagnoses. This paper attempts to identify the critical success factors (csfs) for successfully implementing bt in healthcare. Design/methodology/approach: the paper is methodologically structured in four phases. The first phase leads to identifying success factors by reviewing the extant literature. In the second phase, expert opinions were solicited to authenticate the critical success factors required to implement bt in the healthcare sector. Decision making trial and evaluation laboratory (dematel) method was employed to find the cause-and-effect relationship among the third phase’s critical success factors. In phase 4, the authors resort to validating the final results and findings. Findings: based on the analysis, 21 csfs were identified and grouped under six dimensions. After applying the dematel technique, nine factors belong to the causal group, and the remaining 12 factors fall under the effect group. The top three influencing factors of blockchain technology implementation in the healthcare ecosystem are data transparency, track and traceability and government support, whereas;  implementation cost was the least influential. Originality/value: this study provides a roadmap and may facilitate healthcare professionals to overcome contemporary challenges with the help of bt. © 2022, emerald publishing limited.","","","2023","10.1108/bij-07-2021-0433","","","scopus-2-s2.0-85130883424.pdf","scopus-2-s2.0-85130883424"
"Inventory of surveys on smoking","Massey M. M., Boyd G., Mattson M., Feinleib M. R.","Public Health Reports","","A review of surveys on smoking was undertaken by the Smoking Tobacco and Cancer Program of the National Cancer Institute as part of its planning for smoking control interventions. Eighteen surveys collecting smoking data were identified. The key persons associated with the surveys were interviewed according to a uniform protocol developed to obtain comparable data on the content timeframe population sample methodology availability of data and mode of information dissemination of the surveys. Analysis indicated that the main variations among surveys occurred in the age range of the population sampled the definition of smoking behavior and the quantification of cigarettes smoked. Other issues of special interest compared in the surveys included type of cigarette smoked attempts at smoking cessation smokeless tobacco use passive smoking use of low tar and low nicotine cigarettes and smoking among special populations (women youth Hispanics and blacks). Two main areas of concern in planning targeting and evaluating timely and appropriate smoking behavior interventions are the lag between data collection and publication of survey results and the variability in the content and methodology of the surveys.","","","1987","","","","medline-3112856.pdf","medline-3112856"
"Cloud assisted semi-static secure accountable authority identity-based broadcast encryption featuring public traceability without random oracles","Singh, A.k. And Acharya, K. And Dutta, R.","Annales Des Telecommunications/Annals Of Telecommunications","","Cloud computing has gained widespread popularity in the industry and academia and rapidly becomes an integral part of our everyday life. It offers several benefits including reduced cost on technical support for data backups, saving electric power and maintenance cost. These encourage the major industry players like google, ibm, microsoft to invest into cloud storage with the goal to extend the spectrum of cloud-based services from open public to closed private. One of the crucial challenges in cloud computing is the security of outsourced data. Sharing sensitive data among multiple users under the same domain in a secure and efficient way requires technical solutions. Identity-based broadcast encryption (ibbe) is an important building block in cryptography. This is a one to many encryption that broadcasts a message to many identities. In this paper, we address the key escrow problem of ibbe. As private key generator (pkg) generates secret keys for users, it has the capability to decrypt the ciphertext and recover the message. The accountable authority ibbe was introduced to give accountability in ibbe, where white-box a-ibbe can differentiate the creator of a given pirated private key between the pkg and suspected user and black-box a-ibbe can further trace the creator of a decoder box. In our construction, we have established the secret key by using zero-knowledge proof between the user and pkg. The decryption key is held by the user only. This restricts pkg to re-distribute keys maliciously and solves the key escrow problem. Inspired by the work of zhao et al., we develop an accountable authority identity-based broadcast encryption scheme (a-ibbe). Our construction is the first publicly traceable weak black-box a-ibbe scheme secure against the indistinguishability under chosen-identity and chosen-plaintext attack in the standard model. We support the conjectured security of our candidate by analysis and prove its security without using any random oracle under the hardness of the decision bilinear diffie-hellman exponent (db-dhe) sum problem. Another interesting feature of our scheme is that it features a constant size secret key and ciphertext. More positively, when contrasted with the existing similar schemes, our scheme exhibits favorable results in terms of secret key size and ciphertext length with constant number of pairing computations. © 2022, institut mines-télécom and springer nature switzerland ag.","","","2023","10.1007/s12243-022-00925-8","","","scopus-2-s2.0-85138409150.pdf","scopus-2-s2.0-85138409150"
"In data science, take nothing on faith","Kobielus, J.","Ibm Data Management Magazine","","Adopting a rigid regimen is required for selection of reproducible computational findings. There is a list of specific data and analytic governance rules for computational scientists to follow to ensure reproducibility. For every result, scientists must keep track of how it was produced. They should avoid manual data manipulation steps. Archive the exact versions of all external programs used. Version control all custom scripts. Computer scientists must record all intermediate results, when possible, in standardized formats. For analyses that include randomness, note underlying random seeds. They must always store raw data behind plots;  generate hierarchical analysis output, allowing layers of increasing detail to be inspected. They must also connect textual statements to underlying results and provide public access to scripts, runs, and results.","","","2014","","","","scopus-2-s2.0-84904314987.pdf","scopus-2-s2.0-84904314987"
"Three-parameter lognormal distribution ubiquitously found in cDNA microarray data and its application to parametric data treatment","Konishi T.","BMC Bioinformatics","","BACKGROUND: To cancel experimental variations microarray data must be normalized prior to analysis. Where an appropriate model for statistical data distribution is available a parametric method can normalize a group of data sets that have common distributions. Although such models have been proposed for microarray data they have not always fit the distribution of real data and thus have been inappropriate for normalization. Consequently microarray data in most cases have been normalized with non-parametric methods that adjust data in a pair-wise manner. However data analysis and the integration of resultant knowledge among experiments have been difficult since such normalization concepts lack a universal standard.\\\\\\\\rRESULTS: A three-parameter lognormal distribution model was tested on over 300 sets of microarray data. The model treats the hybridization background which is difficult to identify from images of hybridization as one of the parameters. A rigorous coincidence of the model to data sets was found proving the model's appropriateness for microarray data. In fact a closer fitting to Northern analysis was obtained. The model showed inconsistency only at very strong or weak data intensities. Measurement of z-scores as well as calculated ratios was reproducible only among data in the model-consistent intensity range; also the ratios were independent of signal intensity at the corresponding range.\\\\\\\\rCONCLUSION: The model could provide a universal standard for data simplifying data analysis and knowledge integration. It was deduced that the ranges of inconsistency were caused by experimental errors or additive noise in the data; therefore excluding the data corresponding to those marginal ranges will prevent misleading analytical conclusions.","","","2004","","","","medline-14718068.pdf","medline-14718068"
"Versioned geoscientific workflow for the collaborative geo-simulation of human-nature interactions–a case study of global change and human activities","Chen, Y. And Lin, H. And Xiao, L. And Jing, Q. And You, L. And Ding, Y. And Hu, M. And Devlin, A.t.","International Journal Of Digital Earth","","Global change refers to changes in the relationship between humans and nature. It is desirable to actively integrate human social activities into the unified framework of global change so that their mutual relations and functional mechanisms can be understood. This complicated issue necessitates an appropriate method allowing domain experts to collaboratively contribute their knowledge to geoscientific research. Also, an efficient approach to optimize experimentation is of great importance. The reproducibility of research methods and results needs to be improved to boost the sharing of geographic knowledge and resources. This paper proposes a versioned geoscientific workflow and characterizes its full lifecycle using virtual geographic environments, intending to facilitate and improve research related to the interactions between global change and human activities. The geoscientific workflow management is realized using the concept of version management, making geographic simulation methods and computational results easily reproducible and extendable. The sharing and reuse of geographic knowledge in various forms are archived through version management of geoscientific workflows. A versatile prototype system is implemented which enables the visual modeling of geoscientific workflows, the interactive optimization and collaborative evaluation of geoscientific workflows at runtime, the multi-dimensional dynamic visualization of geo-workflow outputs, and role-based access control for data security. © 2020 informa uk limited, trading as taylor & francis group.","","","2021","10.1080/17538947.2020.1849439","","","scopus-2-s2.0-85096576622.pdf","scopus-2-s2.0-85096576622"
"Implementation of big data privacy preservation technique for electronic health records in multivendor environment","Puri, G.d. And Haritha, D.","International Journal Of Advanced Computer Science And Applications","","Various diagnostic health data formats and standards include both structured and unstructured data. Sensitive information contained in such metadata requires the development of specific approaches that can combine methods and techniques that can extract and reconcile the information hidden in such data. However, when this data needs to be processed and used for other reasons, there are still many obstacles and concerns to overcome. Modern approaches based on machine learning including big data analytics, assist in the information refinement process for later use of clinical evidence. These strategies consist of transforming various data into standard formats in specific scenarios. In fact, in order to conform to these rules, only de-identified diagnostic and personal data may be handled for secondary analysis, especially when information is distributed or transferred across institutions. This paper proposes big data privacy preservation techniques using various privacy functions. This research focused on secure data distribution as well as security access control to revoke the malicious activity or similarity attacks from end-user. The various privacy preservation techniques such as data anonymization, generalization, random permutation, k-anonymity, bucketization, l-diversity with slicing approach have been proposed during the data distribution. The efficiency of system has been evaluated in hadoop distributed file system (hdfs) with numerous experiments. The results obtained from different experiments show that the computation should be changed when changing k-anonymity and l-diversity. As a result, the proposed system offers greater efficiency in hadoop environments by reducing execution time by 15% to 18% and provides a higher level of access control security than other security algorithms © 2023, international journal of advanced computer science and applications.all rights reserved.","","","2023","10.14569/ijacsa.2023.0140214","","","scopus-2-s2.0-85149694945.pdf","scopus-2-s2.0-85149694945"
"Real-time data-sharing techniques for shanghai advanced energy management system","Dong, S. And He, G. And Zhang, W. And Wang, Z.","Dianli Xitong Zidonghua/Automation Of Electric Power Systems","","The advanced energy management system (aems) is a new-type automatic system for performing multi-objective, near-optimal and closed-loop control of electric power grids. The data-sharing platform (dsp) is the fundamental platform of aems that provides data sharing service. The structure of dsp is proposed, and distribution memory cached technique is described. This technique uses string 'key-value' mapping to store shared data in distribution memories, which makes things simple, open and efficient. Finally, serialization techniques for the common information model (cim) data and results of state estimation are proposed. Cim data is compressed before transfer to network which makes data interchange more efficient. The effectiveness of the techniques of data sharing proposed is proved by test results and application. © 2012 state grid electric power research institute press.","","","2012","10.3969/j.issn.1000-1026.2012.12.019","","","scopus-2-s2.0-84865054952.pdf","scopus-2-s2.0-84865054952"
"Ensuring distributed accountability for data sharing in cloud","Karthick, K. And Jennifer, P. And Muthukumaravel, A.","Middle - East Journal Of Scientific Research","","Cloud computing enables highly scalable services to be easily consumed over the internet on an as-needed basis. A major feature of the cloud services is that users' data are usually processed remotely in unknown machines that users do not own or operate. While enjoying the convenience brought by this new emerging technology, users' fears of losing control of their own data (particularly, financial and health data) can become a significant barrier to the wide adoption of cloud services. To address this problem, in this paper, we propose a novel highly decentralized information accountability framework to keep track of the actual usage of the users' data in the cloud. In particular, we propose an object-centered approach that enables enclosing our logging mechanism together with users' data and policies. We leverage the jar programmable capabilities to both create a dynamic and traveling object and to ensure that any access to users' data will trigger authentication and automated logging local to the jars. To strengthen user's control, we also provide distributed auditing mechanisms. We provide extensive experimental studies that demonstrate the efficiency and effectiveness of the proposed approaches. © idosi publications, 2014.","","","2014","10.5829/idosi.mejsr.2014.20.06.11389","","","scopus-2-s2.0-84894623202.pdf","scopus-2-s2.0-84894623202"
"Evaluation of methods for spawner–recruit analysis in mixed-stock pacific salmon fisheries","Staton, B.a. And Catalano, M.j. And Connors, B.m. And Coggins, L.g. And Jones, M.l. And Walters, C.j. And Fleischman, S.j. And Gwinn, D.c.","Canadian Journal Of Fisheries And Aquatic Sciences","","Salmon populations harvested in mixed-stock fisheries can exhibit genotypic, behavioral, and life history diversity that can lead to heterogeneity in population productivity and size. Methods to quantify this heterogeneity among populations in mixed-stock fisheries are not well-established but are critical to assessing harvest–biodiversity trade-offs when setting harvest policies. We developed an integrated, age-structured, state-space model that allows for more complete use of available data and sharing of information than simpler methods. We compared a suite of state-space models of varying structural complexity to simpler regression-based approaches and, as an example case, fitted them to data from 13 chinook salmon (oncorhynchus tshawytscha) populations in the kuskokwim drainage in western alaska. We found biological and policy conclusions were largely consistent among state-space models but differed strongly from regression-based approaches. Simulation trials illustrated our state-space models were largely unbiased with respect to spawner–recruit parameters, abundance states, and derived biological reference points, whereas the regression-based approaches showed substantial bias. These findings suggest our state-space model shows promise for informing harvest policy evaluations of harvest–biodiversity trade-offs in mixed-stock salmon fisheries. © 2020, canadian science publishing. All rights reserved.","","","2020","10.1139/cjfas-2019-0281","","","scopus-2-s2.0-85086243285.pdf","scopus-2-s2.0-85086243285"
"Surrogate endpoints in trials: a call for better reporting","Ciani O., Manyara A. M., Chan A. W., Taylor R. S.","Trials [Electronic Resource]","","Using a surrogate endpoint as a substitute for a patient-relevant final outcome enables randomised controlled trials (RCTs) to be conducted more efficiently. However the use of surrogates remains controversial and there is currently no guideline for the reporting of RCTs using surrogate endpoints; therefore we seek to develop SPIRIT (Standard Protocol Items: Recommendations for Interventional Trials) and CONSORT (Consolidated Standards of Reporting Trials) extensions to improve the reporting of these trials. We would like to invite interested individuals (trial methodologists journal editors healthcare industry regulators and payers and patient/public representative groups) particularly those with experience in the use of surrogate endpoints in trials. Copyright © 2022. The Author(s).","","","2022","10.1186/s13063-022-06904-7","","","medline-36503559.pdf","medline-36503559"
"Social support and caregiver distress: a replication analysis","Miller B., Townsend A., Carpenter E., Montgomery R. V., Stull D., Young R. F.","Journals of Gerontology Series B-Psychological Sciences & Social Sciences","","OBJECTIVES: Prior studies have conceptualized and operationalized social support in different ways making it difficult to determine if the inconsistencies in findings are due to differences in study design samples conceptualization or measurement. The present study examined the replicability of models of social support and caregiver distress across 4 community-based caregiving studies representative of many conducted in the past 10 years. The goal was to identify areas of consistency in findings across the data sets.\\\\\\\\rMETHODS: The authors analyzed 3 models specifying patterns of relationship between social support and depression (main effect mediation effect and moderation effect) separately within data sets using hierarchical ordinary least squares regression. Results were compared across data sets.\\\\\\\\rRESULTS: The replication analysis confirmed the robustness of behavior problems and caregiver health as important contributors to caregiver distress. Results of hypotheses examining the pattern of relationship between social support and distress were inconsistent however. Only 1 type of social support was associated with distress in the expected direction: Less emotional support was associated with higher levels of distress in 2 of the 4 data sets.\\\\\\\\rDISCUSSION: More complex theoretical models that incorporate common measures to represent the linkages between types of stressor types of support and their interactions are needed to foster replicability and generalizability of research results.","","","2001","10.1093/geronb/56.4.s249","","","medline-11445617.pdf","medline-11445617"
"Different housing conditions for zebrafish: What are the effects?","Silva P. F., Garcia de Leaniz C., Freire F. A. M., Silveira V. A. M., Luchiari A. C.","Behavioural Processes","","Zebrafish is a popular experimental model in several research areas but little is known about the effects of using different strains or housing conditions. Poor control of genetic background and housing conditions could affect experimental results and data reproducibility. Here we investigated the effects of two possible sources of variation on zebrafish behaviour: fish origin and environmental parameters (light intensity water temperature and noise). Zebrafish behaviour was then examined using the 'novel tank test' one of the most common paradigms used to assess anxiety-like behaviours in zebrafish. Our results show that an increase in light intensity alters fish behaviour particularly freezing duration and distance from the bottom of the tank indicating increased anxiety. Swimming activity increased at the lowest temperature (25 degreeC). However different levels of background noise did not cause any significant changes in behaviour. Differences were also found between zebrafish strains and populations: while the AB strain from laboratory 1 was minimally influenced by variation in holding conditions the AB strain from laboratory 2 was highly affected by changes in temperature light and background noise. Our study shows that variation in strains and holding conditions can significantly influence the results of behavioural testing and should be carefully considered in the experimental design and properly reported to improve data interpretation and reproducibility. Copyright © 2023 Elsevier B.V. All rights reserved.","","","2023","10.1016/j.beproc.2023.104886","","","medline-37150333.pdf","medline-37150333"
"Data availability improvement in peer-to-peer online social networks","Koohpar, F.k. And Fatemi, A. And Raji, F.","Iet Information Security","","One of the main challenges of centralised social networks is having a central provider that stores the data which imposes some limitations to preserve the privacy of users' data. However, one of the decentralised architectures is peer-to-peer network that every user takes the responsibility of storing and managing his/her data. Although the privacy of data is increased in these networks, authorised friends must have access to the shared data when the user is not online in the network. For this purpose, the user selects some friends and copies his/her data in their space. On the other hand, the amount of used space and the total number of replicas must be reduced as much as possible. In this study, the authors provide some solutions to reduce the amount of used space and the total number of replicas to increase data availability. In this way, they segment the user's data and consider the stability of copy-location, i.e. the selected friends who have a copy of the user's data. The performance evaluation of the proposed methods shows that they considerably reduce the amount of used space as well as the total number of replicas in comparison to other approaches. © the institution of engineering and technology 2020.","","","2020","10.1049/iet-ifs.2019.0363","","","scopus-2-s2.0-85083458400.pdf","scopus-2-s2.0-85083458400"
"Propensity Scoring in Plastic Surgery Research: An Analysis and Best Practice Guide","Chu J. J., Shamsunder M. G., Yin S., Rubenstein R. R., Slutsky H., Fischer J. P., Nelson J. A.","Plastic and Reconstructive Surgery - Global Open","","Randomized controlled trials though considered the gold standard in clinical research are often not feasible in plastic surgery research. Instead researchers rely heavily on observational studies leading to potential issues with confounding and selection bias. Propensity scoring-a statistical technique that estimates a patient's likelihood of having received the exposure of interest-can improve the comparability of study groups by either guiding the selection of study participants or generating a covariate that can be adjusted for in multivariate analyses. In this study we conducted a comprehensive review of research articles published in three major plastic surgery journals (Plastic and Reconstructive Surgery Journal of Plastic Reconstructive & Aesthetic Surgery and Annals of Plastic Surgery) to determine the utilization of propensity scoring methods in plastic surgery research from August 2018 to August 2020. We found that propensity scoring was used in only eight (0.8%) of 971 research articles none of which fully reported all components of their propensity scoring methodology. We provide a brief overview of propensity score techniques and recommend guidelines for accurate reporting of propensity scoring methods for plastic surgery research. Improved understanding of propensity scoring may encourage plastic surgery researchers to incorporate the method in their own work and improve plastic surgeons' ability to understand and analyze future research studies that utilize propensity score methods. Copyright © 2022 The Authors. Published by Wolters Kluwer Health Inc. on behalf of The American Society of Plastic Surgeons.","","","2022","10.1097/gox.0000000000004003","","","medline-35169516.pdf","medline-35169516"
"No time to waste: the role of timing and complementarity of alignment practices in creating business value in it projects","Vermerris, A. And Mocker, M. And Van Heck, E.","European Journal Of Information Systems","","Despite significant research progress, alignment-related issues are among the top concerns of executives. Previous studies mostly focus on a company-wide strategic level of alignment;  while this 'top-down' view has benefits, it largely ignores the operational practices that help achieve alignment in it projects as well as the impact that timing and complementarity of practices have on achieving alignment. In our research we apply four alignment practices-communication, shared understanding, management commitment and it investment evaluation-to individual it projects rather than at a company level;  specifically, we look at the role of timing and complementarity for these alignment practices throughout different project phases. A detailed analysis of six it projects carried out at three companies in the telecommunications industry reveals that it projects creating higher business value employ all four alignment practices immediately from the start. No project was able to recover from failing to establish these four alignment practices in the first phase. While supporting the importance of complementarity of alignment practices, our findings also add the importance of the earliness of this complementarity. © 2014 operational research society ltd.","","","2014","10.1057/ejis.2013.11","","","scopus-2-s2.0-84908672314.pdf","scopus-2-s2.0-84908672314"
"Research guidelines in the era of large-scale collaborations: An analysis of genome-wide association study consortia","Austin M. A., Hair M. S., Fullerton S. M.","American Journal of Epidemiology","","Scientific research has shifted from studies conducted by single investigators to the creation of large consortia. Genetic epidemiologists for example now collaborate extensively for genome-wide association studies (GWAS). The effect has been a stream of confirmed disease-gene associations. However effects on human subjects oversight data-sharing publication and authorship practices research organization and productivity and intellectual property remain to be examined. The aim of this analysis was to identify all research consortia that had published the results of a GWAS analysis since 2005 characterize them determine which have publicly accessible guidelines for research practices and summarize the policies in these guidelines. A review of the National Human Genome Research Institute's Catalog of Published Genome-Wide Association Studies identified 55 GWAS consortia as of April 1 2011. These consortia were comprised of individual investigators research centers studies or other consortia and studied 48 different diseases or traits. Only 14 (25%) were found to have publicly accessible research guidelines on consortia websites. The available guidelines provide information on organization governance and research protocols; half address institutional review board approval. Details of publication authorship data-sharing and intellectual property vary considerably. Wider access to consortia guidelines is needed to establish appropriate research standards with broad applicability to emerging forms of large-scale collaboration. © 2012 The Author.","","","2012","10.1093/aje/kwr441","","","medline-22491085.pdf","medline-22491085"
"Evaluation of hybridization conditions for spotted oligonucleotide-based DNA microarrays","Tsai M. H., Yan H., Chen X., Chandramouli G. V., Zhao S., Coffin D., Coleman C. N., Mitchell J. B., Chuang E. Y.","Molecular Biotechnology","","We compared different hybridization conditions of oligonucleotide-based DNA microarray to acquire optimized and reliable microarray data. Several parameters were evaluated at different hybridization conditions including signal-to-background (S:B) ratios signal dynamic range usable spots and reproducibility. Statistical analysis showed that better results were obtained when spotted presynthesized long oligonucleotide arrays were blocked with succinic anhydride and hybridized at 42 degrees C in the presence of 50% formamide.","","","2005","","","","medline-15767699.pdf","medline-15767699"
"Federated learning enables big data for rare cancer boundary detection","Pati, S. And Baid, U. And Edwards, B. And Sheller, M. And Wang, S.-H. And Reina, G.a. And Foley, P. And Gruzdev, A. And Karkada, D. And Davatzikos, C. And Sako, C. And Ghodasara, S. And Bilello, M. And Mohan, S. And Vollmuth, P. And Brugnara, G. And Preetha, C.j. And Sahm, F. And Maier-Hein, K. And Zenk, M. And Bendszus, M. And Wick, W. And Calabrese, E. And Rudie, J. And Villanueva-Meyer, J. And Cha, S. And Ingalhalikar, M. And Jadhav, M. And Pandey, U. And Saini, J. And Garrett, J. And Larson, M. And Jeraj, R. And Currie, S. And Frood, R. And Fatania, K. And Huang, R.y. And Chang, K. And Quintero, C.b. And Capellades, J. And Puig, J. And Trenkler, J. And Pichler, J. And Necker, G. And Haunschmidt, A. And Meckel, S. And Shukla, G. And Liem, S. And Alexander, G.s. And Lombardo, J. And Palmer, J.d. And Flanders, A.e. And Dicker, A.p. And Sair, H.i. And Jones, C.k. And Venkataraman, A. And Jiang, M. And So, T.y. And Chen, C. And Heng, P.a. And Dou, Q. And Kozubek, M. And Lux, F. And Michálek, J. And Matula, P. And Keřkovský, M. And Kopřivová, T. And Dostál, M. And Vybíhal, V. And Vogelbaum, M.a. And Mitchell, J.r. And Farinhas, J. And Maldjian, J.a. And Yogananda, C.g.b. And Pinho, M.c. And Reddy, D. And Holcomb, J. And Wagner, B.c. And Ellingson, B.m. And Cloughesy, T.f. And Raymond, C. And Oughourlian, T. And Hagiwara, A. And Wang, C. And To, M.-S. And Bhardwaj, S. And Chong, C. And Agzarian, M. And Falcão, A.x. And Martins, S.b. And Teixeira, B.c.a. And Sprenger, F. And Menotti, D. And Lucio, D.r. And Lamontagne, P. And Marcus, D. And Wiestler, B. And Kofler, F. And Ezhov, I. And Metz, M. And Jain, R. And Lee, M. And Lui, Y.w. And Mckinley, R. And Slotboom, J. And Radojewski, P. And Meier, R. And Wiest, R. And Murcia, D. And Fu, E. And Haas, R. And Thompson, J. And Ormond, D.r. And Badve, C. And Sloan, A.e. And Vadmal, V. And Waite, K. And Colen, R.r. And Pei, L. And Ak, M. And Srinivasan, A. And Bapuraj, J.r. And Rao, A. And Wang, N. And Yoshiaki, O. And Moritani, T. And Turk, S. And Lee, J. And Prabhudesai, S. And Morón, F. And Mandel, J. And Kamnitsas, K. And Glocker, B. And Dixon, L.v.m. And Williams, M. And Zampakis, P. And Panagiotopoulos, V. And Tsiganos, P. And Alexiou, S. And Haliassos, I. And Zacharaki, E.i. And Moustakas, K. And Kalogeropoulou, C. And Kardamakis, D.m. And Choi, Y.s. And Lee, S.-K. And Chang, J.h. And Ahn, S.s. And Luo, B. And Poisson, L. And Wen, N. And Tiwari, P. And Verma, R. And Bareja, R. And Yadav, I. And Chen, J. And Kumar, N. And Smits, M. And Van Der Voort, S.r. And Alafandi, A. And Incekara, F. And Wijnenga, M.m.j. And Kapsas, G. And Gahrmann, R. And Schouten, J.w. And Dubbink, H.j. And Vincent, A.j.p.e. And Van Den Bent, M.j. And French, P.j. And Klein, S. And Yuan, Y. And Sharma, S. And Tseng, T.-C. And Adabi, S. And Niclou, S.p. And Keunen, O. And Hau, A.-C. And Vallières, M. And Fortin, D. And Lepage, M. And Landman, B. And Ramadass, K. And Xu, K. And Chotai, S. And Chambless, L.b. And Mistry, A. And Thompson, R.c. And Gusev, Y. And Bhuvaneshwar, K. And Sayah, A. And Bencheqroun, C. And Belouali, A. And Madhavan, S. And Booth, T.c. And Chelliah, A. And Modat, M. And Shuaib, H. And Dragos, C. And Abayazeed, A. And Kolodziej, K. And Hill, M. And Abbassy, A. And Gamal, S. And Mekhaimar, M. And Qayati, M. And Reyes, M. And Park, J.e. And Yun, J. And Kim, H.s. And Mahajan, A. And Muzi, M. And Benson, S. And Beets-Tan, R.g.h. And Teuwen, J. And Herrera-Trujillo, A. And Trujillo, M. And Escobar, W. And Abello, A. And Bernal, J. And Gómez, J. And Choi, J. And Baek, S. And Kim, Y. And Ismael, H. And Allen, B. And Buatti, J.m. And Kotrotsou, A. And Li, H. And Weiss, T. And Weller, M. And Bink, A. And Pouymayou, B. And Shaykh, H.f. And Saltz, J. And Prasanna, P. And Shrestha, S. And Mani, K.m. And Payne, D. And Kurc, T. And Pelaez, E. And Franco-Maldonado, H. And Loayza, F. And Quevedo, S. And Guevara, P. And Torche, E. And Mendoza, C. And Vera, F. And Ríos, E. And López, E. And Velastin, S.a. And Ogbole, G. And Soneye, M. And Oyekunle, D. And Odafe-Oyibotha, O. And Osobu, B. And Shu’aibu, M. And Dorcas, A. And Dako, F. And Simpson, A.l. And Hamghalam, M. And Peoples, J.j. And Hu, R. And Tran, A. And Cutler, D. And Moraes, F.y. And Boss, M.a. And Gimpel, J. And Veettil, D.k. And Schmidt, K. And Bialecki, B. And Marella, S. And Price, C. And Cimino, L. And Apgar, C. And Shah, P. And Menze, B. And Barnholtz-Sloan, J.s. And Martin, J. And Bakas, S.","Nature Communications","","Although machine learning (ml) has shown promise across disciplines, out-of-sample generalizability is concerning. This is currently addressed by sharing multi-site data, but such centralization is challenging/infeasible to scale due to various limitations. Federated ml (fl) provides an alternative paradigm for accurate and generalizable ml, by only sharing numerical model updates. Here we present the largest fl study to-date, involving data from 71 sites across 6 continents, to generate an automatic tumor boundary detector for the rare disease of glioblastoma, reporting the largest such dataset in the literature (n = 6, 314). We demonstrate a 33% delineation improvement for the surgically targetable tumor, and 23% for the complete tumor extent, over a publicly trained model. We anticipate our study to: 1) enable more healthcare studies informed by large diverse data, ensuring meaningful results for rare diseases and underrepresented populations, 2) facilitate further analyses for glioblastoma by releasing our consensus model, and 3) demonstrate the fl effectiveness at such scale and task-complexity as a paradigm shift for multi-site collaborations, alleviating the need for data-sharing. © 2022, the author(s).","","","2022","10.1038/s41467-022-33407-5","","","scopus-2-s2.0-85143349702.pdf","scopus-2-s2.0-85143349702"
"Automated and continuous monitoring of animal welfare through digital alerting","Do J.p. And Defensor E.b. And Ichim C.v. And Lim M.a. And Mechanic J.a. And Rabe M.d. And Schaevitz L.r.","Comp. Med","","A primary goal in preclinical animal research is respectful and responsible care aimed toward minimizing stress and discomfort while enhancing collection of accurate and reproducible scientific data. Researchers use hands-on clinical observations and measurements as part of routine husbandry procedures or study protocols to monitor animal welfare. Although frequent assessments ensure the timely identification of animals with declining health, increased handling can result in additional stress on the animal and increased study variability. We investigated whether automated alerting regarding changes in behavior and physiology can complement existing welfare assessments to improve the identification of animals in pain or distress. Using historical data collected from a diverse range of therapeutic models, we developed algorithms that detect changes in motion and breathing rate frequently associated with sick animals but rare in healthy controls. To avoid introducing selection bias, we evaluated the performance of these algorithms by using retrospective analysis of all studies occurring over a 31-d period in our vivarium. Analyses revealed that the majority of the automated alerts occurred prior to or simultaneously with technicians' observations of declining health in animals. Additional analyses performed across the entire duration of 2 studies (animal models of rapid aging and lung metastasis) demonstrated the sensitivity, accuracy, and utility of automated alerting for detecting unhealthy subjects and those eligible for humane endpoints. The percentage of alerts per total subject days ranged between 0% and 24%, depending on the animal model. Automated alerting effectively complements standard clinical observations to enhance animal welfare and promote responsible scientific advancement.copyright 2020 by the american association for laboratory animal science.","","","2020","10.30802/aalas-cm-19-000090","","","embase-2013946322.pdf","embase-2013946322"
"Privacy-preserving classification rule mining for balancing data utility and knowledge privacy using adapted binary firefly algorithm","Kalyani, G. And Rao, M.v.p.c.s. And Janakiramaiah, B.","Arabian Journal For Science And Engineering","","Privacy-preserving data mining is an embryonic research area that addresses the integration of privacy-preserving concerns to data mining techniques. Classification is a problem in data mining which builds a model to classify the data and then identify the class label of unknown data based on the constructed model. Large amount of data is necessary to build a more accurate classifier. Sharing of data is one of the solutions to have enormous amount of data. When sharing the data among business associates, some sensitive patterns which can be derived from the data need not be revealed to the others. This situation raises a motivating issue of retaining the shared data with high quality by hiding some sensitive patterns. This paper addresses the problem of classification rule hiding by projecting a novel method based on data distortion approach. To select the best possible way of altering the instances and then selecting the optimal instances which reduces the loss of non-sensitive classification rules, a computational intelligence technique binary firefly algorithm is adapted with necessary changes. The transformed data set will be shared to the others which reveals only non-sensitive knowledge. A set of experiments were carried out to estimate the effectiveness of the proposed approach against existing similar ones by considering the performance measures miss cost, artifacts and deviation between original and transformed data sets. The experiments and comparisons have proved that the projected method preserves the privacy of sensitive classification rules as well as maintains quality of the transformed data set also. © 2017, king fahd university of petroleum & minerals.","","","2018","10.1007/s13369-017-2693-x","","","scopus-2-s2.0-85049468023.pdf","scopus-2-s2.0-85049468023"
"Description and analysis of personal knowledge management skills among the staff of ferdowsi university of mashhad","Roohbakhsh, H. And Hosseingholizadeh, R. And Jafarabadi, T.j.k.","Iranian Journal Of Information Processing Management","","The main objective of this study is to describe and analyze personal knowledge management skills among the staff of ferdowsi university of mashhad (fum). To achieve this goal, the case study research was used. The study population included staff that had formal position in fum. Data were collected through self- report questionnaire and semi-structured interview. 135 employees of fum answered the pkm skills questionnaire and 16 employees were interviewed. Result showed that the most important pkm activities include data recovery evaluation of information, organizing information, knowledge and information sharing, data analysis, dissemination of knowledge and information, security of information.","","","2017","","","","scopus-2-s2.0-85014474141.pdf","scopus-2-s2.0-85014474141"
"Developing lay summaries and thank you notes in paediatric pragmatic clinical trials","Zimmerman, K.o. And Perry, B. And Hanlen-Rosado, E. And Nsonwu, A. And Lane, M.d. And Benjamin, D.k. And Becker, M. And Corneli, A. And Best Pharmaceuticals For Children Act-Pediatric Trials Network Steering Committee","Health Expectations","","Introduction: better transparency of research results and participant engagement may help address poor participant accrual in paediatric clinical research. We conducted formative research to assess the acceptability of lay summaries and thank you notes, as well as to refine and expand guidance on participant and family engagement in pediatric trials network's (ptn) pragmatic paediatric clinical research. Methods: informed by draft ptn guidance, we conducted in-depth qualitative interviews with adolescent clinical trial participants and caregivers of paediatric participants in four trials conducted by ptn across eight sites. Participants were shown multiple versions of mock lay summaries and thank you notes and asked questions on their preferences for content and layout, and on trial communications. We used applied thematic analysis to analyse the data. Results: we interviewed 27 individuals engaged in ptn research: 24 caregivers and 3 adolescents. During a trial, participants want regular updates on study progress, reminders of the study purpose and reassurances of data confidentiality. After the trial, participants want to learn the aggregated results, particularly medication effectiveness. Participants reported that lay summaries should include a review of the study's purpose, methods and length, and that they expect to learn individual-level results. Participants stated that thank you notes must be of sufficient length to be meaningful. Conclusions: this is the first study to describe stakeholder preferences for thank you note content and layout. Using these findings, we finalized ptn's trial communication guidance for use in future ptn trials. Research is needed to determine the effect of lay summaries and thank you notes on improving public transparency regarding clinical trials and paediatric trial recruitment and completion. Patient or public contribution: by design, stakeholders (adolescent trial participants and caregivers of pediatric trial participants) contributed to ptn's guidance on the content and layout of lay summaries and thank you notes through their participation in the in-depth interviews. © 2022 the authors. Health expectations published by john wiley & sons ltd.","","","2022","10.1111/hex.13448","","","scopus-2-s2.0-85130862966.pdf","scopus-2-s2.0-85130862966"
"Fluorene derivative disodium salt as a new fluorescent dye for identification of amyloid deposits in the myocardium of mdx mice","Gusel’nikova, V.v. And Antimonova, O.i. And Fedorova, E.a. And Shavloskii, M.m. And Krutikov, A.n. And Mikhailova, E.v. And Kaminskaya, E.v. And Gudkova, A.ya. And Korzhevskii, D.e. And Mikhailov, V.m.","Tsitologiya","","The aim of this study was to develop a new method for the detection of amyloid deposits found in laboratory animals using the analogue of congo red, synthesized on the basis of diaminofluorene. The analogue is the disodium salt of 2,7-(1-amino-4-sulfo-2-naphthylazo)fluorene (dsnaf). Myocardial samples from mdx mice of both genders aged 1 to 1.5 years (n = 8) were used as the material for this study. As the main result of presented study, the optimal protocol for amyloid staining with dsnaf was developed. It has been shown that the sensitivity and specificity of amyloid detection by developed method is comparable with the congo red staining. The undoubted advantages of dsnaf using are the stability of the resulting staining, high fluorescence intensity of amyloid deposits and complete absence of background fluorescence that greatly simplifies the procedure of quantitative evaluation of obtained results. The method of amyloid staining with dsnaf is characterized by simplicity and good reproducibility. Further research will allow to access to the future application of this method for diagnosis of amyloidosis in the practice of clinical research. © 2018 sankt peterburg. All rights reserved.","","","2018","10.31116/tsitol.2018.01.05","","","scopus-2-s2.0-85064592570.pdf","scopus-2-s2.0-85064592570"
"A secure query assurance approach for distributed health records","Clarke, A. And Steele, R.","Health Systems","","Health information system architectures inherently include distributed systems and data repositories across multiple organizations, health providers and with potentially some data stored with the health consumer. This is part of the shift to more fully integrated electronic health systems. Due to the varied stakeholders of these systems, it will become more important to provide a high level of query quality assurance for the parties utilizing these distributed and shared data repositories. A core consideration of health records is providing data confidentiality, including to protect against insider security threats. As such, it will often be desirable that electronic health information be stored in an encrypted format. In this paper, we present and describe the implementation and evaluation of a query assurance model that implements the three requirements of query assurance across sources of searchable encrypted health data. Furthermore, we consider the issue of freshness and data persistence in a multiple data owner environment, including a discussion of the characteristics of consumer interfacing health information systems. © 2013, copyright © 2013, operational research society ltd.","","","2014","10.1057/hs.2013.12","","","scopus-2-s2.0-84929462228.pdf","scopus-2-s2.0-84929462228"
"The campbell collaboration: providing better evidence for a better world","Littell, J.h. And White, H.","Research On Social Work Practice","","In this article, we trace the development of the campbell collaboration and its renewed efforts to build a world library of accurate, synthesized evidence to inform policy and practice and improve human well-being worldwide. Campbell systematic reviews and related evidence synthesis products provide unbiased summaries of entire bodies of empirical evidence, making them uniquely useful sources of information for policy and practice. With recent changes in organizational structure and new leadership, the campbell collaboration is poised to dramatically increase the production, dissemination, and use of rigorous syntheses of research on social, economic, and behavioral interventions. Campbell provides opportunities for social work scholars, practitioners, and consumers to contribute to knowledge about the processes and outcomes of social, behavioral, and economic interventions. © 2017, © the author(s) 2017.","","","2018","10.1177/1049731517703748","","","scopus-2-s2.0-85038403943.pdf","scopus-2-s2.0-85038403943"
"Data-centric mobile crowdsensing","Jiang, C. And Gao, L. And Duan, L. And Huang, J.","Ieee Transactions On Mobile Computing","","Mobile crowdsensing (mcs) is a novel and appealing sensing paradigm that leverages the diverse embedded sensors of massive mobile devices to collect different kinds of data. One of the key challenges in mcs is to efficiently schedule mobile device users to perform different sensing tasks. Prior effort to this problem mainly focused on the interaction between the task-layer and the user-layer, without considering the similar data requirements of tasks and the heterogeneous sensing capabilities of users. In this work, we introduce a new data-layer between tasks and users, and propose a three-layer data-centric mcs framework, which enables different tasks to reveal their common data requirements and hence reuse the common data items. We focus on studying the joint task selection and user scheduling problem under this new framework, aiming at maximizing the social welfare. Specifically, we first analyze theoretical performance gain due to data reuse in the ideal scenario with complete information. We then consider the practical scenario with private information of both tasks and users, and propose a two-sided randomized auction mechanism, which is computationally efficient, individually rational, incentive compatible (truthful) in expectation, and close-to-optimal. We further show that the proposed randomized auction may not be budget balanced, and hence introduce a reserve price into the auction to achieve the desired budget balance at the cost of certain welfare loss. Simulation results show that with data reuse, the social welfare achieved in the proposed randomized auction can be increased from 270 up to 4,500 percent, comparing with those without data reuse. © 2002-2012 ieee.","","","2018","10.1109/tmc.2017.2763956","","","scopus-2-s2.0-85032261156.pdf","scopus-2-s2.0-85032261156"
"Influence of parameter settings in voxel-based morphometry 8. Using DARTEL and region-of-interest on reproducibility in gray matter volumetry","Goto M., Abe O., Aoki S., Hayashi N., Miyati T., Takao H., Matsuda H., Yamashita F., Iwatsubo T., Mori H., Kunimatsu A., Ino K., Yano K., Ohtomo K.","Methods of Information in Medicine","","OBJECTIVES: To investigate whether reproducibility of gray matter volumetry is influenced by parameter settings for VBM 8 using Diffeomorphic Anatomical Registration Through Exponentiated Lie Algebra (DARTEL) with region-of-interest (ROI) analyses.\\\\\\\\rMETHODS: We prepared three-dimensional T1-weighted magnetic resonance images (3D-T1WIs) of 21 healthy subjects. All subjects were imaged with each of five MRI systems. Voxel-based morphometry 8 (VBM 8) and WFU PickAtlas software were used for gray matter volumetry. The bilateral ROI labels used were those provided as default settings with the software: Frontal Lobe Hippocampus Occipital Lobe Orbital Gyrus Parietal Lobe Putamen and Temporal Lobe. All 3D-T1WIs were segmented to gray matter with six parameters of VBM 8 with each parameter having between three and eight selectable levels. Reproducibility was evaluated as the standard deviation (mm3) of measured values for the five MRI systems.\\\\\\\\rRESULTS: Reproducibility was influenced by 'Bias regularization (BiasR)' 'Bias FWHM' and 'De-noising filter' settings but not by 'MRF weighting' 'Sampling distance' or 'Warping regularization' settings. Reproducibility in BiasR was influenced by ROI. Superior reproducibility was observed in Frontal Lobe with the BiasR1 setting and in Hippocampus Parietal Lobe and Putamen with the BiasR3* BiasR1 and BiasR5 settings respectively.\\\\\\\\rCONCLUSION: Reproducibility of gray matter volumetry was influenced by parameter settings in VBM 8 using DARTEL and ROI. In multi-center studies the use of appropriate settings in VBM 8 with DARTEL results in reduced scanner effect.","","","2015","10.3414/me14-01-0049","","","medline-25345402.pdf","medline-25345402"
"An Open Conversation on Using Eye-Gaze Methods in Studies of Neurodevelopmental Disorders","Venker C. E., Kover S. T.","Journal of Speech Language & Hearing Research","","PURPOSE: Eye-gaze methods have the potential to advance the study of neurodevelopmental disorders. Despite their increasing use challenges arise in using these methods with individuals with neurodevelopmental disorders and in reporting sufficient methodological detail such that the resulting research is replicable and interpretable.\\\\\\\\rMETHOD: This tutorial presents key considerations involved in designing and conducting eye-gaze studies for individuals with neurodevelopmental disorders and proposes conventions for reporting the results of such studies.\\\\\\\\rRESULTS: Methodological decisions (e.g. whether to use automated eye tracking or manual coding implementing strategies to scaffold children's performance defining valid trials) have cascading effects on the conclusions drawn from eye-gaze data. Research reports that include specific information about procedures missing data and selection of participants will facilitate interpretation and replication.\\\\\\\\rCONCLUSIONS: Eye-gaze methods provide exciting opportunities for studying neurodevelopmental disorders. Open discussion of the issues presented in this tutorial will improve the pace of productivity and the impact of advances in research on neurodevelopmental disorders.","","","2015","10.1044/2015_jslhr-l-14-0304","","","medline-26363412.pdf","medline-26363412"
"Statistical significance: p value, 0.05 threshold, and applications to radiomics—reasons for a conservative approach","Di Leo, G. And Sardanelli, F.","European Radiology Experimental","","Here, we summarise the unresolved debate about p value and its dichotomisation. We present the statement of the american statistical association against the misuse of statistical significance as well as the proposals to abandon the use of p value and to reduce the significance threshold from 0.05 to 0.005. We highlight reasons for a conservative approach, as clinical research needs dichotomic answers to guide decision-making, in particular in the case of diagnostic imaging and interventional radiology. With a reduced p value threshold, the cost of research could increase while spontaneous research could be reduced. Secondary evidence from systematic reviews/meta-analyses, data sharing, and cost-effective analyses are better ways to mitigate the false discovery rate and lack of reproducibility associated with the use of the 0.05 threshold. Importantly, when reporting p values, authors should always provide the actual value, not only statements of “p < 0.05” or “p ≥ 0.05”, because p values give a measure of the degree of data compatibility with the null hypothesis. Notably, radiomics and big data, fuelled by the application of artificial intelligence, involve hundreds/thousands of tested features similarly to other “omics” such as genomics, where a reduction in the significance threshold, based on well-known corrections for multiple testing, has been already adopted. © 2020, the author(s).","","","2020","10.1186/s41747-020-0145-y","","","scopus-2-s2.0-85081592102.pdf","scopus-2-s2.0-85081592102"
"Extending qgis processing toolbox for assessing the geometrical properties of openstreetmap data","Sehra, S.s. And Singh, J. And Sehra, S.k. And Rai, H.s.","Spatial Information Research","","Openstreetmap (osm) offers an under-explored crowdsourced geospatial data useful to urban street network researchers for assessing the geometrical properties of spatial data. Urban street network analysis can provide the assessment of spatial dataset through these properties. The lack of a suitable evaluation framework renders problem for its potential users to evaluate the geometrical properties of the data. To overcome this difficulty, the capability of processing toolbox of qgis has been extended by developing processing scripts using python. These scripts were further used as components in the graphical modeler. The parameters such as degree centrality, average path length, closeness centrality, betweenness centrality, clustering coefficient, and inter-network indicators are developed to provide insights to the overall nature of the spatial data. For performing the empirical analysis, osm dataset of five biggest cities of state of punjab (india) have been analyzed and compared temporally. The results presented the internal geometrical feature’s evaluation of street network in temporal comparison of osm dataset and its credibility. This study provided the basis for reproducible research by developing components for open source software qgis. The developed model can be used to asses the geometrical properties assessment by the town planners to identify the prominent nodes, edges and their relationships in the datasets. © 2022, the author(s), under exclusive licence to korean spatial information society.","","","2023","10.1007/s41324-022-00480-3","","","scopus-2-s2.0-85138867712.pdf","scopus-2-s2.0-85138867712"
"Guidelines for the reporting of renal artery revascularization in clinical trials","Rundback J. H., Sacks D., Kent K. C., Cooper C., Jones D., Murphy T., Rosenfield K., White C., Bettmann M., Cortell S., Puschett J., Clair D. G., Cole P.","Journal of Vascular & Interventional Radiology","","Although the treatment of atherosclerotic renal artery stenosis with use of percutaneous angioplasty stent placement and surgical revascularization has gained widespread use there exist few prospective randomized controlled trials (RCTs) comparing these techniques to each other or against the standard of medical management alone. To facilitate this process as well as help answer many important questions regarding the appropriate application of renal revascularization well-designed and rigorously conducted trials are needed. These trials must have clearly defined goals and must be sufficiently sized and performed so as to withstand intensive outcomes assessment. Toward this end this document provides guidelines and definitions for the design conduct evaluation and reporting of renal artery revascularization RCTs. In addition areas of critically necessary renal artery revascularization investigation are identified. It is hoped that this information will be valuable to the investigator wishing to conduct research in this important area.","","","2002","10.1016/s1051-0443(07)61860-0","","","medline-12397117.pdf","medline-12397117"
"Database grid system for multi-domain dynamic data integration","Shen, D.-R. And Yu, G. And Nie, T.-Z. And Kou, Y.","Ruan Jian Xue Bao/Journal Of Software","","With the richness of common database resources, distributed users in wide areas hope to transparently access and use these data resources on demand. Ds_grid (database grid) is an soa (service-oriented architecture) based database grid system for data sharing in multiple application domains. Ds_grid adopts a p2p (peer-to-peer) multi-chord (multichord) architecture to realize the distributed storage, query processing and dynamic data integration of data resources. According to the text similarity, the data resources are registered to the corresponding domains to realize rapidly discovering data resources. The domain ontology knowledge and reasoning rules are used to support the semantics based intelligent query. A multi-root and multi-peer maintenance based data resources replica management mechanism is applied to improve the reliability of the system. A keyword filter based distributed data integration strategy is adopted to reduce the communication cost. A distributed clustering technique is used to summarize the huge data information. The experiments demonstrate the feasibility and effectiveness of the key techniques of ds_grid.","","","2006","10.1360/jos172302","","","scopus-2-s2.0-33845871757.pdf","scopus-2-s2.0-33845871757"
"Public reporting of hospital quality: recommendations to benefit patients and hospitals","Rothberg M. B., Benjamin E. M., Lindenauer P. K.","Journal of Hospital Medicine (Online)","","Public reporting of hospital performance holds tremendous promise for improving the care provided by hospitals. To date however consumers have failed to embrace public reporting despite considerable efforts to promote it. We review a number of reasons that public reporting has failed to live up to expectations and we make 10 recommendations to improve the value of public reporting for both patients and hospitals. We also review 3 leading performance reporting programs to evaluate how well they adhere to these recommendations.","","","2009","10.1002/jhm.481","","","medline-19514092.pdf","medline-19514092"
"Evaluation of re-identification risk using anonymization and differential privacy in healthcare","Ratra, R. And Gulia, P. And Gill, N.s.","International Journal Of Advanced Computer Science And Applications","","In the present scenario, due to regulations of data privacy, sharing of data with other organization for research or any medical purpose becomes a big hindrance for different healthcare organizations. To preserve the privacy of patients seems like a crucial challenge for healthcare centre. Numerous techniques are used to preserve the privacy such as perturbation, anonymization, cryptography, etc. Anonymization is well known practical solution of this problem. A number of anonymization methods have been proposed by researchers. In this paper, an improved approach is proposed which is based on k-anonymity and differential privacy approaches. The purpose of proposed approach is to prevent the dataset from re-identification risk more effectively from linking attacks using generalization and suppression techniques. © 2022,international journal of advanced computer science and applications.all rights reserved","","","2022","10.14569/ijacsa.2022.0130266","","","scopus-2-s2.0-85126121691.pdf","scopus-2-s2.0-85126121691"
"Announcing open science badges and reaching for the sky","Grahe Jon E.","The Journal of Social Psychology","","The Journal of Social Psychology is the longest running journal publishing research focused on this sub-discipline. JSP's mission has always been to provide empirically based theoretical contributions to the discipline of the highest quality. Though our tradition is rich we have not always met these idealistic standards. Beginning in 2000 with the significant changes to the executive editorial and consulting editorial review boards we have worked toward the goal of increasing the publication standards of the Journal and thus the quality and impact of research published in JSP. We are ready to take another leap forward. As you hold this issue in your hands you will notice that it has a new size and layout. The timing of this external change also marks an announcement aimed at taking another leap forward in our goal toward again being a leading social psychological journal. (PsycInfo Database Record (c) 2021 APA all rights reserved)","","","2014","10.1080/00224545.2014.853582","","","medline-24689331.pdf","medline-24689331"
"Trapping and marking terrestrial mammals for research: integrating ethics performance criteria techniques and common sense","Powell R. A., Proulx G.","ILAR Journal","","We propose that researchers integrate ethics performance criteria techniques and common sense when developing research trapping programs and in which members of institutional animal care and use committees address these topics when evaluating research protocols. To ask questions about ethics is in the best tradition of science and researchers must be familiar with codes of ethics and guidelines for research published by professional societies. Researchers should always work to improve research methods and to decrease the effects on research animals if for no other reason than to minimize the chances that the methods influence the animals' behavior in ways that affect research results. Traps used in research should meet performance criteria that address state-of-the-art trapping technology and that optimize animal welfare conditions within the context of the research. The proposal includes the following criteria for traps used in research: As Criterion I killing-traps should render >/= 70% of animals caught irreversibly unconscious in </= 3 min (calculated with 95% confidence). As Criterion II live-traps should trap >/= 70% of animals with </= 50 points scored for physical injury (calculated with 95% confidence). The types of traps described include killing-traps (snap traps rotating jaw traps snares pitfalls and drowning sets) common sets and the common types of live-traps (box and cage traps pitfalls foothold traps. snares corrals and nets and dart collars). Also described are trapping methods for specific mammals according to which traps fulfill Criteria I and II for which species and techniques for short-term long-term and permanent marking of mammals.","","","2003","","","","medline-13130157.pdf","medline-13130157"
"Assessing evidence quality in research reporting neurocognitive outcomes following paediatric temporal lobe surgery for epilepsy","Flint A. E., Waterman M. G., Siddell P., Houston A. L., Vadlamani G., Chumas P., Morrall Mchj","Epilepsy Research","","PURPOSE: RCTs are the gold standard in determining intervention efficacy with journal impact factor assumed to index research quality. Flint et al's (2017) systematic review examined neurocognitive outcomes following paediatric temporal lobe epilepsy surgery. Retrieved evidence was restricted to non-RCTs which pose greater risk of bias and thus diminish research quality. The current study evaluated risk of bias in sources retrieved by Flint et al. and explored whether impact factor related to research quality within this selected field.\\\\\\\\rMETHODS: Methodological and reporting bias was evaluated using categories of bias specified by Cochrane. The relationship between the identified number of biases and journal impact factors of retrieved sources was examined.\\\\\\\\rRESULTS: All studies carried substantial risk for bias. Methodology bias included low sample size (76.71%; 56/73) risk of confounding cognitive outcomes due to failure to report pre-surgery neurocognitive data (21.92%; 16/73) and to determine whether patients were prescribed antiepileptic drugs at follow-up (53.42%; 39/73). Reporting bias included overstating claims based on findings (53.42%; 39/73) failure to report individual patient characteristics (66%; 33/50) and omitting the nature of surgical interventions (15.07%; 11/73). The number of sources of common bias within studies was not associated significantly with journal impact factor (p = .878).\\\\\\\\rCONCLUSION: This evaluation highlights risk of bias when sources are predominantly uncontrolled non-RCTs and provides evidence that journal impact factor is not a reliable indicator of quality within this field. Authors should limit bias in their methods and reporting of results to ensure the highest quality evidence possible is used to inform treatment decisions and prognosis. Copyright © 2019 Elsevier B.V. All rights reserved.","","","2019","10.1016/j.eplepsyres.2019.03.013","","","medline-31125839.pdf","medline-31125839"
"Sharing data improves monitoring of trans-boundary populations: the case of wolverines in central scandinavia","Gervasi, V. And Brøseth, H. And Gimenez, O. And Nilsen, E.b. And Odden, J. And Flagstad, . And Linnell, J.d.c.","Wildlife Biology","","Populations of wide-ranging species are likely to extend across multiple jurisdictions, including national and international borders. This requires that local institutions implement data sharing and a standardization of monitoring designs. However, a formal evaluation of the benefits of integrated monitoring systems had not, of yet, been performed. Using the wolverines in central scandinavia as a study case, we assessed the benefits of data sharing for the monitoring of trans-boundary populations. We also assessed the performance of two demographic monitoring systems, one relying on a count of reproductive units, the other resulting from non-invasive genetic sampling and capture-recapture modeling. Sharing data across the border between norway and sweden allowed a strong increase in the precision of population size, population growth rate and vital rates estimates. It also allowed revealing that the probability to emigrate from sweden to norway was significantly higher than in the opposite direction, a required condition for the existence of a source--sink dynamics. These findings would have been impossible without trans-boundary data sharing. While the den count monitoring provided an estimated population growth of 138% over the 12-year period, the dna-based estimate was only 72%. A positive trend likely occurred in the detectability of wolverine dens during the first years of the study, and the index was not able to separate the actual demographic trend from the trend in the system's ability to detect reproductions, thus providing positively biased estimates of population growth rate during the initial phase of the study. Data sharing is a crucial need for the study of the processes occurring in trans-boundary populations. It should be enhanced wherever trans-boundary ecological processes occur. Also, managers should be aware that count-based monitoring has a risk of overestimating population growth during the first years after its implementation. © 2016 norwegian institute for nature research.","","","2016","10.2981/wlb.00142","","","scopus-2-s2.0-84969168238.pdf","scopus-2-s2.0-84969168238"
"Degree outcomes and national calibration: debating academic standards in uk geography","Wyse, S. And Page, B. And Walkington, H. And Hill, J.l.","Area","","In this short intervention we report on work in progress by advance he (formerly the higher education academy) in collaboration with professional bodies such as the rgs-ibg, which seeks to respond to public concerns about “grade inflation” in relation to degree outcomes. We present an updated analysis of degree outcomes in uk geography for 2010–2016 showing a strong correlation between average a-level points score on entry and the proportion of good degrees awarded by uk geography departments. We then go on to report on the results of pilot training activities within the discipline to increase the use of social calibration techniques as a means of providing transparent assurance about the high quality of assessment practices. We conclude that there is good reason to engage positively and actively with the public debate about academic standards and we make the case for regular social calibration exercises to share marking practices across multiple institutions as a potential means of ensuring consistency, reliability and clarity in academic standards. The information, practices and views in this article are those of the author(s) and do not necessarily reflect the opinion of the royal geographical society (with ibg). © 2020 royal geographical society (with the institute of british geographers).","","","2020","10.1111/area.12571","","","scopus-2-s2.0-85070950600.pdf","scopus-2-s2.0-85070950600"
"A survey on cost-effective context-aware distribution of social data streams over energy-efficient data centres","Kilanioti, I. And Fernández-Montes, A. And Fernández-Cerero, D. And Mettouris, C. And Nejkovic, V. And Bashroush, R. And Papadopoulos, G.a.","Simulation Modelling Practice And Theory","","Social media have emerged in the last decade as a viable and ubiquitous means of communication. The ease of user content generation within these platforms, e.g. check-in information, multimedia data, etc., along with the proliferation of global positioning system (gps)-enabled, always-connected capture devices lead to data streams of unprecedented amount and a radical change in information sharing. Social data streams raise a variety of practical challenges, including derivation of real-time meaningful insights from effectively gathered social information, as well as a paradigm shift for content distribution with the leverage of contextual data associated with user preferences, geographical characteristics and devices in general. In this article we present a comprehensive survey that outlines the state-of-the-art situation and organizes challenges concerning social media streams and the infrastructure of the data centres supporting the efficient access to data streams in terms of content distribution, data diffusion, data replication, energy efficiency and network infrastructure. We systematize the existing literature and proceed to identify and analyse the main research points and industrial efforts in the area as far as modelling, simulation and performance evaluation are concerned. © 2018","","","2019","10.1016/j.simpat.2018.11.004","","","scopus-2-s2.0-85056410557.pdf","scopus-2-s2.0-85056410557"
"Reporting format for economic evaluation. Part II: Focus on modelling studies","Nuijten M. J., Pronk M. H., Brorens M. J., Hekster Y. A., Lockefeer J. H., de Smet P. A., Bonsel G., van der Kuy A.","PharmacoEconomics","","This article presents the first version of a reporting format for modelling studies which is based on a general reporting format by our taskforce which was published in the previous issue of this journal. The use of decision-analytical models for economic evaluations is increasing because in practice it is not always possible to derive information from prospective studies. However the acceptance of modelling studies is generally lower than prospective studies not only because of the use of secondary data but also because the reports of modelling studies do not always have sufficient transparency. Hence a standardised reporting format may improve the transparency and consequently the acceptance of modelling studies. This article presents an example of a reporting format for economic evaluation based on modelling studies which may facilitate the development of future guidelines for modelling studies. The format consists of a number of headings which are followed by a brief recommendation on the content. This format does not deal with methodology and data management but especially addresses validation and quality assurance which may increase the transparency of the report.","","","1998","","","","medline-10186465.pdf","medline-10186465"
"Design of bbs with visual representation for online data analysis","Takama, Y. And Seo, Y.","Studies In Computational Intelligence","","A concept of bulletin board system (bbs) equipped with information visualization techniques is proposed for supporting online data analysis. Although a group discussion is known to be effective for analyzing data from various viewpoints, the number of participants has to be limited in terms of time and space constraints. To solve the problem, this paper proposes to augment bbs, which is one of popular tools on the web. In order for discussion participants to share the data online, the system provides them with a visual representation of target data, with functions for supporting comment generation as well as retrieving posted comments. In order to show the potential of the concept, a bbs equipped with keygraph is also developed for supporting online chance discovery. It has functions for making visual annotations on the keygraph, as well as a function for retrieving similar scenarios. The experimental result shows the effectiveness of the bbs in terms of the usefulness of scenario generation support functions as well as that of scenario retrieval engines. © 2008 springer-verlag berlin heidelberg.","","","2008","10.1007/978-3-540-78733-4_6","","","scopus-2-s2.0-51349164444.pdf","scopus-2-s2.0-51349164444"
"Research and design of program complexity measurement technology based on oink framework","Qiao, L. And Zou, X. And Duan, R. And Jia, X.","Mathematical Models In Engineering","","With the expansion of software system scale, the study of software complexity has become a hot topic in software engineering. However, the domestic research on software complexity analysis technology is not mature, especially the measurement and evaluation methods of software complexity are not perfect. In order to solve the problem of prediction and evaluation of program structure complexity in software engineering more effectively, this paper proposed a program complexity measurement technique based on oink framework. The technology uses the data sharing interface design to analysis target program by extracting the complex relationship between oink components. On this basis, the technology adopts the layered software architecture to realize the automatic design of the function of the measurement data acquisition module, the complexity measurement module and the data management module of measurement results, thus, the structure complexity of the target program can be analyzed more clearly and accurately. At the same time, this technique applies multiple measurement methods to quantify the complexity of program structure, such as mccabe, halstead, and line count. Experimental results show that this method can effectively measure the complexity of program structure. The solution on software complexity based on the open source onik framework will be open up worldwide, and will be continuously supported and improved by global communities and teams under the constraints of common driving forces. © 2023 liping qiao, et al.","","","2023","10.21595/mme.2023.23162","","","scopus-2-s2.0-85163990613.pdf","scopus-2-s2.0-85163990613"
"Introducing the concept of virtual control groups into preclinical toxicology animal testing","Steger-Hartmann, T. And Kreuchwig, A. And Vaas, L. And Wichard, J. And Bringezu, F. And Amberg, A. And Muster, W. And Pognan, F. And Barber, C.","Altex","","Sharing legacy data from in vivo toxicity studies offers the opportunity to analyze the variability of control groups stratified for strain, age, duration of study, vehicle, and other experimental conditions. Historical animal control group data collected in a repository could be used to construct virtual control groups (vcgs) for toxicity studies. Vcgs are an established concept in clinical trials, but the idea of replacing living beings with virtual data sets has so far not been introduced into the design of regulatory animal studies. The use of vcgs has the potential to reduce animal use by 25% by replacing control group animals with existing randomized data sets. Prerequisites for such an approach are the availability of large and well-structured control data sets as well as thorough statistical evaluations. The foundation of data-sharing has been laid within the innovative medicines initiatives projects etox and etransafe. To establish proof of principle, participating companies have started to collect control group data for subacute (4-week) glp studies with wistar rats (the strain preferentially used in europe) and are characterizing these data for its variability. In a second step, the control group data will be shared among the companies, and cross-company variability will be investigated. In a third step, a set of studies will be analyzed to assess whether the use of vcg data would have influenced the outcome of the study compared to the real control group. © 2020 altex edition. All rights reserved.","","","2020","10.14573/altex.2001311","","","scopus-2-s2.0-85088496437.pdf","scopus-2-s2.0-85088496437"
"Efficient privacy preserving in iomt with blockchain and lightweight secret sharing","Li, C. And Dong, M. And Xin, X. And Li, J. And Chen, X.-B. And Ota, K.","Ieee Internet Of Things Journal","","Internet of medical things (iomt) aggregates a series of smart medical devices and fully uses the collected health data to improve user experience, medical resource utilization, and full life cycle protection. However, privacy leakage, data loss, and inefficient sharing problems are still serious in the data-sharing process between different smart medical devices. This article first introduces an efficient privacy-preserving model with blockchain to construct a secure data-sharing mechanism between different device nodes. This model utilizes distributed storage form to solve the centralized management problem and provides a fundamental secret reconstruction and retrieval framework. Then, a lightweight (t,n) -threshold secret sharing (t/n -ss) scheme is designed to strengthen the medical data-sharing security and efficiency. It utilizes the interleaving encode technology to decrease the length of original message into n small shares. These small shares are also suitable for data transmission and processing with a more energy-efficient way. It can protect privacy by destroying the data's semantic meaning. Meanwhile, it only needs less than t (t≤ n) shares to recover the original secrets, making the sharing process more efficient. Moreover, the performance evaluations of transaction processing in iomt show that the proposed model is very stable. The simulation and performance evaluation results show that this t/n -ss scheme is energy efficient, storage saving, and strong fault tolerance than similar literature. © 2014 ieee.","","","2023","10.1109/jiot.2023.3296595","","","scopus-2-s2.0-85165239172.pdf","scopus-2-s2.0-85165239172"
"A systematic review of repeatability and reproducibility studies of diffusion tensor imaging of cervical spinal cord","Al-Shaari H., J F., R M., Cj H.","British Journal of Radiology","","OBJECTIVES: Diffusion tensor imaging (DTI) techniques are being studied as a possible diagnostic and predictive tool for the evaluation of cervical spinal cord disease. This systematic review aims to evaluate the previous DTI studies that specifically investigated the repeatability and reproducibility of DTI in the cervical spinal cord.\\\\\\\\rMETHODS AND MATERIALS: A search in the PubMed Scopus Web of Science and Ovid electronic databases was conducted for articles published between January 1990 and February 2022 that related to the repeatability and reproducibility of DTI in evaluating the cervical spinal cord using one of the following measurements: the intraclass correlation coefficient (ICC) and/or the coefficient of variation (CV) and/or Bland-Altman (BA) differences analysis methods. DTI studies that presented full statistical analysis of repeatability and/or reproducibility tests of the cervical spinal cord in peer-reviewed full-text publications published in journals were included. Articles that included at least one of the keywords within the titles or abstracts were identified. Additional full-text papers were found by searching the citations and reference lists of related articles. This review has followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidance. Risk of bias was evaluated with 13 criteria weighted toward methodological quality of reported studies using the QuADS assessment criteria. This assessment only included full-text articles written in English.\\\\\\\\rRESULTS: A total of 11 studies were included and assessed for different characteristics including sample size(3-34) re-test time interval (<1 h to >3 months) test-retest reproducibility scores and acquisition method. Six studies used ICC which ranged from poor (ICC<0.37) to excellent reproducibility (ICC 0.91-0.99). Four studies reported an overall CV lower than 40% for all DTI metrics. Three studies reported the Bland-Altman (BA) differences and reported a minimum percentage showing no strong differences between repeated measurements. Quantitative analysis was not undertaken due to heterogeneity of methods. Repeatability and reproducibility measures were generally found to be good.\\\\\\\\rCONCLUSION: This study revealed that the application of DTI and its related measures in a clinical setting in the assessment of cervical spinal cord changes is feasible and reproducible. However cervical spinal cord DTI suffers from some existing limitations that prevent it from being routinely used in research and clinical settings.\\\\\\\\rADVANCES IN KNOWLEDGE: DTI with its parametric maps provide broad evaluation of the tissue structure of axonal white matter and are being studied as a possible diagnostic and predictive tool for the assessment of cervical spinal cord (CSC) disease.","","","2023","10.1259/bjr.20221019","","","medline-37751162.pdf","medline-37751162"
"Older adults and family caregivers' experience of digital health technology in frailty care: A systematic review and meta-ethnography protocol","Darley A., Dix R., Rocher E., Stokes D., Carroll A.","Hrb Open Research","","Background: Digital health technology has been identified as a valuable tool to support older adults with frailty needs in their home setting. Despite the numerous technologies and evaluations of these innovations a synthesis of the older person and family caregivers' experience using technology for support self-management has not been conducted to date. Methods and analysis: A systematic review and meta-ethnography will be conducted in accordance with the PRISMA and eMERGe reporting guidelines. Four peer-reviewed empirical evidence databases will be searched (Medline (Ovid) CINAHL EMBASE PsycINFO) using a defined search strategy. Studies containing qualitative data on the experiences of older people or family caregivers of using digital health technology to support frailty care will be included. Covidence software will be used to screen studies and extract data. The Critical Appraisal Skills Programme (CASP) checklist for qualitative research will be used by two independent reviewers to appraise all included papers. A meta-ethnography will be undertaken in accordance with the seven-phase method described by Noblit and Hare: (1) Getting started (2) Deciding what is relevant to the initial interest (3) Reading the studies (4) Determining how the studies are related (5) Translating the studies into one another (6) Synthesizing translations and (7) Expressing the synthesis. Discussion: To the best of our knowledge this will be the first systematic review to integrate and synthesize the findings of qualitative studies of older citizens' experience of digital health technology. The findings of this meta-ethnography will endeavour to inform future research policy and clinical practice. In particular the results will help to inform the design of future digital health technology to meet the needs of older adults. PROSPERO registration number: Submitted 05/04/2022 and currently under review. Copyright: © 2022 Darley A et al.","","","2022","10.12688/hrbopenres.13549.1","","","medline-36072817.pdf","medline-36072817"
"Open Benchmarking for Click-Through Rate Prediction","Zhu J., Liu J., Yang S., Zhang Q., He X.","","","Click-through rate (CTR) prediction is a critical task for many applications as its accuracy has a direct impact on user experience and platform revenue. In recent years CTR prediction has been widely studied in both academia and industry resulting in a wide variety of CTR prediction models. Unfortunately there is still a lack of standardized benchmarks and uniform evaluation protocols for CTR prediction research. This leads to non-reproducible or even inconsistent experimental results among existing studies which largely limit the practical value and potential impact of their research. In this work we aim to perform open benchmarking for CTR prediction and present a rigorous comparison of different models in a reproducible manner. To this end we ran over 7000 experiments for more than 12000 GPU hours in total to re-evaluate 24 existing models on multiple dataset settings. Surprisingly our experiments show that with sufficient hyper-parameter search and model tuning many deep models have smaller differences than expected. The results also reveal that making real progress on the modeling of CTR prediction is indeed a very challenging research task. We believe that our benchmarking work could not only allow researchers to gauge the effectiveness of new models conveniently but also make them fairly compare with the state of the arts. We have publicly released the benchmarking tools evaluation protocols and experimental settings of our work to promote reproducible research in this field. © 2021 ACM.","","","2021","10.1145/3459637.3482486","","","scopus-2-s2.0-85119205542.pdf","scopus-2-s2.0-85119205542"
"Opera: optional dimensional privacy-preserving data aggregation for smart healthcare systems","Liu, H. And Gu, T. And Shojafar, M. And Alazab, M. And Liu, Y.","Ieee Transactions On Industrial Informatics","","Massive multidimensional health data collected from internet of things (iot) devices are driving a new era of smart health, and with it come privacy concerns. Privacy-preserving data aggregation (pda) is a proven solution providing statistics while hiding raw data. However, existing pda schemes ignore the willingness of data owners to share, so data owners may refuse to share data. To increase their willingness to contribute data, we propose an optional dimensional privacy-preserving data aggregation scheme (opera) to provide data contributors with options on sharing dimensions while keeping their choices and data private. Opera uses selection vectors to represent the decisions of users and count participants dimensionally and achieves data privacy and utility based on a multisecret sharing method and symmetric homomorphic cryptography. Analyses show that in opera, the probability of adversaries breaching privacy is less than 4.68e-97. Performance evaluations demonstrate that opera is outstanding in computation and practical in communication. © 2005-2012 ieee.","","","2023","10.1109/tii.2022.3192037","","","scopus-2-s2.0-85135249152.pdf","scopus-2-s2.0-85135249152"
"Creating a national nonmotorized traffic count archive: process and progress","Nordback, K. And Tufte, K.a. And Harvey, M. And Mcneil, N. And Stolz, E. And Liu, J.","Transportation Research Record","","Robust bicycle and pedestrian data on a national scale would help promote effective planning and engineering of walking and bicycling facilities, build the evidence-based case for funding such projects, and dispel notions that walking and cycling are not occurring. To organize and promote the collection of nonmotorized traffic data, a team of transportation professionals and computer scientists is creating a national bicycle and pedestrian count archive. This archive will enable data sharing by centralizing continuous and short-duration traffic counts in a publicly available online archive. Although other archives exist, this will be the first archive that will be national in scope and enable data to be uploaded directly to the site. This archive will include online input, data quality evaluation, data visualization functions, and the ability to download user-specified data and exchange the data with other archives and applications. This paper details the first steps in creating the archive: (a) review count types, standard formats, and existing online archives;  (b) list primary functional requirements;  (c) design archive architecture;  and (d) develop archive data structure. The archive's versatile data structure allows for both mobile counters and validation counts of the same traffic flow, an innovation in design that greatly expands the usefulness of the archive.","","","2015","10.3141/2527-10","","","scopus-2-s2.0-84975841256.pdf","scopus-2-s2.0-84975841256"
"Pathology and laboratory medicine in cancer care: a global analysis of national cancer control plans","Parra-Herran, C. And Romero, Y. And Milner, D.","International Journal Of Cancer","","In order to understand the structure and effectiveness of national cancer control systems, the international cancer control partnership, the world health organization, the national cancer institute and the union for international cancer control underwent a review of available national cancer health plans (nccps) and noncommunicable diseases plans (ncdps) worldwide. Pathology and laboratory medicine (palm) plays a major role in cancer management, from prevention and screening to patient care (diagnosis and treatment) and population-level cancer surveillance. This review concentrates on the analysis of elements in national cancer care plans pertaining to palm. Of 157 countries surveyed, 90 (57%) had a nccp and 123 (78%) had a ncdp. While 54% of plans included guidelines on cancer diagnosis or plans to develop standards protocols for diagnosis, only 14% included palm as a component of the plan. Palm-related variables such as synoptic pathology reporting, cancer staging guidelines and cancer genetics programs were similarly underrepresented (being mentioned in only 6%, 17% and 16% of plans, respectively). Absence of palm-related variables tended to be more frequent in lower-income countries. Our analysis highlights an important gap in national cancer control initiatives worldwide represented by the overall lack of inclusion of palm resources. Cancer control will only be effective if laboratory sciences are placed as a priority. Based on the data presented herein, there is a need to increase awareness about the importance of palm in cancer care, and to incorporate this discipline in the design and implementation of multilevel cancer control strategies. © 2020 uicc","","","2021","10.1002/ijc.33384","","","scopus-2-s2.0-85097161281.pdf","scopus-2-s2.0-85097161281"
"Simulation of medical data compression and transmission through wlans","Algaet, M.a. And Noh, Z.a.b.m. And Basari, A.s.b.h. And Shibghatullah, A.s. And Milad, A.a. And Mustapha, A.","Journal Of Theoretical And Applied Information Technology","","Therefore, the main objective of this study is to develop a new simulation application for medical data compression and transmission based wi-fi ieee 802.11 with high robust in term of image quality endurance to noise caused by transmission signal. The development of two main modules, namely, wi-fi transmission and medical data compression modules is required to achieve this objective. The focus of the study is to find a new method of medical data compression that has good ability to transmit the medical data even though any noise occurs during data transmission. The wi-fi transmission module was developed based on ieee 802.11b protocol in 1 mbsp data size transmission. The medical data compression modules were developed based on shared dictionary data between sender and receiver part. The shared dictionary was computed by independent component analysis (ica) using each type of medical data. In this study, tree type of data was used to generate shared dictionary: natural image, ultrasound image and fundus image. The performance evaluation includes two parts for the measurement of the error during simulation. First, the performance results related to the transmitted and received data similarity that represented by an error bit. The second performance results are regarded as the similarity between original image before and after transmitted that computed using a peak signal noise ratio (psnr). The developed compression shows promising results with a capability of restoring image with psnr 30 db using medical image. In conclusion, this research has achieved its stated goal of developing a simulation application for medical data compression and transmission based wi-fi ieee 802.11b. © 2005-2015 jatit & lls.","","","2015","","","","scopus-2-s2.0-84950309607.pdf","scopus-2-s2.0-84950309607"
"[Study on the method of automatically determining maxillary complex landmarks based on non-rigid registration algorithms]","Gao Z. X., Wang J., Wen A. N., Zhu Y. J., Qin Q. Z., Wang Y., Zhao Y. J.","Chung-Hua Kou Chiang i Hsueh Tsa Chih Chinese Journal of Stomatology","","Objective: To explore an automatic landmarking method for anatomical landmarks in the three-dimensional (3D) data of the maxillary complex and preliminarily evaluate its reproducibility and accuracy. Methods: From June 2021 to December 2022 spiral CT data of 31 patients with relatively normal craniofacial morphology were selected from those who visited the Department of Oral and Maxillofacial Surgery Peking University School and Hospital of Stomatology. The sample included 15 males and 16 females with the age of (33.3+/-8.3) years. The maxillary complex was reconstructed in 3D using Mimics software and the resulting 3D data of the maxillary complex was mesh-refined using Geomagic software. Two attending physicians and one associate chief physician manually landmarked the 31 maxillary complex datasets determining 24 anatomical landmarks. The average values of the three expert landmarking results were used as the expert-defined landmarks. One case that conformed to the average 3D morphological characteristics of healthy individuals' craniofacial bones was selected as the template data while the remaining 30 cases were used as target data. The open-source MeshMonk program (a non-rigid registration algorithm) was used to perform an initial alignment of the template and target data based on 4 landmarks (nasion left and right zygomatic arch prominence and anterior nasal spine). The template data was then deformed to the shape of the target data using a non-rigid registration algorithm resulting in the deformed template data. Based on the unchanged index property of homonymous landmarks before and after deformation of the template data the coordinates of each landmark in the deformed template data were automatically retrieved as the automatic landmarking coordinates of the homonymous landmarks in the target data thus completing the automatic landmarking process. The automatic landmarking process for the 30 target data was repeated three times. The root-mean-square distance (RMSD) of the dense corresponding point pairs (approximately 25 000 pairs) between the deformed template data and the target data was calculated as the deformation error of the non-rigid registration algorithm and the intra-class correlation coefficient (ICC) of the deformation error in the three repetitions was analyzed. The linear distances between the automatic landmarking results and the expert-defined landmarks for the 24 anatomical landmarks were calculated as the automatic landmarking errors and the ICC values of the 3D coordinates in the three automatic landmarking repetitions were analyzed. Results: The average three-dimensional deviation (RMSD) between the deformed template data and the corresponding target data for the 30 cases was (0.70+/-0.09) mm with an ICC value of 1.00 for the deformation error in the three repetitions of the non-rigid registration algorithm. The average automatic landmarking error for the 24 anatomical landmarks was (1.86+/-0.30) mm with the smallest error at the anterior nasal spine (0.65+/-0.24) mm and the largest error at the left oribital (3.27+/-2.28) mm. The ICC values for the 3D coordinates in the three automatic landmarking repetitions were all 1.00. Conclusions: This study established an automatic landmarking method for three-dimensional data of the maxillary complex based on a non-rigid registration algorithm. The accuracy and repeatability of this method for landmarking normal maxillary complex 3D data were relatively good.","","","2023","10.3760/cma.j.cn112144-20230218-00053","","","medline-37272000.pdf","medline-37272000"
"Beam hardening artifacts in micro-computed tomography scanning can be reduced by X-ray beam filtration and the resulting images can be used to accurately measure BMD","Meganck J. A., Kozloff K. M., Thornton M. M., Broski S. M., Goldstein S. A.","Bone","","Bone mineral density (BMD) measurements are critical in many research studies investigating skeletal integrity. For pre-clinical research micro-computed tomography (microCT) has become an essential tool in these studies. However the ability to measure the BMD directly from microCT images can be biased by artifacts such as beam hardening in the image. This three-part study was designed to understand how the image acquisition process can affect the resulting BMD measurements and to verify that the BMD measurements are accurate. In the first part of this study the effect of beam hardening-induced cupping artifacts on BMD measurements was examined. In the second part of this study the number of bones in the X-ray path and the sampling process during scanning was examined. In the third part of this study microCT-based BMD measurements were compared with ash weights to verify the accuracy of the measurements. The results indicate that beam hardening artifacts of up to 32.6% can occur in sample sizes of interest in studies investigating mineralized tissue and affect mineral density measurements. Beam filtration can be used to minimize these artifacts. The results also indicate that for murine femora the scan setup can impact densitometry measurements for both cortical and trabecular bone and morphologic measurements of trabecular bone. Last when a scan setup that minimized all of these artifacts was used the microCT-based measurements correlated well with ash weight measurements (R(2)=0.983 when air was excluded) indicating that microCT can be an accurate tool for murine bone densitometry.","","","2009","10.1016/j.bone.2009.07.078","","","medline-19651256.pdf","medline-19651256"
"Sharing of individual participant data from clinical trials: general comparison and hiv use case","Mayer, C.s. And Williams, N. And Gold, S. And Fung, K.w. And Huser, V.","Amia ... Annual Symposium Proceedings. Amia Symposium","","Sharing of individual participant data is encouraged by the international committee of medical journal editors. We analyzed clinical trial registry data from clinicaltrials.gov (ctg) and determined the proportion of trials sharing de-identified individual participant data (ipd). We looked at 3,138 medical conditions (as medical subject heading terms). Overall, 10.8% of trials with first registration date after december 1, 2015 answered 'yes' to plan to share de-identified ipd data. This sharing rate ranges between 0% (biliary tract neoplasms) to 72.2% (meningitis, meningococcal) when analyzed by disease that is focus of a study. Via a predictive model, we found that studies that deposited basic summary results data to ctg results registry, large studies and phase 3 interventional studies are most likely to declare intent to share ipd data. As part of an hiv common data element analysis project, we further compared a body of hiv trials (24% sharing rate) to other diseases. ©2019 amia - all rights reserved.","","","2019","","","","scopus-2-s2.0-85083812089.pdf","scopus-2-s2.0-85083812089"
"Recognition-linked information management system (iims). The next major advance in computing","Schein, Alan","Optical Information Systems","","In the world of the fortune 1000, integrated information management is a fact of life. Computers and workstations communicate over high-speed networks, distributing data and sharing resources. Whole libraries of information are accessible through optical and magnetic media. Page layout software and laser printers make it possible to combine, arrange and print text and graphics in a wide variety of formats. More recently, the use of scanners and recognition technology has not only made it possible to capture the image of a page but perhaps more important, to convert the captured text into electronically manipulable or ascii-coded data. The addition of a text-recognition capability has been a turning point in the development of fully integrated information management. For the first time, true two-way interconversion of electronic and paper-based data is a reality. With text recognition, information from virtually any printed or typed source can be rapidly turned into electronic data - often without human intervention - greatly multiplying the power and productivity of information management systems.","","","1990","","","","scopus-2-s2.0-0025389957.pdf","scopus-2-s2.0-0025389957"
"Implementation of the Radiological Society of North America Expert Consensus Guidelines on Reporting Chest CT Findings Related to COVID-19: A Multireader Performance Study","Som A., Lang M., Yeung T., Carey D., Garrana S., Mendoza D. P., Flores E. J., Li M. D., Sharma A., McDermott S., Shepard J. O., Little B. P.","Radiology Cardiothoracic Imaging","","BACKGROUND: RSNA expert consensus guidelines provide a framework for reporting CT findings related to COVID-19 but have had limited multireader validation.\\\\\\\\rPURPOSE: To assess the performance of the RSNA guidelines and quantify interobserver variability in application of the guidelines in patients undergoing chest CT for suspected COVID-19 pneumonia.\\\\\\\\rMATERIALS AND METHODS: A retrospective search from 1/15/20 to 3/30/20 identified 89 consecutive CT scans whose radiological report mentioned COVID-19. One positive or two negative RT-PCR tests for COVID-19 were considered the gold standard for diagnosis. Each chest CT scan was evaluated using RSNA guidelines by 9 readers (6 fellowship trained thoracic radiologists and 3 radiology resident trainees). Clinical information was obtained from the electronic medical record.\\\\\\\\rRESULTS: There was strong concordance of findings between radiology training levels with agreement ranging from 60 to 86% among attendings and trainees (kappa 0.43 to 0.86). Sensitivity and specificity of ""typical"" CT findings for COVID-19 per the RSNA guidelines were on average 86% (range 72%-94%) and 80.2% (range 75-93%) respectively. Combined ""typical"" and ""indeterminate"" findings had a sensitivity of 97.5% (range 94-100%) and specificity of 54.7% (range 37-62%). A total of 163 disagreements were seen out of 801 observations (79.6% total agreement). Uncertainty in classification primarily derived from difficulty in ascertaining peripheral distribution multiple dominant disease processes or minimal disease.\\\\\\\\rCONCLUSION: The ""typical appearance"" category for COVID-19 CT reporting has an average sensitivity of 86% and specificity rate of 80%. There is reasonable interreader agreement and good reproducibility across various levels of experience. Copyright 2020 by the Radiological Society of North America Inc.","","","2020","10.1148/ryct.2020200276","","","medline-33778625.pdf","medline-33778625"
"(Im)possible executions of higher education quality assurance practices: imposing quality model","Selesho, J.m.","Mediterranean Journal Of Social Sciences","","This paper reports on the research undertaken at universities of technology concentrating on institutionalising the academic quality assurance model for higher education institutions. The paper draw significantly from the impact of quality cycles and its impact on institutions, evolution of quality assurance as well as the preferences in choosing the quality assurance phenomenon. The researcher made use of the descriptive survey as it fits perfectly in this kind of study. Questionnaires and structured interviews were utilised. The purpose of using the qualitative research method is to understand the current quality assurance philosophy exercised by institutions, hence the researcher have decided to use idiographic strategy, in which a single case and its structural coherence with a larger context are examined. The population of this study consists of all six universities of technology. Deans of faculties, heads of academic department and programme coordinators the researcher selected only 135 from institutions, as they were able to participate in the study. For the purpose of this study, questionnaire was developed to measure various aspects of quality assurance. From the analysis and interpretation of the empirical findings of this study, it is clear that academics have different perceptions about how the heqc is conducting its re-accreditation process that flows from internal self-evaluation. It is also proposed that the findings of the self-evaluation process be used to benchmark faculties, and departments at heis, but also that he be benchmarked with other quality models worldwide to share best practices. The study concludes that instead of proposing a quality assurance model academics should, rather apply certain principles. Historically, role-players steeped in modern culture have to make it a general practice to build relationships by entering into a dialogue of renegotiating quality principles within the uot community. Solving problems or contributing positively requires cooperation, and cooperation requires a relationship. The study reveals that quality assurance unit did not have adequate staffing to support academic departments and faculties. These weaken the oversight role played by the quality assurance unit.","","","2014","10.5901/mjss.2014.v5n1p507","","","scopus-2-s2.0-84892494808.pdf","scopus-2-s2.0-84892494808"
"Penetrating neck trauma: lack of universal reporting guidelines","Atta H. M., Walker M. L.","American Surgeon","","Penetrating neck injuries constitute a heterogeneous group. Two different classifications of zones of the neck exist in trauma literature. Injuries crossing the midline are not accurately reported. Records of 50 patients with stab wounds (30) gunshot wounds (GSWs; 17) and shotgun wounds (SGWs; 3) were reviewed. Injuries involved zone I in 8 patients zone II in 37 patients zone III in 8 patients posterior triangle in 6 patients and multiple zones in 5 patients. All 11 patients with transcervical GSWs and SGWs sustained vascular or aerodigestive injuries and had longer hospital stays (14.0 +/- 2.6 days) compared with patients with other GSWs (6.6 +/- 2.0 days) and stab wounds (3.6 +/- 0.5 days). We emphasize the lethal potential of transcervical GSWs and SGWs. We suggest that these particular injuries be reported separately. We recommend the universal adoption of one system of classification of neck zones.","","","1998","","","","medline-9520810.pdf","medline-9520810"
"Efficient semantic search in peer-to-peer systems","Zhou, A. And Ling, B. And Lu, Z. And Ng, W. And Shu, Y. And Tan, K.-L.","Lecture Notes In Computer Science (Including Subseries Lecture Notes In Artificial Intelligence And Lecture Notes In Bioinformatics)","","While many p2p-based data sharing applications have been deployed, most of them just support semantics-free and coarse granularity (file level) sharing. Moreover, they are not efficient, either from user's view on service quality or in terms of resources utilization in the systems. In this paper, we present our solutions to support efficient semantic-based search in unstructured p2p systems. We propose a scheme to categorize and manage data in a peer based on the vector-space model. We also propose a scheme that allows peers with similar content to be clustered together. Finally, we examine an adaptive scheme to route queries. We conduct an extensive experimental study to evaluate the effectiveness of our solutions and obtain promising results. © springer-verlag berlin heidelberg 2003.","","","2003","10.1007/978-3-540-45160-0_27","","","scopus-2-s2.0-33646834226.pdf","scopus-2-s2.0-33646834226"
"Searching across-cohort relatives in 54092 GWAS samples via encrypted genotype regression","Zhang Q. X., Liu T., Guo X., Zhen J., Yang M. Y., Khederzadeh S., Zhou F., Han X., Zheng Q., Jia P., Ding X., He M., Zou X., Liao J. K., Zhang H., He J., Zhu X., Lu D., Chen H., Zeng C., Liu F., Zheng H. F., Liu S., Xu H. M., Chen G. B.","PLoS Genetics","","Explicitly sharing individual level data in genomics studies has many merits comparing to sharing summary statistics including more strict QCs common statistical analyses relative identification and improved statistical power in GWAS but it is hampered by privacy or ethical constraints. In this study we developed encG-reg a regression approach that can detect relatives of various degrees based on encrypted genomic data which is immune of ethical constraints. The encryption properties of encG-reg are based on the random matrix theory by masking the original genotypic matrix without sacrificing precision of individual-level genotype data. We established a connection between the dimension of a random matrix which masked genotype matrices and the required precision of a study for encrypted genotype data. encG-reg has false positive and false negative rates equivalent to sharing original individual level data and is computationally efficient when searching relatives. We split the UK Biobank into their respective centers and then encrypted the genotype data. We observed that the relatives estimated using encG-reg was equivalently accurate with the estimation by KING which is a widely used software but requires original genotype data. In a more complex application we launched a finely devised multi-center collaboration across 5 research institutes in China covering 9 cohorts of 54092 GWAS samples. encG-reg again identified true relatives existing across the cohorts with even different ethnic backgrounds and genotypic qualities. Our study clearly demonstrates that encrypted genomic data can be used for data sharing without loss of information or data sharing barrier. Copyright: © 2024 Zhang et al. This is an open access article distributed under the terms of the Creative Commons Attribution License which permits unrestricted use distribution and reproduction in any medium provided the original author and source are credited.","","","2024","10.1371/journal.pgen.1011037","","","medline-38206971.pdf","medline-38206971"
"A large-scale evaluation of u.s. financial institutions' standardized privacy notices","Cranor, L.f. And Leon, P.g. And Ur, B.","Acm Transactions On The Web","","Financial institutions in the united states are required by the gramm-leach-bliley act to provide annual privacy notices. In 2009, eight federal agencies jointly released a model privacy form for these disclosures. While the use of this model privacy form is not required, it has been widely adopted. We automatically evaluated 6,191 u.s. financial institutions' privacy notices posted on the world wide web. We found large variance in stated practices, even among institutions of the same type. While thousands of financial institutions share personal information without providing the opportunity for consumers to opt out, some institutions' practices are more privacy protective. Regression analyses show that large institutions and those headquartered in the northeastern region share consumers' personal information at higher rates than all other institutions. Furthermore, our analysis helped us uncover institutions that do not let consumers limit data sharing when legally required to do so, as well as institutions making self-contradictory statements. We discuss implications for privacy in the financial industry, issues with the design and use of the model privacy form on the world wide web, and future directions for standardized privacy notice. © 2016 acm.","","","2016","10.1145/2911988","","","scopus-2-s2.0-84984806924.pdf","scopus-2-s2.0-84984806924"
"Survey study of research integrity officers' perceptions of research practices associated with instances of research misconduct","Kalichman M.","Research Integrity & Peer Review","","BACKGROUND: Research on research integrity has tended to focus on frequency of research misconduct and factors that might induce someone to commit research misconduct. A definitive answer to the first question has been elusive but it remains clear that any research misconduct is too much. Answers to the second question are so diverse it might be productive to ask a different question: What about how research is done allows research misconduct to occur?\\\\\\\\rMETHODS: With that question in mind research integrity officers (RIOs) of the 62 members of the American Association of Universities were invited to complete a brief survey about their most recent instance of a finding of research misconduct. Respondents were asked whether one or more good practices of research (e.g. openness and transparency keeping good research records) were present in their case of research misconduct.\\\\\\\\rRESULTS: Twenty-four (24) of the respondents (39% response rate) indicated they had dealt with at least one finding of research misconduct and answered the survey questions. Over half of these RIOs reported that their case of research misconduct had occurred in an environment in which at least nine of the ten listed good practices of research were deficient.\\\\\\\\rCONCLUSIONS: These results are not evidence for a causal effect of poor practices but it is arguable that committing research misconduct would be more difficult if not impossible in research environments adhering to good practices of research.","","","2020","10.1186/s41073-020-00103-1","","","medline-33303039.pdf","medline-33303039"
"Data quality self-assessment of child health and sexual reproductive health indicators in Botswana 2016-2017","Tlale L. B., Morake B., Lesetedi O., Maribe L., Masweu M., Faye C., Asiki G.","PLoS ONE [Electronic Resource]","","There is no published data on quality of administrative data for various health indicators in Botswana yet such data are used for policy making and future planning. This article reports on quality of data on child health and sexual and reproductive health (SRH) indicators in Botswana. The main objective of the study was to assess the quality of administrative data from Expanded Immunization Program (EPI) and condom use Depo-Provera uptake and domiciliary care attendance in Botswana. This was a retrospective study entailing a review of data retrieved from district health records and District Health Information System (DHIS). A total of 30 clinics and health posts were randomly selected from two cities a town and three rural villages which makes up 6 districts commonly denoted urban semi-urban and rural respectively. Through a stratified random sampling health facilities were selected. EPI data (Penta 3- third dose of pentavalent vaccine and Measles vaccine) and SRH data (condom use Depo-Provera uptake and Domiciliary care) were assessed for completeness discrepancies and verification factor using WHO Routine data quality (RDQA) assessment tool. A verification score of less than 90%% was considered as underreporting while more than 110% is over reporting. However the score which is within +-10% is acceptable reliable and a good indicator of data quality and reporting system. About 56% (9/16) SRH indicators had a verification factor score outside the accepted range and 87% (13/15) discrepancy value outside the accepted range. For immunization 10% (1/10) had a verification factor score outside the accepted range and 33% (3/9) had a discrepancy value outside the accepted range. The level of completeness was high for both Penta3 and Measles coverage and it was lowest for condom. Our findings highlight a poorer data quality for SRH indicators compared to child health indicators. A comprehensive program review drawing lessons from the child health indicators is required to improve the quality of administrative data in Botswana.","","","2019","10.1371/journal.pone.0220313","","","medline-31408470.pdf","medline-31408470"
"Globechain: an interoperable blockchain for global sharing of healthcare data - a covid-19 perspective","Biswas, S. And Sharif, K. And Li, F. And Bairagi, A.k. And Latif, Z. And Mohanty, S.p.","Ieee Consumer Electronics Magazine","","Contagious diseases are prevalent even in the current era of advanced technology. A uniformed initiative is required to build a reliable interactive information exchange service targeting vaccination data management and other medical services. The conventional data exchange mechanism is centralized, creating many vulnerable issues such as a single point failure, data leakage, access control, etc. This article introduces a blockchain-based medical data-sharing framework (called globechain) to overcome the technical challenges to handle the outbreak records. The challenges that might arise due to the proposed blockchain-based framework are also presented as a future direction that grabs the proposal's effectiveness. © 2012 ieee.","","","2021","10.1109/mce.2021.3074688","","","scopus-2-s2.0-85105040663.pdf","scopus-2-s2.0-85105040663"
"A secure protocol for sharing trust data in hybrid p2p network","Lin, H. And Zhou, Y.","Journal Of Networks","","The trust data is critical to the trust model of p2p system. In this paper we present an efficient certificateless cryptography scheme and propose a protocol which provides the ability for sharing trust data securely. The protocol avoids the escrow problem identity-based cryptosystem and the secure delivery of private keys. The security of scheme is based on some underlying problems closely related to the bilinear diffie-hellman problem are computationally hard. It tolerates the type i and type ii adversary. The proof of security is presented in the random oracle model. Through security discussion, we show that my secure protocol is extremely secure when encounter a variety of possible attacks. © 2011 academy publisher.","","","2011","10.4304/jnw.6.4.607-614","","","scopus-2-s2.0-79955495442.pdf","scopus-2-s2.0-79955495442"
"A comparison of agree and right: which clinical practice guideline reporting checklist should be followed by guideline developers?","Yao, X. And Ma, J. And Wang, Q. And Kanters, D. And Ali, M.u. And Florez, I.d.","Journal Of General Internal Medicine","","Background: a clinical practice guideline (cpg) reporting checklist is used to assist cpg developers in recording what content should be provided in a cpg report. Recently, two checklists have become available on the enhancing the quality and transparency of health research network website: agree (appraisal of guidelines, research and evaluation) published in 2016 and right (reporting items for practice guidelines in healthcare) published in 2017. The objective of this study was to describe the advantages and disadvantages of these two cpg reporting checklists. Methods: two epidemiologists who lacked experience using both agree and right but were familiar with evidence-based medicine methodology independently compared agree with right on an item-by-item basis. Their assessments were compiled on a pre-designed data form and any disagreements were resolved through discussion. Three other co-authors independently compared agree with right and decided if they agreed with the results of comparison of the two cpg reporting checklists from the first two co-authors. Finally, another co-author reviewed the comparison results to ensure that the description was clear and understandable. Results: the following six relationships between the two checklists were observed: (1) 11 items from agree completely matched with 12 items from right;  (2) four items were listed in agree only;  (3) 12 items were listed in right only;  (4) three items in agree were partially covered by three items in right;  (5) six items in right were partially covered by three items in agree;  and (6) two items intersected across agree and right. Based on the comparison results, the potential impact analysis of selecting either checklist is described. Discussion: we recommend that cpg developers use either agree plus items unique to right or right plus items unique to agree. © 2019, society of general internal medicine.","","","2020","10.1007/s11606-019-05508-3","","","scopus-2-s2.0-85075179654.pdf","scopus-2-s2.0-85075179654"
"Dashboard to show key metrics for teams following agile methodology","Sangeeta, S. And Malarvizhi, V.","International Journal Of Applied Engineering Research","","Developer awareness and being well informed about the project status are important factors for successful product development. Understanding, analyzing and transforming results into a form that helps the team to track the progress and quality of a product will help in their efficiency, effectiveness and performance. There is a need to ease out this process of analyzing data and sharing them across members of a team. This paper talks about the implementation of an on premise information visualization tool or a dashboard that exposes key metrics for developers who are following an agile model. The tool involves a widget based presentation of metrics and allows creation of customizable dashboards. This dashboard is aimed to provide all the statistical data of a project running on sonar & jenkin by giving a comprehensive measure of risk to ship a product. © research india publications.","","","2015","","","","scopus-2-s2.0-84937912768.pdf","scopus-2-s2.0-84937912768"
"Empirical research on organizational infrastructure model impact to spatial data sharing","Chao, H. And Chou, T.-Y.","Annals Of Gis","","There are many factors in various aspects that affect spatial data sharing (sds), such as organization, personnel, legal system, data use, technique, motives, cost, fairness, power balance and data standards. Early research had mostly dealt with personal experience, which lacked holistic thinking and resolving. In recent years, researchers who believed sds as a social phenomenon began study using social network analysis and observed the role played by organizational networks during the process of sds to explain how organizational networks affected sds. While there exist few studies on sds between units and persons within an organization, and past research lacked effective methods of message gathering and filtering from the targeted organizations, this study proposed the empirical method and dimensions, unlike before, to understand and promote sds from various aspects. After observation on organizational process of sds over a long period, this article gathered empirical data on the behaviours of sds in taichung city government over 17 years and explained the sharing structure model of spatial data in organizational network by social network analysis and graph theory. The importance of the connection between the centre node in such structural model and the routine affairs of the organization was elaborated. This study provided the empirical method and scientifically generated results. © 2013 taylor & francis group.","","","2013","10.1080/19475683.2013.843592","","","scopus-2-s2.0-84889680077.pdf","scopus-2-s2.0-84889680077"
"Communicating results in post-Belmont era biomonitoring studies: Lessons from genetics and neuroimaging research","Morello-Frosch R., Varshavsky J., Liboiron M., Brown P., Brody J. G.","Environmental Research","","Background: Biomonitoring is a critical tool to assess the effects of chemicals on health as scientists seek to better characterize life-course exposures from diverse environments. This trend coupled with increased institutional support for community-engaged environmental health research challenge established ethical norms related to biomonitoring results communication and data sharing between scientists study participants and their wider communities. Method(s): Through a literature review participant observation at workshops and interviews we examine ethical tensions related to reporting individual data from chemical biomonitoring studies by drawing relevant lessons from the genetics and neuroimaging fields. Result(s): In all three fields ethical debates about whether/how to report-back results to study participants are precipitated by two trends. First changes in analytical methods have made more data accessible to stakeholders. For biomonitoring improved techniques enable detection of more chemicals at lower levels and diverse groups of scientists and health advocates now conduct exposure studies. Similarly innovations in genetics have catalyzed large-scale projects and broadened the scope of who has access to genetic information. Second increasing public interest in personal medical information has compelled imaging researchers to address demands by participants to know their personal data despite uncertainties about their clinical significance. Four ethical arenas relevant to biomonitoring results communication emerged from our review: tensions between participants' right-to-know their personal results versus their ability or right-to-act to protect their health; whether and how to report incidental findings; informed consent in biobanking; and open-access data sharing. Conclusion(s): Ethically engaging participants in biomonitoring studies requires consideration of several issues including scientific uncertainty about health implications and exposure sources the ability of participants to follow up on potentially problematic results tensions between individual and community research protections governance and consent regarding secondary use of tissue samples and privacy challenges in open access data sharing. Copyright © 2014 Elsevier Inc.","","","2015","10.1016/j.envres.2014.10.001","","","medline-25460657.pdf","medline-25460657"
"Closing the circle: the knowledge management spiral of project management","Jugdev, K.","International Journal Of Knowledge Management Studies","","Using nonaka’s conceptual framework, we present empirical findings from a study on project management knowledge-sharing practices. Following a review of key concepts on competitive advantage and project management, we present our theoretical framework and methodology. The paper places our knowledge-sharing spiral findings in the context of an earlier multivariate study. Our findings support the socialisation-externalisation-combination-internalisation knowledge transfer model, as the majority of the correlations were highest as one moved between the four quadrants;  the lowest correlation was between externalisation and combination. Although the correlations between the four modes of knowledge sharing did not consistently show strong enough relationships to support the view that project management as a whole was a source of temporary or sustained competitive advantage, the findings support the importance of emphasising knowledge development and sharing among all four quadrants. © 2007 inderscience enterprises ltd.","","","2007","10.1504/ijkms.2007.012533","","","scopus-2-s2.0-40349095292.pdf","scopus-2-s2.0-40349095292"
"Gait recognition from motion capture data","Balazia, M. And Sojka, P.","Acm Transactions On Multimedia Computing, Communications And Applications","","Gait recognition from motion capture data, as a pattern classification discipline, can be improved by the use of machine learning. This article contributes to the state of the art with a statistical approach for extracting robust gait features directly from raw data by a modification of linear discriminant analysis with maximum margin criterion. Experiments on the cmu mocap database show that the suggested method outperforms 13 relevant methods based on geometric features and a method to learn the features by a combination of principal component analysis and linear discriminant analysis. The methods are evaluated in terms of the distribution of biometric templates in respective feature spaces expressed in a number of class separability coefficients and classification metrics. Results also indicate a high portability of learned features, what means that we can learn what aspects of walk people generally differ in and extract those as general gait features. Recognizing people without needing group-specific features is convenient, as particular people might not always provide annotated learning data. As a contribution to reproducible research, our evaluation framework and database have been made publicly available. This research makes motion capture technology directly applicable for human recognition. © 2018 acm","","","2018","10.1145/3152124","","","scopus-2-s2.0-85042907000.pdf","scopus-2-s2.0-85042907000"
"Searchable attribute-based mechanism with efficient data sharing for secure cloud storage","Liang, K. And Susilo, W.","Ieee Transactions On Information Forensics And Security","","To date, the growth of electronic personal data leads to a trend that data owners prefer to remotely outsource their data to clouds for the enjoyment of the high-quality retrieval and storage service without worrying the burden of local data management and maintenance. However, secure share and search for the outsourced data is a formidable task, which may easily incur the leakage of sensitive personal information. Efficient data sharing and searching with security is of critical importance. This paper, for the first time, proposes a searchable attribute-based proxy reencryption system. When compared with the existing systems only supporting either searchable attribute-based functionality or attribute-based proxy reencryption, our new primitive supports both abilities and provides flexible keyword update service. In particular, the system enables a data owner to efficiently share his data to a specified group of users matching a sharing policy and meanwhile, the data will maintain its searchable property but also the corresponding search keyword(s) can be updated after the data sharing. The new mechanism is applicable to many real-world applications, such as electronic health record systems. It is also proved chosen ciphertext secure in the random oracle model. © 2015 ieee.","","","2015","10.1109/tifs.2015.2442215","","","scopus-2-s2.0-84938701752.pdf","scopus-2-s2.0-84938701752"
"Study on smes credit evaluation system in e-commerce environment","Li, J.-M. And Wu, J.-Y. And Zhang, J.-L. And Ke, L.-M.","Xitong Gongcheng Lilun Yu Shijian/System Engineering Theory And Practice","","Based on the generalization of the ec credibility theory, we made a research into the credibility assessment index system for small and mid-enterprises. Referring to various kinds of credit assessment index and the general credibility evaluation for enterprises, we have established four categories of assessment indexes, or fifteen items in all, via positive research method and analytic hierarchy process (ahp) combined with the characteristics of b2b e-commerce business. After the comprehensive assessment of the credit rating of the small and medium e-commerce enterprises, we have set up the e-commerce credit evaluation model, which has been applied to thirty small and medium-sized ec enterprises. Hence, a scientific and convenient credit assessment method has been provided for b2b small and medium-sized ec enterprises.","","","2012","","","","scopus-2-s2.0-84859640284.pdf","scopus-2-s2.0-84859640284"
"Evaluation of big data construction for eco-environment and its information disclosure by environmental agencies in china","Yi, Z. And Guizhcn, H. And Yonglong, L. And Yanfei, M. And Shuai, S.","Shengtai Xuebao","","Big data const met ion for eco-environment has beromr- a creative approach in environmental management, and it is also the basic requirement for building the "" data power"" in china. Aiming to explore the general situation of big data construction for eco-environment by environmental agencies, this study conducted literature analyses and website interviews of environmental agencies in 3! Provinces, 27 provincial capital cities, and 6 big data construction pilot cities in 2018. The results showed that although considerable progress had been made in data resource integration, there were still many problems with regional development, institution building, data sharing, and big data applications. Therefore, we proposed the following four suggestions: ( 1) expanding the relevant functions of environmental information center;  (2) accelerating the progress of integration and sharing for big data;  (3) strengthening international exchanges;  (4) promoting the applications of big data in key areas. © 2019 science press. All rights reserved.","","","2019","10.5846/stxb201809152013","","","scopus-2-s2.0-85063316849.pdf","scopus-2-s2.0-85063316849"
"A semi-automated pipeline for fulfillment of resource requests from a longitudinal alzheimer's disease registry","Mckenzie K.a. And Hunt S.l. And Hulshof G. And Mudaranthakam D.p. And Meyer K. And Vidoni E.d. And Burns J.m. And Mahnken J.d.","Jamia Open","","Objective: managing registries with continual data collection poses challenges, such as following reproducible research protocols and guaranteeing data accessibility. The university of kansas (ku) alzheimer's disease center (adc) maintains one such registry: curated clinical cohort phenotypes and observations (c3po). We created an automated and reproducible process by which investigators have access to c3po data. Material(s) and method(s): data was input into research electronic data capture. Monthly, data part of the uniform data set (uds), that is data also collected at other adcs, was uploaded to the national alzheimer's coordinating center (nacc). Quarterly, nacc cleaned, curated, and returned the uds to the ku data management and statistics (dms) core, where it was stored in c3po with other quarterly curated site-specific data. Investigators seeking to utilize c3po submitted a research proposal and requested variables via the publicly accessible and searchable data dictionary. The dms core used this variable list and an automated sas program to create a subset of c3po. Result(s): c3po contained 1913 variables stored in 15 datasets. From 2017 to 2018, 38 data requests were completed for several ku departments and other research institutions. Completing data requests became more efficient;  c3po subsets were produced in under 10 seconds. Discussion(s): the data management strategy outlined above facilitated reproducible research practices, which is fundamental to the future of research as it allows replication and verification to occur. Conclusion(s): we created a transparent, automated, and efficient process of extracting subsets of data from a registry where data was changing daily.copyright © the author(s) 2019. Published by oxford university press on behalf of the american medical informatics association. This is an open access article distributed under the terms of the creative commons attribution non-commercial license (http://creativecommons.org/licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited.","","","2019","10.1093/jamiaopen/ooz032","","","embase-631253608.pdf","embase-631253608"
"Quality of reporting for randomised clinical trials published in latin american and spanish journals: a protocol for a systematic survey of three clinical specialities","Bachelet, V.c. And Carrasco, V.a. And Bravo-Córdova, F. And Díaz, R.a. And Lizana, F.j. And Meza-Ducaud, N. And Pardo-Hernandez, H. And Uribe, F.a. And Vergara, A.f. And Villanueva, J. And Navarrete, M.s.","Bmj Open","","Introduction: quality of reporting refers to how published articles communicate how the research was done and what was found. Gaps and imprecisions of reporting hamper the assessment of the methodological quality and internal and external validity. The consolidated standards of reporting trials (consort) are a set of evidence-based recommendations of the minimum elements to be included in the reporting of randomised controlled trials (rcts) to ensure a complete and transparent account of what was done, how it was done and what was found. Few studies have been conducted on the impact of consort on rcts published in latin american and spanish journals. We aim to assess the reporting quality of rcts of three clinical specialities published in spanish and latin american journals, as well as to assess changes over time and associations of quality with journal and country indicators. Methods and analysis: we will conduct a systematic survey of all rcts published in spanish-language journals in three clinical fields (dentistry, neurology and geriatrics) from 1990 to 2018. We will include rcts from previous work that has identified all rcts on these medical fields published in spain and latin america. We will update this work via handsearching of relevant journals. Assessment of quality of reporting will be conducted independently and in duplicate using the consort 2010 statement. We will also extract journal and country indicators. We will conduct descriptive statistics and secondary analyses considering the year, country, and journal of publication, among others. Ethics and dissemination: the universidad de santiago de chile's ethics committee approved the protocol. We will disseminate the results of this work in peer-reviewed scientific journals and conference proceedings. We expect to raise awareness among researchers, journal editors and funders on the importance of training in reporting guidelines and using them from the inception of rct protocols. © author(s) (or their employer(s)) 2020. Re-use permitted under cc by-nc. No commercial re-use. See rights and permissions. Published by bmj.","","","2020","10.1136/bmjopen-2019-036148","","","scopus-2-s2.0-85086792110.pdf","scopus-2-s2.0-85086792110"
"Mentoring and the impact of the research climate","Roberts G. C., Kavussanu M., Sprague R. L.","Science & Engineering Ethics","","In this article we focus on the mentoring process and we argue that the internal and external pressures extant at research universities may create a research culture that may be antithetical to appropriate mentoring. We developed a scale based on motivation theory to determine the perceived research culture in departments and research laboratories and a mentoring scale to determine approaches to mentoring graduate students. Participants were 610 faculty members across 49 departments at a research oriented university. The findings were that a mastery-oriented research climate and an outcome-oriented research climate were manifested at the university. More importantly each research climate had its own unique impact on how the faculty approached mentoring graduate students. A mastery research climate was related to a more supportive approach to mentoring than the outcome research climate. We concluded by suggesting that the outcome research climate may have an adverse effect on effective mentoring and on maintaining research ethics.","","","2001","","","","medline-11697009.pdf","medline-11697009"
"Sharing practice innovation experiences: the 'flat-pack' approach","Carr, S.m. And Lhussier, M.","Practice Development In Health Care","","Much practice innovation knowledge is vulnerable owing to a lack of processes to share the learning experiences at individual and organizational levels. This article describes how members of a collaborative learning group within a public health intervention evaluation attempted to tackle the perennial challenges of sharing innovation learning. The outcome was the development of a user-friendly 10-point guide, which systematically describes key steps to be considered for the replication and sustainability of any multi-intervention approach to tackle a health improvement issue in a determined geographical area. Copyright © 2008 john wiley & sons, ltd.","","","2008","10.1002/pdh.267","","","scopus-2-s2.0-58049211974.pdf","scopus-2-s2.0-58049211974"
"Towards open and reproducible multi-instrument analysis in gamma-ray astronomy","Nigro, C. And Deil, C. And Zanin, R. And Hassan, T. And King, J. And Ruiz, J.e. And Saha, L. And Terrier, R. And Brügge, K. And Nöthe, M. And Bird, R. And Lin, T.t.y. And Aleksić, J. And Boisson, C. And Contreras, J.l. And Donath, A. And Jouvin, L. And Kelley-Hoskins, N. And Khelifi, B. And Kosack, K. And Rico, J. And Sinha, A.","Astronomy And Astrophysics","","The analysis and combination of data from different gamma-ray instruments involves the use of collaboration proprietary software and case-by-case methods. The effort of defining a common data format for high-level data, namely event lists and instrument response functions (irfs), has recently started for very-high-energy gamma-ray instruments, driven by the upcoming cherenkov telescope array (cta). In this work we implemented this prototypical data format for a small set of magic, veritas, fact, and h.e.s.s. Crab nebula observations, and we analyzed them with the open-source gammapy software package. By combining data from fermi-lat, and from four of the currently operating imaging atmospheric cherenkov telescopes, we produced a joint maximum likelihood fit of the crab nebula spectrum. Aspects of the statistical errors and the evaluation of systematic uncertainty are also commented upon, along with the release format of spectral measurements. The results presented in this work are obtained using open-access on-line assets that allow for a long-term reproducibility of the results. © eso 2019.","","","2019","10.1051/0004-6361/201834938","","","scopus-2-s2.0-85065234943.pdf","scopus-2-s2.0-85065234943"
"Physician and stakeholder perceptions of conflict of interest policies in oncology","Lockhart A. C., Brose M. S., Kim E. S., Johnson D. H., Peppercorn J. M., Michels D. L., Storm C. D., Schuchter L. M., Rathmell W. K.","Journal of Clinical Oncology","","PURPOSE: The landscape of managing potential conflicts of interest (COIs) has evolved substantially across many disciplines in recent years but rarely are the issues more intertwined with financial and ethical implications than in the health care setting. Cancer care is a highly technologic arena with numerous physician-industry interactions. The American Society of Clinical Oncology (ASCO) recognizes the role of a professional organization to facilitate management of these interactions and the need for periodic review of its COI policy (Policy).\\\\\\\\rMETHODS: To gauge the sentiments of ASCO members and nonphysician stakeholders two surveys were performed. The first asked ASCO members to estimate opinions of the Policy as it relates to presentation of industry-sponsored research. Respondents were classified as consumers or producers of research material based on demographic responses. A similar survey solicited opinions of nonphysician stakeholders including patients with cancer survivors family members and advocates.\\\\\\\\rRESULTS: The ASCO survey was responded to by 1967 members (1% of those solicited); 80% were producers and 20% were consumers. Most respondents (93% of producers; 66% of consumers) reported familiarity with the Policy. Only a small proportion regularly evaluated COIs for presented research. Members favored increased transparency about relationships over restrictions on presentations of research. Stakeholders (n = 264) indicated that disclosure was ""very important"" to ""extremely important"" and preferred written disclosure (77%) over other methods.\\\\\\\\rCONCLUSION: COI policies are an important and relevant topic among physicians and patient advocates. Methods to simplify the disclosure process improve transparency and facilitate responsiveness are critical for COI management.","","","2013","10.1200/jco.2012.47.5475","","","medline-23530092.pdf","medline-23530092"
"Improvements in the infrastructure for nursing research in universities in Kazakhstan","Jarvinen S., Heikkila J., Meyermanova I., Kuanysh Z., Molotov-Luchanskiy V.","International Nursing Review","","AIM: This study aimed to describe the status and analyze the improvements made by universities in Kazakhstan to nursing research infrastructure in the following services: library internationalization finance information and communication technology (ICT) and research development and innovation (RDI).\\\\\\\\rBACKGROUND: In higher education institutions (HEIs) a strong research infrastructure is a necessity for academic education and research. In Central Asian countries nursing is regarded as an assistive field to medicine affecting nursing research infrastructures.\\\\\\\\rMETHODS: In this descriptive study following benchmarking and a recommendations report an interview of nursing faculty members was used to obtain data regarding nursing research infrastructure in ten universities in Kazakhstan. The SQUIRE-EDU was used to ensure the quality of reporting.\\\\\\\\rRESULTS: The Kazakhstani universities providing nursing education are still in the process of developing their nursing research infrastructure. They have not acquired access to nursing databases and only one textbook concerning nursing research can be found from their libraries. None of the universities have joined international nursing networks. The participation of the university staff and students in conferences with nursing themes has increased. The universities are investing in staff capacity building but not yet in nursing research projects.\\\\\\\\rDISCUSSION AND CONCLUSION: Kazakhstani universities have the autonomy to develop nursing research and its infrastructure. Active measures by the university management such as financing access to nursing databases international cooperation and international projects are necessary.\\\\\\\\rIMPLICATIONS FOR NURSING AND HEALTH POLICY: Research infrastructures' quality strongly impacts the development of nursing science and practice in any country. It is crucial to increase the volume of research that demonstrates the effectiveness of clinical nursing and its contribution to health outcomes. To enable the faster development of nursing science in Central Asian countries this development should be supported through international collaboration. Copyright © 2022 The Authors. International Nursing Review published by John Wiley & Sons Ltd on behalf of International Council of Nurses.","","","2023","10.1111/inr.12791","","","medline-35895978.pdf","medline-35895978"
"Scientific history biogeography and biological traits predict presence of cryptic or overlooked species","Cahill A. E., Meglecz E., Chenuil A.","Biological Reviews of the Cambridge Philosophical Society","","Genetic data show that many nominal species are composed of more than one biological species and thus contain cryptic species in the broad sense (including overlooked species). When ignored cryptic species generate confusion which beyond biodiversity or vulnerability underestimation blurs our understanding of ecological and evolutionary processes and may impact the soundness of decisions in conservation or medicine. However very few hypotheses have been tested about factors that predispose a taxon to contain cryptic or overlooked species. To fill this gap we surveyed the literature on free-living marine metazoans and built two data sets one of 187603 nominal species and another of 83 classes or phyla to test several hypotheses correcting for sequence data availability taxon size and phylogenetic relatedness. We found a strong effect of scientific history: the probability of a taxon containing cryptic species was highest for the earliest described species and varied among time periods potentially consistently with an influence of prevailing scientific theories. The probability of cryptic species being present was also increased for species with large distribution ranges. They were more frequent in the north polar and south polar zones contradicting previous predictions of more cryptic species in the tropics and supporting the hypothesis that many cryptic species diverged recently. The number of cryptic species varied among classes with an excess in hydrozoans and polychaetes and a deficit in actinopterygians for example but precise class ranking was relatively sensitive to the statistical model used. For all models biological traits rather than phylum appeared responsible for the variation among classes: there were fewer cryptic species than expected in classes with hard skeletons (perhaps because they provide good characters for taxonomy) and image-forming vision (in which selection against heterospecific mating may enhance morphological divergence) and more in classes with internal fertilisation. We estimate that among marine free-living metazoans several thousand additional cryptic species complexes could be identified as more sequence data become available. The factors identified as important for marine animal cryptic species are likely important for other biomes and taxa and should aid many areas in biology that rely on accurate species identification. Copyright © 2023 The Authors. Biological Reviews published by John Wiley & Sons Ltd on behalf of Cambridge Philosophical Society.","","","2023","10.1111/brv.13034","","","medline-38049930.pdf","medline-38049930"
"The Resource Identification Initiative: a cultural shift in publishing","Bandrowski A., Brush M., Grethe J. S., Haendel M. A., Kennedy D. N., Hill S., Hof P. R., Martone M. E., Pols M., Tan S. C., Washington N., Zudilova-Seinstra E., Vasilevsky N.","Brain and Behavior","","A central tenet in support of research reproducibility is the ability to uniquely identify research resources that is reagents tools and materials that are used to perform experiments. However current reporting practices for research resources are insufficient to identify the exact resources that are reported or to answer basic questions such as ""How did other studies use resource X?"" To address this issue the Resource Identification Initiative was launched as a pilot project to improve the reporting standards for research resources in the methods sections of papers and thereby improve identifiability and scientific reproducibility. The pilot engaged over 25 biomedical journal editors from most major publishers as well as scientists and funding officials. Authors were asked to include Research Resource Identifiers (RRIDs) in their manuscripts prior to publication for three resource types: antibodies model organisms and tools (i.e. software and databases). RRIDs are assigned by an authoritative database for example a model organism database for each type of resource. To make it easier for authors to obtain RRIDs resources were aggregated from the appropriate databases and their RRIDs made available in a central web portal ( http://scicrunch.org/resources). RRIDs meet three key criteria: they are machine readable free to generate and access and are consistent across publishers and journals. The pilot was launched in February of 2014 and over 300 papers have appeared that report RRIDs. The number of journals participating has expanded from the original 25 to more than 40 with RRIDs appearing in 62 different journals to date. Here we present an overview of the pilot project and its outcomes to date. We show that authors are able to identify resources and are supportive of the goals of the project. Identifiability of the resources post-pilot showed a dramatic improvement for all three resource types suggesting that the project has had a significant impact on identifiability of research resources.","","","2016","10.1002/brb3.417","","","medline-27110440.pdf","medline-27110440"
"Comparing the protection and use of online personal information in south africa and the united kingdom in line with data protection requirements","Da Veiga, A. And Vorster, R. And Li, F. And Clarke, N. And Furnell, S.m.","Information And Computer Security","","Purpose: the purpose of this study was to investigate the difference between south africa (sa) and the united kingdom (uk) in terms of data protection compliance with the aim to establish if a country that has had data protection in place for a longer period of time has a higher level of compliance with data protection requirements in comparison with a country that is preparing for compliance. Design/methodology/approach: an insurance industry multi-case study within the online insurance services environment was conducted. Personal information of four newly created consumer profiles was deposited to 10 random insurance organisation websites in each country to evaluate a number of data privacy requirements of the data protection act and protection of personal information act. Findings: the results demonstrate that not all the insurance organisations honored the selected opt-out preference for receiving direct marketing material. This was evident in direct marketing material that was sent from the insurance organisations in the sample to both the sa and uk consumer profiles who opted out for it. A total of 42 unsolicited third-party contacts were received by the sa consumer profiles, whereas the uk consumer profiles did not receive any third-party direct marketing. It was also found that the minimality principle is not always met by both sa and uk organisations. Research limitations/implications: as a jurisdiction with a heavy stance towards privacy implementation and regulation, it was found that the uk is more compliant than sa in terms of implementation of the evaluated data protection requirements included in the scope of this study, however not fully compliant. Originality/value: based upon the results obtained from this research, it suggests that the sa insurance organisations should ensure that the non-compliance aspects relating to direct marketing and sharing data with third parties are addressed. Sa insurance companies should learn from the manner in which the uk insurance organisations implement these privacy requirements. Furthermore, the uk insurance organisations should focus on improved compliance for direct marking and the minimality principle. The study indicates the positive role that data protection legislation plays in a county like the uk, with a more mature stance toward compliance with data protection legislation. © 2019, emerald publishing limited.","","","2020","10.1108/ics-11-2018-0135","","","scopus-2-s2.0-85071663731.pdf","scopus-2-s2.0-85071663731"
"Where are the scientific standards for high-quality replication studies?","Fiedler, Klaus","Psychologische Rundschau","","There is wide consensus that replication affords an important instrument for identifying valid findings and solid research approaches. However, if replication research serves a major scientific function, then it must be evaluated in terms of strict methodological rules and clearly articulated scientific criteria. A critical analysis of contemporary replication projects-such as the recently published report by the open science collaboration-reveals, however, that no logically sound methodology for state-of-the art replication research has been developed and applied so far. As a consequence, the validity of inferences drawn from many replication studies remains equivocal. Four aspects of this fundamental problem are discussed: uncertainty about the objective of replication (replicandum);  neglect of specific methodological problems (regressiveness;  reliability;  change measurement);  one-sided focus on the avoidance of allegedly expensive ""false-positives"" in the absence of any serious attempt to run a cost-benefit analysis;  and the sorely neglected goal of implementing excellent replication research that leads to new insights and genuine scientific progress. (Psycinfo database record (c) 2021 apa, all rights reserved) abstract (german) es gibt einen breiten konsens, dass replikation ein wichtiges instrument ist, um valide befunde und solide forschung zu erkennen. Wenn sie aber wissenschaftlich bedeutsam ist, dann muss auch die replikationsforschung an strengen methodischen regeln und an klar artikulierten wissenschaftlichen zielen gemessen werden. Eine kritische beschaftigung mit der aktuellen replikationsforschung-etwa im jungst veroffentlichten bericht der open science collaboration-zeigt jedoch, dass eine strenge und forschungslogisch begrundete methodologie fur replikationsstudien bislang weder angewandt noch entwickelt wurde. Infolgedessen bleibt die validitat der schlusse, die aus replikationsstudien gezogen werden durfen, oftmals unklar. Dieses grundlegende problem wird hier unter vier gesichtspunkten diskutiert: unklarheit des gegenstandes der replikation (replicandum), vernachlassigung einschlagiger methodischer probleme (regressivitat;  reliabilitat der veranderungsmessung), einseitige vermeidung von angeblich kostentrachtigen falsch-positiven"" ohne versuch einer systematischen kosten-nutzen-messung sowie das vernachlassigte ziel, replikationsforschung so zu implementieren, dass sie echte erkenntnisfortschritte bringt und als exzellente forschung anerkannt werden kann. (Psycinfo database record (c) 2021 apa, all rights reserved)","","","2018","10.1026/0033-3042/a000388","","","psychinfo-2018-01295-004.pdf","psychinfo-2018-01295-004"
"Water, water, everywhere: defining and assessing data sharing in academia","Van Tuyl S. And Whitmire A.l.","Plos One","","Sharing of research data has begun to gain traction in many areas of the sciences in the past few years because of changing expectations from the scientific community, funding agencies, and academic journals. National science foundation (nsf) requirements for a data management plan (dmp) went into effect in 2011, with the intent of facilitating the dissemination and sharing of research results. Many projects that were funded during 2011 and 2012 should now have implemented the elements of the data management plans required for their grant proposals. In this paper we define 'data sharing' and present a protocol for assessing whether data have been shared and how effective the sharing was. We then evaluate the data sharing practices of researchers funded by the nsf at oregon state university in two ways: by attempting to discover project-level research data using the associated dmp as a starting point, and by examining data sharing associated with journal articles that acknowledge nsf support. Sharing at both the project level and the journal article level was not carried out in the majority of cases, and when sharing was accomplished, the shared data were often of questionable usability due to access, documentation, and formatting issues. We close the article by offering recommendations for how data producers, journal publishers, data repositories, and funding agencies can facilitate the process of sharing data in a meaningful way.copyright © 2016 van tuyl, whitmire. This is an open access article distributed under the terms of the creative commons attribution license, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","","2016","10.1371/journal.pone.0147942","","","embase-608829276.pdf","embase-608829276"
"Not clinically effective but cost-effective' - paradoxical conclusions in randomised controlled trials with 'doubly null' results: a cross-sectional study","Raftery, J. And Williams, H.c. And Clarke, A. And Thornton, J. And Norrie, J. And Snooks, H. And Stein, K.","Bmj Open","","Objectives randomised controlled trials in healthcare increasingly include economic evaluations. Some show small differences which are not statistically significant. Yet these sometimes come to paradoxical conclusions such as: 'the intervention is not clinically effective' but 'is probably cost-effective'. This study aims to quantify the extent of non-significant results and the types of conclusions drawn from them. Design cross-sectional retrospective analysis of randomised trials published by the uk's national institute for health research (nihr) health technology assessment programme. We defined as 'doubly null' those trials that found non-statistically significant differences in both primary outcome and cost per patient. Paradoxical was defined as concluding in favour of an intervention, usually compared with placebo or usual care. No human participants were involved. Our sample was 226 randomised trial projects published by the health technology assessment programme 2004 to 2017. All are available free online. Results the 226 projects contained 193 trials with a full economic evaluation. Of these 76 (39%) had at least one 'doubly null' comparison. These 76 trials contained 94 comparisons. In these 30 (32%) drew economic conclusions in favour of an intervention. Overall report conclusions split roughly equally between those favouring the intervention (14), and those favouring either the control (7) or uncertainty (9). Discussion trials with 'doubly null' results and paradoxical conclusions are not uncommon. The differences observed in cost and quality-adjustedlife year were small and non-statistically significant. Almost all these trials were also published in leading peer-reviewed journals. Although some guidelines for reporting economic results require cost-effectiveness estimates regardless of statistical significance, the interpretability of paradoxical results has nowhere been addressed. Conclusions reconsideration is required of the interpretation of cost-effectiveness analyses in randomised controlled trials with 'doubly null' results, particularly when economics favours a novel intervention. © author(s) (or their employer(s)) 2020.","","","2020","10.1136/bmjopen-2019-029596","","","scopus-2-s2.0-85077765395.pdf","scopus-2-s2.0-85077765395"
"Evaluation of simulation credibility based on rough set and gray correlation analysis","Liu, H. And Qian, Y.","Xitong Fangzhen Xuebao / Journal Of System Simulation","","The evaluation of simulation model credibility has always been a hot issue in the simulation field. How to evaluate the credibility of the simulation is the key to the development of the simulation technology. It is of great significance for our country to carry out the credibility evaluation research. In view of the issue, the grey correlation analysis theory and the related principles in rough set theory are analyzed and the simulation credibility evaluation model based on rough set and grey correlation analysis is proposed. The indiscernibility principle in rough set is used to assign the weight distribution of each factor objectively. The comprehensive evaluation of simulation credibility is carried out by combining the grey correlation analysis method with the indiscernibility principle in rough set. The feasibility of this method is verified through an example of the flight simulation system. © 2018, the editorial board of journal of system simulation. All right reserved.","","","2018","10.16182/j.issn1004731x.joss.201802012","","","scopus-2-s2.0-85059278716.pdf","scopus-2-s2.0-85059278716"
"An investigation into agile learning processes and knowledge sharing practices to prevent identity theft in the online retail organisations","Shah, M. And Maitlo, A. And Jones, P. And Yusuf, Y.","Journal Of Knowledge Management","","Purpose: lack of individual awareness of knowledge sharing practices to prevent identity theft is a significant issue for online retail organisations (oros). Agile learning processes and sharing of knowledge is essential, but the lack of relevant training inhibits these processes within the online industry. This study aims to identify the inhibiting factors in agile learning and knowledge sharing process with recommendations for best practice for organisations and staff to effectively share knowledge on identity theft prevention. Design/methodology/approach: three qualitative case studies were undertaken in oros in the uk. Data were collected using semi-structured interviews, internal documents and related external material. The data were analysed using a thematic analysis method. Findings: the findings identified that individual staff members within oros from the information security and fraud prevention departments often share their knowledge as a community. However, there is no formal knowledge sharing process or any related training facilitating this exchange. There is a need for agile learning environment in oros of the uk. Originality/value: the study offers both theoretical and practical contributions to the extant literature of agile learning of knowledge sharing to prevent identity theft in oros. Existing learning opportunities are not being used to enhance the knowledge of individuals, and oros need to increase the skills and trust of their staff to share knowledge efficiently. This study identifies the systemic weaknesses inherent in the process of knowledge sharing and existing training provision within oros. It provides oro managers with practical guidelines in facilitating trust between individuals and developing appropriate training systems to educate staff on sharing organisational knowledge. This study contributes by extending the knowledge sharing framework proposed by chong et al. (2011) for enhanced individual knowledge sharing processes to prevent identity theft within oros. It also identifies oros’ weaknesses in knowledge sharing learning processes for theft prevention and offers prevention guidelines and recommendations for developing effective agile learning environments. © 2019, emerald publishing limited.","","","2019","10.1108/jkm-06-2018-0370","","","scopus-2-s2.0-85075722627.pdf","scopus-2-s2.0-85075722627"
"Research fatigue in COVID-19 pandemic and post-disaster research: Causes consequences and recommendations","Patel S. S., Webster R. K., Greenberg N., Weston D., Brooks S. K.","Disaster Prevention & Management","","PURPOSE: Research fatigue occurs when an individual or population of interest tires of engaging with research consequently avoiding further participation. This paper considers research fatigue in the context of the current COVID-19 pandemic to identify contributory factors and possible solutions for future post-disaster research.\\\\\\\\rMETHODOLOGY: We draw on examples from the literature and our own observations from the recruitment and data collection phases of qualitative and quantitative studies to provide an overview of possible research fatigue in the current COVID-19 pandemic with implications for future post-disaster research.\\\\\\\\rFINDINGS: People affected by disasters sometimes receive multiple requests for study participation by separate teams who may not necessarily be coordinating their work. Not keeping participants informed of the research process or outcomes can lead to disillusionment. Being overburdened with too many research requests and failing to see any subsequent changes following participation may cause individuals to experience research fatigue.\\\\\\\\rORIGINALITY: Guidelines for researchers wishing to reduce the occurrence of research fatigue include ensuring greater transparency within research; sharing of results; and using oversight or gatekeeper bodies to aid coordination. Failure to restrict the number of times that people are asked to participate in studies risks poor participation rates. This can subsequently affect the quality of information with which to inform policy-makers and protect the health of the public during the COVID-19 pandemic or other public health disasters/emergencies.","","","2020","10.1108/dpm-05-2020-0164","","","medline-33679011.pdf","medline-33679011"
"An efficient data sharing scheme for privacy protection based on blockchain and edge intelligence in 6g-vanet","Wang, Z. And Xu, Y. And Liu, J. And Li, Z. And Li, Z. And Jia, H. And Wang, D.","Wireless Communications And Mobile Computing","","With the substantial increase in the number of smart cars, vehicular ad hoc network (vanet), where data can be shared between vehicles to enrich existing vehicle services and improve driving safety, is gaining more and more attention, thus creating a more efficient intelligent transportation system. Moreover, the in-depth research and development of 6g and ai technology further strengthen the interconnection of various entities in vanet and can realize edge intelligence, which fundamentally enhances the efficiency of data sharing. However, reliable transmission and secure storage of data have always been a great challenge in data sharing. Although some schemes store shared data in the blockchain, most of the consensus mechanisms they use employ full nodes to verify signature information and timestamps, which cannot effectively judge the reliability of the shared data itself. Some other schemes use scoring mechanisms to evaluate data uploaded by vehicles, but these methods can be affected by network hardware failures and cannot effectively detect duplicate data. In addition, participants' privacy may also be disclosed in the process of data sharing, such as participants' location and identity information. Therefore, to address the above problems, this paper proposes a data sharing scheme in 6g-vanet, which can not only ensure the reliability and security of shared data but also protect the privacy of participants. Firstly, a consortium chain is adopted to realize the secure storage of shared data in 6g-vanet, which meets the requirements of tamper-proof and traceability of data. Secondly, a voting consensus mechanism is designed in combination with smart contract to ensure the reliability of data. Thirdly, the trained word2vec natural language processing model is deployed to edge nodes to realize edge intelligence, effectively eliminate the duplicate shared data, and enhance storage efficiency. Finally, a participant privacy protection mechanism is designed using the private set intersection (psi) protocol, and a secure and efficient data sharing scheme is finally realized. The effectiveness of the proposed scheme is demonstrated by security analysis and experimental evaluation. The experimental results show that the time and space overhead of blockchain can meet the practical requirements, and the proposed psi protocol of large-scale vehicles can be completed in a short time. © 2022 zhihua wang et al.","","","2022","10.1155/2022/5031112","","","scopus-2-s2.0-85135259035.pdf","scopus-2-s2.0-85135259035"
"The next controversy in genetic testing: clinical data as trade secrets?","Cook-Deegan R. And Conley J.m. And Evans J.p. And Vorhaus D.","Eur. J. Hum. Genet","","Sole-source business models for genetic testing can create private databases containing information vital to interpreting the clinical significance of human genetic variations. But incomplete access to those databases threatens to impede the clinical interpretation of genomic medicine. National health systems and insurers, regulators, researchers, providers and patients all have a strong interest in ensuring broad access to information about the clinical significance of variants discovered through genetic testing. They can create incentives for sharing data and interpretive algorithms in several ways, including: promoting voluntary sharing;  requiring laboratories to share as a condition of payment for or regulatory approval of laboratory services;  establishing - and compelling participation in - resources that capture the information needed to interpret the data independent of company policies;  and paying for sharing and interpretation in addition to paying for the test itself. Us policies have failed to address the data-sharing issue. The entry of new and established firms into the european genetic testing market presents an opportunity to correct this failure.european journal of human genetics advance online publication, 14 november 2012;  doi:10.1038/ejhg.2012.217.","","","2012","10.1038/ejhg.2012.217","","","embase-52303297.pdf","embase-52303297"
"[From record keeping to scientific research: obstacles and opportunities for research with electronic health records]","Scholte R. A., Opmeer B. C., Ploem M. C.","Nederlands Tijdschrift voor Geneeskunde","","As a result of increasing digitisation of medical record keeping electronic health records (EHRs) are an attractive source for data reuse. However such record-based research is still suffering from poor quality of data stored in EHRs. Lack of consent for reuse of data also plays an impeding role especially in retrospective record-based research. That said increasing cooperation between healthcare institutions and current attention for EHR organisation also offer opportunities for record-based research. Patient data can be recorded in more standardised ways and in increasingly harmonised EHRs. In addition if healthcare institutions were to establish a generic consent procedure - preferably with national scope - the potential of EHRs for scientific research could be exploited in considerably better ways.","","","2017","","","","medline-29192569.pdf","medline-29192569"
"Diagnostic and functional dependencies of credibility","Gackowski, Z.j.","Informing Science","","This is an inquiry into the ""actionable credibility"" of information values in informing and how it depends on indirect attributes of information quality. Empirical survey-based research by wang and strong (1996) ignores the multidimensional aspects of credibility. Studies that ignore them may produce unreliable results. Most publications discuss quality attributes as independent factors. This paper identifies and describes the ignored dependencies with regard to credibility. To yield research results of a more lasting validity, one must go beyond empirical studies. This inquiry continues the development of a theoretical model of operation quality requirements of data and information values as proposed by gackowski (2004, 2005a, 2005b).","","","2006","10.28945/481","","","scopus-2-s2.0-33845361321.pdf","scopus-2-s2.0-33845361321"
"Reproducibility of a peripheral quantitative computed tomography scan protocol to measure the material properties of the second metatarsal","Chaplais E., Greene D., Hood A., Telfer S., du Toit V., Singh-Grewal D., Burns J., Rome K., Schiferl D. J., Hendry G. J.","BMC Musculoskeletal Disorders","","BACKGROUND: Peripheral quantitative computed tomography (pQCT) is an established technology that allows for the measurement of the material properties of bone. Alterations to bone architecture are associated with an increased risk of fracture. Further pQCT research is necessary to identify regions of interest that are prone to fracture risk in people with chronic diseases. The second metatarsal is a common site for the development of insufficiency fractures and as such the aim of this study was to assess the reproducibility of a novel scanning protocol of the second metatarsal using pQCT.\\\\\\\\rMETHODS: Eleven embalmed cadaveric leg specimens were scanned six times; three times with and without repositioning. Each foot was positioned on a custom-designed acrylic foot plate to permit unimpeded scans of the region of interest. Sixty-six scans were obtained at 15% (distal) and 50% (mid shaft) of the second metatarsal. Voxel size and scan speed were reduced to 0.40 mm and 25 mm.sec(-1). The reference line was positioned at the most distal portion of the 2(nd) metatarsal. Repeated measurements of six key variables related to bone properties were subject to reproducibility testing. Data were log transformed and reproducibility of scans were assessed using intraclass correlation coefficients (ICC) and coefficients of variation (CV%).\\\\\\\\rRESULTS: Reproducibility of the measurements without repositioning were estimated as: trabecular area (ICC 0.95; CV% 2.4) trabecular density (ICC 0.98; CV% 3.0) Strength Strain Index (SSI) - distal (ICC 0.99; CV% 5.6) cortical area (ICC 1.0; CV% 1.5) cortical density (ICC 0.99; CV% 0.1) SSI - mid shaft (ICC 1.0; CV% 2.4). Reproducibility of the measurements after repositioning were estimated as: trabecular area (ICC 0.96; CV% 2.4) trabecular density (ICC 0.98; CV% 2.8) SSI - distal (ICC 1.0; CV% 3.5) cortical area (ICC 0.99; CV%2.4) cortical density (ICC 0.98; CV% 0.8) SSI - mid shaft (ICC 0.99; CV% 3.2).\\\\\\\\rCONCLUSIONS: The scanning protocol generated excellent reproducibility for key bone properties measured at the distal and mid-shaft regions of the 2(nd) metatarsal. This protocol extends the capabilities of pQCT to evaluate bone quality in people who may be at an increased risk of metatarsal insufficiency fractures.","","","2014","10.1186/1471-2474-15-242","","","medline-25037451.pdf","medline-25037451"
"Measurements of alveolar bone height at tooth and implant abutments on intraoral radiographs. A comparison of reproducibility of Eggen technique utilized with and without a bite impression","Larheim T. A., Eggen S.","Journal of Clinical Periodontology","","A short review of various radiographic methods for quantitation of marginal bone changes is given. With the method suggested by Eggen (1973) alveolar bone heights on intraoral paralleling radiographs of tooth and implant abutments could be determined directly in ""true' values. A calibrated measuring film (increments adjusted in accordance with the approximately constant magnification) was utilized with a magnifying (x 2) viewer. The reproducibility of this direct method was tested with and without a bite impression and found to be high. The use of an impression did not seem to have any significant influence on the reproducibility of the method when measuring bone heights at teeth. However regarding bone height measurements at implants the impression seemed to bring about a small but significant improvement. The main source of error seemed to be the recognition of the reference points in the alveolar bone. The discussion of available quantitation principles indicated that radiographic bone height should be evaluated in absolute values in clinical studies of comparative nature. The present method seems to be suitable for comparative clinical examinations of alveolar bone height at teeth and implants.","","","1982","10.1111/j.1600-051x.1982.tb02058.x","","","medline-7047578.pdf","medline-7047578"
"Ebsco collections’ discoverability rate by ex libris’ central discovery index (cdi)","Chen, X.","Collection Management","","This study aims to find out ebsco’s content discoverability rate by ex libris’ central discovery index (cdi), under the circumstance that ex libris/proquest and ebsco do not share index data with each other. In early 2022, 512 random sample articles were collected from two ebsco databases, academic search complete and cinahl. They were searched in primo by title. 492 (96.09%) ebsco samples can be found in primo. Most of the 20 (3.91%) samples not available in primo are non-journal and non-english items. The uncooperativeness between ex libris/proquest and ebsco no longer seems to be a big factor for each other’s discovery service to discover and link to the items in the other party’s electronic collections. © 2022 the author(s). Published with license by taylor & francis group, llc.","","","2023","10.1080/01462679.2022.2081277","","","scopus-2-s2.0-85131660171.pdf","scopus-2-s2.0-85131660171"
"Influence of data errors on differential privacy","Wang, T. And Xu, Z. And Wang, D. And Wang, H.","Cluster Computing","","The rapid development of data sharing applications brings a serious problem of privacy disclosure. As an effective privacy-preserving method, the differential privacy, which strictly defines the privacy-preserving degree and data utility mathematically, can balance the privacy and data utility. However, the differential privacy has a hypothesis premise that the raw data are accurate without any error, so it could not limit the privacy security and the data utility to the expected range when processing data with errors. Hence, this paper focuses on the study on the influence of data errors on differential privacy. Taking the random error as an example, we analyze the influence mode and mechanism of data errors on differential privacy, especially on the privacy budget ε. The theoretical derivations and experimental simulations prove that the laplace mechanism still preserves ε′ -indistinguishability for data with errors. Moreover, the random algorithm can realize the expected privacy preserving strength by adding less noise compared with the algorithm that do not consider data errors, and has a better data utility by reducing the unnecessary cost of utility. This paper defines the research directions on the differential privacy theory concerning of data errors, and provides the foundations of perfecting the theory system and promoting the practicality of the differential privacy. © 2017, springer science+business media, llc, part of springer nature.","","","2019","10.1007/s10586-017-1457-4","","","scopus-2-s2.0-85037631254.pdf","scopus-2-s2.0-85037631254"
"A review of center of pressure (COP) variables to quantify standing balance in elderly people: Algorithms and open-access code*","Quijoux F., Nicolai A., Chairi I., Bargiotas I., Ricard D., Yelnik A., Oudre L., Bertin-Hugault F., Vidal P. P., Vayatis N., Buffat S., Audiffren J.","Physiological Reports","","Postural control is often quantified by recording the trajectory of the center of pressure (COP)-also called stabilogram-during human quiet standing. This quantification has many important applications such as the early detection of balance degradation to prevent falls a crucial task whose relevance increases with the aging of the population. Due to the complexity of the quantification process the analyses of sway patterns have been performed empirically using a number of variables such as ellipse confidence area or mean velocity. This study reviews and compares a wide range of state-of-the-art variables that are used to assess the risk of fall in elderly from a stabilogram. When appropriate we discuss the hypothesis and mathematical assumptions that underlie these variables and we propose a reproducible method to compute each of them. Additionally we provide a statistical description of their behavior on two datasets recorded in two elderly populations and with different protocols to hint at typical values of these variables. First the balance of 133 elderly individuals including 32 fallers was measured on a relatively inexpensive portable force platform (Wii Balance Board Nintendo) with a 25-s open-eyes protocol. Second the recordings of 76 elderly individuals from an open access database commonly used to test static balance analyses were used to compute the values of the variables on 60-s eyes-open recordings with a research laboratory standard force platform. Copyright © 2021 The Authors. Physiological Reports published by Wiley Periodicals LLC on behalf of The Physiological Society and the American Physiological Society.","","","2021","10.14814/phy2.15067","","","medline-34826208.pdf","medline-34826208"
"Sharing is not always caring: delving into personal data transfer compliance in android apps","Rodriguez, D. And Del Alamo, J.m. And Fernandez-Aller, C. And Sadeh, N.","Ieee Access","","In an era marked by ubiquitous reliance on mobile applications for nearly every need, the opacity of apps&#x2019;  behavior poses significant threats to their users&#x2019;  privacy. Although major data protection regulations require apps to disclose their data practices transparently, previous studies have pointed out difficulties in doing so. To further delve into this issue, this article describes an automated method to capture data-sharing practices in android apps and assess their proper disclosure according to the eu general data protection regulation. We applied the method to 9,000 random android apps, unveiling an uncomfortable reality: over 80% of android applications that transfer personal data off device potentially fail to meet gdpr transparency requirements. We further investigate the role of third-party libraries, shedding light on the source of this problem and pointing towards measures to address it. Authors","","","2024","10.1109/access.2024.3349425","","","scopus-2-s2.0-85181556676.pdf","scopus-2-s2.0-85181556676"
"Privacy-preserving multi-keyword top-ksimilarity search over encrypted data","Ding, X. And Liu, P. And Jin, H.","Ieee Transactions On Dependable And Secure Computing","","Cloud computing provides individuals and enterprises massive computing power and scalable storage capacities to support a variety of big data applications in domains like health care and scientific research, therefore more and more data owners are involved to outsource their data on cloud servers for great convenience in data management and mining. However, data sets like health records in electronic documents usually contain sensitive information, which brings about privacy concerns if the documents are released or shared to partially untrusted third-parties in cloud. A practical and widely used technique for data privacy preservation is to encrypt data before outsourcing to the cloud servers, which however reduces the data utility and makes many traditional data analytic operators like keyword-based top-k k document retrieval obsolete. In this paper, we investigate the multi-keyword top-k k search problem for big data encryption against privacy breaches, and attempt to identify an efficient and secure solution to this problem. Specifically, for the privacy concern of query data, we construct a special tree-based index structure and design a random traversal algorithm, which makes even the same query to produce different visiting paths on the index, and can also maintain the accuracy of queries unchanged under stronger privacy. For improving the query efficiency, we propose a group multi-keyword top-k k search scheme based on the idea of partition, where a group of tree-based indexes are constructed for all documents. Finally, we combine these methods together into an efficient and secure approach to address our proposed top-k k similarity search. Extensive experimental results on real-life data sets demonstrate that our proposed approach can significantly improve the capability of defending the privacy breaches, the scalability and the time efficiency of query processing over the state-of-the-art methods. © 2004-2012 ieee.","","","2019","10.1109/tdsc.2017.2693969","","","scopus-2-s2.0-85063002140.pdf","scopus-2-s2.0-85063002140"
"Optimized detection of differential expression in global profiling experiments: Case studies in clinical transcriptomic and quantitative proteomic datasets","Elo L. L., Hiissa J., Tuimala J., Kallio A., Korpelainen E., Aittokallio T.","Briefings in Bioinformatics","","Identification of reliable molecular markers that show differential expression between distinct groups of samples has remained a fundamental research problem in many large-scale profiling studies such as those based on DNA microarray or mass-spectrometry technologies. Despite the availability of a wide spectrum of statistical procedures the users of the high-throughput platforms are still facing the crucial challenge of deciding which test statistic is best adapted to the intrinsic properties of their own datasets. To meet this challenge we recently introduced an adaptive procedure named ROTS (Reproducibility-Optimized Test Statistic) which learns an optimal statistic directly from the given data and whose relative benefits have previously been shown in comparison with state-of-the-art procedures for detecting differential expression. Using gene expression microarray and mass-spectrometry (MS)-based protein expression datasets as case studies we illustrate here the practical usage and advantages of ROTS toward detecting reliable marker lists in clinical transcriptomic and proteomic studies. In a public leukemia microarray dataset the procedure could improve the sensitivity of the gene marker lists detected with high specificity. When applied to a recent LC-MS dataset involving plasma samples from severe burn patients the procedure could identify several peptide markers that remained undetected in the conventional analysis thus demonstrating the effectiveness of ROTS also for global quantitative proteomic studies. To promote its widespread usage we have made freely available efficient implementations of ROTS which are easily accessible either as a stand-alone R-package or as integrated in the open-source data analysis software Chipster. © The Author 2009. Published by Oxford University Press.","","","2009","10.1093/bib/bbp033","","","medline-19549804.pdf","medline-19549804"
"Improving outcome reporting in clinical trial reports and protocols: study protocol for the instrument for reporting planned endpoints in clinical trials (inspect)","Butcher, N.j. And Monsour, A. And Mew, E.j. And Szatmari, P. And Pierro, A. And Kelly, L.e. And Farid-Kapadia, M. And Chee-A-Tow, A. And Saeed, L. And Monga, S. And Ungar, W. And Terwee, C.b. And Vohra, S. And Fergusson, D. And Askie, L.m. And Williamson, P.r. And Chan, A.-W. And Moher, D. And Offringa, M.","Trials","","Background: inadequate and poor quality outcome reporting in clinical trials is a well-documented problem that impedes the ability of researchers to evaluate, replicate, synthesize, and build upon study findings and impacts evidence-based decision-making by patients, clinicians, and policy-makers. To facilitate harmonized and transparent reporting of outcomes in trial protocols and published reports, the instrument for reporting planned endpoints in clinical trials (inspect) is being developed. The final product will provide unique inspect extensions to the spirit (standard protocol items: recommendations for interventional trials) and consort (consolidated standards of reporting trials) reporting guidelines. Methods: the inspect spirit and consort extensions will be developed in accordance with the methodological framework created by the equator (enhancing the quality and transparency of health research quality) network for reporting guideline development. Development will consist of (1) the creation of an initial list of candidate outcome reporting items synthesized from expert consultations and a scoping review of existing guidance for reporting outcomes in trial protocols and reports;  (2) a three-round international delphi study to identify additional candidate items and assess candidate item importance on a 9-point likert scale, completed by stakeholders such as trial report and protocol authors, systematic review authors, biostatisticians and epidemiologists, reporting guideline developers, clinicians, journal editors, and research ethics board representatives;  and (3) an in-person expert consensus meeting to finalize the set of essential outcome reporting items for trial protocols and reports, respectively. The consensus meeting discussions will be independently facilitated and informed by the empirical evidence identified in the primary literature and through the opinions (aggregate rankings and comments) collected via the delphi study. An integrated knowledge translation approach will be used throughout inspect development to facilitate implementation and dissemination, in addition to standard post-development activities. Discussion: inspect will provide evidence-informed and consensus-based standards focused on outcome reporting in clinical trials that can be applied across diverse disease areas, study populations, and outcomes. Inspect will support the standardization of trial outcome reporting, which will maximize trial usability, reduce bias, foster trial replication, improve trial design and execution, and ultimately reduce research waste and help improve patient outcomes. © 2019 the author(s).","","","2019","10.1186/s13063-019-3248-0","","","scopus-2-s2.0-85062586422.pdf","scopus-2-s2.0-85062586422"
"Knowing, learning and acting in health care organizations and services: challenges and opportunities for qualitative research","Bosio, C. And Graffigna, G. And Scaratti, G.","Asia Pacific Journal Of Marketing And Logistics","","Purpose – the purpose of this paper is to discuss the value of post-modern psychosocial approaches to studying knowledge and practice construction in health care organizations and settings (hco&s) and the increasing ability of qualitative research to furnish a deeper, more ecological, and more usable understanding of the social construction of health knowledge and practices. Design/methodology/approach – the argument proposed in the paper is based on a critical literature review conducted on the psychinfo, scopus, pubmed and web of science databases. Findings – recent years have seen cultural changes in the values and goals of healthcare interventions that are deeply reconfiguring hco&s. These changes are reframing hco&s action and are highlighting the importance of understanding and managing not only the “expert context” but also the “lay contexts” of healthcare interventions. In an attempt to deal with these emergent changes (and challenges), hco&s are taking advantage of new insights matured in the post-modern turn of organizational analysis. In this frame, qualitative research proves suitable for connecting hco&s needs and priorities with the new post-modern paradigm of knowledge- and practice-sharing in organizations. Originality/value – the paper demonstrates the value of qualitative research in the analysis of hco&s and casts light on the new research trends and new technical-methodological options arising in this field. © emerald group publishing limited.","","","2012","10.1108/17465641211279743","","","scopus-2-s2.0-84931082862.pdf","scopus-2-s2.0-84931082862"
"Clinical replicability of rehabilitation interventions in randomized controlled trials reported in main journals is inadequate","Negrini S., Arienti C., Pollet J., Engkasan J. P., Francisco G. E., Frontera W. R., Galeri S., Gworys K., Kujawa J., Mazlan M., Rathore F. A., Schillebeeckx F., Kiekens C.","Journal of Clinical Epidemiology","","OBJECTIVE: The objective of this study was to study if randomized controlled trials (RCTs) in rehabilitation (a field where complex interventions prevail) published in main journals include all the details needed to replicate the intervention in clinical practice (clinical replicability). STUDY DESIGN AND SETTING: Forty-seven rehabilitation clinicians of 5 professions from 7 teams (Belgium Italy Malaysia Pakistan Poland Puerto Rico the USA) reviewed 76 RCTs published by main rehabilitation journals exploring 14 domains chosen through consensus and piloting. RESULTS: The response rate was 99%. Inter-rater agreement was moderate/good. All clinicians considered unanimously 12 (16%) RCTs clinically replicable and none not replicable. At least one ""absent"" information was found by all participants in 60 RCTs (79%) and by a minimum of 85% in the remaining 16 (21%). Information considered to be less well described (8-19% ""perfect"" information) included two providers (skills experience) and two delivery (cautions relationships) items. The best described (50-79% ""perfect"") were the classic methodological items included in CONSORT (descending order: participants materials procedures setting and intervention). CONCLUSION: Clinical replicability must be considered in RCTs reporting particularly for complex interventions. Classical methodological checklists such as CONSORT are not enough and also Template for Intervention Description and Clinical replication do not cover all the requirements. This study supports the need for field-specific checklists.","","","2019","10.1016/j.jclinepi.2019.06.008","","","medline-31220570.pdf","medline-31220570"
"MDPHnet: secure distributed sharing of electronic health record data for public health surveillance evaluation and planning","Vogel J., Brown J. S., Land T., Platt R., Klompas M.","American Journal of Public Health","","Electronic health record systems contain clinically detailed data from large populations of patients that could significantly enrich public health surveillance. Clinical practices' security privacy and proprietary concerns however have limited their willingness to share these data with public health agencies. We describe a novel distributed network for public health surveillance called MDPHnet. The system allows the Massachusetts Department of Public Health (MDPH) to initiate custom queries against participating practices' electronic health records while the data remain behind each practice's firewall. Practices can review proposed queries before execution and approve query results before releasing them to the health department. MDPH is using the system for routine surveillance for priority conditions and to evaluate the impact of public health interventions.","","","2014","10.2105/ajph.2014.302103","","","medline-25322301.pdf","medline-25322301"
"Design and implementation of information tracing platform for crop whole industry chain based on csbft-blockchain","Ren, S. And He, Z. And Zhou, Z. And Gu, X. And Xiong, Y. And Yuan, P. And Xu, H.","Nongye Gongcheng Xuebao/Transactions Of The Chinese Society Of Agricultural Engineering","","The safety of agricultural products concerns people's health. To ensure food safety and accountability, it is crucial to establish a credible food traceability system. The blockchain technology can greatly improve the integrity, security and credibility of traceability information of traditional agricultural product traceability system, thanks to its properties such as decentralization, non-tamperability and information traceability. This paper proposes an improved blockchain consensus algorithm, based on the credit-supervisor byzantine fault tolerance (csbft). It mainly includes credit update strategy and supervisor node selection strategy. Various credit update strategies are formulated according to the node types and whether they can actively forward a message, and then the supervisor node selection strategies are made based on the credit of the node. The csbft algorithm uses the supervisor to monitor the behavior of the master node to prevent problems such as sending different messages to different nodes;  while the consensus mechanism of centralized nodes and distributed nodes can improve the supervisory node generating efficiency because the master node does not need to be generated cyclically and it can choose a more reliable node as a supervisory node according to the supervisory node selection strategy. To prove the effectiveness of csbft algorithm, the paper uses the common transfer transaction information as experimental data and the experiments were repeated ten times to compare the consensus delays of pbft (practical byzantine fault tolerance), mbft and csbft with the transaction numbers of 5, 10, 20 and 50 respectively. The average of 10 repeated experiments is used as the final statistical value and the result proves that csbft has higher robustness, lower consensus delay and higher safety. This paper studied and analyzed the information flow of the whole industrial chain of crops from agricultural product purchase, planting management, processing and production, logistics and transportation to grain sales, to build a blockchain alliance chain based on csbft. It analyzed, designed and realized the whole industrial chain information traceability platform based on embedded csbft, via object-oriented software engineering method. The platform can automatically save the key up-chain information through pre-designed smart contracts to generate corresponding traceability codes for consumers to query. Compared with the traditional food traceability system, the csbft algorithm endows the platform with higher security and less delay in information chaining. Future research on data privacy protection will be conducted. To protect the data privacy, users of various levels in the whole industrial chain hesitate to share their data. Therefore, how to collect and share the information without leaking the private data is the future research direction. © 2020, editorial department of the transactions of the chinese society of agricultural engineering. All right reserved.","","","2020","10.11975/j.issn.1002-6819.2020.03.034","","","scopus-2-s2.0-85083338430.pdf","scopus-2-s2.0-85083338430"
"Influence of author's affiliation and funding sources on the results of cohort studies on occupational cancer","Rollin, L. And Griffon, N. And Darmoni, S.j. And Gehanno, J.-F.","American Journal Of Industrial Medicine","","Background: reliability and credibility of research conducted by industry have been questioned, including in the field of occupational health. Methods: cohort studies on occupational cancer published between 2000 and 2010 were compared according to their results, their conclusions, their funding, and the affiliation of their authors. Results: overall, 510 articles were included. Studies published by authors with public affiliation or funded by public grants concluded that their study showed an excess of cancer more frequently (p=0.01) than studies published by authors with private affiliation or funded by private grants (88% [95%ci=85-91] vs. 73% [95%ci=56-88] and 92% [95%ci=86-97] vs. 71% [95%ci=57-84], respectively). Discrepancies between statistical results and conclusion occurred more frequently in articles written by authors from the private sector than from the public sector (42% [ic95%=26-60] vs. 23% [ic95%=18-26], p=0.02). Conclusions: industry affiliations of authors or industry support of studies are associated with the results of published studies on occupational cancer. The underlying mechanisms warrant further investigation. Am. J. Ind. Med. 59:221-226, 2016. © 2016 wiley periodicals, inc.","","","2016","10.1002/ajim.22549","","","scopus-2-s2.0-84958645265.pdf","scopus-2-s2.0-84958645265"
"Washington state cadastral framework project: implementing the fgdc cadastral data content standard and integrating data from multiple sources 1","Tudor, G.s. And Wolfe, C.","Surveying And Land Information Systems","","The washington cadastral framework project is a national spatial data infrastructure (nsdi) demonstration project intended to show the benefits of building partnerships, sharing costs and coordinating work, standardizing data and tools, speeding up application development, improving and documenting data, resolving data conflicts, and sharing data. The washington cadastral framework project is broken down into two phases which are pilot projects designed to implement a standard cadastral data set and to integrate cadastral data from multiple data sources. Phase 1 (september 1997 to september 1998) involves extending and implementing the federal geographic data committee (fgdc) cadastral data content standard in sde/oracle, populating the database with initial data, developing metadata on the data, and distributing the data over the internet to project partners. The cadastral data content standard was extended to work with other framework data content themes: geodetic control, hydrography, transportation, and governmental units. Phase 2 (september 1998 to september 1999) involves adapting the fgdc cadastral data transfer standard for data exchange, integrating data from several representative partner sources (federal, state, regional, county, city, and private organizations), developing update-locking procedures for long transactions over the internet, and automating the integration process so that minimal intervention is required for enforcing standards and resolving conflicts.","","","1999","","","","scopus-2-s2.0-0033384131.pdf","scopus-2-s2.0-0033384131"
"Glossing and vocabulary learning","Boers, F.","Language Teaching","","This article offers a critical review of research on the use of glossing and its contribution to second language (l2) vocabulary acquisition. Discussion topics include the complexity of estimating the effectiveness of glossing relative to reading non-glossed texts, the quest for optimal implementations of glossing, issues of ecological validity, and ambiguity around the nature of vocabulary learning from glosses. The general conclusion is that, despite the substantial number of research studies on this subject, many questions remain to which only tentative and provisional answers are currently available. This is partly owing to the wide diversity in research designs across studies and the lack of transparency of many research reports. Suggestions are made for further research on glossing with a view to enabling future systematic reviews to produce more nuanced answers and more informed recommendations for the design of l2 reading materials. Copyright © the author(s), 2021. Published by cambridge university press.","","","2022","10.1017/s0261444821000252","","","scopus-2-s2.0-85122796451.pdf","scopus-2-s2.0-85122796451"
"Long-term daily dataset of surface sensible heat flux and latent heat release over the tibetan plateau based on routine meteorological observations","Duan, A. And Liu, S. And Hu, W. And Hu, D. And Peng, Y.","Big Earth Data","","As the main components of the atmospheric heat source/sink over the tibetan plateau (tp), up-to-date spatiotemporal fields of surface sensible heat flux and latent heat release by precipitation are vital for investigating the local land–atmosphere interaction and the effect of the thermal forcing of the tp on global weather and climate. This study recalculates the long-term daily dataset of surface sensible heat flux and latent heat release of condensation over the tp based on 293 routine meteorological observations, with the latest date being 31 december 2019. Most stations have adequate and valid records during the period 1981–2019, and the results for 1951–1980 are also calculated if the observations are available. Moreover, a brief evaluation of the climatology and long-term variation during 1981–2019 is conducted. By providing the most continuous and longest set of observational surface sensible heat flux and latent heat release of condensation data over the tp with a high degree of credibility, this new dataset will support research concerning the multi-timescale variation of diabatic heating/cooling over the tp and its remote influence. It is openly available on the lasg data-sharing platform (http://data.lasg.ac.cn/tpshlh/). © 2022 the author(s). Published by taylor & francis group and science press on behalf of the international society for digital earth, supported by the international research center of big data for sustainable development goals, and casearth strategic priority research programme.","","","2022","10.1080/20964471.2022.2037203","","","scopus-2-s2.0-85125348000.pdf","scopus-2-s2.0-85125348000"
"Evidence of misuse of nonparametric tests in the presence of heteroscedasticity within obesity research","Kroeger, C.m. And Brown, A.w. And Hannon, B.a. And Halliday, T.m. And Ejima, K. And Teran-Garcia, M.","F1000research","","Background: classic nonparametric tests (cnpts), like kruskal-wallis or mann-whitney u, are sometimes used to detect differences in central tendency ( i.e., means or medians). However, when the tests' assumptions are violated, such as in the presence of unequal variance and other forms of heteroscedasticity, they are no longer valid for testing differences in central tendency. Yet, sometimes researchers erroneously use cnpts to account for heteroscedasticity. Objective: to document the appropriateness of cnpt use in obesity literature, characterize studies that use cnpts, and evaluate the citation and public sharing patterns of these articles. Methods: we reviewed obesity studies published in 2017 to determine whether the authors used cnpts: (1) to correct for heteroscedasticity (invalid);  (2) when heteroscedasticity was clearly not present (correct);  or (3) when it was unclear whether heteroscedasticity was present (unclear). Open science r packages were used to transparently search literature and extract data on how often papers with errors have been cited in academic literature, read in mendeley, and disseminated in the media. Results: we identified nine studies that used a cnpt in the presence of heteroscedasticity (some because of the mistaken rationale that the test corrected for heteroscedasticity), 25 articles that did not explicitly state whether heteroscedasticity was present when a cnpt was used, and only four articles that appropriately reported that heteroscedasticity was not present when a cnpt was used. Errors were found in observational and interventional studies, in human and rodent studies, and only when studies were unregistered. Studies with errors have been cited 113 times, read in mendeley 123 times, and disseminated in the media 41 times, by the public, scientists, science communicators, and doctors. Conclusions: examples of inappropriate use of cnpts exist in the obesity literature, and those articles perpetuate the errors via various audiences and dissemination platforms. © 2021 kroeger cm et al.","","","2021","10.12688/f1000research.52693.1","","","scopus-2-s2.0-85123612206.pdf","scopus-2-s2.0-85123612206"
"Hierarchical and multi-group data sharing for cloud-assisted industrial internet of things","Li, T. And Zhang, J. And Shen, Y. And Ma, J.","Ieee Transactions On Services Computing","","With the development of industrial internet of things (iiot) and 5g, massive data are easily collected and transmitted in cloud. Therefore, it is critical to guarantee the security of data sharing. In iiot applications, the users of a group are in hierarchical structure and they intend to access data by external groups, which requires fine-grained access control, data authenticity and data retrieval. However, existing approaches rarely provide such solutions to satisfy these requirements simultaneously. In this paper, we propose an efficient hierarchical and multi-group data sharing framework (hmgdsf) in cloud-assisted iiot. Apart from fine-grained data access control for hierarchical users with key leakage resilience, hmgdsf achieves user anonymity with traceability and keyword-based data retrieval. Moreover, the approach supports data authenticity and integrity verification for multi-group data sharing by integrating group signature mechanism. We provide proof for the security of framework and demonstrate its efficiency and practicability by extensive evaluations. © 2008-2012 ieee.","","","2023","10.1109/tsc.2023.3262563","","","scopus-2-s2.0-85151498261.pdf","scopus-2-s2.0-85151498261"
"Evaluating the quality of systematic reviews in the emergency medicine literature","Kelly K. D., Travers A., Dorgan M., Slater L., Rowe B. H.","Annals of Emergency Medicine","","STUDY OBJECTIVE: The objective of this study was to examine the scientific quality of systematic reviews published in 5 leading emergency medicine journals.\\\\\\\\rMETHODS: MEDLINE and EMBASE databases were electronically searched to identify published systematic reviews. Searches were only conducted in emergency medicine journals during the past 10 years; 4 of the journals were also hand searched. Potential reviews were assessed independently by 2 reviewers for inclusion. Data regarding methods were extracted from each review independently by 2 reviewers. All systematic reviews were retrieved and rated for quality by using the 10 questions from the overview quality assessment questionnaire.\\\\\\\\rRESULTS: Twenty-nine reviews were identified from more than 100 citations. The overall scientific quality of the systematic reviews was low (mean score 2.7; 95% confidence interval 2.1 to 3.2; maximum possible score 7.0). Selection and publication biases were rarely addressed in this collection of reviews. For example the search strategies were only identified in 9 (31%) reviews whereas independent study selection (6 [21%]) and quality assessment of included studies (9 [31%]) were infrequently performed. Overall the majority of reviews had extensive flaws and only 3 (10%) had minimal flaws.\\\\\\\\rCONCLUSION: The results of the study indicate that many of the systematic reviews published in the emergency medicine literature contain major flaws; reviews with poor methodology may limit the validity of reported results. Further efforts should be made to improve the design reporting and publication of systematic reviews in emergency medicine.","","","2001","10.1067/mem.2001.115881","","","medline-11679863.pdf","medline-11679863"
"Development of web-based distributed cooperative development environment of sign-language animation system and its evaluation","Yuizono, T. And Hara, K. And Nakayama, S.","Ieej Transactions On Electronics, Information And Systems","","A web-based distributed cooperative development environment of sign-language animation system has been developed, we have extended the system from the previous animation system that was constructed as three tiered system which consists of sign-language animation interface layer, sign-language data processing layer, and sign-language animation database. Two components of a web client using vrml plug-in and web servlet are added to the previous system. The systems can support humanoid-model avatar for interoperability, and can use the stored sign language animation data shared on the database. It is noted in the evaluation of this system that the inverse kinematics function of web client improves the sign-language animation making. © 2003, the institute of electrical engineers of japan. All rights reserved.","","","2003","10.1541/ieejeiss.123.1745","","","scopus-2-s2.0-85024726133.pdf","scopus-2-s2.0-85024726133"
"Usability evaluation and visualization software design for power quality disturbance data","Wang, J. And Zhang, H. And Hu, W. And Li, Y. And Zhao, Y. And Xiao, X. And Wang, Y.","Dianwang Jishu/Power System Technology","","During the acquisition of power quality disturbance data, the data quality may be affected to varying degrees due to system equipment failures or human maloperations. Accurate evaluation of the data availability level is a prerequisite for subsequent data cleaning and analysis. The existing methods usually adopt a single index to evaluate the partial data quality but are difficult to quantify to what extent the data can be utilized in the following analysis. In view of this, combined with its own characteristics of the power quality disturbance, this paper adopts multiple monitoring frequency correlation to evaluate the data timeliness. For the accuracy evaluation fails to detect the connection errors, an accuracy evaluation method based on the hierarchical rule test is proposed to improve the reliability. After analyzing the influence of different dimension data qualities on the perturbation analysis results, the availability evaluation method of the power quality disturbance data is proposed. On this basis, taking the power quality monitoring data as an example, based on the vxworks operating system in the power quality monitoring system, the data availability visualization software is developed for the power supply system operators to analyze the operating status of the monitoring devices in the massive data. Finally the online measured data is used to verify the method in this article, and the result proves that the method in this paper has an engineering practical value. © 2022, power system technology press. All right reserved.","","","2022","10.13335/j.1000-3673.pst.2021.0524","","","scopus-2-s2.0-85126441021.pdf","scopus-2-s2.0-85126441021"
"A privacy and efficiency-oriented data sharing mechanism for iots","Wang, C. And Wang, S. And Cheng, X. And He, Y. And Xiao, K. And Fan, S.","Ieee Transactions On Big Data","","With the volume of data increasing in the internet of things, a new business mode, where data owners share their own data to others for rewards, has emerged. Therefore, how to motivate data owners to participate in the data trading process is the main challenge. So far, lots of works focus on the motivation mechanism designing and ensure a fair distribution of profits among data owners. However, some security and privacy issues are still not well solved and the data owners are still unwilling to participate in the process. Especially, when a data provider claims rewards with its real identity for the shared data, the linkage between its real identity and the shared data will expose the participator's private information included in the shared data, such as location information. To protect user's privacy in the scenario, a privacy and efficiency-oriented data sharing mechanism for iots is proposed in this paper. We first propose a blockchain-based data sharing framework in which the behavior of all participants will be supervised. Then, in order to hide the real identities of data providers during the data sharing process, an anonymous certificate-based data sharing policy is proposed. At last, two novel non-interactive zero-knowledge proofs are designed to hide the identities of qualified data providers while claiming rewards to the system. Through security analysis and performance evaluation, the feasibility and effectiveness of the data sharing scheme are illustrated. © 2022 ieee.","","","2023","10.1109/tbdata.2022.3148181","","","scopus-2-s2.0-85124184744.pdf","scopus-2-s2.0-85124184744"
"Race by hearts: using technology to facilitate enjoyable and social workouts","Sonne, T. And Jensen, M.m.","Lecture Notes In Computer Science (Including Subseries Lecture Notes In Artificial Intelligence And Lecture Notes In Bioinformatics)","","In this paper, we explore the qualities of sharing biometric data in real-time between athletes, in order to increase two motivational factors for gym-goers: enjoyment and social interaction. We present a novel smartphone application, called race by hearts, which enables competition based on heart rate data sharing between users in real-time. Through an empirical study conducted in the gym, we show that sharing biometric data in real-time can strengthen social relations between participants, increase motivation, and improve the enjoyment of the fitness activity. Nevertheless, we found that introducing competition based on real-time sharing of biometric data can cause exasperation and discouragement for some athletes. Based on our findings from the study, we discuss how technology can facilitate and modify competition in fitness exercises in general. © ifip international federation for information processing 2014.","","","2014","10.1007/978-3-662-45212-7_16","","","scopus-2-s2.0-84921415800.pdf","scopus-2-s2.0-84921415800"
"Transferability and within- and between-laboratory reproducibilities of episensa for predicting skin sensitization potential in vitro: a ring study in three laboratories","Mizumachi H. And Sakuma M. And Ikezumi M. And Saito K. And Takeyoshi M. And Imai N. And Okutomi H. And Umetsu A. And Motohashi H. And Watanabe M. And Miyazawa M.","J. Appl. Toxicol","","The epidermal sensitization assay (episensa) is an in vitro skin sensitization test method based on gene expression of four markers related to the induction of skin sensitization;  the assay uses commercially available reconstructed human epidermis. Episensa has exhibited an accuracy of 90% for 72 chemicals, including lipophilic chemicals and pre-/pro-haptens, when compared with the results of the murine local lymph node assay. In this work, a ring study was performed by one lead and two naive laboratories to evaluate the transferability, as well as within- and between-laboratory reproducibilities, of episensa. Three non-coded chemicals (two lipophilic sensitizers and one non-sensitizer) were tested for the assessment of transferability and 10 coded chemicals (seven sensitizers and three non-sensitizers, including four lipophilic chemicals) were tested for the assessment of reproducibility. In the transferability phase, the non-coded chemicals (two sensitizers and one non-sensitizer) were correctly classified at the two naive laboratories, indicating that the episensa protocol was transferred successfully. For the within-laboratory reproducibility, the data generated with three coded chemicals tested in three independent experiments in each laboratory gave consistent predictions within laboratories. For the between-laboratory reproducibility, 9 of the 10 coded chemicals tested once in each laboratory provided consistent predictions among the three laboratories. These results suggested that episensa has good transferability, as well as within- and between-laboratory reproducibility.copyright © 2018 john wiley & sons, ltd.","","","2018","10.1002/jat.3634","","","embase-621982054.pdf","embase-621982054"
"Efficient multi-authority attribute-based searchable encryption scheme with blockchain assistance for cloud-edge coordination","Liu, P. And He, Q. And Zhao, B. And Guo, B. And Zhai, Z.","Computers, Materials And Continua","","Cloud storage and edge computing are utilized to address the storage and computational challenges arising from the exponential data growth in iot. However, data privacy is potentially risky when data is outsourced to cloud servers or edge services. While data encryption ensures data confidentiality, it can impede data sharing and retrieval. Attribute-based searchable encryption (abse) is proposed as an effective technique for enhancing data security and privacy. Nevertheless, abse has its limitations, such as single attribute authorization failure, privacy leakage during the search process, and high decryption overhead. This paper presents a novel approach called the blockchain-assisted efficient multi-authority attribute-based searchable encryption scheme (bem-abse) for cloud-edge collaboration scenarios to address these issues. Bem-abse leverages a consortium blockchain to replace the central authentication center for global public parameter management. It incorporates smart contracts to facilitate reliable and fair ciphertext keyword search and decryption result verification. To minimize the computing burden on resource-constrained devices, bem-abse adopts an online/offline hybrid mechanism during the encryption process and a verifiable edge-assisted decryption mechanism. This ensures both low computation cost and reliable ciphertext. Security analysis conducted under the random oracle model demonstrates that bem-abse is resistant to indistinguishable chosen keyword attacks (ind-cka) and indistinguishable chosen plaintext attacks (ind-cpa). Theoretical analysis and simulation results confirm that bem-abse significantly improves computational efficiency compared to existing solutions. © 2023 tech science press. All rights reserved.","","","2023","10.32604/cmc.2023.041167","","","scopus-2-s2.0-85174420022.pdf","scopus-2-s2.0-85174420022"
"Faculty research following merger: a job stress and social identity theory perspective","Slade, C.p. And Ribando, S.j. And Fortner, C.k.","Scientometrics","","With conflicting public pressure for greater access to higher education and budget reductions and with continuing backlash over increasing tuition and skyrocketing student debt, public universities have intensified efforts to improve organizational efficiency, effectiveness, and productivity. One strategic option is merging institutions of higher education to better utilize resources, reap cost savings, and increase scholarly outputs. Mergers and acquisitions more commonly occur in the business domain and analysis specific to the higher education arena is limited to this point. Our research examines the effects of university merger on knowledge production in the form of faculty scholarly productivity. We use results of a continuing study of merger of two state-funded higher education institutions, with quite different organizational cultures and research orientations, to explore merger impacts. Using the extensive prior literature on job stress and associated person–organization fit, as well as social identity theory, we develop a model of predictors of post-merger research time allocation and associated productivity. We find lingering effects of pre-merger institutional affiliation, particularly for the low status university faculty, on post-merger job stress, organizational fit, and resulting research productivity. The results of our study advance practical approaches to mergers in higher education for policy makers and managers of higher education. © 2016, akadémiai kiadó, budapest, hungary.","","","2016","10.1007/s11192-016-1881-x","","","scopus-2-s2.0-84957590885.pdf","scopus-2-s2.0-84957590885"
"rCASC: reproducible classification analysis of single-cell sequencing data","Alessandri L., Cordero F., Beccuti M., Arigoni M., Olivero M., Romano G., Rabellino S., Licheri N., De Libero G., Pace L., Calogero R. A.","GigaScience","","BACKGROUND: Single-cell RNA sequencing is essential for investigating cellular heterogeneity and highlighting cell subpopulation-specific signatures. Single-cell sequencing applications have spread from conventional RNA sequencing to epigenomics e.g. ATAC-seq. Many related algorithms and tools have been developed but few computational workflows provide analysis flexibility while also achieving functional (i.e. information about the data and the tools used are saved as metadata) and computational reproducibility (i.e. a real image of the computational environment used to generate the data is stored) through a user-friendly environment. FINDINGS: rCASC is a modular workflow providing an integrated analysis environment (from count generation to cell subpopulation identification) exploiting Docker containerization to achieve both functional and computational reproducibility in data analysis. Hence rCASC provides preprocessing tools to remove low-quality cells and/or specific bias e.g. cell cycle. Subpopulation discovery can instead be achieved using different clustering techniques based on different distance metrics. Cluster quality is then estimated through the new metric ""cell stability score"" (CSS) which describes the stability of a cell in a cluster as a consequence of a perturbation induced by removing a random set of cells from the cell population. CSS provides better cluster robustness information than the silhouette metric. Moreover rCASC's tools can identify cluster-specific gene signatures. CONCLUSIONS: rCASC is a modular workflow with new features that could help researchers define cell subpopulations and detect subpopulation-specific markers. It uses Docker for ease of installation and to achieve a computation-reproducible analysis. A Java GUI is provided to welcome users without computational skills in R.","","","2019","10.1093/gigascience/giz105","","","medline-31494672.pdf","medline-31494672"
"Lessons learned from an investigation exploring association between grit and student performance in a pharmacy skills laboratory course","Dy-Boarman, E.a. And Bottenberg, M.m. And Diehl, B. And Mobley-Bukstein, W. And Quaerna, B.","Currents In Pharmacy Teaching And Learning","","Background: a challenge for many pharmacy educators is early identification of students who may struggle with various aspects of the pharmacy curriculum. While grade point average, demographic factors, and personality traits may be helpful considerations, we felt there was a need to further explore methods for readily identifying at-risk students who may benefit from early intervention. The grit scale has recently been explored, presented, and published in academic pharmacy. The goal of this study was to determine if there was an association between students’ grit scores and performance on a laboratory practical examination. However, it became apparent that there were substantial limitations leading to difficulties analyzing and interpreting our study data and results. Impact: the interpretation of data was confounded due to study design limitations, including use of the grit-o scale (rather than grit-s), low response rate, and lack of validation evidence for laboratory practical assessments. Recommendations: thoughtful consideration during the design of the study may have produced better data for analysis. Psychometric considerations are paramount, both for the instrument (grit-o) and the dependent/outcome variable (laboratory practical assessment). Discussion: while this study did not yield meaningful results for interpretation, it highlighted important lessons for investigators at the college to use moving forward. We hope that the lessons learned from this investigation might support the academy in improving design and rigor of educational research. © 2018 elsevier inc.","","","2018","10.1016/j.cptl.2018.08.014","","","scopus-2-s2.0-85051640251.pdf","scopus-2-s2.0-85051640251"
"Outcomes in intervention research on snakebite envenomation: a systematic review","Bhaumik S., Beri D., Tyagi J., Clarke M., Sharma S. K., Williamson P. R., Jagnoor J.","F1000Research","","INTRODUCTION: A core outcome set (COS) is a minimal list of consensus outcomes that should be used in all intervention research in a specific domain. COS enhance the ability to undertake meaningful comparisons and to understand the benefits or harms of different treatments. A first step in developing a COS is to identify outcomes that have been used previously. We did this global systematic review to provide the foundation for development of a region-specific COS for snakebite envenomation. Methods: We searched 15 electronic databases eight trial registries and reference lists of included studies to identify reports of relevant trials protocols registry records and systematic reviews. We extracted verbatim data on outcomes their definitions measures and time-points. Outcomes were classified as per an existing outcome taxonomy and we identified unique outcomes based on similarities in the definition and measurement of the verbatim outcomes.\\\\\\\\rRESULTS: We included 107 records for 97 studies which met our inclusion criteria. These reported 538 outcomes with a wide variety of outcome measures definitions and time points for measurement. We consolidated these into 88 unique outcomes which we classified into core areas of mortality (1 1.14 %) life impact (6 6.82%) resource use (15 17.05%) adverse events (7 7.95%) physiological/clinical (51 57.95%) and composite (8 9.09%) outcomes. The types of outcomes varied by the type of intervention and by geographic region. Only 15 of the 97 trials (17.04%) listed Patient Related Outcome Measures (PROMS).\\\\\\\\rCONCLUSION: Trials evaluating interventions for snakebite demonstrate heterogeneity on outcomes and often omit important information related to outcome measurement (definitions instruments and time points). Developing high quality region-specific COS for snakebite could inform the design of future trials and improve outcome reporting. Measurement of PROMS resource use and life impact outcomes in trials on snakebite remains a gap. Copyright: © 2022 Bhaumik S et al.","","","2022","10.12688/f1000research.122116.1","","","medline-36300033.pdf","medline-36300033"
"NSF Anticipates Pushing Boundaries on Open-Access Plan","Basken Paul","Chronicle of Higher Education. Feb","","The National Science Foundation (NSF) in carrying out the Obama administration's new push for greater public access to research published in scientific journals will consider exclusivity periods shorter than the 12-month standard in the White House directive as well as trade-offs involving data-sharing and considerations of publishers' financial sustainability. The administration's directive announced on Friday after two years of deliberation asks agencies that sponsor research to impose a 12-month upper limit on how long journals can hold subscription-only rights to articles describing research that was financed with federal funds. The National Institutes of Health (NIH) adopted such a requirement almost five years ago and now all other federal agencies that spend at least $100-million a year on research and development are being given six months to draft a similar policy. The NIH announced this past November that it would soon begin enforcement by blocking the renewal of grant awards in cases where journal publications arising from the awards do not comply with its open-access rule. The NSF the largest provider of federal money for basic scientific research after the NIH will very likely follow the NIH in setting a 12-month period of exclusivity as its general rule. The White House science adviser John P. Holdren in announcing the new policy on Friday described an expansion of public access to federally financed research as important to economic growth. Scientific research supported by the federal government spurs scientific breakthroughs and economic advances when research results are made available to innovators. Demands for open-access research have generated years of heated debate involving publishers universities researchers and various advocacy groups. The NIH instituted its 12-month policy in April 2008 but only after strenuous objections from private publishing companies that fought back against an original proposal for six months. Congress has refused to pass a government-wide mandate despite several years of attempts by some lawmakers. And only a year ago the Obama administration appeared to have given up on the idea after a year of studying the question. In the end the plan outlined by Mr. Holdren does ""a very good job of balancing interests"" of libraries universities researchers and publishers. Industry representatives appeared to agree. In a statement issued Friday the Association of American Publishers said the new policy ""outlines a reasonable balanced resolution of issues around public access to research funded by federal agencies."" (ERIC)","","","2013","","","","unknown-1135.pdf","unknown-1135"
"Privacy-aware and security-enhanced efficient matchmaking encryption","Sun, J. And Xu, G. And Zhang, T. And Yang, X. And Alazab, M. And Deng, R.h.","Ieee Transactions On Information Forensics And Security","","Data sharing technologies enable users to outsource data and privately share information with arbitrary recipients without geographic barriers. However, existing efforts for secure data sharing are either inflexible, insufficiently-secure or inefficient. In this paper, we invent ps-me, the first privacy-aware and security-enhanced efficient matchmaking encryption (me) for flexible data sharing. To be more specific, we first formulate an identity-based broadcast matchmaking encryption (ib-bme) for one-to-many data sharing, which enables both participants to specify respective access policies to the encrypted data, such that the data can be revealed by multiple recipients in the case that both access policies are satisfied. In ib-bme, a general matchmaking transformation solution realizing one-to-many sharing is initialized. We also formulate the ps-me with the general matchmaking transformation solution of ib-bme as the underlying approach, which in addition to featuring ib-bme's all desirable properties, enables efficient decryption, identity anonymity and cca-security, where we address the open problem of me regarding cca-security (raised in crypto'2019). Finally, the comprehensively rigorous security proofs indicate the security of the suggested methodologies. The experimental results are also shown to demonstrate their practicability and effectiveness. © 2005-2012 ieee.","","","2023","10.1109/tifs.2023.3294725","","","scopus-2-s2.0-85164690021.pdf","scopus-2-s2.0-85164690021"
"Mindmap: establishing an integrated database infrastructure for research in ageing, mental well-being, and the urban environment","Beenackers, M.a. And Doiron, D. And Fortier, I. And Noordzij, J.m. And Reinhard, E. And Courtin, E. And Bobak, M. And Chaix, B. And Costa, G. And Dapp, U. And Diez Roux, A.v. And Huisman, M. And Grundy, E.m. And Krokstad, S. And Martikainen, P. And Raina, P. And Avendano, M. And Van Lenthe, F.j.","Bmc Public Health","","Background: urbanization and ageing have important implications for public mental health and well-being. Cities pose major challenges for older citizens, but also offer opportunities to develop, test, and implement policies, services, infrastructure, and interventions that promote mental well-being. The mindmap project aims to identify the opportunities and challenges posed by urban environmental characteristics for the promotion and management of mental well-being and cognitive function of older individuals. Methods: mindmap aims to achieve its research objectives by bringing together longitudinal studies from 11 countries covering over 35 cities linked to databases of area-level environmental exposures and social and urban policy indicators. The infrastructure supporting integration of this data will allow multiple mindmap investigators to safely and remotely co-analyse individual-level and area-level data. Individual-level data is derived from baseline and follow-up measurements of ten participating cohort studies and provides information on mental well-being outcomes, sociodemographic variables, health behaviour characteristics, social factors, measures of frailty, physical function indicators, and chronic conditions, as well as blood derived clinical biochemistry-based biomarkers and genetic biomarkers. Area-level information on physical environment characteristics (e.g. green spaces, transportation), socioeconomic and sociodemographic characteristics (e.g. neighbourhood income, residential segregation, residential density), and social environment characteristics (e.g. social cohesion, criminality) and national and urban social policies is derived from publically available sources such as geoportals and administrative databases. The linkage, harmonization, and analysis of data from different sources are being carried out using piloted tools to optimize the validity of the research results and transparency of the methodology. Discussion: mindmap is a novel research collaboration that is combining population-based cohort data with publicly available datasets not typically used for ageing and mental well-being research. Integration of various data sources and observational units into a single platform will help to explain the differences in ageing-related mental and cognitive disorders both within as well as between cities in europe, the us, canada, and russia and to assess the causal pathways and interactions between the urban environment and the individual determinants of mental well-being and cognitive ageing in older adults. © 2018 the author(s).","","","2018","10.1186/s12889-018-5031-7","","","scopus-2-s2.0-85040723839.pdf","scopus-2-s2.0-85040723839"
"K-anonymity in practice: how generalisation and suppression affect machine learning classifiers","Slijepčević, D. And Henzl, M. And Daniel Klausner, L. And Dam, T. And Kieseberg, P. And Zeppelzauer, M.","Computers And Security","","The protection of private information is a crucial issue in data-driven research and business contexts. Typically, techniques like anonymisation or (selective) deletion are introduced in order to allow data sharing, e. g. in the case of collaborative research endeavours. For use with anonymisation techniques, the k-anonymity criterion is one of the most popular, with numerous scientific publications on different algorithms and metrics. Anonymisation techniques often require changing the data and thus necessarily affect the results of machine learning models trained on the underlying data. In this work, we conduct a systematic comparison and detailed investigation into the effects of different k-anonymisation algorithms on the results of machine learning models. We investigate a set of popular k-anonymisation algorithms with different classifiers and evaluate them on different real-world datasets. Our systematic evaluation shows that with an increasingly strong k-anonymity constraint, the classification performance generally degrades, but to varying degrees and strongly depending on the dataset and anonymisation method. Furthermore, mondrian can be considered as the method with the most appealing properties for subsequent classification. © 2021 the author(s)","","","2021","10.1016/j.cose.2021.102488","","","scopus-2-s2.0-85117127897.pdf","scopus-2-s2.0-85117127897"
"Who is running croatian enterprises?","Krištofić, B.","Post-Communist Economies","","According to the results of empirical studies, the croatian post-socialist executive elite contains an equal number of old socialist directors and new managers. The data presented therefore provide equal support for the thesis of survival and for the thesis of change in the elite. The thesis of conversion of power is supported by data on share ownership. Through the process of privatisation the majority of directors converted the power they had under socialism into shares. Since the new elite is younger and less educated than the socialist cadres the thesis of technocratic continuity cannot be accepted. Changes in ideology are reflected in the data on party membership. Under socialism, about 15% of directors were not members of the communist party, and today almost two-thirds of managers are not members of any party. But among those who are party members, most are in the ruling hdz party. Regardless of party (dis)affiliation, the vast majority of both the elite and citizens accepted the new ideology which gives priority to the nation over the individual. This resulted in a delay in solving the problems which have appeared in the process of privatisation.","","","1999","10.1080/14631379995869","","","scopus-2-s2.0-0033369032.pdf","scopus-2-s2.0-0033369032"
"Structural and functional imaging studies in chronic cannabis users: a systematic review of adolescent and adult findings","Batalla, A. And Bhattacharyya, S. And Yücel, M. And Fusar-Poli, P. And Crippa, J.a. And Nogué, S. And Torrens, M. And Pujol, J. And Farré, M. And Martin-Santos, R.","Plos One","","Background: the growing concern about cannabis use, the most commonly used illicit drug worldwide, has led to a significant increase in the number of human studies using neuroimaging techniques to determine the effect of cannabis on brain structure and function. We conducted a systematic review to assess the evidence of the impact of chronic cannabis use on brain structure and function in adults and adolescents. Methods: papers published until august 2012 were included from embase, medline, pubmed and lilacs databases following a comprehensive search strategy and pre-determined set of criteria for article selection. Only neuroimaging studies involving chronic cannabis users with a matched control group were considered. Results: one hundred and forty-two studies were identified, of which 43 met the established criteria. Eight studies were in adolescent population. Neuroimaging studies provide evidence of morphological brain alterations in both population groups, particularly in the medial temporal and frontal cortices, as well as the cerebellum. These effects may be related to the amount of cannabis exposure. Functional neuroimaging studies suggest different patterns of resting global and brain activity during the performance of several cognitive tasks both in adolescents and adults, which may indicate compensatory effects in response to chronic cannabis exposure. Limitations: however, the results pointed out methodological limitations of the work conducted to date and considerable heterogeneity in the findings. Conclusion: chronic cannabis use may alter brain structure and function in adult and adolescent population. Further studies should consider the use of convergent methodology, prospective large samples involving adolescent to adulthood subjects, and data-sharing initiatives. © 2013 batalla et al.","","","2013","10.1371/journal.pone.0055821","","","scopus-2-s2.0-84873489002.pdf","scopus-2-s2.0-84873489002"
"A novel visual secret sharing scheme based on qr codes","Wan, S. And Lu, Y. And Yan, X. And Liu, L.","International Journal Of Digital Crime And Forensics","","In this paper, a novel visual secret sharing (vss) scheme using qr codes is investigated. The proposed visual secret sharing scheme based on qr codes(vssqr) can visually reveal secret image by stacking sufficient (shadow images) shares as well as scan the qr code by a qr code reader. Our vssqr exploits the error correction mechanism in the qr code structure, to embed the bits corresponding to shares generated by vss from a secret bit into the same locations of qr codes in the processing of encoding qr. Each output share is a valid qr code, which may reduce the likelihood of attracting the attention of potential attackers. The secret image can be recovered by stacking sufficient qr code shares based on the human visual system without any computation. In addition, it can assist alignment for vss recovery. The experiment results show the effectiveness of our scheme. Copyright © 2017, igi global.","","","2017","10.4018/ijdcf.2017070104","","","scopus-2-s2.0-85020702266.pdf","scopus-2-s2.0-85020702266"
"Game over: empower early career researchers to improve research quality","De Herde, V. And Björnmalm, M. And Susi, T.","Insights: The Uksg Journal","","Processes of research evaluation are coming under increasing scrutiny, with detractors arguing that they have adverse effects on research quality, and that they support a research culture of competition to the detriment of collaboration. Based on three personal perspectives, we consider how current systems of research evaluation lock early career researchers and their supervisors into practices that are deemed necessary to progress academic careers within the current evaluation frameworks. We reflect on the main areas in which changes would enable better research practices to evolve;  many align with open science. In particular, we suggest a systemic approach to research evaluation, taking into account its connections to the mechanisms of financial support for the institutions of research and higher education in the broader landscape. We call for more dialogue in the academic world around these issues and believe that empowering early career researchers is key to improving research quality. © 2021 ubiquity press. All rights reserved.","","","2021","10.1629/uksg.548","","","scopus-2-s2.0-85109964563.pdf","scopus-2-s2.0-85109964563"
"6g oriented blockchain based internet of things data sharing and storage mechanism","Jiang, Y. And Ge, X. And Yang, Y. And Wang, C. And Li, J.","Tongxin Xuebao/Journal On Communications","","Considering the heterogeneity of various iot system and the single point failure of centralized data-processing platform, a decentralized iot data sharing and storage method based on blockchain technology was proposed. The block consensus and decentralized storage of shared data were realized through the pos consensus mechanism. A block layered propagation mechanism between consensus node and verified node was proposed based on the gossip protocol. The block propagation delay model and decentralization evaluation model of blockchain networks were derived. The trade-off between the block propagation delay and the decentralization degree of networks was analyzed. The simulation results demonstrate that the block propagation delay and degree of network decentralization decrease with the increase of minimal capabilities of consensus nodes. As an application example, in the trajectory data sharing scenario of confirmed patients, the data sharing smart contract is implemented and tested based on the ethereum development platform. © 2020, editorial board of journal on communications. All right reserved.","","","2020","10.11959/j.issn.1000-436x.2020211","","","scopus-2-s2.0-85096031748.pdf","scopus-2-s2.0-85096031748"
"Securing data with blockchain and ai","Wang, K. And Dong, J. And Wang, Y. And Yin, H.","Ieee Access","","Data is the input for various artificial intelligence (ai) algorithms to mine valuable features, yet data in internet is scattered everywhere and controlled by different stakeholders who cannot believe in each other, and usage of the data in complex cyberspace is difficult to authorize or to validate. As a result, it is very difficult to enable data sharing in cyberspace for the real big data, as well as a real powerful ai. In this paper, we propose the secnet, an architecture that can enable secure data storing, computing, and sharing in the large-scale internet environment, aiming at a more secure cyberspace with real big data and thus enhanced ai with plenty of data source, by integrating three key components: 1) blockchain-based data sharing with ownership guarantee, which enables trusted data sharing in the large-scale environment to form real big data;  2) ai-based secure computing platform to produce more intelligent security rules, which helps to construct a more trusted cyberspace;  3) trusted value-exchange mechanism for purchasing security service, providing a way for participants to gain economic rewards when giving out their data or service, which promotes the data sharing and thus achieves better performance of ai. Moreover, we discuss the typical use scenario of secnet as well as its potentially alternative way to deploy, as well as analyze its effectiveness from the aspect of network security and economic revenue. © 2013 ieee.","","","2019","10.1109/access.2019.2921555","","","scopus-2-s2.0-85068340161.pdf","scopus-2-s2.0-85068340161"
"Exploring city digital twins as policy tools: a task-based approach to generating synthetic data on urban mobility","Papyshev, G. And Yarime, M.","Data And Policy","","This article discusses the technology of city digital twins (cdts) and its potential applications in the policymaking context. The article analyzes the history of the development of the concept of digital twins and how it is now being adopted on a city-scale. One of the most advanced projects in the field - virtual singapore - is discussed in detail to determine the scope of its potential domains of application and highlight challenges associated with it. Concerns related to data privacy, availability, and its applicability for predictive simulations are analyzed, and potential usage of synthetic data is proposed as a way to address these challenges. The authors argue that despite the abundance of urban data, the historical data are not always applicable for predictions about the events for which there does not exist any data, as well as discuss the potential privacy challenges of the usage of micro-level individual mobility data in cdts. A task-based approach to urban mobility data generation is proposed in the last section of the article. This approach suggests that city authorities can establish services responsible for asking people to conduct certain activities in an urban environment in order to create data for possible policy interventions for which there does not exist useful historical data. This approach can help in addressing the challenges associated with the availability of data without raising privacy concerns, as the data generated through this approach will not represent any real individual in society. © the author(s), 2021. Published by cambridge university press.","","","2021","10.1017/dap.2021.17","","","scopus-2-s2.0-85128999673.pdf","scopus-2-s2.0-85128999673"
"The impacts of accessibility measure choice on public transit project evaluation: a comparative study of cumulative, gravity-based, and hybrid approaches","Klar, B. And Lee, J. And Long, J.a. And Diab, E.","Journal Of Transport Geography","","This paper investigates whether different types of accessibility measures can perform similarly when evaluating changes in accessibility before and after transport interventions. Specifically, we compare three types of placed-based accessibility approaches: 1) cumulative-opportunity, 2) gravity-based, and 3) hybrid of the two. We conduct a comprehensive comparison of 12 accessibility measures by combining different operational forms, impedance functions, and parameters to see if the results of project appraisals are sensitive to the choice of accessibility measure. For case studies, we consider two scenarios in canada: new bus rapid transit (brt) services in vancouver and transit system redesign (tsr) in edmonton. We carry out high spatio-temporal resolution accessibility analyses based on general transit feed specification (gtfs) datasets through an open-source transit analytics tool. Results demonstrate that the three types of measures perform differently when evaluating changes in accessibility pre and post transit interventions. Accessibility change scores generated by cumulative-opportunity measures are notably different from those produced by gravity-based and hybrid measures. Also, the capability of cumulative-opportunity approach in capturing the geographic extent of areas affected by transit interventions is limited. We found that the project appraisal results can even change from positive to negative or vice versa, depending on the chosen accessibility measure. We recommend an analyst test several types of accessibility measure with a range of parameters for a more robust evaluation on the impacts of new public transit services on accessibility. We share our code and data to promote reproducible transportation science in planning practice. © 2022 elsevier ltd","","","2023","10.1016/j.jtrangeo.2022.103508","","","scopus-2-s2.0-85145594968.pdf","scopus-2-s2.0-85145594968"
"Dual-quorum: a highly available and consistent replication system for edge services","Gao, L. And Dahlin, M. And Zheng, J. And Alvisi, L. And Iyengar, A.","Ieee Transactions On Dependable And Secure Computing","","This paper introduces dual-quorum replication, a novel data replication algorithm designed to support internet edge services. Edge services allow clients to access internet services via distributed edge servers that operate on a shared collection of underlying data. Although it is generally difficult to share data while providing high availability, good performance, and strong consistency, replication algorithms designed for specific access patterns can offer nearly ideal trade-offs among these metrics. In this paper, we focus on the key problem of sharing read/write data objects across a collection of edge servers when the references to each object 1) tend not to exhibit high concurrency across multiple nodes and 2) tend to exhibit bursts of read-dominated or write-dominated behavior. Dual-quorum replication combines volume leases and quorum-based techniques to achieve excellent availability, response time, and consistency for such workloads. In particular, through both analytical and experimental evaluations, we show that the dual-quorum protocol can (for the workloads of interest) approach the optimal performance and availability of read-one/write-all-asynchronously (rowa-a) epidemic algorithms without suffering the weak consistency guarantees and resulting design complexity inherent in rowa-a systems. © 2006 ieee.","","","2010","10.1109/tdsc.2008.36","","","scopus-2-s2.0-77952741967.pdf","scopus-2-s2.0-77952741967"
"Learning and understanding the Kruskal-Wallis one-way analysis-of-variance-by-ranks test for differences among three or more independent groups","Chan Y., Walmsley R. P.","Physical Therapy","","When several treatment methods are available for the same problem many clinicians are faced with the task of deciding which treatment to use. Many clinicians may have conducted informal ""mini-experiments"" on their own to determine which treatment is best suited for the problem. These results are usually not documented or reported in a formal manner because many clinicians feel that they are ""statistically challenged."" Another reason may be because clinicians do not feel they have controlled enough test conditions to warrant analysis. In this update a statistic is described that does not involve complicated statistical assumptions making it a simple and easy-to-use statistical method. This update examines the use of two statistics and does not deal with other issues that could affect clinical research such as issues affecting credibility. For readers who want a more in-depth examination of this topic references have been provided. The Kruskal-Wallis one-way analysis-of-variance-by-ranks test (or H test) is used to determine whether three or more independent groups are the same or different on some variable of interest when an ordinal level of data or an interval or ratio level of data is available. A hypothetical example will be presented to explain when and how to use this statistic how to interpret results using the statistic the advantages and disadvantages of the statistic and what to look for in a written report. This hypothetical example will involve the use of ratio data to demonstrate how to choose between using the nonparametric H test and the more powerful parametric F test.","","","1997","","","","medline-9413454.pdf","medline-9413454"
"Modular framework for similarity-based dataset discovery using external knowledge","Nečaský, M. And Škoda, P. And Bernhauer, D. And Klímek, J. And Skopal, T.","Data Technologies And Applications","","Purpose: semantic retrieval and discovery of datasets published as open data remains a challenging task. The datasets inherently originate in the globally distributed web jungle, lacking the luxury of centralized database administration, database schemes, shared attributes, vocabulary, structure and semantics. The existing dataset catalogs provide basic search functionality relying on keyword search in brief, incomplete or misleading textual metadata attached to the datasets. The search results are thus often insufficient. However, there exist many ways of improving the dataset discovery by employing content-based retrieval, machine learning tools, third-party (external) knowledge bases, countless feature extraction methods and description models and so forth. Design/methodology/approach: in this paper, the authors propose a modular framework for rapid experimentation with methods for similarity-based dataset discovery. The framework consists of an extensible catalog of components prepared to form custom pipelines for dataset representation and discovery. Findings: the study proposes several proof-of-concept pipelines including experimental evaluation, which showcase the usage of the framework. Originality/value: to the best of authors’ knowledge, there is no similar formal framework for experimentation with various similarity methods in the context of dataset discovery. The framework has the ambition to establish a platform for reproducible and comparable research in the area of dataset discovery. The prototype implementation of the framework is available on github. © 2021, martin nečaský, petr škoda, david bernhauer, jakub klímek and tomáš skopal.","","","2022","10.1108/dta-09-2021-0261","","","scopus-2-s2.0-85125073753.pdf","scopus-2-s2.0-85125073753"
"Clinical experimentation in pediatrics","Vivaldi, F. And Polvani, M. And Dal Canto, L. And Carmignani, A.","Giornale Italiano Di Farmacia Clinica","","Introduction. Performing specific clinical trials in the paediatric population would allow children to have safe and effective drugs, without the risks connected with an off label use in children of drugs licensed for use in adults. Clinical research in paediatrics is ampered by ethical and practical issues, and also by the lack of economic interest by pharmaceutical companies. Methods. About these items has been conducted an evaluation of clinical trial protocols of paediatric studies examined in the year 2006 by the ethical committee of azienda ospedaliero-universitaria pisana. Results. Fourteen paediatric studies have been examined in the year 2006: 4 are observational, 1 is observational-interventional, 9 are interventional;  10 of 14 studies resulted no-profit. Conclusions. The analysis of the protocols highlights the need of an adequate information to parents but mainly to children involved in clinical trials. Protocols should generate reproducible data in specific age categories, and a follow-up long enough to verify efficacy and safety of new medicines over time.","","","2008","","","","scopus-2-s2.0-46749086598.pdf","scopus-2-s2.0-46749086598"
"Looking back in time: conducting a cohort study of the long-term effects of treatment of adolescent tall girls with synthetic hormones","Bruinsma F. J., Rayner J. A., Venn A. J., Pyett P., Werther G.","BMC Public Health","","OBJECTIVE: Public health research is an endeavour that often involves multiple relationships far-reaching collaborations divergent expectations and various outcomes. Using the Tall Girls Study as a case study this paper will present and discuss a number of methodological ethical and legal challenges that have implications for other public health research.\\\\\\\\rAPPROACH: The Tall Girls Study was the first study to examine the long-term health and psychosocial effects of oestrogen treatment for tall stature.\\\\\\\\rRESULTS: In undertaking this study the research team overcame many hurdles: in maintaining collaboration with treating clinicians and with the women they had treated as girls - groups with opposing points of view and different expectations; using private practice medical records to trace women who had been patients up to forty years earlier; and exploring potential legal issues arising from the collection of data related to treatment.\\\\\\\\rCONCLUSION: While faced with complex challenges the Tall Girls Study demonstrated that forward planning ongoing dialogue between all stakeholders transparency of processes and the strict adherence to group-developed protocols were keys to maintaining rigour while undertaking pragmatic research.\\\\\\\\rIMPLICATIONS: Public health research often occurs within political and social contexts that need to be considered in the planning and conduct of studies. The quality and acceptability of research findings is enhanced when stakeholders are engaged in all aspects of the research process.","","","2011","10.1186/1471-2458-11-s5-s7","","","medline-22168546.pdf","medline-22168546"
"Evidence-based chinese medicine: theory and practice","Zhang, J.-H. And Li, Y.-P. And Zhang, B.-L.","Zhongguo Zhongyao Zazhi","","The introduction and popularization of evidence-based medicine has opened up a new research field of clinical efficacy evaluation of traditional chinese medicine(tcm), produced new research ideas and methods, and promoted the progress of clinical research of tcm. After about 20 years assiduous study and earnest practice, the evidence based evaluation method and technique, which conforms to the characteristics of tcm theory and practice, has been developing continuously. Evidence-based chinese medicine (ebcm) has gradually formed and become an important branch of evidence-based medicine. The basic concept of evidence-based chinese medicine: ebcm is an applied discipline, following the theory and methodology of evidence-based medicine, to collect, evaluate, produce, transform the evidence of effectiveness, safety and economy of tcm, to reveal the feature and regular pattern of tcm taking effect, and to guide the development of clinical guidelines, clinical pathways and health decisions. The effects and achievements of ebcm development: secondary studies mainly based on systematic review/meta-analysis were extensively carried out;  clinical efficacy studies mainly relying on randomized controlled trials grew rapidly;  clinical safety evaluations based on real world study have been conducted;  methodological researches mainly focused on study quality control deepened gradually;  internationalization researches mainly on report specifications have got some breakthroughs;  standardization researches based on treatment specification were strengthened gradually;  the research team and talents with the characteristics of inter-disciplinary have been steadily increased. A number of high-quality research findings have been published at international well-known journals;  the clinical efficacy and safety evidence of tcm has been increased;  the level of clinical rational use of tcm has been improved;  a large number of chinese patent medicines with big market have been cultured. The future missions of ebcm mainly consist of four categories (scientific research, methodology and standard, platform construction and personnel training) with nine tasks. (1) carry out systematic reviews to systematically collect clinical trial reports of tcm and establish database of clinical evidence of tcm;  (2) carry out evidence transformation research to lay the foundation for the development of clinical diagnosis and treatment guidelines, clinical pathways of tcm, and for the screening of basic drug list and medical insurance list, and for the policy-making relevant to tcm;  (3) conduct researches to evaluate the advantages and effective regular patterns of tcm and form the evidence chain of tcm efficacy;  (4) carry out researches for the safety evaluation of tcm, and provide evidence supporting the rational and safe use of tcm in clinical practice;  (5) conduct researches on methodology of ebcm and provide method for developing high quality evidence;  (6) carry out researches to develop standards and norms of tcm, and to form methods, standards, specifications and technical systems;  (7) establish data management platform for evidence-based evaluation of tcm, and promote data sharing;  (8) build international academic exchange platform to promote international cooperation and mutual recognition of ebcm research;  (9)carry out education and popularization activities of evidence-based evaluation methods, and train undergraduate students, graduate students, clinical healthcare providers and practitioners of tcm. The development of ebcm, as it was, not only promoted the transformation of clinical research and decision-making mode of tcm, contributed to the modernization and internationalization of tcm, but also enriched the connotation of evidence-based medicine. © 2018, editorial board of china journal of chinese materia medica. All right reserved.","","","2018","10.19540/j.cnki.cjcmm.20171127.001","","","scopus-2-s2.0-85045000096.pdf","scopus-2-s2.0-85045000096"
"How Reproducible Research Leads to Non-Rote Learning within Socially Constructivist Statistics Education","Wessa Patrick","Electronic Journal of e-Learning","","This paper discusses the implementation of a new e-learning environment that supports non-rote learning of exploratory and inductive statistics within the pedagogical paradigm of social constructivism. The e-learning system is based on a new computational framework that allows us to create an electronic research environment where students are empowered to interact with reproducible computations from peers and the educator. The underlying technology effectively supports social interaction (communication) knowledge construction collaboration and scientific experimentation even if the student population is very large. In addition the system allows us to measure important aspects of the actual learning process which are otherwise unobservable. With this new information it is possible to explore (and investigate) the effectiveness of e-based learning the impact of software usability and the importance of knowledge construction through various feedback and communication mechanisms. Based on a preliminary empirical analysis from two courses (with large student populations) it is shown that there are strong relationships between actual constructivist learning activities and scores on objective examinations in which the questions assess conceptual understanding. It is also explained that non-rote learning is supported by the fact that the system allows users to reproduce results and reuse them in derived research that can be easily communicated. (Contains 2 tables.)","","","2009","","","","eric-ej867115.pdf","eric-ej867115"
"Structural under-reporting of informed consent data handling and sharing ethical approval and application of Open Science principles as proxies for study quality conduct in COVID-19 research: a systematic scoping review","Wilmes N., Hendriks C. W. E., Viets C. T. A., Cornelissen Sjwm, van Mook Wnka, Cox-Brinkman J., Celi L. A., Martinez-Martin N., Gichoya J. W., Watkins C., Bakhshi-Raiez F., Wynants L., van der Horst I. C. C., van Bussel B. C. T.","BMJ Global Health","","BACKGROUND: The COVID-19 pandemic required science to provide answers rapidly to combat the outbreak. Hence the reproducibility and quality of conducting research may have been threatened particularly regarding privacy and data protection in varying ways around the globe. The objective was to investigate aspects of reporting informed consent and data handling as proxies for study quality conduct.\\\\\\\\rMETHODS: A systematic scoping review was performed by searching PubMed and Embase. The search was performed on November 8th 2020. Studies with hospitalised patients diagnosed with COVID-19 over 18 years old were eligible for inclusion. With a focus on informed consent data were extracted on the study design prestudy protocol registration ethical approval data anonymisation data sharing and data transfer as proxies for study quality. For reasons of comparison data regarding country income level study location and journal impact factor were also collected.\\\\\\\\rRESULTS: 972 studies were included. 21.3% of studies reported informed consent 42.6% reported waivers of consent 31.4% did not report consent information and 4.7% mentioned other types of consent. Informed consent reporting was highest in clinical trials (94.6%) and lowest in retrospective cohort studies (15.0%). The reporting of consent versus no consent did not differ significantly by journal impact factor (p=0.159). 16.8% of studies reported a prestudy protocol registration or design. Ethical approval was described in 90.9% of studies. Information on anonymisation was provided in 17.0% of studies. In 257 multicentre studies 1.2% reported on data sharing agreements and none reported on Findable Accessible Interoperable and Reusable data principles. 1.2% reported on open data. Consent was most often reported in the Middle East (42.4%) and least often in North America (4.7%). Only one report originated from a low-income country.\\\\\\\\rDISCUSSION: Informed consent and aspects of data handling and sharing were under-reported in publications concerning COVID-19 and differed between countries which strains study quality conduct when in dire need of answers. Copyright © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.","","","2023","10.1136/bmjgh-2023-012007","","","medline-37257937.pdf","medline-37257937"
"A descriptive framework for academic listening pedagogy: an observational study","Lacroix, J.a.","Tesol Journal","","This article reports on a case study that centers experienced language teachers as participants. To depict their instructional practices, the researcher employed grounded theory with open and axial coding design. To describe results, a listening experience framework was created that highlights the choices second language (l2) listening instructors make in what they explicitly ask their learners to listen to, reflect on, and respond to. Data analysis revealed that instructors spent far more class time offering strategies and instruction for adapted audio sources regardless of directionality than unadapted counterparts. Five percent of observed classes included a focused listening activity, but specific features of spoken language were not highlighted. Suggestions for a more systematic approach to l2 listening curriculum design and materials are shared. © 2023 tesol international association.","","","2023","10.1002/tesj.712","","","scopus-2-s2.0-85150306493.pdf","scopus-2-s2.0-85150306493"
"Organizational practices and employee performance: the case of the canadian primary textile industry","Patibandla, M. And Chandra, P.","Journal Of Economic Behavior And Organization","","This study investigates variations in the adoption of different organizational practices and productivity using a survey of the canadian primary textile industry. The results suggest that monitoring and profit-sharing are substitutes. The effectiveness of these practices in eliciting high employee performance depends on the size of organizations and adoption of complementary practices. Profit-sharing practice appears to be more effective in small firms than large firms.","","","1998","10.1016/s0167-2681(98)00116-4","","","scopus-2-s2.0-0040081122.pdf","scopus-2-s2.0-0040081122"
"Crossed audit of the quality management system: optimization of professional practices in radiotherapy","Leroy, É. And Ponsard, N.","Cancer/Radiotherapie","","A working group within the french association of radiotherapy quality managers (afqsr) proposed to implement an inter-institution audit among radiotherapy quality managers to share best practices, experience, and to have an external measurement of the effectiveness of the quality control processes implemented. A checklist was devised based on the french nuclear safety authority guide no 5 and a procedure was formalized. The audit focuses on the effectiveness of the quality management process in radiotherapy. This article details the rationale for the project and conduct of the audit. © 2015.","","","2015","10.1016/j.canrad.2015.07.150","","","scopus-2-s2.0-84942831075.pdf","scopus-2-s2.0-84942831075"
"Attribute-based hierarchical access control with extendable policy","Xiao, M. And Li, H. And Huang, Q. And Yu, S. And Susilo, W.","Ieee Transactions On Information Forensics And Security","","Attribute-based encryption scheme is a promising mechanism to realize one-to-many fine-grained access control which strengthens the security in cloud computing. However, massive amounts of data and various data sharing requirements bring great challenges to the complex but isolated and fixed access structures in most of the existing attribute-based encryption schemes. In this paper, we propose an attribute-based hierarchical encryption scheme with extendable policy, called extendable hierarchical ciphertext-policy attribute-based encryption (eh-cp-abe), to improve the data sharing efficiency and security simultaneously. The scheme realizes the function of hierarchical encryption, in which, data with hierarchical access control relationships could be encrypted together flexibly to improve the efficiency. The scheme also achieves external and internal extension of the access structure to further encrypt newly added hierarchical data without updating the original ciphertexts or with only a minor update depending on the data sharing requirements, which simplifies the encryption process and greatly reduces the computation overhead. We formally prove the security of the scheme is ind-cca secure in the random oracle model based on bilinear diffie-hellman assumption, and we also implement our scheme to demonstrate its efficiency and practicality. © 2005-2012 ieee.","","","2022","10.1109/tifs.2022.3173412","","","scopus-2-s2.0-85130647606.pdf","scopus-2-s2.0-85130647606"
"Standard quality criteria in retracted vs nonretracted obstetrical randomized controlled trials","Anderson K. M., Doulaveris G., Bennett C., Mol B. W., Berghella V.","American Journal of Obstetrics & Gynecology MFM","","BACKGROUND: The number of retracted articles in peer-reviewed journals is increasing within the field of obstetrics. The most common reason for article retraction is scientific misconduct. Unfortunately article retraction often occurs years after publication allowing inaccurate data to be widely distributed to readers. There exists a great need for validated screening criteria for obstetric journals to use when reviewing randomized controlled trials for scientific misconduct.\\\\\\\\rOBJECTIVE: This study aimed to compare retracted obstetric randomized controlled trials with nonretracted randomized controlled trials with regard to their inclusion of 7 quality metrics: prospective trial registration trial registration number ethics approval statement name of the approving committee statement of informed consent adherence to the Consolidated Standards of Reporting Trials guidelines and a data sharing statement.\\\\\\\\rSTUDY DESIGN: Obstetric randomized controlled trials retracted between 1995 and 2021 identified through Retraction Watch were compared with nonretracted randomized controlled trials published between 2018 and 2020 with regard to inclusion of the 7 quality metrics. The main outcome was the difference in prospective trial registration. Secondary outcomes were the percentage of individual criteria met and the screening performance of quality criteria in predicting article retraction.\\\\\\\\rRESULTS: A total of 150 randomized controlled trials were identified of which 14 (9.3%) were retracted and 136 (90.7%) nonretracted. Retracted randomized controlled trials were less likely than nonretracted randomized controlled trials to be prospectively registered (14.3% vs 80.1%; P<.001). The median number of quality criteria met was lower for retracted randomized controlled trials (3 vs 6; P<.01). Using a cutoff of <=4 criteria was associated with 85.7% (95% confidence interval 57.2-98.2) sensitivity and 92.0% (95% confidence interval 86.2-96.0) specificity in distinguishing the retracted randomized controlled trials from nonretracted studies.\\\\\\\\rCONCLUSION: Retracted obstetric randomized controlled trials were less likely to include the 7 quality metrics required on submission by most top obstetrics and gynecology journals. Copyright © 2023. Published by Elsevier Inc.","","","2023","10.1016/j.ajogmf.2023.100889","","","medline-36804302.pdf","medline-36804302"
"Encode4openu and the preparation and delivery of an international collaborative mooc: a preliminary analysis of its pedagogical and technical implementation","Salvaterra, C. And Bencivenni, A. And Fogagnolo, M. And Gheldof, T. And Vagionakis, I.","Education Sciences","","Among the potential intellectual outputs of the encode project is the production of a mooc that introduces teaching staff and scientific experts to the digital transition in the field of ancient writing cultures. The basis for this mooc is the need to foster awareness of the importance of digital competences and to use a structured framework to introduce people to the available innovative teaching and learning materials and opportunities for organizing (self-)training in this field of research. For specialists in the humanities, there is often an unexpected reluctance to go beyond simply using digital tools and to deepen their understanding of the implications of the digital transitions of research fields, as well as considering the readiness of young graduates to acquire digital competences. This mooc, which is easily accessible, affordable, sustainable, and flexible, may achieve the initial aim of the project, namely, bridging the gap between the highly specialized competences in the humanities and the innovative digital skills needed in open science practices. The main methodological issue concerns the design and adaptation of cooperative tools in order to implement a common pedagogical approach and to produce mooc content that integrates the different competences and insights of the project participants. This report on the experiment provides useful insights into the differing expectations of academic staff as content producers, issues surrounding mooc-cooperative design between universities in different countries, the usability of the tested platform and of the different features provided, and sustainability, as guaranteed through the connection with digital infrastructures. In the concluding section, the originality of the mooc at a more general scale is emphasized. The ways in which the mooc can facilitate and support the digital transition are assessed according to the fair principles in higher education institutions. Moreover, the mooc offers models for hands-on experiences of digital training and the evaluation of learning outcomes according to shared european frameworks;  it demonstrates the importance of being connected with larger projects and digital infrastructures. © 2022 by the authors.","","","2023","10.3390/educsci13010043","","","scopus-2-s2.0-85146822969.pdf","scopus-2-s2.0-85146822969"
"Problems and strategies of clinical efficacy evaluation of traditional chinese medicine in the new era","Zhang, J. And Liu, Y. And Shang, H.","Kexue Tongbao/Chinese Science Bulletin","","Traditional chinese medicine (tcm) has been widely used to prevent and treat coronavirus disease 2019 (covid-19). In the absence of any miracle drug or vaccine, tcm was applied to all stages of the covid-19 prevention and treatment for the first time and played a significant role. In addition to the first-line clinical treatment for the covid-19, tcm scholars have also carried out various types of clinical research to evaluate the efficacy and safety of tcm. However, the lack of high-quality research evidence has led to tcm not being included in the list of treatment options recommended by the world health organization (who), which makes it difficult to provide references for tcm treatment protocols for the prevention and treatment of the covid-19 for other countries, which significantly limits its promotion and internationalization. Evidence-based medicine has been operative in the tcm research field for more than 20 years. How best to combine the methods of evidence-based medicine with the characteristics and advantages of tcm so that the effect of tcm can be ""clarified and understood"" has always been a big challenge. The emergence of covid-19 has highlighted the importance of this issue. Based on the concept of evidence-based medicine, this paper has elicited the shortcomings of tcm clinical research and efficacy evaluation during the covid-19, such as design flaws, replicated research, insufficient professional involvement and lack of information sharing. It discusses the strategies of tcm clinical research on new emergent diseases in the new era from the aspects of research design and implementation. It is worth emphasizing that in future research, we should pay attention to the individualized efficacy evaluation of tcm, introduce the design concept of the master protocol platform, strengthen the overall planning of clinical research resources, retain the involvement of professionals, and establish a data-sharing mechanism. It is necessary to promote the integration of evidence-based norms and tcm differentiation and treatment, provide new ideas for clinical efficacy evaluation of tcm, enhance the ability of tcm clinical evidence to support decision-making, promote the development of the tcm industry and present tcm to the world. At the same time, we suggest that in response to the challenge of emerging infectious diseases, we should strengthen the clinical research into integrated traditional chinese and western medicine, quickly collect high-quality research evidence, formulate evidence-based emergency intervention protocols, and build a more scientifically coordinated traditional chinese and western medicine treatment system. In the meantime, we need to pay attention to multi-disciplinary and multi-knowledge integration, combined with modern science and technology such as big data and artificial intelligence, build a new paradigm of clinical research into traditional chinese medicine, and improve the level and efficiency of tcm clinical research. © 2022, science press. All right reserved.","","","2022","10.1360/tb-2021-1268","","","scopus-2-s2.0-85127223088.pdf","scopus-2-s2.0-85127223088"
"Towards local community involvement in students’ science learning: perspectives of students and teachers","Montero, C.s. And Leite, L.o.","Journal Of Teaching And Learning","","The european commission calls for schools to move towards becoming open to their communities, integrating external social, civil, and expert stakeholders into authentic learning experiences’ development alongside teachers and students, particularly in terms of science education. However, little research or practical implementation has been reported on how community actors could participate in the development of such curricular learning activities. In this study, we present an implementation of the open science schooling (oss) approach to science learning, where community involvement in the development of science missions takes a vital role. During the study, students developed science missions related to local societal issues that interested them in collaboration with their teachers and community experts, with frequent hands-on investigations outside their classrooms or laboratories, in five european countries and israel. Questionnaires with quantitative and qualitative questions concerning students’ and teachers’ views and perspectives about implementing science education using oss were administered after the participants finished their science missions. The results indicate the effectiveness of the oss approach to science learning involving the community from both students’ and teachers’ perspectives. This study is a step towards supporting schools in becoming active agents of change through the implementation of contextualized learning experiences alongside external stakeholders. © this work is licensed under a creative commons attribution-noncommercial 4.0 international license (cc by-nc 4.0)","","","2022","10.22329/jtl.v16i3.6961","","","scopus-2-s2.0-85150411186.pdf","scopus-2-s2.0-85150411186"
"More on random utility models with bounded ambiguity","Manski, C.f.","Theory And Decision","","Econometric analysis of discrete choice has made considerable use of random utility models to interpret observed choice behavior. Much empirical research concerns choice problems in which persons act with partial knowledge of the utilities of the feasible actions. Economists use random expected utility models to analyze such choice problems. A common practice is to specify fully the expectations that persons hold, in which case choice analysis reduces to inference on preferences alone. However, the expectations assumptions made in empirical research rarely have much foundation. To enable more credible research, this paper considers inference when one specifies a set of expectations that decision makers may plausibly hold. I first pose the idea in abstraction and then specialize to binary response with linear utilities, where the analysis is particularly straightforward. I initially assume that decision makers possess unique subjective probability distributions on the states of nature and make choices that maximize expected utility. I later consider the possibility that persons place only partial probabilistic structure on the states of nature and make undominated choices. © 2017, springer science+business media, llc.","","","2018","10.1007/s11238-017-9620-1","","","scopus-2-s2.0-85021774327.pdf","scopus-2-s2.0-85021774327"
"Mapping the structure and evolution of software testing research over the past three decades","Salahirad, A. And Gay, G. And Mohammadi, E.","Journal Of Systems And Software","","Background: the field of software testing is growing and rapidly-evolving. Aims: based on keywords assigned to publications, we seek to identify predominant research topics and understand how they are connected and have evolved. Methods: we apply co-word analysis to map the topology of testing research as a network where author-assigned keywords are connected by edges indicating co-occurrence in publications. Keywords are clustered based on edge density and frequency of connection. We examine the most popular keywords, summarize clusters into high-level research topics examine how topics connect, and examine how the field is changing. Results: testing research can be divided into 16 high-level topics and 18 subtopics. Creation guidance, automated test generation, evolution and maintenance, and test oracles have particularly strong connections to other topics, highlighting their multidisciplinary nature. Emerging keywords relate to web and mobile apps, machine learning, energy consumption, automated program repair and test generation, while emerging connections have formed between web apps, test oracles, and machine learning with many topics. Random and requirements-based testing show potential decline. Conclusions: our observations, advice, and map data offer a deeper understanding of the field and inspiration regarding challenges and connections to explore. Editor's note: open science material was validated by the journal of systems and software open science board. © 2022 the author(s)","","","2023","10.1016/j.jss.2022.111518","","","scopus-2-s2.0-85139315300.pdf","scopus-2-s2.0-85139315300"
"Intra-observer reproducibility and diagnostic performance of breast shear-wave elastography in Asian women","Park H. Y., Han K. H., Yoon J. H., Moon H. J., Kim M. J., Kim E. K.","Ultrasound in Medicine & Biology","","Our aim was to evaluate intra-observer reproducibility of shear-wave elastography (SWE) in Asian women. Sixty-four breast masses (24 malignant 40 benign) were examined with SWE in 53 consecutive Asian women (mean age 44.9 y old). Two SWE images were obtained for each of the lesions. The intra-observer reproducibility was assessed by intra-class correlation coefficients (ICC). We also evaluated various clinicoradiologic factors that can influence reproducibility in SWE. The ICC of intra-observer reproducibility was 0.789. In clinicoradiologic factor evaluation masses surrounded by mixed fatty and glandular tissue (ICC: 0.619) showed lower intra-observer reproducibility compared with lesions that were surrounded by glandular tissue alone (ICC: 0.937; p < 0.05). Overall the intra-observer reproducibility of breast SWE was excellent in Asian women. However it may decrease when breast tissue is in a heterogeneous background. Therefore SWE should be performed carefully in these cases. Copyright © 2014 World Federation for Ultrasound in Medicine & Biology. Published by Elsevier Inc. All rights reserved.","","","2014","10.1016/j.ultrasmedbio.2013.12.021","","","medline-24636639.pdf","medline-24636639"
"Unveiling the burden of compassion fatigue in nurses","Tasdemir H. I., Aydin R., Dursun Ergezen F., Tasdemir D., Ergezen Y.","Nursing Ethics","","BACKGROUND: The COVID-19 pandemic has placed an unprecedented burden on nurses who have been at the forefront of patient care. The continuous exposure to suffering death and overwhelming demands has the potential to lead to compassion fatigue a state of emotional physical and cognitive exhaustion.\\\\\\\\rRESEARCH AIM: The study aimed to explore and understand the phenomenon of compassion fatigue in nurses as the effect of the COVID-19 pandemic.\\\\\\\\rRESEARCH DESIGN: A constructivist grounded theory design was used.\\\\\\\\rPARTICIPANTS AND RESEARCH CONTEXT: The research data were collected from 20 nurses who had been employed in pandemic clinics in Turkey for a minimum of 6 months. Data were collected using a two-step approach: purposeful sample selection followed by theoretical sample selection. Individual interviews were conducted via an online platform with participants who consented to participate in the study from January 16th to April 28th 2022. The collected data underwent initial focused and theoretical coding for analysis. The research findings were reported following the Consolidated Criteria for Reporting Qualitative Research guidelines.\\\\\\\\rETHICAL CONSIDERATIONS: Ethical approval for the study was received from Non-Interventional Clinical Research Ethics Committee. The study was conducted following the Declaration of Helsinki.\\\\\\\\rFINDINGS: The study identified a core category namely the desire to provide the best care which was accompanied by five main categories: causes symptoms consequences coping methods and the benefits of coping methods.\\\\\\\\rCONCLUSION: During the pandemic process nurses have experienced compassion fatigue due to various factors and have seen its symptoms. Nurses have developed various coping mechanisms individually. However they have not indicated any institutional-level support. It has become necessary to plan nurse-centered comprehensive interventions that will reduce compassion fatigue.","","","2023","10.1177/09697330231200571","","","medline-37735789.pdf","medline-37735789"
"Reproducibility of maximal exercise test data in the HERITAGE family study","Skinner J. S., Wilmore K. M., Jaskolska A., Jaskolski A., Daw E. W., Rice T., Gagnon J., Leon A. S., Wilmore J. H., Rao D. C., Bouchard C.","Medicine & Science in Sports & Exercise","","PURPOSE: The reproducibility of responses to maximal cycle ergometer testing was determined using data from the HERITAGE Family study at four Clinical Centers in the United States and Canada.\\\\\\\\rMETHODS: Reproducibility was determined from maximal exercise test data obtained a) on 2 d in a sample of 390 subjects (198 men and 192 women) b) across 4 d in an Intracenter Quality Control (ICQC) substudy with 55 subjects who were not part of the main study and c) across 2 wk in a Traveling Crew Quality Control (TCQC) substudy with the same eight subjects who were tested at each of the four centers. Reproducibility was evaluated using technical errors coefficients of variation (CV) for repeated measures and intraclass correlation coefficients (ICC) for selected variables obtained on the main cohort as well as on the ICQC and TCQC substudies.\\\\\\\\rRESULTS: With the exception of systolic and diastolic blood pressures and respiratory exchange ratio all the other variables (heart rate ventilation VO2 and VCO2) were highly reproducible with CV below 10% and ICC over 0.86. These results were similar to those previously reported on the same subjects at a submaximal power output associated with 60% VO2max. Results were consistent for the main cohort the ICQC sample the TCQC sample and across all four Clinical Centers.\\\\\\\\rCONCLUSIONS: Day-to-day variations are small and reproducibility is high for maximal values of heart rate ventilation VO2 and VCO2 at each of the four Clinical Centers of the HERITAGE Family Study.","","","1999","10.1097/00005768-199911000-00020","","","medline-10589867.pdf","medline-10589867"
"User-friendly libraries for active teaching and learning: a case of business, technical and vocational education and training colleges in uganda","Lugya, F.k.","Information And Learning Science","","Purpose: the purpose of this paper is to report the training of college librarians, academic and management staff, it managers and students on how to organise, manage and use a user-friendly library. In uganda, as in many countries, the problem is that school and/or college libraries are managed by librarians who may have good cataloguing and management skills, but who do not have the pedagogic skills and knowledge of the school curricula that are necessary for librarians to be able to guide and mentor both teachers and students or organise curriculum-related activities or facilitate research. The development of user-friendly libraries contributes in improving education quality through nurturing the interest of students and teachers in literacy activities and active search for knowledge. Under the stewardship of the belgium technical cooperation and the ministry of education in uganda, library stakeholders were trained on how to put users – rather than themselves – in the centre of the library’s operations and introduced to active teaching and learning methodologies and activities with emphasis on getting engaged in transforming spaces, services, outreach to users and collections. Several measures, short and long term were taken to address the gaps limiting the performance of the librarians. Given the disparities in the trainees’ education level and work experience, the training was delivered in seven modules divided into three units for over eight months in 2015. By the end of the training, trainees developed unique library strategic plan, library policies and procedures, capacity to use library systems, physical design and maintenance systems, partnerships, library structure and staff job descriptions. Design/methodology/approach: to effectively engage the participants each topic was conducted using active teaching and learning (atl) methodologies, including: lecture with slides and hands-on practice – each topic was introduced in a lecture form with slides and hands-on exercises. The main goal was to introduce the participants to the concepts discussed, offer opportunities to explore alternative approaches, as well define boundaries for discussion through brainstorming. The question-answer approach kept the participants alert and to start thinking critically on the topic discussed – brainstorming sessions allowed thinking beyond the presentation room, drawing from personal experiences to provide alternatives to anticipated challenges. The goal here was for the participants to provide individual choices and approaches for real life problems;  group discussions: case study/ scenario and participant presentations – participants were provided with a scenario and asked to provide alternative approaches that could solve the problem based on their personal experience at their colleges. By the end of the group discussion, participants presented a draft of the deliverable as per the topic under discussion. More so, group discussions were an excellent approach to test participant’s teamwork skills and ability to compromise, as well as respecting team decisions. It was an opportunity to see how librarians will work with the library committees. Group discussions further initiated and cemented the much-needed librarian–academic staff – college management relationship. During the group discussion, librarians, teaching staff, ict staff and college management staff, specifically the principals and deputy principals interacted freely thus starting and cultivating a new era of work relationship between them. Individual presentation: prior to the workshop, participants were sent instructions to prepare a presentation on a topic. For example, participants were asked to provide their views of what a “user-friendly library” would look like or what would constitute a “user-friendly library”;  the college library of htc-mulago was asked to talk about their experience working with book reserves, challenges faced and plans they have to address the challenges, while the college librarian from ntc-kaliro was asked to describe a situation where they were able to assist a patron, the limitations they faced and how they addressed them. Doing so did not only assist to emotionally prepare the participants for the training but also helped to make them start thinking about the training in relation to their libraries and work. Take-home assignment: at the end of each session, participants were given home assignments to not only revise the training material but also prepare for the next day training. Further the take-home assignments provided time for the participants to discuss with their colleagues outside of the training room so as to have a common ground/ understanding on some of the very sensitive issues. Most interesting assignment was when participants were asked to review an article and to make a presentation in relation to their library experiences. Participant reports: participant reports resulted from the take-home assignments and participants were asked to make submission on a given topic. For example, participants were asked to review ifla section on library management and write a two-page report on how such information provided supported their own work, as well as a participant report came from their own observation after a library visit. Invited talks with library expert: two invited talks by library experts from consortium of uganda university libraries and uganda library and information science association with the goal to share their experience, motivate the participants to strive higher and achieve great things for their libraries. Library visitation: there were two library visits conducted on three separate days – international hospital kampala (ihk) library, makerere university library and aga khan university hospital library. Each of these library visits provided unique opportunities for the participants to explore best practices and implement similar practices in their libraries. Visual aids – videos, building plans and still photos: these were visual learning aids to supplement text during the lectures because they carried lot of information while initiating different thoughts best on the participants’ past experience and expertise. The training advocated for the use of atl methodologies and likewise similar methodologies were used to encourage participants do so in their classrooms. Findings: addressing key concerns: several measures, both long and short term, were taken to address the gaps limiting the performance of the librarians. The measures taken included: selected representative sample of participants including all college stakeholders as discussed above;  active teaching and learning methodologies applied in the training and blended in the content of the training materials;  initiated and formulated approaches to collaborations, networks and partnerships;  visited different libraries to benchmark library practices and encourage future job shadowing opportunities;  and encouraged participants to relate freely, understand and value each other’s work to change their mindsets. College librarians were encouraged to ensure library priorities remain on the agenda through advocacy campaigns. Short-term measures: the ufl training was designed as a practical and hands-on training blended with individual and group tasks, discussions, take-home assignments and presentations by participants. This allowed participates to engage with the material and take responsibility for their own work. Further, the training material was prepared with a view that librarians support the academic life of teaching staff and students. Participants were tasked to develop and later fine-tune materials designed to support their work. For example, developing a subject bibliography and posting it on the library website designed using open source tools such as google website, wikis, blogs. The developed library manual includes user-friendly policies and procedures referred to as “dos and don’ts in the library” that promote equitable open access to information;  drafting book selection memos;  new book arrivals lists;  subscribing to open access journals;  current awareness services and selective dissemination of information service displays and electronic bulletins. Based on their library needs and semester calendar, participants developed action points and timelines to implement tasks in their libraries at the end of each unit training. Librarians were encouraged to share their experiences through library websites, facebook page, group e-mail/listserv and instagram;  however, they were challenged with intimate internet access. College libraries were rewarded for their extraordinary job. Given their pivotal role in the management and administration of financial and material resources, on top of librarians, the participants in this training were college administrators/ management, teaching and ict staff, researchers and student leadership. Participants were selected to address the current and future needs of the college library. These are individuals that are perceived to have a great impact towards furthering the college library agenda. The practical nature of this training warranted conducting the workshops from developed but similar library spaces, for example, aga khan university library and kampala capital city, makerere university library, international hospital kampala library and uganda christian university library. Participants observed orientation sessions, reference desk management and interviews, collection management practices, preservation and conservation, secretarial bureau management, etc. Long-term measures: changing the mindset of librarians, college administrators and teaching staff is a long-term commitment which continues to demand for innovative interventions. For example: job shadowing allowed college librarian short-term attachments to makerere university library, uganda christian university library, aga khan hospital university library and international hospital kampala library – these libraries were selected because of their comparable practices and size. The mentorship programme lasted between two-three weeks;  on-spot supervision and follow-up visits to assess progress with the action plan by the librarians and college administration and college library committee;  ensuring that all library documents – library strategic plan, library manual, library organogram, etc are approved by the college governing council and are part of the college wide governing documents;  and establishing the library committee with a job description for each member – this has strengthened the library most especially as an advocacy tool, planning and budgeting mechanism, awareness channel for library practices, while bringing the library to the agenda – reemphasizing the library’s agenda. To bridge the widened gap between librarians and the rest of the stakeholders, i.e. teaching staff, ict staff, college administration and students, a college library committee structure and its mandate were established comprising: library committee chairperson – member of the teaching staff;  library committee secretary – college librarian;  student representative – must be a member of the student guild with library work experience;  and representative from each college academic department. A library consortium was formed involving all the four project supported colleges to participate in resource sharing practices, shared work practices like shared cataloguing, information literacy training, reference interview and referral services as well a platform for sharing experiences. A library consortium further demanded for automating library functions to facilitate collaboration and shared work. Plans are in place to install koha integrated library system that will cultivate a strong working relationship between librarians and students, academic staff, college administration and it managers. This was achieved by ensuring that librarians innovatively implement library practices and skills acquired from the workshop as well as show their relevance to the academic life of the academic staff. Cultivating relationships takes a great deal of time, thus college librarians were coached on: creating inclusive library committees, timely response to user needs, design library programmes that address user needs, keeping with changing technology to suite changing user needs, seeking customer feedback and collecting user statistics to support their requests, strengthening the library’s financial based by starting a secretarial bureau and conducting user surveys to understand users’ information-seeking behaviour. To improve the awareness of new developments in the library world, college librarians were introduced to library networks at national, regional and international levels, as a result they participated in conferences, workshops, seminars at local, regional and international level. For example, for the first time and with funding from belgium technical cooperation, college librarians attended 81st ifla world library and information congress in south african in 2015. College libraries are now members of the consortium of uganda university libraries and uganda library and information science association and have attended meetings of these two very important library organisations in uganda’s lis profession. The college librarians have attended meetings and workshops organized by these two organisations. Originality/value: at the end of the three units training, participants were able to develop: a strategic plan for their libraries;  an organogram with staffing needs and job description matching staff functions;  a library committee for each library and with a structure unifying all the four project-support colleges;  a library action plan with due dates including deliverables and responsibilities for implementation;  workflow plan and organisation of key sections of the library such as reserved and public spaces;  furniture and equipment inventory (assets);  a library manual and collection development policy;  partnerships with kcca library and consortium of uganda university libraries;  skills to use koha ilms for performing library functions including: cataloguing, circulation, acquisitions, serials management, reporting and statistics;  skills in searching library databases and information literacy skills;  skills in designing simple and intuitive websites using google sites tools;  and improved working relationship between the stakeholders was visible. To further the user-friendly libraries principle of putting users in the centre of the library’s operations, support atl methodologies and activities with emphasis on getting engaged in transforming spaces, services, outreach to users and collections the following initiatives are currently implemented in the colleges: getting approval of all library policy documents by college governing. © 2018, emerald publishing limited.","","","2018","10.1108/ils-07-2017-0073","","","scopus-2-s2.0-85049497498.pdf","scopus-2-s2.0-85049497498"
"'Science is only half of it': Expert perspectives on operationalising infectious disease control cooperation in the ASEAN region","Durrance-Bagale A., Marzouk M., Ananthakrishnan A., Nagashima-Hayashi M., Lam S. T., Sittimart M., Howard N.","PLOS Global Public Health","","Governmental awareness of the potential spread of infectious disease exemplified by the current Covid-19 pandemic ideally results in collective action as countries coordinate a response that benefits all contributing expertise resources knowledge and experience to achieve a common public good. However operationalising regional cooperation is difficult with barriers including lack of political will regional heterogeneity and existing geopolitical issues. We interviewed 23 people with regional expertise focusing on Asia Africa the Americas and Europe. All interviewees held senior positions in regional bodies or networks or had significant experience working with them. Operationalisation of a regional infectious disease body is complex but areas interviewees highlighted-organisational factors (e.g. integration and harmonisation; cross-border issues; funding financing and sustainability; capacity-building; data sharing); governance and diplomacy (e.g. building collaborations and partnerships; communication; role of communities; diplomacy; leadership; ownership; sovereignty; political commitment); and stakeholders and multilateral agreements-will help promote successful operationalisation. The international infectious disease community has learned valuable lessons from the Covid-19 pandemic not least the necessity of pooling human financial and technological resources constructing positive working relationships with neighbours and sharing data. Without this kind of regional cooperation infectious diseases will continue to threaten our future and the next pandemic may have even more far-reaching effects. Copyright: © 2022 Durrance-Bagale et al. This is an open access article distributed under the terms of the Creative Commons Attribution License which permits unrestricted use distribution and reproduction in any medium provided the original author and source are credited.","","","2022","10.1371/journal.pgph.0000424","","","medline-36962233.pdf","medline-36962233"
"Forecast evaluation with shared data sets","Sullivan, R. And Timmermann, A. And White, H.","International Journal Of Forecasting","","Data sharing is common practice in forecasting experiments in situations where fresh data samples are difficult or expensive to generate. This means that forecasters often analyze the same data set using a host of different models and sets of explanatory variables. This practice introduces statistical dependencies across forecasting studies that can severely distort statistical inference. Here we examine a new and inexpensive recursive bootstrap procedure that allows forecasters to account explicitly for these dependencies. The procedure allows forecasters to merge empirical evidence and draw inference in the light of previously accumulated results. In an empirical example, we merge results from predictions of daily stock prices based on (1) technical trading rules and (2) calendar rules, demonstrating both the significance of problems arising from data sharing and the simplicity of accounting for data sharing using these new methods. © 2001 international institute of forecasters. Published by elsevier science b.v. All rights reserved.","","","2003","10.1016/s0169-2070(01)00140-6","","","scopus-2-s2.0-1842680450.pdf","scopus-2-s2.0-1842680450"
"An empirical study of c++ vulnerabilities in crowd-sourced code examples","Verdi, M. And Sami, A. And Akhondali, J. And Khomh, F. And Uddin, G. And Motlagh, A.k.","Ieee Transactions On Software Engineering","","Software developers share programming solutions in q&a sites like stack overflow, stack exchange, android forum, and so on. The reuse of crowd-sourced code snippets can facilitate rapid prototyping. However, recent research shows that the shared code snippets may be of low quality and can even contain vulnerabilities. This paper aims to understand the nature and the prevalence of security vulnerabilities in crowd-sourced code examples. To achieve this goal, we investigate security vulnerabilities in the c++ code snippets shared on stack overflow over a period of 10 years. In collaborative sessions involving multiple human coders, we manually assessed each code snippet for security vulnerabilities following cwe (common weakness enumeration) guidelines. From the 72,483 reviewed code snippets used in at least one project hosted on github, we found a total of 99 vulnerable code snippets categorized into 31 types. Many of the investigated code snippets are still not corrected on stack overflow. The 99 vulnerable code snippets found in stack overflow were reused in a total of 2859 github projects. To help improve the quality of code snippets shared on stack overflow, we developed a browser extension that allows stack overflow users to be notified for vulnerabilities in code snippets when they see them on the platform. © 1976-2012 ieee.","","","2022","10.1109/tse.2020.3023664","","","scopus-2-s2.0-85130830573.pdf","scopus-2-s2.0-85130830573"
"Isolation and extraction of microplastics from environmental samples: an evaluation of practical approaches and recommendations for further harmonization","Lusher, A.l. And Munno, K. And Hermabessiere, L. And Carr, S.","Applied Spectroscopy","","Researchers have been identifying microplastics in environmental samples dating back to the 1970s. Today, microplastics are a recognized environmental pollutant attracting a large amount of public and government attention, and in the last few years the number of scientific publications has grown exponentially. An underlying theme within this research field is to achieve a consensus for adopting a set of appropriate procedures to accurately identify and quantify microplastics within diverse matrices. These methods should then be harmonized to produce quantifiable data that is reproducible and comparable around the world. In addition, clear and concise guidelines for standard analytical protocols should be made available to researchers. In keeping with the theme of this special issue, the goals of this focal point review are to provide researchers with an overview of approaches to isolate and extract microplastics from different matrices, highlight associated methodological constraints and the necessary steps for conducting procedural controls and quality assurance. Simple samples, including water and sediments with low organic content, can be filtered and sieved. Stepwise procedures require density separation or digestion before filtration. Finally, complex matrices require more extensive steps with both digestion and density adjustments to assist plastic isolation. Implementing appropriate methods with a harmonized approach from sample collection to data analysis will allow comparisons across the research community. © the author(s) 2020.","","","2020","10.1177/0003702820938993","","","scopus-2-s2.0-85091206406.pdf","scopus-2-s2.0-85091206406"
"Portuguese authorship in published clinical trials: differences in industry and investigator initiated trials","Pinheiro Andrade, M. And Matias, D. And Batuca, J. And Gouveia, N. And Mota-Filipe, H. And Carreira Monteiro, E. And Madeira, C.","Acta Medica Portuguesa","","Introduction: the aim of this study was to investigate the portuguese authorship in publications resulting from trials initiated by the industry or investigators and run in portugal. Material and methods: clinical trials with portuguese institutions as sponsor or recruiting centers, and registered in four clinical trial registries, in the last 14 years, were assessed. Publications of completed trials, from both the initiative of the industry and investigators were screened and compared. Results: the percentage of published trials initiated by industry and investigators was similar (28.0%). However, the percentage of completed investigator-initiated trials (43.6%) was lower when compared to industry trials (69.7%). There was a higher percentage of portuguese authorship in published investigator-initiated trials when compared with industry-initiated trials (47.1% vs 8.5%, respectively). Moreover, industry-initiated trials with portuguese authors were published in journals with lower journal impact factor when compared with those published without authorship of portuguese investigators. Oncology was the therapeutic area with the highest number of clinical trial registrations and publications. However, in publications with portuguese authors, industry initiated trials mainly focused on neurology while investigator-initiated trials had a higher number of papers in the fields of gastroenterology and infection diseases. Published trials with portuguese authorship, initiated by the industry or investigators, also targeted different populations and had different purposes. In both cases, no significant differences were observed in terms of the journal impact factor or in the alignment of the published randomized trials with the respective reporting guidelines. Discussion: when compared with previous publications, this study showed an increasing trend in the number of clinical trials in portugal, published within similar timeframes, after trial conclusion. Even though both industry and investigator trials are published within the standards for reporting trials, the low number of portuguese authorships in industry publications might underline the need for invigorating these independent clinical trials in portugal by capacitating and empowering national clinical research teams. Conclusion: this study confirmed that even though all registered trials had the involvement of portuguese institutions as a recruiting center, not all the published trials had portuguese investigators as authors, mainly those initiated by the industry. © 2021 celom. All rights reserved.","","","2021","10.20344/amp.14554","","","scopus-2-s2.0-85119040093.pdf","scopus-2-s2.0-85119040093"
"Addressing the Challenges of Conducting Research in Developing Countries","Amerson R. M., Strang C. W.","Journal of Nursing Scholarship","","PURPOSE: To explore the unique challenges that occur when conducting research in developing countries so the reader can consider approaches for providing ethically and culturally appropriate research strategies applicable for the context of the host country.\\\\\\\\rORGANIZING CONSTRUCT: This article presents an overview of the challenges which are organized based on the phases of the research period: pre-enrollment enrollment and post-enrollment. At each stage examples of adaptation to meet the challenges are presented and recommendations are posited.\\\\\\\\rCONCLUSIONS: Strategies for research should protect the rights of the most vulnerable and disadvantaged populations while balancing the needs of society at large provide culturally relevant ethical informed consent while balancing institutional review board requirements and conduct research in a culturally appropriate manner for the host country while balancing the principles of ethical research established by developed countries.\\\\\\\\rCLINICAL RELEVANCE: Researchers are implored to focus on the ethical and cultural appropriateness of each aspect of the study process to afford the highest level of research credibility and validity. Copyright © 2015 Sigma Theta Tau International.","","","2015","10.1111/jnu.12171","","","medline-26444697.pdf","medline-26444697"
"‘Help us better understand our changing climate’: exploring the discourse of citizen science","Pérez-Llantada, C.","Discourse And Communication","","In this article i claim that online citizen science projects are exemplars of a digital genre that acts as text and medium. To support this claim i apply a previously proposed two-dimensional genre analytical model and develop empirical procedures to identify how ‘communicative purpose’ is realised by functional units/links, which in turn are realised by rhetorical strategies (verbal and visual) in two dimensions, the reading mode and the navigation mode. Empirical data show that this genre fulfils a set of distinct communicative purposes, namely to build credibility and trust in scientific research, to make specialised contents accessible to audiences with different levels of scientific literacy, to convey emotion and to build and maintain citizen-volunteers’ engagement. Such multifunctionality fulfils the social exigence of the genre, that is, supporting participatory science. The study contributes to the empirical characterisation of non-linear, multimodal genres taking into account the roles of text producer and text receiver. © the author(s) 2023.","","","2023","10.1177/17504813231158927","","","scopus-2-s2.0-85151073819.pdf","scopus-2-s2.0-85151073819"
"Differential privacy based on data provenance publishing method","Ni, W.-W. And Shen, T. And Yan, D.","Jisuanji Xuebao/Chinese Journal Of Computers","","Data provenance describes the mechanism and process of data generation and evolution, which records information about the node module executions used to produce concrete data items, as well as those intermediate data items acting as parameters passed between nodes' executions. Data provenance plays an important role in research and applications of data quality assessment, data recovery and data analysis. With increasingly deepening of data sharing, the need for publishing and sharing workflow of provenance, which is the main representation structure of data provenance, becomes increasingly urgent. However, the provenance workflow often contains private or confidential data. For instance, the node modules included in the provenance workflow, as well as the temporal relations among those nodes, may involve the privacy of the data owner. Direct release of provenance workflow will inevitably bring privacy protection issues. Privacy-preserving data provenance publication becomes an urgent problem to be solved. That is to say, the utility of published provenance workflow needs well maintaining under the premise that data privacy should not be disclosed. The existing research mainly focuses on the maintenance of the local mapping relationship of provenance workflow. For example, privacy protection process is implemented to the provenance workflow, which ensures that the degree of a single node would not be leaked, or sensitive mapping relationship would not be leaked in parallel with effective maintaining of provenance workflow's overall input and output mapping relations. For another important manifestation of provenance workflow's utility, i.e. temporal dependence among those front and corresponding back task nodes of the provenance workflow, the maintenance effect is relatively poor. As for the privacy of adjacent nodes distribution in the provenance workflow, the protection ability of existing methods is also far insufficient. To solve the above problems, the definition of input and output degree sequence with scale i model is introduced to describe the degree distribution of provenance workflow nodes. It provides a carrier for describing the utility and privacy-sensitive information of provenance workflow. As a by-product, it can also accommodate the extraction of directional characteristics of the provenance workflow well. The definition of previous-next sequence is further devised to describe the substructure distribution characteristics of the workflow. This structure can reduce the possible loss of workflow's temporal relations in adding differential noise. By constructing schema of previous-next sequence, the substructure characteristics of those nodes and their adjacent nodes in workflow are captured, and the temporal constraints in workflow are maintained during the reconstruction process. On this basis, a differential privacy-based on privacy-preserving provenance workflow publishing method dpripp is proposed to implement a weak background knowledge-dependent privacy-preserving provenance workflow publication, it can also provide well maintenance to temporal dependance relations of the provenance workflow. Targeted experiments are designed to verify the effectiveness and privacy protection effect of our proposal. The theoretical analysis and experimental results demonstrate that the proposed algorithm can effectively maintain both the local and global temporal dependence relations of nodes in the workflow, while protecting the directional distribution privacy of the locally adjacent nodes in the provenance workflow well. © 2020, science press. All right reserved.","","","2020","10.11897/sp.j.1016.2020.00573","","","scopus-2-s2.0-85083763182.pdf","scopus-2-s2.0-85083763182"
"The future of Cochrane Neonatal","Soll R. F., Ovelman C., McGuire W.","Early Human Development","","Cochrane Neonatal was first established in 1993 as one of the original review groups of the Cochrane Collaboration. In fact the origins of Cochrane Neonatal precede the establishment of the collaboration. In the 1980's the National Perinatal Epidemiology Unit at Oxford led by Dr. Iain Chalmers established the ""Oxford Database of Perinatal Trials"" (ODPT) a register of virtually all randomized controlled trials in perinatal medicine to provide a resource for reviews of the safety and efficacy of interventions used in perinatal care and to foster cooperative and coordinated research efforts in the perinatal field [1]. An effort that was clearly ahead of its time ODPT comprised four main elements: a register of published reports of trials; a register of unpublished trials; a register of ongoing and planned trials; and data derived from pooled overviews (meta-analyses) of trials. This core effort grew into the creation of the seminal books ""Effective Care in Pregnancy and Childbirth"" as well as ""Effective Care of the Newborn Infant"" [23]. As these efforts in perinatal medicine grew Iain Chalmers thought well beyond perinatal medicine into the creation of a worldwide collaboration that became Cochrane [4]. The mission of the Cochrane Collaboration is to promote evidence-informed health decision-making by producing high-quality relevant accessible systematic reviews and other synthesized research evidence (www.cochrane.org). Cochrane Neonatal has continued to be one of the most productive review groups publishing between 25 tpo to 40 new or updated systematic reviews each year. The impact factor has been steadily increasing over four years and now rivals most of the elite journals in pediatric medicine. Cochrane Neonatal has been a worldwide effort. Currently there are 404 reviews involving 1206 authors from 52 countries. What has Cochrane done for babies? Reviews from Cochrane Neonatal have informed guidelines and recommendations worldwide. From January 2018 through June 2020 77 international guidelines cited 221 Cochrane Neonatal reviews. These recommendations have included recommendations of the use of postnatal steroids inhaled nitric oxide feeding guidelines for preterm infants and other core aspects of neonatal practice. In addition Cochrane Reviews has been the impetus for important research including the large-scale trial of prophylactic indomethacin therapy a variety of trials of postnatal steroids trials of emollient ointment and probiotic trials [6]. While justifiably proud of these accomplishments one needs to examine the future contribution of Cochrane Neonatal to the neonatal community. The future of Cochrane Neonatal is inexorably linked to the future of neonatal research. Obviously there is no synthesis of trials data if as a community we fail to provide the core substrate for that research. As we look at the current trials' environment fewer randomized controlled trial related to neonates are being published in recent years. A simple search of PubMed limiting the search to ""neonates"" and ""randomized controlled trials"" shows that in the year 2000 321 randomized controlled trials were published. These peaked five years ago in 2015 with close to 900 trials being published. However in 2018 only 791 studies are identified. Does this decrease represent a meaningful change in the neonatal research environment? Quite possibly. There are shifting missions of clinical neonatology at academic medical institutions at least in the United States with a focus on business aspects as well as other important competing clinical activities. Quality improvement has taken over as one of the major activities at both private and academic neonatal practices. Clearly this is a needed improvement. All units at levels need to be dedicated to improving the outcomes of the sick and fragile population we care for. However this need not be at the expense of formal clinical trials. It is understandable that this approach would be taken. Newer interventions frequently relate to complex systems of care a","","","2020","10.1016/j.earlhumdev.2020.105191","","","medline-33036834.pdf","medline-33036834"
"Large, open datasets for human connectomics research: considerations for reproducible and responsible data use","Laird A.r.","Neuroimage","","Large, open datasets have emerged as important resources in the field of human connectomics. In this review, the evolution of data sharing involving magnetic resonance imaging is described. A summary of the challenges and progress in conducting reproducible data analyses is provided, including description of recent progress made in the development of community guidelines and recommendations, software and data management tools, and initiatives to enhance training and education. Finally, this review concludes with a discussion of ethical conduct relevant to analyses of large, open datasets and a researcher's responsibility to prevent further stigmatization of historically marginalized racial and ethnic groups. Moving forward, future work should include an enhanced emphasis on the social determinants of health, which may further contextualize findings among diverse population-based samples. Leveraging the progress to date and guided by interdisciplinary collaborations, the future of connectomics promises to be an impressive era of innovative research, yielding a more inclusive understanding of brain structure and function.copyright © 2021","","","2021","10.1016/j.neuroimage.2021.118579","","","embase-2014616454.pdf","embase-2014616454"
"Demand driven replication research: an overview of financial services for the poor replication research","Wood, B.d.k. And Mutemi, A. And Gaarder, M.m.","Journal Of Development Effectiveness","","Spurred on by the ‘reproducibility crisis’, social scientists are starting to adopt research transparency practices. Research funders are largely unaware that replication work could strengthen the reliability, rigour, and relevance of their investments. The gates foundation commissioned the international initiative for impact evaluation (3ie) to award and quality assure the strongest financial services for the poor evidence. By working with the gates foundation to identify the studies, screen the applicants, and quality assure the seven replication research, 3ie ensured policy relevant papers. By publishing this special issue, 3ie is ensuring that the replication research is appreciated by the development community. © 2019, © 2019 informa uk limited, trading as taylor & francis group.","","","2019","10.1080/19439342.2019.1696871","","","scopus-2-s2.0-85076455061.pdf","scopus-2-s2.0-85076455061"
"Realist evaluation of social and behaviour change interventions: co-building theory and evidence of impact","Igras, S. And Diakité, M. And Kohli, A. And Fogliani, C.","African Evaluation Journal","","Background: a complexity-aware approach, realist evaluation is ideal for norms-shifting interventions (nsis), which are not well-understood but gaining prominence in behaviour change programming in africa and globally to foster enabling socionormative environments that sustain behaviour change. A new application of realist evaluation to nsis uses an adapted approach employing realism values that is suitable for social and behaviour change (sbc) programme evaluation more generally. Objectives: this article shares the authors’ reflections on tailoring realist evaluation approaches for use with community-based norms-shifting programmes. It describes how realist evaluation enables co-building of programme theory that conceptually underpins nsis, guides evaluation efforts and yields benefits beyond theory-proving. Method: two nsis in niger and senegal illustrate how locally refined theories of change (toc) and identification of evidence gaps in causal pathways guided a series of rapid programme and quasi-experimental outcome studies. Over two years externally and internally led studies assessed intermediate or mediating norms-shifting effects and outcomes comprising the realist evaluation. Studies drew from experiential, existing and new data. Results: the tailored approach created a co-owned evaluation, from joint exploration of sbc theory to review of evidence generation. Five values applied to the research–practice partnerships reinforced a realist perspective: participatory, complexity, shared ownership, practice-oriented and valuing all forms of data. Conclusion: bounded by toc exploration for programme inquiry, realist evaluation embeds learning and assessment concretely into local programming and knowledge building. Integrating evaluation practice with realism values creates a nexus and a unique and significant dynamic between programme implementers and evaluators that transcends nsi research and programme practice © 2022. The authors. Licensee: aosis. This work is licensed under the creative commons attribution license","","","2022","10.4102/aej.v10i1.657","","","scopus-2-s2.0-85147687838.pdf","scopus-2-s2.0-85147687838"
"Multiscale electrophysiology format: an open-source electrophysiology format using data compression encryption and cyclic redundancy check","Brinkmann B. H., Bower M. R., Stengel K. A., Worrell G. A., Stead M.","Annual International Conference Of The IEEE Engineering In Medicine And Biology Society","","Continuous long-term (up to 10 days) electrophysiological monitoring using hybrid intracranial electrodes is an emerging tool for presurgical epilepsy evaluation and fundamental investigations of seizure generation. Detection of high-frequency oscillations and microseizures could provide valuable insights into causes and therapies for the treatment of epilepsy but requires high spatial and temporal resolution. Our group is currently using hybrid arrays composed of up to 320 micro- and clinical macroelectrode arrays sampled at 32 kHz per channel with 18-bits of A/D resolution. Such recordings produce approximately 3 terabytes of data per day. Existing file formats have limited data compression capabilities and do not offer mechanisms for protecting patient identifying information or detecting data corruption during transmission or storage. We present a novel file format that employs range encoding to provide a high degree of data compression a three-tiered 128-bit encryption system for patient information and data security and a 32-bit cyclic redundancy check to verify the integrity of compressed data blocks. Open-source software to read write and process these files are provided.","","","2009","10.1109/iembs.2009.5332915","","","medline-19963940.pdf","medline-19963940"
"Rejoinder: editorial policies regarding statistical significance tests: further comments","Thompson, B.","Educational Researcher","","In this response to robinson and levin's comments on thompson (1996), it is argued that describing results as ""significant"" rather than ""statistically significant"" is confusing to those persons most susceptible to misinterpreting this telegraphic wording. Contrary to robinson and levin's view, it is noted that the utility of the characterization of results as being due to ""nonchance"" is limited by the nature of the null hypothesis assumed to be true. It is suggested that effect sizes are important to interpret, even though they too can be misinterpreted;  recent empirical studies of publications indicate that effect sizes are still too rarely reported. Finally, the value of ""external"" replicability analyses is acknowledged, but it is argued that ""internal"" replicability analyses can also be useful, and certainly are superior to statistical significance tests regarding evaluating result replicability, because statistical significance tests do not evaluate replicability.","","","1997","10.3102/0013189x026005029","","","scopus-unknown-accession-7274368.pdf","scopus-unknown-accession-7274368"
"Two database systems for the access to materials data and for their statistical analysis","Dathe, Gert","Sampe Journal","","The impact of the availability of materials data on economy and innovation and recommendations for the implementation of a materials data system are pointed out. Two operational database systems for standard values and test values, respectively are described. Examples are given for the selection of materials, for the output of properties of selected materials, and for the evaluation of test values. Those examples concern but are not limited to properties of iron and steel. Some problems of standard data and possibilities for their solution are given. Those problems are the structural complexity of standards, the different scales of ranges, influencing parameters, different test methods and units. Available information products and online services are mentioned.","","","1984","","","","scopus-2-s2.0-0021526969.pdf","scopus-2-s2.0-0021526969"
"Integrating transactions into the data-driven multi-threading model using the tflux platform","Diavastos, A. And Trancoso, P. And Luján, M. And Watson, I.","International Journal Of Parallel Programming","","The introduction of multi-core processors has renewed the interest in programming models which can efficiently exploit general purpose parallelism. Data-flow is one such model which has demonstrated significant potential in the past. However, it is generally associated with functional styles of programming which do not deal well with shared mutable state. There have been a number of attempts to introduce state into data-flow models and functional languages but none have proved able to maintain the simplicity and efficiency of pure data-flow parallelism. Transactional memory is a concurrency control mechanism that simplifies sharing data when developing parallel applications while at the same time promises to deliver affordable performance. In this paper we report our experience of integrating transactional memory and data-flow within the tflux platform. The ability of the data-flow model to expose large amounts of parallelism is maintained while transactional memory provides simplified sharing of mutable data in those circumstances where it is important to the expression of the program. The isolation property of transactions ensures that the exploitation of data-flow parallelism is not compromised. In this study we extend the tflux platform, a data-driven multi-threading implementation, to support transactions. We achieve this by proposing new pragmas that allow the programmer to specify transactions. In addition we extend the runtime functionality by integrating a software transactional memory library with tflux. To test the proposed system, we ported two applications that require transactional memory: random counter and labyrinth an implementation of lee’s parallel routing algorithm. Our results show good opportunities for scaling when using the integration of the two models. © 2015, springer science+business media new york.","","","2016","10.1007/s10766-015-0369-2","","","scopus-2-s2.0-84931418090.pdf","scopus-2-s2.0-84931418090"
"Public private collaboration model in spatial data infrastructure: potential elements","Othman, R.b. And Mahamud, K.r.b.k. And Bakar, M.s.b.a.","International Journal Of Supply Chain Management","","The rapid development of geospatial technology locally and globally spurs the development of spatial data infrastructure (sdi), mainly developed to help managing the growth of spatial data. Although the use of spatial data is reported as 'vast growth', sdi initiative is still reported to be below maturity due to low quality of data in terms of completeness and consistency, nonexistence of custodian policy and information sharing act, and poor human capacity. These affected the full potential of spatial data as the main source to be used in development and decision-making activities. The availability of business centric data at the private sector further encourages the effort to collaborate these entities to gauge the full potential of sdi initiative. A conceptual model is proposed to solve issues in public-private collaboration in spatial data infrastructure. The conclusion on exposure, acceptance, and spatial data sharing is based on the analysis of the outcome from the interview with seven entities related to spatial data infrastructure initiative. The outcome indicates that though the use is high, effectiveness of the geospatial technology is reported low due to the quality and heterogeneous data. Furthermore, the potential elements for collaborating public and private entities are proposed to optimise the utilisation of geospatial information, and create the synergy to spur the growth, hence sustaining the sdi initiative. © excelingtech pub, uk.","","","2017","","","","scopus-2-s2.0-85030527358.pdf","scopus-2-s2.0-85030527358"
"Long-term retention and separation reproducibility for analytical scale fused-core® columns","Mchale, C. And Funk, C. And Libert, B.p. And Soliven, A. And Schuster, S.a.","Chromatographia","","We present the long-term retention and separation data reproducibility between 2013 and 2020 for analytical scale (4.6 mm internal diameter) superficially porous particle (spp) columns. The retention factor for a small molecule—naphthalene—separated on 60 randomized manufactured lots, resulted in a 1.04% rsd;  for a large molecule—bovine ribonuclease—separated on 31 randomized lots, 1.16% rsd. The peak shapes for three lots within this 7-year period were overlaid to visualize the chromatographic profile reproducibility. Naphthalene’s tailing factor had a % rsd of 4.42 and bovine ribonuclease’s peak width had an % rsd of 2.94;  these metrics are sensitive to variability of the total error contribution of the column and system. A small and a large molecule application demonstrated reproducibility using three spp manufactured lots packed in a narrow bore 2.1 mm i.d. analytical scale format. 15 peaks of the small molecule study resulted with a retention time %rsd reproducibility of ≤ 0.32, and for the large molecule study ≤ 1.12. The information in this study and the detailed discussion of the variability associated to different separation metrics is critical for industries that use hplc and must adhere to stringent regulatory specifications, e.g., pharmaceutical, food and beverage industry. © 2021, the author(s), under exclusive licence to springer-verlag gmbh germany, part of springer nature.","","","2021","10.1007/s10337-021-04050-x","","","scopus-2-s2.0-85107155194.pdf","scopus-2-s2.0-85107155194"
"Internet-based monitoring of asthma symptoms peak flow meter readings and absence data in a school-based clinical trial","McClure L. A., Harrington K. F., Graham H., Gerald L. B.","Clinical Trials","","BACKGROUND: Asthma is the most common chronic childhood disease and has significant impact on morbidity and mortality in children. Proper adherence to asthma medication has been shown to reduce morbidity among those with asthma; however adherence to medications is known to be low especially among low-income urban populations. We conducted a randomized clinical trial to examine the effectiveness of an intervention designed to increase adherence to asthma medication among children with asthma that required daily collection of data.\\\\\\\\rPURPOSE: and\\\\\\\\rMETHODS: A specifically designed web-based data collection system the Asthma Agents System was used to collect daily data from participant children at school. These data were utilized to examine the intervention's effectiveness in reducing the frequency of asthma exacerbations. This study examines the Asthma Agents System's effect on the frequency of missing data. Data collection methods are discussed in detail as well as the processes for retrieving missing data.\\\\\\\\rRESULTS: For the 290 children randomized 97% of the daily data expected were available. Of the outcome data retrieved via the Asthma Agents System 5% of those expected were missing during the period examined.\\\\\\\\rLIMITATIONS: Challenges encountered in this study include issues regarding the use of technology in urban school settings transfer of data between study sites and availability of data during school breaks.\\\\\\\\rCONCLUSIONS: Use of the Asthma Agents System resulted in lower rates of missing data than rates reported elsewhere in the literature. Clinical Trials 2008; 5: 31-37. http://ctj.sagepub.com.","","","2008","10.1177/1740774507086647","","","medline-18283077.pdf","medline-18283077"
"Requirements for sharing process data in the life cycle of process plants","Yang, X. And Mcgreavy, C.","Computers And Chemical Engineering","","This paper addresses the issues related to the practice of modelling process data for computer aided concurrent engineering (cage) environment in the context of the development of a step (the standard for the exchange of product model data) application protocol (ap). The requirements for the process data over the life cycle of process plant are identified and emphasise sharability, reusability, and interoperability of data models. The approach follows the epistle (european process industries step technical liaison executive) framework and core model to develop a process data model. Subsequent analysis provides a basis for evaluation of the benefits of such models in which some extensions suggest to the epistle data modelling methodology.","","","1996","10.1016/0098-1354(96)00071-3","","","scopus-2-s2.0-0029719730.pdf","scopus-2-s2.0-0029719730"
"Implementing next generation privacy and ethics research in education technology","Marshall, R. And Pardo, A. And Smith, D. And Watson, T.","British Journal Of Educational Technology","","For the developers of next-generation education technology (edtech), the use of learning analytics (la) is a key competitive advantage as the use of some form of la in edtech is fast becoming ubiquitous. At its core la involves the use of artificial intelligence and analytics on the data generated by technology-mediated learning to gain insights into how students learn, especially for large cohorts, which was unthinkable only a few decades ago. This la growth-spurt coincides with a growing global “ethical ai” movement focussed on resolving questions of personal agency, freedoms, and privacy in relation to ai and analytics. At this time, there is a significant lack of actionable information and supporting technologies, which would enable the goals of these two communities to be aligned. This paper describes a collaborative research project that seeks to overcome the technical and procedural challenges of running a data-driven collaborative research project within an agreed set of privacy and ethics boundaries. The result is a reference architecture for ethical research collaboration and a framework, or roadmap, for privacy-preserving analytics which will contribute to the goals of an ethical application of learning analytics methods. Practitioner notes what is already known about this topic privacy enhancing technologies, including a range of provable privacy risk reduction techniques (differential privacy) are effective tools for managing data privacy, though currently only pragmatically available to well-funded early adopters. Learning analytics is a relatively young but evolving field of research, which is beginning to deliver tangible insights and value to the education and edtech industries. A small number of procedural frameworks have been developed in the past two decades to consider data privacy and other ethical aspects of learning analytics. What this paper adds this paper describes the mechanisms for integrating learning analytics, data privacy technologies and ethical practices into a unified operational framework for ethical and privacy-preserving learning analytics. It introduces a new standardised measurement of privacy risk as a key mechanism for operationalising and automating data privacy controls within the traditional data pipeline;  it describes a repeatable framework for conducting ethical learning analytics. Implications for practice and/or policy for the learning analytics (la) and education technology communities the approach described here exemplifies a standard of ethical la practice and data privacy protection which can and should become the norm. The privacy risk measurement and risk reduction tools are a blueprint for how data privacy and ethics can be operationalised and automated. The incorporation of a standardised privacy risk evaluation metric can help to define clear and measurable terms for inter- and intra-organisational data sharing and usage policies and agreements (author, ruth marshall, is an expert contributor on iso/iec jtc 1/sc 32/wg 6 ""data usage"", due for publication in early 2022). © 2022 british educational research association.","","","2022","10.1111/bjet.13224","","","scopus-2-s2.0-85128890808.pdf","scopus-2-s2.0-85128890808"
"Diagnosis of the most frequent benign ovarian cysts: is ultrasonography accurate and reproducible?","Guerriero S., Alcazar J. L., Pascual M. A., Ajossa S., Gerada M., Bargellini R., Virgilio B., Melis G. B.","Journal of Women's Health","","OBJECTIVE: To evaluate the reproducibility and the accuracy of B-mode ultrasonographic features of three different kinds of benign ovarian cysts: ovarian endometrioma mature teratoma and serous cyst.\\\\\\\\rMETHODS: Digitally stored B-mode sonographic images of 98 women submitted to surgery for the presence of an adnexal mass were evaluated by five different examiners with different degrees of experience. The histological type of each mass was predicted on the basis of the B-mode typical benign findings as in the case of endometrioma (groundglass endocystic pattern) cystic teratoma (echogenic pattern with or without acoustic shadow) and serous cyst (anechoic cyst without endocystic vegetations). To assess the reproducibility of the B-mode findings intraobserver and interobserver agreements were calculated using the kappa index.\\\\\\\\rRESULTS: The intraobserver agreement was good or very good for all examiners and for all patterns (kappa = 0.71-1) except for the dermoid cyst which showed moderate agreement (kappa = 0.42) for the highly experienced operator. The interobserver agreement was good for all experts for endometrioma (kappa = 0.66-0.78) and for serous cyst (kappa = 0.82-1) whereas it was moderate or good for cystic teratoma (kappa = 0.51-0.72). Interobserver agreement between experts and highly experienced operators was fair (kappa = 0.33-0.36) for teratoma and good or very good for endometrioma (kappa = 0.70-0.83) and serous cyst (kappa = 0.76-0.82). For different kinds of cysts the accuracy was comparable among different operators.\\\\\\\\rCONCLUSIONS: Typical features of benign masses using grayscale transvaginal ultrasonography are reproducible even in moderately experienced examiners although more experience was associated with better interobserver agreement. The diagnostic performance of different operators with different degrees of experience is similar.","","","2009","10.1089/jwh.2008.0997","","","medline-19361320.pdf","medline-19361320"
"Federated electronic data capture (fEDC): Architecture and prototype","Ganzinger M., Blumenstock M., Furstberger A., Greulich L., Kestler H. A., Marschollek M., Niklas C., Schneider T., Spreckelsen C., Tute E., Varghese J., Dugas M.","Journal of Biomedical Informatics","","In clinical research as well as patient care structured documentation of findings is an important task. In many cases this is achieved by means of electronic case report forms (eCRF) using corresponding information technology systems. To avoid double data entry eCRF systems can be integrated with electronic health records (EHR). However when researchers from different institutions collaborate in collecting data they often use a single joint eCRF system on the Internet. In this case integration with EHR systems is not possible in most cases due to information security and data protection restrictions. To overcome this shortcoming we propose a novel architecture for a federated electronic data capture system (fEDC). Four key requirements were identified for fEDC: Definitions of forms have to be available in a reliable and controlled fashion integration with electronic health record systems must be possible patient data should be under full local control until they are explicitly transferred for joint analysis and the system must support data sharing principles accepted by the scientific community for both data model and data captured. With our approach sites participating in a joint study can run their own instance of an fEDC system that complies with local standards (such as being behind a network firewall) while also being able to benefit from using identical form definitions by sharing metadata in the Operational Data Model (ODM) format published by the Clinical Data Interchange Standards Consortium (CDISC) throughout the collaboration. The fEDC architecture was validated with a working open-source prototype at five German university hospitals. The fEDC architecture provides a novel approach with the potential to significantly improve collaborative data capture: Efforts for data entry are reduced and at the same time data quality is increased since barriers for integrating with local electronic health record systems are lowered. Further metadata are shared and patient privacy is ensured at a high level. Copyright © 2023 Elsevier Inc. All rights reserved.","","","2023","10.1016/j.jbi.2023.104280","","","medline-36623781.pdf","medline-36623781"
"The formation of concern for face and its impact on knowledge sharing intention in knowledge management systems","Young, M.-L.","Knowledge Management Research And Practice","","Previous empirical studies have shown that in chinese culture face is critical for the success of knowledge sharing in knowledge management systems (kms). However, much less is known about the factors shaping the concern for face and the way they impact on the individual's knowledge sharing intention in kms. Using data drawn from professionals' knowledge sharing practices in taiwanese organizations, this study focuses on a detailed investigation of the concern for face and how it impedes individuals' knowledge sharing intention in the kms context. The research findings show that the perfection of authentic self and the scrutiny of others (referred to as others' watch) together explain 27.7% of the variance in face in relation to public self. In turn, face related to public self explains 20.7% of subjective norms. Finally, face related to public self and subjective norms together account for 41.2% of the variance in knowledge sharing intention. The research findings have important theoretical and managerial implications. © 2014 operational research society ltd. All rights reserved.","","","2014","10.1057/kmrp.2012.50","","","scopus-2-s2.0-84894176191.pdf","scopus-2-s2.0-84894176191"
"Cognitive elaboration: basic research and clinical application","Barone, D.f. And Hutchings, P.s.","Clinical Psychology Review","","This article reviews two lines of research in social-clinical psychology demonstrating that a person's own elaborative thinking mediates cognitive, affective, and behavioral change. Research on attitude change has found that what kind of arguments a person generates in response to a message predicts whether subsequent attitudes and behavior will be more resistant or changed. When an unmotivated person generates no arguments, belief is based on cues such as therapist credibility. Analogue research supports the importance of argument strength over source credibility in promoting attitude and behavior change in therapy. Research on simulation has found that when a person imagines a scenario of how he or she might behave and why, expectancies about such behavior and its actual performance are increased. Analogue research supports the role of constructing scenarios in changing the behavior of persons with low self-esteem and of clients in counseling. A research agenda is provided for assessing cognitive elaboration as a mediator of long-term change in therapy, for evaluating various interventions which should promote it, and for matching interventions to the cognitive style of clients. © 1993.","","","1993","10.1016/0272-7358(93)90040-s","","","scopus-2-s2.0-0027478995.pdf","scopus-2-s2.0-0027478995"
"The teaching and learning of communication skills in social work education","Reith-Hall, E. And Montgomery, P.","Research On Social Work Practice","","Purpose: this article presents a systematic review of research into the teaching and learning of communication skills in social work education. Methods: we conducted a systematic review, adhering to the cochrane handbook of systematic reviews for interventions and prisma reporting guidelines for systematic reviews and meta-analyses. Results: sixteen records reporting on fifteen studies met the eligibility criteria. Studies consisted of randomised trials and quasi-experimental designs. Outcome measures included knowledge, attitudes and skills. Significant heterogeneity meant a narrative synthesis rather than meta-analysis was undertaken. Systematic communication skills training supports the development of students’ communication skills including the demonstration of expressed empathy and interviewing skills. Discussion: the existing body of literature is limited but promising. Researchers conducting studies into communication skills training should seek to carry out robust and rigorous outcomes-focused studies. Further investigation into the theoretical underpinnings of the educational interventions and the roles played by key stakeholders is also required. © the author(s) 2022.","","","2022","10.1177/10497315221088285","","","scopus-2-s2.0-85129250033.pdf","scopus-2-s2.0-85129250033"
"Evidence-based road safety practice in India: assessment of the adequacy of publicly available data in meeting requirements for comprehensive road safety data systems","Barffour M., Gupta S., Gururaj G., Hyder A. A.","Traffic Injury Prevention","","OBJECTIVE: To assess the availability and coverage of publicly available road safety data at the national and state levels in India.\\\\\\\\rMETHODS: We reviewed the 2 publicly accessible data sources in India for the availability of data related to traffic injuries and deaths: (1) the National Crime Records Bureau (NCRB) and (2) the Ministry of Road Transport and Highways (MORTH). Using the World Health Organization (WHO) manual for the comprehensive assessment of road safety data we developed a checklist of indicators required for comprehensive road safety assessment. These indicators were then used to assess the availability of road safety data in India using the NCRB and MORTH data. We assessed the availability of data on outcomes and exposures indicators (i.e. number of crashes injuries deaths timing of deaths gender and age distribution of injuries and deaths) safety performance indicators (i.e. with reference to select risk factors of speeding alcohol and helmet use) and cost indicators (i.e. medical costs material costs intervention costs productivity costs time costs and losses to quality of life).\\\\\\\\rRESULTS: Information on outcome indicators was the most comprehensive in terms of availability. Both NCRB and MORTH databases had data for most of the need areas specified by the WHO under outcomes and exposure indicators. Regarding outcome and exposure indicators data were available for 81 and 91 percent of specified need areas at the national level from NCRB and MORTH databases respectively. At the state level data on outcome and exposure indicators were available for only 54 percent of need areas from either of the 2 sources. There were no data on safety performance indicators in the NCRB database. From the MORTH database data availability on safety performance indicators was 60 percent at both national and state levels. Data availability on costs and process indicators was found to be below 20 percent at the national and state levels.\\\\\\\\rCONCLUSION: Overall there is an urgent need to improve the publicly available road safety data in India. This will enhance monitoring of the burden of traffic injuries and deaths enable sound interpretation of national road safety data and allow the formulation effective road safety policies.","","","2012","10.1080/15389588.2011.636780","","","medline-22414124.pdf","medline-22414124"
"Blockchain aware proxy re-encryption algorithm-based data sharing scheme","Keshta, I. And Aoudni, Y. And Sandhu, M. And Singh, A. And Xalikovich, P.a. And Rizwan, A. And Soni, M. And Lalar, S.","Physical Communication","","The blockchain stores transaction data in a distributed shared global ledger. It is challenging to strike a balance between privacy protection and usefulness while sharing data. Moreover, the dynamic adjustment of blockchain data access rights is a challenging problem. To this end, this paper suggests a blockchain data-controlled sharing scheme based on proxy re-encryption. First, a proxy re-encryption algorithm is constructed based on sm2 and the blockchain. Blockchain data sharing can give businesses a secure way to store and share data. Since this network is decentralized, and data is transmitted across a peer-to-peer network under the protection of an unchangeable cryptographic signature. Blockchain makes it more difficult to alter or hack the data. The data-controlled sharing scheme uses proxy re-encryption to protect transaction data privacy and realize data security sharing. Secondly, a dynamic adjustment mechanism for user rights is proposed. Blockchain nodes divide labor and manage re-encryption key parameters separately to achieve user access rights determinism update, the visibility of transaction data is dynamically adjusted. Finally, the performance and security evaluation demonstrate that this scheme can realize the dynamic sharing of blockchain data while protecting transaction privacy and has advantages in computing overhead, which is better applicable to the controlled sharing of blockchain data. This research suggests a regulated blockchain-based data-sharing system that makes use of proxy re-encryption. They are developing a proxy re-encryption algorithm with sm2 in order to fully safeguard the privacy of transaction data and to achieve data access authority determination by controlling proxy re-encryption key parameters. It is suggested to employ a hybrid attribute-based proxy re-encryption method that enables the proxy server to change attribute-encrypted cypher texts into identity-based encrypted cypher texts so that users with limited resources can access the previously encrypted material. © 2023 elsevier b.v.","","","2023","10.1016/j.phycom.2023.102048","","","scopus-2-s2.0-85151273190.pdf","scopus-2-s2.0-85151273190"
"A robust ambient temperature collection and stabilization strategy: Enabling worldwide functional studies of the human microbiome","Anderson E. L., Li W., Klitgord N., Highlander S. K., Dayrit M., Seguritan V., Yooseph S., Biggs W., Venter J. C., Nelson K. E., Jones M. B.","Scientific Reports","","As reports on possible associations between microbes and the host increase in number more meaningful interpretations of this information require an ability to compare data sets across studies. This is dependent upon standardization of workflows to ensure comparability both within and between studies. Here we propose the standard use of an alternate collection and stabilization method that would facilitate such comparisons. The DNA Genotek OMNIgene.Gut Stool Microbiome Kit was compared to the currently accepted community standard of freezing to store human stool samples prior to whole genome sequencing (WGS) for microbiome studies. This stabilization and collection device allows for ambient temperature storage automation and ease of shipping/transfer of samples. The device permitted the same data reproducibility as with frozen samples and yielded higher recovery of nucleic acids. Collection and stabilization of stool microbiome samples with the DNA Genotek collection device combined with our extraction and WGS provides a robust reproducible workflow that enables standardized global collection storage and analysis of stool for microbiome studies.","","","2016","10.1038/srep31731","","","medline-27558918.pdf","medline-27558918"
"Enabling reproducible research in sensor-based transportation mode recognition with the sussex-huawei dataset","Wang, L. And Gjoreski, H. And Ciliberto, M. And Mekki, S. And Valentin, S. And Roggen, D.","Ieee Access","","Transportation and locomotion mode recognition from multimodal smartphone sensors is useful for providing just-in-time context-aware assistance. However, the field is currently held back by the lack of standardized datasets, recognition tasks, and evaluation criteria. Currently, the recognition methods are often tested on the ad hoc datasets acquired for one-off recognition problems and with different choices of sensors. This prevents a systematic comparative evaluation of methods within and across research groups. Our goal is to address these issues by: 1) introducing a publicly available, large-scale dataset for transportation and locomotion mode recognition from multimodal smartphone sensors;  2) suggesting 12 reference recognition scenarios, which are a superset of the tasks we identified in the related work;  3) suggesting relevant combinations of sensors to use based on energy considerations among accelerometer, gyroscope, magnetometer, and global positioning system sensors;  and 4) defining precise evaluation criteria, including training and testing sets, evaluation measures, and user-independent and sensor-placement independent evaluations. Based on this, we report a systematic study of the relevance of statistical and frequency features based on the information theoretical criteria to inform recognition systems. We then systematically report the reference performance obtained on all the identified recognition scenarios using a machine-learning recognition pipeline. The extent of this analysis and the clear definition of the recognition tasks enable future researchers to evaluate their own methods in a comparable manner, thus contributing to further advances in the field. The dataset and the code are available online. © 2013 ieee.","","","2019","10.1109/access.2019.2890793","","","scopus-2-s2.0-85061086624.pdf","scopus-2-s2.0-85061086624"
"Learning to ""share your science"": the open notebook as textual object and dynamic rhetorical space","Wickman, Chad","","","Laboratory notebooks have historically provided scientists with an important resource for documenting, warranting, and communicating the outcomes of their day-to-day research. Over the past decade, however, the genre has undergone some interesting changes: once a situated, print-bound activity, the practice of note making has begun to develop into a highly distributed, multimedia undertaking-a development that is beginning to reconfigure the traditional relationship between the laboratory, scientific community, and broader public sphere. The growing movement toward ""open notebook science"" (see bradley, 2006;  bradley, owens, & williams, 2008) specifically raises questions about .the ways in which notebooks function as a proprietary safeguard for individual scientists and as a dynamic rhetorical space within which groups of scientists and other stakeholders can present, discuss, revise, and circulate information. Through analysis of openwetware, a web-based scientific community, this chapter examines how scientists use familiar genres to balance the relationship between stability and change as they make the transition from traditional rhetorical practices that focus on individual ownership to emerging rhetorical practices that focus on the open sharing of information through digital infi^tmctures. I will argue specifically that open notebooks reinforce a type of ""shared praxis"" (nielsen, 2011) that is necessary for open access to take hold in the scientific community and that may be contributing to a broader shift in the rhetorical and epistemological dimensions of scientific research culture. (Psycinfo database record (c) 2023 apa, all rights reserved)","","","2016","","","","psychinfo-2016-17989-002.pdf","psychinfo-2016-17989-002"
"Studying vulnerable populations: lessons from the Roma minority","Kosa K., Adany R.","Epidemiology","","There are important disparities in health outcomes between racial/ethnic minorities and majorities in all countries where minority health has been investigated. This holds true for the largest minority population of Europe the Roma although research data related to Roma are scarcer and more contested than for other minorities. We discuss major obstacles that hinder or prevent the collection of reliable data in Roma and other minorities. The definitions and classification systems on race/ethnicity vary widely pointing to the social construction of both race and ethnicity. Imprecision in taxonomy and definition of target groups is compounded by challenges in data collection analysis and interpretation along with ethnocentricity that shapes the perspectives and approaches of the researchers. However administrative data collection on race/ethnicity serves legitimate purposes although such data must comply with less-stringent quality requirements as opposed to data meant for scientific analysis. Research on minorities should consider race/ethnicity as proxy indicators of complex health determinants and should aim at dissecting these determinants into separate items. Careful documentation of methodology and active involvement of the minorities themselves can increase trust between the investigators and the research subjects which can in turn improve research on minority health.","","","2007","10.1097/01.ede.0000258919.15281.4f","","","medline-17435436.pdf","medline-17435436"
"KBOC: Keystroke biometrics OnGoing competition","Morales A., Fierrez J., Gomez-Barrero M., Ortega-Garcia J., Daza R., Monaco J. V., Montalvão J., Canuto J., George A.","","","This paper presents the first Keystroke Biometrics Ongoing evaluation platform and a Competition (KBOC) organized to promote reproducible research and establish a baseline in person authentication using keystroke biometrics. The ongoing evaluation tool has been developed using the BEAT platform and includes keystroke sequences (fixed-text) from 300 users acquired in 4 different sessions. In addition the results of a parallel offline competition based on the same data and evaluation protocol are presented. The results reported have achieved EERs as low as 5.32% which represent a challenging baseline for keystroke recognition technologies to be evaluated on the new publicly available KBOC benchmark. © 2016 IEEE.","","","2016","10.1109/btas.2016.7791180","","","scopus-2-s2.0-85011271323.pdf","scopus-2-s2.0-85011271323"
"Deep multilayer percepted policy attribute lamport certificateless signcryption for secure data access and sharing in cloud","Mala, J. And Jayanthi, A.n.","Distributed And Parallel Databases","","Data sharing is a method that allows users to legally access data over the cloud. Cloud computing architecture is used to enable the data sharing capabilities only to the authorized users from the data stored in the cloud server. In the cloud, the number of users is extremely large and the users connect and leave randomly hence that the system needs to protect the data access. Many algorithms have been reviewed but the most challenging issue in cloud computing is a data-sharing system and access policy for an authorized user. A novel technique called deep multilayer percepted policy attribute lamport certificateless signcryption (dmppalcs) is introduced for improving the security level of data access in the cloud with multiple layers. Initially, the users register their details to the cloud server for retrieving the numerous services. After that the cloud server generates the private and public keys for each registered user using lamport certificateless signcryption. After the key generation, the user sends a request to the cloud server for acquiring the data. The cloud server validates that the requested user is authorized or not based on the policy attributes. Then the cloud server facilities the user requested data in the form of ciphertext and generates the signature to the cloud user. Finally, the signature is verified at the user side to decrypt the data. If the signature is valid, then the authorized users obtain the original data and improve secure data access. The proposed dmppalcs technique is used for evaluating various security parameters. © 2021, the author(s), under exclusive licence to springer science+business media, llc, part of springer nature.","","","2022","10.1007/s10619-021-07336-z","","","scopus-2-s2.0-85105168044.pdf","scopus-2-s2.0-85105168044"
"Integrative factorization of bidimensionally linked matrices","Park, J.y. And Lock, E.f.","Biometrics","","Advances in molecular “omics” technologies have motivated new methodologies for the integration of multiple sources of high-content biomedical data. However, most statistical methods for integrating multiple data matrices only consider data shared vertically (one cohort on multiple platforms) or horizontally (different cohorts on a single platform). This is limiting for data that take the form of bidimensionally linked matrices (eg, multiple cohorts measured on multiple platforms), which are increasingly common in large-scale biomedical studies. In this paper, we propose bidimensional integrative factorization (bidifac) for integrative dimension reduction and signal approximation of bidimensionally linked data matrices. Our method factorizes data into (a) globally shared, (b) row-shared, (c) column-shared, and (d) single-matrix structural components, facilitating the investigation of shared and unique patterns of variability. For estimation, we use a penalized objective function that extends the nuclear norm penalization for a single matrix. As an alternative to the complicated rank selection problem, we use results from the random matrix theory to choose tuning parameters. We apply our method to integrate two genomics platforms (messenger rna and microrna expression) across two sample cohorts (tumor samples and normal tissue samples) using the breast cancer data from the cancer genome atlas. We provide r code for fitting bidifac, imputing missing values, and generating simulated data. © 2019 the international biometric society","","","2020","10.1111/biom.13141","","","scopus-2-s2.0-85076533898.pdf","scopus-2-s2.0-85076533898"
"Oddpub – a text-mining algorithm to detect data sharing in biomedical publications","Riedel, N. And Kip, M. And Bobrov, E.","Data Science Journal","","Open research data are increasingly recognized as a quality indicator and an important resource to increase transparency, robustness and collaboration in science. However, no standardized way of reporting open data in publications exists, making it difficult to find shared datasets and assess the prevalence of open data in an automated fashion. We developed oddpub (open data detection in publications), a text-mining algorithm that screens biomedical publications and detects cases of open data. Using english-language original research publications from a single biomedical research institution (n = 8689) and randomly selected from pubmed (n = 1500) we iteratively developed a set of derived keyword categories. Oddpub can detect data sharing through field-specific repositories, general-purpose repositories or the supplement. Additionally, it can detect shared analysis code (open code). To validate oddpub, we manually screened 792 publications randomly selected from pubmed. On this validation dataset, our algorithm detected open data publications with a sensitivity of 0.73 and specificity of 0.97. Open data was detected for 11.5% (n = 91) of publications. Open code was detected for 1.4% (n = 11) of publications with a sensitivity of 0.73 and specificity of 1.00. We compared our results to the linked datasets found in the databases pubmed and web of science. Our algorithm can automatically screen large numbers of publications for open data. It can thus be used to assess open data sharing rates on the level of subject areas, journals, or institutions. It can also identify individual open data publications in a larger publication corpus. Oddpub is published as an r package on github. © 2019 the author(s).","","","2020","10.5334/dsj-2020-042","","","scopus-2-s2.0-85098960465.pdf","scopus-2-s2.0-85098960465"
"Current situation analysis and quality evaluation of chinese clinical practice guidelines in general practice","Wang, P. And Wu, S. And Sun, Y. And Lan, H. And Ren, M. And Zhao, J. And Wang, L. And Su, R. And Zhou, Q. And Wang, Z. And Wang, Q. And Ma, L. And Hou, T. And Chen, Y.","Chinese General Practice","","Background the clinical practice guidelines in general practice can improve healthcare quality in primary health care，however，no study has yet systematically investigated the current status and quality of the guidelines in china. Objective to investigate the current status and influencing factors of quality of the guidelines in china. Methods we searched china national knowledge infrastructure，wanfang data knowledge service platform，chinese biomedical literature database，and cqvip website，and included the published guidelines in china. We analyzed the basic characteristics and used right to evaluate the reporting quality and agree-china for methodological quality. Results a total of 150 guidelines were included，mainly published from 2019 to 2021. Most of the guidelines〔108（72.0%）〕focused on the diagnosis and treatment of diseases. The top three specialties were cardiovascular disease〔40（26.7%）〕，gastroenterology〔31（20.7%）〕，and clinical pharmacy〔27（18.0%）〕. The main development institutions were the chinese medical association and its branches〔123 （82.0%）〕，the editorial committee of the chinese journal of general practitioners〔119（79.3%）〕，and the chinese medical journals publishing house〔116（77.3%）〕. In terms of reporting quality，the average reporting rate of right was 23.6%（11.4%-42.9%）；the reporting rate of basic information（59.8%）was higher，and that of evidence（0.3%）was the lowest. As for methodological quality，the average agree-china score was 23.4（12.0-40.0）；the reporting rates of conflicts of interest（63.0%）and availability/feasibility（53.0%）were higher，and that of economics（7.0%）was the lowest. Conclusion the number of chinese clinical practice guidelines in general practice has increased rapidly in the past five years，which has played an important role in promoting the quality of primary health care. In the future，it is necessary to further develop the guidelines in different specialties and diseases and accelerate the methodology of development and reporting of the guidelines. © 2023 chinese general practice. All rights reserved.","","","2023","10.12114/j.issn.1007-9572.2023.0044","","","scopus-unknown-accession-3206862.pdf","scopus-unknown-accession-3206862"
"PepC: proteomics software for identifying differentially expressed proteins based on spectral counting","Heinecke N. L., Pratt B. S., Vaisar T., Becker L.","Bioinformatics","","UNLABELLED: Identifying biologically significant changes in protein abundance between two conditions is a key issue when analyzing proteomic data. One widely used approach centers on spectral counting a label-free method that sums all the tandem mass spectra for a protein observed in an analysis. To assess the significance of the results we recently combined the t-test and G-test with random permutation analysis and we validated this approach biochemically. To automate the statistical method we developed PepC a software program that balances the trade-off between the number of differentially expressed proteins identified and the false discovery rate. This tool can be applied to a wide range of proteomic datasets making data analysis rapid reproducible and easily interpretable by proteomics specialists and non-specialists alike.\\\\\\\\rAVAILABILITY AND IMPLEMENTATION: The software is implemented in Java. It has been added to the Trans Proteomic Pipeline project's 'Petunia' web interface but can also be run as a command line program. The source code is GNU Lesser General Public License and the program is freely available on the web. http://sashimi.svn.sourceforge.net/viewvc/sashimi/trunk/trans_proteomic_pipeline/src/Quantitation/Pepc.","","","2010","10.1093/bioinformatics/btq171","","","medline-20413636.pdf","medline-20413636"
"A blockchain-based preserving and sharing system for medical data privacy","Chen, Z. And Xu, W. And Wang, B. And Yu, H.","Future Generation Computer Systems","","With the rapid development of information and network technology, hospital information systems (his) has also become a hot research area. However, data could be subjected to the threat of security attacks, leakage, tampering, and forgery during medical data transmissions, data storage, and sharing based on public networks and cloud environments. The immutability, decentralization and anonymity of the blockchain provided new ways for solving the aforementioned problems. This paper proposes a complete medical information system model based on blockchain technology, to realize the goal of safe storage and sharing of medical data. A data collection system based on internet of things (iot) was also developed that can simultaneously collect data from different types of non-invasive medical instruments to realize real-time collection of patient health record during surgery (shr). This system designed an anonymous medical data sharing scheme based on cloud servers and proxy re-encryption algorithm to improve the security of private medical data sharing. The system was implemented based on the permissioned blockchain architecture hyperledger fabric, and a dual-channel fabric deployment architecture and medical chaincode were designed for data management and access control. We also carried out computing overhead test, performance test and safety evaluation on the system, and the test results meet the requirements of actual medical production environment. The research work of this paper provides means for remote diagnosis and treatment, data mining and other practical applications based on the medical data on the blockchain. © 2021 elsevier b.v.","","","2021","10.1016/j.future.2021.05.023","","","scopus-2-s2.0-85108096199.pdf","scopus-2-s2.0-85108096199"
"Not Normal: the uncertainties of scientific measurements","Bailey D. C.","Royal Society Open Science","","Judging the significance and reproducibility of quantitative research requires a good understanding of relevant uncertainties but it is often unclear how well these have been evaluated and what they imply. Reported scientific uncertainties were studied by analysing 41 000 measurements of 3200 quantities from medicine nuclear and particle physics and interlaboratory comparisons ranging from chemistry to toxicology. Outliers are common with 5sigma disagreements up to five orders of magnitude more frequent than naively expected. Uncertainty-normalized differences between multiple measurements of the same quantity are consistent with heavy-tailed Student's t-distributions that are often almost Cauchy far from a Gaussian Normal bell curve. Medical research uncertainties are generally as well evaluated as those in physics but physics uncertainty improves more rapidly making feasible simple significance criteria such as the 5sigma discovery convention in particle physics. Contributions to measurement uncertainty from mistakes and unknown problems are not completely unpredictable. Such errors appear to have power-law distributions consistent with how designed complex systems fail and how unknown systematic errors are constrained by researchers. This better understanding may help improve analysis and meta-analysis of data and help scientists and the public have more realistic expectations of what scientific results imply.","","","2017","10.1098/rsos.160600","","","medline-28280557.pdf","medline-28280557"
"Does the framing of transparency impact trust? Differences between self-benefit and other-benefit message frames","Fisher, J. And Hopp, T.","International Journal Of Strategic Communication","","This study examines the impacts of self-(i.e., egoistic) versus other-(i.e., social) benefit frames used in organizational transparency messaging. While research in various strategic communication disciplines has presented organizational transparency as useful to achieving positive outcomes, limited empirical research on the effects of strategic decision-making around information presentation in transparency messaging has been conducted. The experiment used here shows that self- versus other-benefit message frames have meaningful implications pertaining to the perception of transparency and the formation of organizational trust among audiences. Specifically, we drew on prior theory to suggest that transparency messages that emphasize an organization’s commitment to the social good (i.e., other-benefit frames) are more likely to increase the perception of transparency and to elicit trust-based gains than transparency messages that emphasize the organization’s value to the self. The results of two experiments supported this contention. As such, we argue that message framing should be strategically implemented in order to support the effectiveness of transparent communication and enhance trust with stakeholders, an important goal for many organizations. © 2020 taylor & francis group, llc.","","","2020","10.1080/1553118x.2020.1770767","","","scopus-2-s2.0-85090303045.pdf","scopus-2-s2.0-85090303045"
"Open science and evaluation","Galimberti, P.","Scires-It","","The aim of this contribution is to investigate how open science can influence/support research evaluation and whether and how open science practice can be evaluated in its effort to avoid what is predicted by goodhart's law (when a measure becomes a target, it ceases to be a good measure). The enterprise is not simple, as it focus on giving up points of reference that have been part of common practice of hard sciences for years while we are now trying to implement them in humanities and social sciences. We must accept that the internet has changed the way science is produced, disseminated, validated and evaluated and has multiplied its channels of communication. For this reason the traditional bibliometric indicators, which refer to articles published in peer reviewed journals, preferably in english, as the only viable publication channel, become inapplicable. In an open environment, the role of peer review, in particular the idea of blind (single or double) peer review must also radically change. © 2020. Scientific research and information technology ricerca scientifica e tecnologie dell'informazione. All rights reserved.","","","2020","10.2423/i22394303v10sp65","","","scopus-2-s2.0-85098932047.pdf","scopus-2-s2.0-85098932047"
"GWAS and genomic prediction of milk urea nitrogen in Australian and New Zealand dairy cattle","van den Berg I., Ho P. N., Nguyen T. V., Haile-Mariam M., MacLeod I. M., Beatson P. R., O'Connor E., Pryce J. E.","Genetics Selection Evolution","","BACKGROUND: Urinary nitrogen leakage is an environmental concern in dairy cattle. Selection for reduced urinary nitrogen leakage may be done using indicator traits such as milk urea nitrogen (MUN). The result of a previous study indicated that the genetic correlation between MUN in Australia (AUS) and MUN in New Zealand (NZL) was only low to moderate (between 0.14 and 0.58). In this context an alternative is to select sequence variants based on genome-wide association studies (GWAS) with a view to improve genomic prediction accuracies. A GWAS can also be used to detect quantitative trait loci (QTL) associated with MUN. Therefore our objectives were to perform within-country GWAS and a meta-GWAS for MUN using records from up to 33873 dairy cows and imputed whole-genome sequence data to compare QTL detected in the GWAS for MUN in AUS and NZL and to use sequence variants selected from the meta-GWAS to improve the prediction accuracy for MUN based on a joint AUS-NZL reference set.\\\\\\\\rRESULTS: Using the meta-GWAS we detected 14 QTL for MUN located on chromosomes 1 6 11 14 19 22 26 and the X chromosome. The three most significant QTL encompassed the casein genes on chromosome 6 PAEP on chromosome 11 and DGAT1 on chromosome 14. We selected 50000 sequence variants that had the same direction of effect for MUN in AUS and MUN in NZL and that were most significant in the meta-analysis for the GWAS. The selected sequence variants yielded a genetic correlation between MUN in AUS and MUN in NZL of 0.95 and substantially increased prediction accuracy in both countries.\\\\\\\\rCONCLUSIONS: Our results demonstrate how the sharing of data between two countries can increase the power of a GWAS and increase the accuracy of genomic prediction using a multi-country reference population and sequence variants selected based on a meta-GWAS. Copyright © 2022. The Author(s).","","","2022","10.1186/s12711-022-00707-9","","","medline-35183113.pdf","medline-35183113"
"Doping prevalence in competitive sport: evidence synthesis with ""best practice"" recommendations and reporting guidelines from the wada working group on doping prevalence","Gleaves J. And Petroczi A. And Folkerts D. And De Hon O. And Macedo E. And Saugy M. And Cruyff M.","Sports Med","","Background: the prevalence of doping in competitive sport, and the methods for assessing prevalence, remain poorly understood. This reduces the ability of researchers, governments, and sporting organizations to determine the extent of doping behavior and the impacts of anti-doping strategies. Objective(s): the primary aim of this subject-wide systematic review was to collate and synthesize evidence on doping prevalence from published scientific papers. Secondary aims involved reviewing the reporting accuracy and data quality as evidence for doping behavior to (1) develop quality and bias assessment criteria to facilitate future systematic reviews;  and (2) establish recommendations for reporting future research on doping behavior in competitive sports to facilitate better meta-analyses of doping behavior. Method(s): the preferred reporting items for systematic reviews and meta-analyses (prisma) guidelines were used to identify relevant studies. Articles were included if they contained information on doping prevalence of any kind in competitive sport, regardless of the methodology and without time limit. Through an iterative process, we simultaneously developed a set of assessment criteria;  and used these to assess the studies for data quality on doping prevalence, potential bias and reporting. Result(s): one-hundred and five studies, published between 1975 and 2019,were included. Doping prevalence rates in competitive sport ranged from 0 to 73% for doping behavior with most falling under 5%. To determine prevalence, 89 studies used self-reported survey data (srp) and 17 used sample analysis data (sap) to produce evidence for doping prevalence (one study used both srp and sap). In total, studies reporting athletes totaled 102,515 participants, (72.8% men and 27.2% women). Studies surveyed athletes in 35 countries with 26 involving athletes in the united states, while 12 studies examined an international population. Studies also surveyed athletes from most international sport federations and major professional sports and examined international, national, and sub-elite level athletes, including youth, masters, amateur, club, and university level athletes. However, inconsistencies in data reporting prevented meta-analysis for sport, gender, region, or competition level. Qualitative syntheses were possible and provided for study type, gender, and geographical region. The quality assessment of prevalence evidence in the studies identified 20 as ""high"", 60 as ""moderate"", and 25 as ""low."" Of the 89 studies using srp, 17 rated as ""high"", 52 rated as ""moderate"", and 20 rated as ""low."" Of the 17 studies using sap, 3 rated as ""high"", 9 rated as ""moderate"", and 5 rated as ""low."" Examining ratings by year suggests that both the quality and quantity of the evidence for doping prevalence in published studies are increasing. Conclusion(s): current knowledge about doping prevalence in competitive sport relies upon weak and disparate evidence. To address this, we offer a comprehensive set of assessment criteria for studies examining doping behavior data as evidence for doping prevalence. To facilitate future evidence syntheses and meta-analyses, we also put forward ""best practice"" recommendations and reporting guidelines that will improve evidence quality.copyright © 2021. The author(s), under exclusive licence to springer nature switzerland ag.","","","2021","10.1007/s40279-021-01477-y","","","embase-636610337.pdf","embase-636610337"
"A reflection on participatory research methodologies in the light of the COVID-19 - lessons learnt from the European Research Project TRIPS","Konig A., Hatzakis T., Andrushevich A. A., Hoogerwerf E. J., Vasconcelos E., Launo C., Alciauskaite L., Barbosa S., Andersen K.","Open Research Europe","","The coronavirus disease (COVID-19) outbreak has had considerable impacts on research projects particularly those adopting participatory approaches. This paper reflects on the methodological adaptations employed by the European research project TRIPS to facilitate co-design and open innovation practices towards the development of accessible mobility solutions. The article reports how the methods were adapted to facilitate participatory research with almost no physical meetings. In doing so the paper presents the alternative 'distanced-based' participatory approaches employed to engage users with disabilities and institutional stakeholders in the transport ecosystem like online workshops social media content analysis online surveys and peer-to-peer telephone interviews. Lessons learnt and practical guidelines for distance-based participatory research are presented and discussed with the aim of increasing resilience in the light of future changes. Copyright: © 2022 Konig A et al.","","","2021","10.12688/openreseurope.14315.2","","","medline-37645198.pdf","medline-37645198"
"A model for understanding the causes and consequences of walking impairments","Schwartz, M.h. And Steele, K.m. And Ries, A.j. And Georgiadis, A.g. And Macwilliams, B.a.","Plos One","","Walking is an important skill with positive impacts on health, function, and well-being. Many disorders impair walking and its positive impacts through a variety of complex and interrelated mechanisms. Any attempt to understand walking impairments, or the effects of interventions intended to treat these impairments, must respect this complexity. Therefore, our main objectives in conducting this study were to (1) propose a comprehensive model for quantifying the causes and consequences of walking impairments and (2) demonstrate the potential utility of the model for supporting clinical care and addressing basic scientific questions related to walking. To achieve these goals, we introduced a model, described by a directed acyclic graph, consisting of 10 nodes and 23 primary causal paths. We gave detailed descriptions of each node and path based on domain knowledge. We then demonstrated the model’s utility using a large sample of gait data (n = 9504) acquired as part of routine care at a regional referral center. We analyzed five relevant examples that involved many of the model’s nodes and paths. We computed causal effect magnitudes as shapley values and displayed the overall importance of variables (mean absolute shapley value), the variation of shapley values with respect to underlying variables, and shapley values for individual observations (case studies). We showed that the model was plausible, captured some well-known cause-effect relationships, provided new insights into others, and generated novel hypotheses requiring further testing through simulation or experiment. To aid in transparency, reproducibility, and future enhancements we have included an extensively commented rmarkdown file and a deidentified data set. © 2022 schwartz et al. This is an open access article distributed under the terms of the creative commons attribution license, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","","2022","10.1371/journal.pone.0270731","","","scopus-2-s2.0-85145022681.pdf","scopus-2-s2.0-85145022681"
"Standards for reporting interventions in clinical trials of cupping (strictoc): extending the consort statement","Zhang, X. And Tian, R. And Lam, W.c. And Duan, Y. And Liu, F. And Zhao, C. And Wu, T. And Shang, H. And Tang, X. And Lyu, A. And Bian, Z.","Chinese Medicine (United Kingdom)","","Background: the standards for reporting interventions in clinical trials of cupping (strictoc), in the form of a checklist and explanations for users, were designed to improve reporting of cupping trials, particularly the interventions, and thereby facilitating their interpretation and replication. Methods: a group of clinical experts, methodologists, epidemiologists, and editors has developed this strictoc checklist through a comprehensive process, including registration of this guideline, literature review, solicitation of comments, consensus meeting, revision, and finalization. Results: the strictoc checklist includes 6 items and 16 sub-items, namely cupping rationale, details of cupping, treatment regimen, other components of treatment, treatment provider background, and control or comparator interventions. Illustrative examples of each item are also provided. Conclusions: it is intended that the strictoc, in conjunction with both the main consolidated standards of reporting trials (consort) statement and extension for nonpharmacologic treatment, will raise the reporting quality of clinical trials of cupping. Trial registration we have registered this study on the enhancing the quality and transparency of health research (equator) network: http://www.equator-network.org/library/reporting-guidelines-under-development/reporting-guidelines-under-development-for-clinical-trials/#strictoc. © 2020 the author(s).","","","2020","10.1186/s13020-020-0293-2","","","scopus-2-s2.0-85079064952.pdf","scopus-2-s2.0-85079064952"
"Closing the gap: data-based decisions in food nutrition and health systems: proceedings of the Fifth International Summit on Medical and Public Health Nutrition Education and Research","Laur C., Johnsen J. T., Bradfield J., Eden T., Mitra S., Ray S.","BMJ Nutrition Prevention & Health","","INTRODUCTION: Like many of the biological sciences nutrition has rapidly become a science which relies heavily on data collection analysis and presentation. Knowledge gaps exist where data does not and so the fifth annual International Summit on Medical and Public Health Nutrition Education and Research was held to address the theme of 'Closing the Gap: Data-based Decisions in Food Nutrition and Health Systems'.\\\\\\\\rSETTING: Homerton College University of Cambridge Cambridge in July 2019.\\\\\\\\rKEY FINDINGS: Data-driven decision making is more likely to lead to positive change in areas such as malnutrition food insecurity and food production. These decisions must be informed by multiple stakeholders from various backgrounds in multisectorial collaboration. Case examples presented at the Summit contribute to the International Knowledge Application Network in Nutrition 2025 which aims to help identify and close gaps in nutrition and healthcare.\\\\\\\\rCONCLUSIONS: Formation of international networks are required to advance nutrition research identify gaps and generate high-quality data. These data can be used to adequately train healthcare professionals resulting in positive impact on clinical and public health. Strengthening collaboration between existing networks will be essential in sharing data for better health outcomes. Copyright © Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.","","","2020","10.1136/bmjnph-2020-000118","","","medline-33521551.pdf","medline-33521551"
"How to improve the study design of clinical trials in internal medicine: recent advances in the evidence-based methodology","Lund H., Bala M., Blaine C., Brunnhuber K., Robinson K. A.","Polish Archives Of Internal Medicine","","Meta-research has highlighted that up to half of all clinical studies may be redundant and do not add any value. We suggest that such unnecessary studies will continue to be prepared and published unless researchers systematically and transparently identify and consider the existing evidence. This approach of identifying and utilizing the existing knowledge base before and after conducting a new trial is called Evidence-Based Research (EBR) defined as the use of prior research in a systematic and transparent way to inform a new study so that it is answering questions that matter in a valid efficient and accessible manner. This paper describes the issues that have led to the development of the EBR approach suggests what researchers should do to avoid wasteful and unnecessary research and outlines the benefits of conducting evidence-based research. Finally we present the international EBR Network established to support the efforts to minimize waste in research and increase the value of clinical studies.","","","2021","10.20452/pamw.16076","","","medline-34590450.pdf","medline-34590450"
"Research on the Influence Mechanism of Epidemic Information Disclosure on Screening Authenticity Information","Huang X., Li G., Wang Y., Li X.","Procedia Computer Science","","In early 2020 the new coronavirus pneumonia (Referred to as COVID-19) spread rapidly throughout the country which has a major impact on economic and social development. Timely and accurate disclosure of epidemic information will enhance the public's ability to discriminate against false information. The influence mechanism of epidemic information disclosure on the identification of true and false information was studied and the influencing factors of epidemic information disclosure were analyzed and studied under the framework of the ""Technology-Organization-Environment"" (TOE) model and the two-factor theory of driving factors and impeding factors. Combined with the relevant data from the Open Data Network of Shandong and Jinan and the attention of hot news events on the Internet since the outbreak of the epidemic it is proposed that information disclosure is conducive to reasonably guiding the public attitude and enhancing the ability of information screening. Copyright © 2021 The Author(s). Published by Elsevier B.V.","","","2021","10.1016/j.procs.2021.04.040","","","medline-34149966.pdf","medline-34149966"
"Continuous-flow production of polymeric micelles in microreactors: experimental and computational analysis","Capretto L., Carugo D., Cheng W., Hill M., Zhang X.","Journal of Colloid & Interface Science","","We report the development of a microfluidic-based process for the production of polymeric micelles (PMs) in continuous-flow microreactors where Pluronic R tri-block copolymer is used as model polymeric biomaterial relating to drug delivery applications. A flow focusing configuration is used enabling a controllable and fast mixing process to assist the formation of polymeric micelles through nanoprecipitation which is triggered by a solvent exchange process when organic solutions of the polymer mixed with a non-solvent. We experientially investigate the effect of polymer concentration flow rate ratio and microreactor dimension on the PMs size characteristics. The mixing process within the microfluidic reactors is further analyzed by computational modeling in order to understand the hydrodynamic process and its implication for the polymeric micelles formation process. The results obtained show that besides the effect of the flow rate ratio the chemical environment in which the aggregation takes place plays an important role in determining the dimensional characteristics of the produced polymeric micelles. It is demonstrated that microfluidic reactors provide a useful platform for the continuous-flow production of polymeric micelles with improved controllability reproducibility and homogeneity of the size characteristics. Copyright © 2011 Elsevier Inc. All rights reserved.","","","2011","10.1016/j.jcis.2011.01.085","","","medline-21353232.pdf","medline-21353232"
"Confidentiality in participatory research: challenges from one study","Petrova, E. And Dewing, J. And Camilleri, M.","Nursing Ethics","","Aim: this article presents key ethical challenges that were encountered when conducting a participatory qualitative research project with a very specific, small group of nurses, in this case with practice development nurses in malta. Background: with the small number of nurses employed in practice development roles in malta, there are numerous difficulties of maintaining confidentiality. Poorly constructed interventions by the researcher could have resulted in detrimental effects to research participants and the overall trustworthiness of the research. Generally, ethical guidelines for research exist to reinforce validity of research;  however, there is not an established consensus on how these strategies can be utilised in some types of qualitative field work. Research design: the researcher used an exploratory case study methodology. The sample consisted of 10 participants who were interviewed twice using face-to-face interviews, over a period of 2 months. Ethical considerations: the study was ethically reviewed by the university research ethics committee and the faculty research ethics committee, university of malta. The participants referred to in this article have been given adequate information about the study and their consent has been obtained. Discussion: numerous strategies for ensuring confidentiality during recruitment of the participants, during data collection, during transcription and data analysis and during dissemination of research results assisted the researcher in responding to potential and actual ethical issues. Conclusion: this article emphasises the main strategies that can be used to respond to ethical challenges when researching with a small easily identifiable group. The learning discussed here may be relevant to or even transferable to other similar research studies or research contexts. These methods fostered a greater credibility throughout the research process and predisposed the participants to greater trust, and thus, they disclosed their experiences and speak more freely, thus enhancing the quality of the study. © 2014, © the author(s) 2014.","","","2016","10.1177/0969733014564909","","","scopus-2-s2.0-84973496081.pdf","scopus-2-s2.0-84973496081"
"Sharing, shared responsibility and shared governance—the new challenges and solutions of precision medicine ethics","Guoyu, W.","Kexue Tongbao/Chinese Science Bulletin","","As a new medical concept and medical model, precision medicine cannot develop without the collection, storage and sharing of medical clinical data and biomedical big data. These data include personal information such as personal genetic information, electronic medical records, living environment and clinical data. However, information sharing in the context of big data faces many ethical challenges: (1) the issue of ownership of biomedical data, that is, once the biological information (including behavioral information) originally belonging to individuals is mined;  (2) the exposure of personal privacy and group privacy and the resulting discrimination and injustice;  (3) the reconstruction of the subject of informed consent and the unclear purpose;  (4) data conversion for the distribution of benefits after the value, etc. Precision medicine is a scientific and technological activity that benefits both individuals and humankind in general. The development of precision medicine must resolve the contradiction between data sharing and privacy protection. The key to solving this problem is to establish a biomedical big data management mechanism of sharing, joint responsibility, and joint governance, so as to lead the development of precision medicine in the direction of rigorous regulation, scientific order, effective implementation, and proper supervision. On the one hand, it is necessary to strengthen the sense of responsibility and ethics of scientific researchers;  on the other hand, it is necessary to strengthen the supervision and governance responsibilities of institutions. On the basis of ensuring the security of personal data, the public is encouraged to donate and contribute personal biomedical data in the spirit of solidarity, benevolence, and mutual aid. To this end, this paper puts forward the following principles: first, respect independent decision-making and encourage data sharing. It must be clear that individuals are the subjects of rights to their biomedical data. At the same time, the public is encouraged to actively participate in precision medicine cohort studies and actively share personal data. Second, protect privacy and balance risks and benefits. While ensuring the sharing of biomedical data, no one shall infringe on personal privacy and endanger the safety of individuals and related groups. To this end, it is necessary to develop and construct privacy and security protection information technology and policies, laws and regulations corresponding to precision medicine from multiple dimensions such as technology, ethics, policy and law. Third, to strengthen shared responsibility and strengthen institutional governance, it is necessary to strengthen moral education and ethical training for practitioners involved in biomedical data, not only to make relevant personnel familiar with and master relevant national laws and regulations, but also to strengthen the privacy protection responsibility of relevant personnel. Those who intentionally leak or even maliciously sell and transfer other people’s biomedical data should be held accountable legally and administratively. © 2023 chinese academy of sciences. All rights reserved.","","","2023","10.1360/tb-2022-1293","","","scopus-2-s2.0-85160363806.pdf","scopus-2-s2.0-85160363806"
"Short-term reproducibility of ambulatory blood pressure measurements: a systematic review and meta-analysis of 35 observational studies","Bo Y., Kwok K. O., Chung V. C., Yu C. P., Tsoi K. K., Wong S. Y., Lee E. K.","Journal of Hypertension","","OBJECTIVE: A systematic review on the reproducibility of ambulatory blood pressure measurements (ABPM) has not yet been conducted. This meta-analysis compared 24-h/daytime/night-time SBP and DBP mean values and SBP/DBP nocturnal dipping status from ABPMs in participants with or without hypertension.\\\\\\\\rMETHODS: Ovid MEDLINE EMBASE and CINAHL Complete databases were searched for articles published before 3 May 2019. Eligible studies reporting a 24-h ABPM repeated at least once within 1 month were included. The mean daytime/night-time/24-h BP values percentage of nocturnal dipping and proportion of nondippers were compared between the first and second day of measurements and the proportion of participants with inconsistent dipping status were estimated using a random effect model.\\\\\\\\rRESULTS: Population-based analysis found a 0-1.1 mmHg difference between the first and second ABPM for 24-h/daytime/night-time SBP and DBP and 0-0.5% for percentage of SBP/DBP nocturnal dipping. The proportion of non-dippers was not different between the first and second ABPM. Intra-individual analysis found that the 95% limit of agreements (LOA) for SBP/DBP were wide and the 95% LOA for daytime SBP common reference to diagnose hypertension ranged -16.7 to 18.4 mmHg. Similarly 32% of participants had inconsistent nocturnal dipping status.\\\\\\\\rCONCLUSION: ABPM had excellent reproducibility at the population level favouring its application for research purposes; but reproducibility of intra-individual BP values and dipping status from a 24-h ABPM was limited. The available evidence was limited by the lack of high-quality studies and lack of studies in non-Western populations.","","","2020","10.1097/hjh.0000000000002522","","","medline-32555001.pdf","medline-32555001"
"A mobile agent approach for p2p-based semantic file retrieval","Fukuta, N.","Journal Of Information Processing","","Peer-to-peer (p2p) data sharing is a valuable approach for sharing data among people when they are belonging to different institutions. There are strong demands on both flexible, high-precision search and protection of privacy at peer-to-peer data retrievals. Especially, it is demanded for searching relevant files in p2p environment by using metadata while the terms in metadata that are used in such queries and annotations include some private information. In this paper, i present a mechanism and an analysis of p2p-based semantic file sharing and retrieval that uses mobile agents. The mechanism enables us to utilize private ontologies for flexible concept-oriented semantic searches without loss of privacy in processing semantic matching among private metadata of files and the requested semantic queries. The private ontologies are formed on a certain reference ontology with differential ontologies for personalization. In my approach, users can manage and annotate their files with their own private ontologies. Reference ontologies are used to find out semantically relevant files for the given queries that include semantic relations among existing files and the requested files. Mobile agent approach is applied for both implementing a system with less use of network bandwidth and coding it into a set of simple and small programs. I show the effectiveness of the use of private ontologies in metadata-based file retrieval. Also i show that the mobile agent approach has somewhat less overhead in execution time when the network latency is relatively high, while it is small enough even when the network is ideally fast. © 2012 information processing society of japan.","","","2012","10.2197/ipsjjip.20.607","","","scopus-2-s2.0-84871221523.pdf","scopus-2-s2.0-84871221523"
"Principles Relevant to Health Research among Indigenous Communities","O'Donahoo F. J., Ross K. E.","International Journal of Environmental Research & Public Health [Electronic Resource]","","Research within Indigenous communities has been criticised for lacking community engagement for being exploitative and for poorly explaining the processes of research. To address these concerns and to ensure 'best practice' Jamieson et al. (2012) recently published a summary of principles outlined by the NHMRC (2003) in ""one short accessible document"". Here we expand on Jamieson et al.'s paper which while commendable lacks emphasis on the contribution that communities themselves can make to the research process and how culturally appropriate engagement can allow this contribution to be assured specifically with respect to engagement with remote communities. Engagement started before the research proposal is put forward and continued after the research is completed has integrity. We emphasise the value of narratives of understanding cultural and customary behaviours and leadership the importance of cultural legitimacy and of the need for time not just to allow for delays but to ensure genuine participatory engagement from all members of the community. We also challenge researchers to consider the outcomes of their research on the basis that increasing clinical evidence does not always result in better outcomes for the community involved.","","","2015","10.3390/ijerph120505304","","","medline-25996884.pdf","medline-25996884"
"Reducing meat consumption by appealing to animal welfare: protocol for a meta-analysis and theoretical review","Mathur, M.b. And Robinson, T.n. And Reichling, D.b. And Gardner, C.d. And Nadler, J. And Bain, P.a. And Peacock, J.","Systematic Reviews","","Background: reducing meat consumption may improve human health, curb environmental damage and greenhouse gas emissions, and limit the large-scale suffering of animals raised in factory farms. Previous work has begun to develop interventions to reduce individual meat consumption, often by appealing directly to individual health motivations. However, research on nutritional behavior change suggests that interventions additionally linking behavior to ethical values, identity formation, and existing social movements may be particularly effective and longer-lasting. Regarding meat consumption, preliminary evidence and psychological theory suggest that appeals related to animal welfare may have considerable potential to effectively leverage these elements of human psychology. We aim to conduct a systematic review and quantitative meta-analysis evaluating the effectiveness of animal welfare-related appeals on actual or intended meat consumption or purchasing. Our investigation will critically synthesize the current state of knowledge regarding psychological mechanisms of intervening on individual meat consumption and empirically identify the psychological characteristics underlying the most effective animal welfare-based interventions. Methods: we will systematically search eight academic databases and extensively search unpublished grey literature. We will include studies that assess interventions intended to reduce meat consumption or purchase through the mention or portrayal of animal welfare, that measure outcomes related to meat consumption or purchase, and that have a control condition. Eligible studies may recruit from any human population, be written in any language, and be published or released any time. We will meta-analyze the studies, reporting the pooled point estimate and additional metrics that describe the distribution of potentially heterogeneous effects. We will assess studies' risk of bias and conduct sensitivity analyses for publication bias. We describe possible follow-up analyses to investigate hypothesized moderators of intervention effectiveness. Discussion: the findings of the proposed systematic review and meta-analysis, including any identified methodological limitations of the existing literature, could inform the design of successful evidence-based interventions with broad potential to improve human, animal, and environmental well-being. Systematic review registration: the protocol was preregistered via the open science framework (https://osf.io/d3y56/registrations). © 2020 the author(s).","","","2020","10.1186/s13643-019-1264-5","","","scopus-2-s2.0-85077564505.pdf","scopus-2-s2.0-85077564505"
"[Studies of mutagenic activity of positively charged alkyl glycerolipids in Ames test]","Romanova S. G., Belitskii G. A., Khitrovo I. A., Serebrennikova G. A., Shtil A. A.","Biomeditsinskaia Khimiia","","Mutagenic activity of non-phosphorous cationic alkyl glycerolipid rac-N-{4-[(2-Methoxy-3-octadecyloxy)propyl]oxycarbonylbutyl}-NN-dimethyl-N-(2-hydroxyethyl) ammonium iodide was evaluated. According performed Ames assay results indicated on non-mutagenic properties tested compound. Resulting data open the possibility to carry out biological study in vivo for class of ether cationic glycerolipids and further applications as a potential agent of anticancer therapy.","","","2011","","","","medline-22066268.pdf","medline-22066268"
"A socioecological perspective on intimate partner violence research: a decade in review","Hardesty, J.l. And Ogolsky, B.g.","Journal Of Marriage And Family","","Intimate partner violence (ipv) is a significant public health issue impacting millions globally. To frame this decade in review, we organize the research published since 2010 at each of four ecological levels (individual, relational, community, and sociocultural) to demonstrate advances and gaps in each. At the individual and relational level, we review the prevalence, directionality, typologies, predictors, and outcomes of ipv. We attend to postseparation dynamics as well as research on youth exposure. We also discuss key theoretical advances. Our review of individual and relational research is more substantial as most research on ipv focuses on these factors with less attention to community and sociocultural contexts. Reflecting the state of the research within each ecological level, we review men's violence against women and incorporate developing research on men's victimization, reciprocal violence between men and women, and ipv among same-sex partners. Throughout the review, we address key developments in knowledge as well as gaps and methodological strengths and limitations. We close with an integrated summary and recommendations for rigorous collaborative research across disciplines in the next decade to broaden our knowledge base and inform preventions and interventions. © 2019 national council on family relations","","","2020","10.1111/jomf.12652","","","scopus-2-s2.0-85077321777.pdf","scopus-2-s2.0-85077321777"
"Big data for business management in the retail industry","Santoro, G. And Fiano, F. And Bertoldi, B. And Ciampi, F.","Management Decision","","Purpose: the purpose of this paper is to shed light on how big data deployment transforms organizational practices, thereby generating potential benefits, in a specific industry: retail. Design/methodology/approach: to achieve the paper’s goal, the authors have conducted several semi-structured interviews with marketing managers of four retailers in italy, and researched secondary data to get a broader picture of big data deployment in the organizations. Findings: data analysis helped identify specific aspects related to big data deployment, data gathering methods, required competences and data sharing approaches. Originality/value: despite the growing interest in big data in various fields of research, there are still few empirical studies on big data deployment in organizations in the management field, and even fewer on specific sectors. This research provides evidence of specific areas of analysis concerning big data in the retail industry. © 2018, emerald publishing limited.","","","2019","10.1108/md-07-2018-0829","","","scopus-2-s2.0-85057624886.pdf","scopus-2-s2.0-85057624886"
"Conservative and adaptive reuse interventions in qatar","Mazzetto, S.","Preservation, Digital Technology And Culture","","In the past decades, many gulf cities have faced accelerated growth that has generated complicated problems of urbanization. Some arab cities have transformed massive urban development into new global cities despite their relatively short history. Contrasting the direction of the rapid urbanization, there is a growing interest in the conservation and rehabilitation of the local heritage, which has generated a perpetual conflict between the construction of contemporary identity and the promotion of traditional architecture. The new emerging arab cities, in the struggle for the construction of their new architectural identity, showed a growing interest in the action needed to preserve architectural heritage. The number of conservation projects has increased recognition of the local traditions in construction, rejuvenating the historical value of the qatari heritage. This paper shows significant examples of conservation and adaptive reuse projects recently completed in qatar. The intention is to describe several conservation interventions, compare the proposals for reusing the restored artifacts, and compare the preservation methodologies and techniques within the historical, political, and social forces that inform preservation practices. The research presents a possible methodology for classifying the proposals offering a new approach for comparing the interventions that could be applied to other adaptive reuse projects. © 2022 walter de gruyter gmbh, berlin/boston.","","","2022","10.1515/pdtc-2022-0004","","","scopus-2-s2.0-85135939742.pdf","scopus-2-s2.0-85135939742"
"Cloudflow: a data-aware programming model for cloud workflow applications on modern hpc systems","Zhang, F. And Malluhi, Q.m. And Elsayed, T. And Khan, S.u. And Li, K. And Zomaya, A.y.","Future Generation Computer Systems","","Traditional high-performance computing (hpc) based big-data applications are usually constrained by having to move large amount of data to compute facilities for real-time processing purpose. Modern hpc systems, represented by high-throughput computing (htc) and many-task computing (mtc) platforms, on the other hand, intend to achieve the long-held dream of moving compute to data instead. This kind of data-aware scheduling, typically represented by hadoop mapreduce, has been successfully implemented in its map phase, whereby each map task is sent out to the compute node where the corresponding input data chunk is located. However, hadoop mapreduce limits itself to a one-map-to-one-reduce framework, leading to difficulties for handling complex logics, such as pipelines or workflows. Meanwhile, it lacks built-in support and optimization when the input datasets are shared among multiple applications and/or jobs. The performance can be improved significantly when the knowledge of the shared and frequently accessed data is taken into scheduling decisions. To enhance the capability of managing workflow in modern hpc system, this paper presents cloudflow, a hadoop mapreduce based programming model for cloud workflow applications. Cloudflow is built on top of mapreduce, which is proposed not only being data aware, but also shared-data aware. It identifies the most frequently shared data, from both task-level and job-level, replicates them to each compute node for data locality purposes. It also supports user-defined multiple map- and reduce functions, allowing users to orchestrate the required data-flow logic. Mathematically, we prove the correctness of the whole scheduling framework by performing theoretical analysis. Further more, experimental evaluation also shows that the execution runtime speedup exceeds 4x compared to traditional mapreduce implementation with a manageable time overhead. © 2014 elsevier b.v. All rights reserved.","","","2015","10.1016/j.future.2014.10.028","","","scopus-2-s2.0-84930575853.pdf","scopus-2-s2.0-84930575853"
"Socio-semantic integration of educational resources - the case of the meducator project","Dietze, S. And Kaldoudi, E. And Dovrolis, N. And Giordano, D. And Spampinato, C. And Hendrix, M. And Protopsaltis, A. And Taibi, D. And Yu, H.q.","Journal Of Universal Computer Science","","Research in technology-enhanced learning (tel) throughout the last decade has largely focused on sharing and reusing educational resources and data. This effort has led to a fragmented landscape of competing metadata schemas, such as ieee lom or adl scorm, and interface mechanisms, such as oai-pmh, sqi and rest-ful services in general. More recently, semantic technologies were taken into account to improve interoperability. However, so far web-scale integration of resources is not facilitated, mainly due to the lack of take-up of shared principles, datasets and schemas. On the other hand, the linked data approach has emerged as the de facto standard for sharing data on the web and is fundamentally based on established w3c standards. This paper presents results of the european commission-funded project meducator, which exploits linked data principles for (1) semantic integration and (2) social interconnecting of educational data, resources and actors. We describe a general approach to exploit the wealth of already existing educational data on the web by allowing its exposure as linked data and by taking into account automated enrichment and interlinking techniques to provide a rich and well-interlinked graph for the educational domain. Additionally, the paper presents an evaluation of our work with respect to a set of socio-semantic dimensions. Experimental results demonstrate improved interoperability and retrievability of the resulting resource descriptions as part of an interlinked resource graph. © j.ucs.","","","2013","","","","scopus-2-s2.0-84884488164.pdf","scopus-2-s2.0-84884488164"
"Advancing research methodologies in management: revisiting debates, setting new grounds for pluralism","Christofi, M. And Ηadjielias, E. And Hughes, M. And Plakoyiannaki, E.","British Journal Of Management","","The purpose of this introduction and special issue (si) is to offer a unique and timely opportunity to explore, revisit and critically examine key methodological debates and tensions with the purpose of advancing diversity and novel theorizing in the field. We join voices with the authors of the five papers of this si to problematize taken-for-granted assumptions and research traditions and pave the way for inclusive and novel theorizing in management scholarship. We revisit four long-lasting debates that hinder methodological pluralism and diversity in management scholarship: (a) the quantitative-qualitative research divide, (b) the legitimacy of mixed-methods research, (c) the rigour versus relevance tension and (d) the lack of methodological innovation. We suggest that these debates are at least partly counterproductive because they create silos and opposing camps, thereby inhibiting an appreciation of different worldviews and collective learning. The dominance of functionalism and positivism in quantitative research and the inappropriate transfer of quantitative logics in qualitative research have led to a lack of diversity in empirical methodologies. The field's limited methodological diversity is further proliferated by a strict adherence to quality standards that have inadvertently promoted homogeneity. This introduction highlights the challenges and potential of mixed methods, which are gaining momentum owing to calls for methodological pluralism. We also call for a re-evaluation of quality standards to encourage more innovative and diverse research methodologies. © 2024 the authors. British journal of management published by john wiley & sons ltd on behalf of british academy of management.","","","2024","10.1111/1467-8551.12791","","","scopus-2-s2.0-85181234764.pdf","scopus-2-s2.0-85181234764"
"Crowdsourcing seizure detection: algorithm development and validation on human implanted device recordings","Baldassano S.n. And Brinkmann B.h. And Ung H. And Blevins T. And Conrad E.c. And Leyde K. And Cook M.j. And Khambhati A.n. And Wagenaar J.b. And Worrell G.a. And Litt B.","Brain","","There exist significant clinical and basic research needs for accurate, automated seizure detection algorithms. These algorithms have translational potential in responsive neurostimulation devices and in automatic parsing of continuous intracranial electroencephalography data. An important barrier to developing accurate, validated algorithms for seizure detection is limited access to high-quality, expertly annotated seizure data from prolonged recordings. To overcome this, we hosted a kaggle.com competition to crowdsource the development of seizure detection algorithms using intracranial electroencephalography from canines and humans with epilepsy. The top three performing algorithms from the contest were then validated on out-of-sample patient data including standard clinical data and continuous ambulatory human data obtained over several years using the implantable neurovista seizure advisory system. Two hundred teams of data scientists from all over the world participated in the kaggle.com competition. The top performing teams submitted highly accurate algorithms with consistent performance in the out-of-sample validation study. The performance of these seizure detection algorithms, achieved using freely available code and data, sets a new reproducible benchmark for personalized seizure detection. We have also shared a 'plug and play' pipeline to allow other researchers to easily use these algorithms on their own datasets. The success of this competition demonstrates how sharing code and high quality data results in the creation of powerful translational tools with significant potential to impact patient care.copyright © the author (2017).","","","2017","10.1093/brain/awx098","","","embase-617273167.pdf","embase-617273167"
"Ebss: a secure blockchain-based sharing scheme for real estate financial credentials","Wu, Y. And Tie, G. And Yu, Y. And Li, J. And Song, J.","World Wide Web","","With the development of internet finance, the real estate financial credentials have been extensively utilized in capital and trading markets. The extensive use of these private credentials, e.g., exchange, circulation or sharing on public clouds, can cause severe security and privacy problems. Existing security solutions for financial credentials may either introduce undesired overhead or fail to provide traceability and anonymity for data sharing. In this paper, we propose an enhanced blockchain-based secure sharing scheme for real estate financial credentials, providing the following three properties: credential confidentiality, anonymous authentication, identity tracking and transaction auditing. A comprehensive evaluation, including security analysis, efficiency analysis and simulation evaluation, is presented to show the security and feasibility of the proposed scheme. © 2022, the author(s), under exclusive licence to springer science+business media, llc, part of springer nature.","","","2023","10.1007/s11280-022-01106-2","","","scopus-2-s2.0-85139230242.pdf","scopus-2-s2.0-85139230242"
"Clinical academic careers for general practice nurses: a rapid evidence assessment","Bradbury A., Shortland S., Jones S., Hewett F., And Karen Storey","Journal of Research in Nursing","","BACKGROUND: Clinical academics are health professionals who provide direct patient care alongside engaging in health research. Despite the generally agreed consensus that such roles enhance evidence-based care availability and uptake has been sporadic in non-medical professions. With no data readily available regarding general practice nurses undertaking clinical academic roles there is a need to understand the barriers and enabling factors that impact general practice nurses considering or pursuing a clinical academic career.\\\\\\\\rAIMS: This review aims to address the question 'What are the barriers and enablers relevant to general practice nurses in the UK pursuing clinical academic careers?' by providing an overview of the relevant existing literature and drawing out the implications for policy and practice.\\\\\\\\rMETHODS: Literature published in the past 10 years was systematically searched. Using agreed inclusion criteria papers were first screened on titles and abstracts with papers included at this stage reviewed as full texts.\\\\\\\\rRESULTS: Thirteen papers met the criteria for inclusion. The extraction and synthesis of findings allowed for the development of three themes: roles and responsibilities; embarking on a clinical academic career; and organisational research culture.\\\\\\\\rCONCLUSIONS: Findings suggest that infrastructure developments are required across higher education institutions and general practice organisations to bring about a cultural change to equip and empower general practice nurses to consider and pursue clinical academic careers. Copyright © The Author(s) 2020.","","","2021","10.1177/1744987120954261","","","medline-35251266.pdf","medline-35251266"
"High resolution mass spectrometry-based non-target screening can support regulatory environmental monitoring and chemicals management","Hollender, J. And Van Bavel, B. And Dulio, V. And Farmen, E. And Furtmann, K. And Koschorreck, J. And Kunkel, U. And Krauss, M. And Munthe, J. And Schlabach, M. And Slobodnik, J. And Stroomberg, G. And Ternes, T. And Thomaidis, N.s. And Togola, A. And Tornero, V.","Environmental Sciences Europe","","Non-target screening (nts) including suspect screening with high resolution mass spectrometry has already shown its feasibility in detecting and identifying emerging contaminants, which subsequently triggered exposure mitigating measures. Nts has a large potential for tasks such as effective evaluation of regulations for safe marketing of substances and products, prioritization of substances for monitoring programmes and assessment of environmental quality. To achieve this, a further development of nts methodology is required, including: (i) harmonized protocols and quality requirements, (ii) infrastructures for efficient data management, data evaluation and data sharing and (iii) sufficient resources and appropriately trained personnel in the research and regulatory communities in europe. Recommendations for achieving these three requirements are outlined in the following discussion paper. In particular, in order to facilitate compound identification it is recommended that the relevant information for interpretation of mass spectra, as well as about the compounds usage and production tonnages, should be made accessible to the scientific community (via open-access databases). For many purposes, nts should be implemented in combination with effect-based methods to focus on toxic chemicals. © 2019, the author(s).","","","2019","10.1186/s12302-019-0225-x","","","scopus-2-s2.0-85069043099.pdf","scopus-2-s2.0-85069043099"
"Sexual health promotion for sexual and gender minorities in primary care: a scoping review protocol","Homme P., Truong R., Gong J., Ziegler C., Freitas C., Yeung A., Tan D. H., Burchell A. N.","BMJ Open","","INTRODUCTION: Sexual and gender minorities (SGMs) face health disparities related to systemic discrimination and barriers to sexual health. Sexual health promotion encompasses strategies that enable individuals groups and communities to make informed decisions regarding their sexual well-being. Our objective is to describe the existing sexual health promotion interventions tailored for SGMs within the primary care context.\\\\\\\\rMETHODS AND ANALYSIS: We will conduct a scoping review and search for articles in 12 medical and social science academic databases on interventions that are targeted towards SGMs in the primary care context in industrialised countries. Searches were conducted on 7 July 2020 and 31 May 2022. We defined sexual health interventions in the inclusion framework as: (1) promote positive sexual health or sex and relationship education; (2) reduce the incidence of sexually transmitted infections; (3) reduce unintended pregnancies; or (4) change prejudice stigma and discrimination around sexual health or increase awareness surrounding positive sex. Two independent reviewers will select articles meeting inclusion criteria and extract data. Participant and study characteristics will be summarised using frequencies and proportions. Our primary analysis will include a descriptive summary of key interventional themes from content and thematic analysis. Gender-based Analysis Plus will be used to stratify themes based on gender race sexuality and other identities. The secondary analysis will include the use of the Sexual and Gender Minority Disparities Research Framework to analyse the interventions from a socioecological perspective.\\\\\\\\rETHICS AND DISSEMINATION: No ethical approval is required for a scoping review. The protocol was registered on the Open Science Framework Registries (https://doi.org/10.17605/OSF.IO/X5R47). The intended audiences are primary care providers public health researchers and community-based organisations. Results will be communicated through peer-reviewed publication conferences rounds and other opportunities to reach primary care providers. Community-based engagement will occur through presentations guest speakers community forums and research summary handouts. Copyright © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.","","","2023","10.1136/bmjopen-2022-066704","","","medline-36868597.pdf","medline-36868597"
"Attitude of nursing students toward scientific research: a cross-sectional study in turkey","Ünver, S. And Semerci, R. And Özkan, Z.k. And Avcibaşi, I.","Journal Of Nursing Research","","Background: nursing, a social applied science, is a dynamic profession. Professional nurses must be curious, investigative, and open to learning as well as practice critical and analytic thinking to sustain their professionalism. Purpose: the aim of this study was to determine the attitudes of nursing students toward scientific research. Methods: a descriptive and cross-sectional study design was used. This study was conducted at a nursing department of a university in turkey. A sample of 375 nursing students participated. Data were collected using the ""personal information form"" and ""attitude scale towards scientific studies."" Standard descriptive statistical methods, correlation, mann-whitney u, kruskal-wallis, and post hoc bonferroni were used in data analysis. Results: nearly all (90.1%) of the participants were female, and 33.9% were sophomore (second-year) students. Junior (third-year) students held the most positive attitudes toward research, as compared with the participants in other academic years. Participants who had participated in scientific activities held more positive attitudes toward research than those who had not. Participants who had prior experience doing scientific research showed more positive attitudes toward research and researchers than those without this experience. Being older, having scientific research experience, following the continuous broadcasts related to nursing, and participating in scientific activities all significantly influenced attitude toward research (p <.05). Conclusions/implications for practice: although nursing students who participated in this study exhibited generally positive attitudes toward scientific research, they had relatively little experience participating in scientific activities. Therefore, to foster a positive scientific research culture among undergraduate students, grants should be provided that encourage wider participation in scientific activities and offer opportunities for undergraduate students to do scientific research.","","","2018","10.1097/jnr.0000000000000244","","","scopus-2-s2.0-85053561368.pdf","scopus-2-s2.0-85053561368"
"Quality of survival reporting in chemotherapy and surgery trials in patients with metastatic colorectal carcinoma","Martin R. C., Augenstein V. A., Scoggins C. R., McMasters K. M.","Cancer","","BACKGROUND: Patients with metastatic colorectal carcinoma (MCC) to the liver receive conflicting management recommendations because of the lack of prospective randomized controlled trials (RCTs) clarifying the optimal management in this disease. The objective of the current study was to evaluate the reporting of prognostic factors in MCC from chemotherapy and surgery trials and evaluate the ability to compare these results across treatments.\\\\\\\\rMETHODS: RCTs and retrospective series of greater than 75 MCC patients published between 1980-2004 were reviewed to identify 10 critical prognostic elements of overall survival reported in both types of journals.\\\\\\\\rRESULTS: A review 92 RCTs and 116 retrospective reports with 64898 patients analyzed found 7 (3%) reporting all prognostic factors with both studies demonstrating no difference in the success of reporting criteria met. The only criterion that was universally reported among both chemotherapy and surgery trials was the mortality rates of the study. All remaining prognostic factors in the evaluation of overall survival were significantly different between both chemotherapy and surgical studies. Considerable variation was observed in the disease-free interval number of hepatic metastases size of hepatic metastases and performance status and were significantly different among some of the most significant factors for patients evaluating treatment: complication reporting surgical margin evaluation and overall response rate.\\\\\\\\rCONCLUSIONS: The reporting of results in MCC in chemotherapy trials and surgical reports is limited to general outcomes with a paucity of prognostic factors which hinders any ability to compare results across treatments. A mandatory reporting criteria of all metastatic colorectal trials is imperative to optimally manage these patients in both academic and community centers. Copyright (c) 2006 American Cancer Society.","","","2006","","","","medline-16453329.pdf","medline-16453329"
"A health informatics transformation model based on intelligent cloud computing - exemplified by type 2 diabetes mellitus with related cardiovascular diseases","Lin H.-C. And Kuo Y.-C. And Liu M.-Y.","Comput. Methods Programs Biomed","","Background and objective: many studies regarding health analysis request structured datasets but the legacy resources provide scattered data. This study aims to establish a health informatics transformation model (hitm) based upon intelligent cloud computing with the self-developed analytics modules by open source technique. The model was exemplified by the open data of type 2 diabetes mellitus (dm2) with related cardiovascular diseases. Method(s): the apache-spark framework was employed to generate the infrastructure of the hitm, which enables the machine learning (ml) algorithms including random forest, multi-layer perceptron classifier, support vector machine, and naive bayes classifier as well as the regression analysis for intelligent cloud computing. The modeling applied the mimic-iii open database as an example to design the health informatics data warehouse, which embeds the pl/sql-based modules to extract the analytical data for the training processes. A coupling analysis flow can drive the ml modules to train the sample data and validate the results. Result(s): the four modes of cloud computation were compared to evaluate the feasibility of the cloud platform in accordance with its system performance for more than 11,500 datasets. Then, the modeling adaptability was validated by simulating the featured datasets of obesity and cardiovascular-related diseases for patients with dm2 and its complications. The results showed that the run-time efficiency of the platform performed in around one minute and the prediction accuracy of the featured datasets reached 90%. Conclusion(s): this study helped contribute the modeling for efficient transformation of health informatics. The hitm can be customized for the actual clinical database, which provides big data for training, with the proper ml modules for a predictable process in the cloud platform. The feedback of intelligent computing can be referred to risk assessment in health promotion.copyright © 2020","","","2020","10.1016/j.cmpb.2020.105409","","","embase-2005113198.pdf","embase-2005113198"
"How qualitative research methods can be leveraged to strengthen mixed methods research in public policy and public administration?","Hendren, K. And Newcomer, K. And Pandey, S.k. And Smith, M. And Sumner, N.","Public Administration Review","","Recently, there have been a variety of arguments voiced to encourage that more attention be given to the role qualitative methods can play in mixed methods research in public policy and public administration. This article discusses these claims and describes the benefits of qualitative approaches, and how qualitative research methods can be leveraged to strengthen mixed methods research in public administration. We also provide a guide for improving the credibility of mixed methods research through increasing transparency and discussions of all methodological decisions. This study is based on a systematic content analysis of 186 mixed methods studies published in public policy and public administration journals between 2010 and 2018. We found that findings from the quantitative methods dominated the mixed methods studies, little diversity in data collection and analysis methods, and frequent failure to integrate insights from both methods. We also analyzed the 36 qualitative-dominant studies in the sample, and illuminated seven different ways that authors of qualitative-dominant studies leveraged the qualitative strand to strengthen mixed methods research. We developed lessons from our analysis of the qualitative-dominant articles on how to incorporate qualitative methods in a thoughtful manner, articulate a role for each strand, and effectively support findings with one or more strands. © 2022 american society for public administration.","","","2023","10.1111/puar.13528","","","scopus-2-s2.0-85132606461.pdf","scopus-2-s2.0-85132606461"
"The pearl-dgs formula: the development of an open-source machine learning-based thick iol calculation formula","Debellemaniere G. And Dubois M. And Gauvin M. And Wallerstein A. And Brenner L.f. And Rampat R. And Saad A. And Gatinel D.","Am. J. Ophthalmol","","Purpose: to describe an open-source, reproducible, step-by-step method to design sum-of-segments thick intraocular lens (iol) calculation formulas, and to evaluate a formula built using this methodology. Design(s): retrospective, multicenter case series methods: a set of 4242 eyes implanted with finevision iols (physiol, liege, belgium) was used to devise the formula design process and build the formula. A different set of 677 eyes from the same center was kept separate to serve as a test set. The resulting formula was evaluated on the test set as well as another independent data set of 262 eyes. Result(s): the lowest standard deviation (sd) of prediction errors on set 1 were obtained with the pearl-dgs formula (+/-0.382 d), followed by k6 and olsen (+/-0.394 d), evo 2.0 (+/-0.398 d), rbf 3.0, and buii (+/-0.402 d). The formula yielding the lowest sd on set 2 was the pearl-dgs (+/-0.269 d), followed by olsen (+/-0.272 d), k6 (+/-0.276 d), evo 2.0 (+/-0.277 d), and buii (+/-0.301 d). Conclusion(s): our methodology achieved an accuracy comparable to other state-of-the-art iol formulas. The open-source tools provided in this article could allow other researchers to reproduce our results using their own data sets, with other iol models, population settings, biometric devices, and measured, rather than calculated, posterior corneal radius of curvature or sum-of-segments axial lengths.copyright © 2021","","","2021","10.1016/j.ajo.2021.05.004","","","embase-2014888178.pdf","embase-2014888178"
"Automatic extraction of rock mass discontinuity based on 3d laser scanning","Chen, N. And Cai, X. And Li, S. And Zhang, X. And Jiang, Q.","Quarterly Journal Of Engineering Geology And Hydrogeology","","Discontinuity information is important in evaluating the security of a rock mass for the distribution of discontinuity spacings, which affects the mechanical properties and stability of the rock mass. Numerous studies have been conducted on the semi-automatic or automatic extraction of discontinuities from point cloud data. We developed a random sample consensus discontinuity detection (ransac) method to automatically extract discontinuities in a rock mass. The proposed method is entirely based on a raw point instead of a triangular mesh, which can retain the integrity of the data. A modified ransac algorithm is used to increase the degree of automation. The proposed approach consists of four steps: (1) calculation of the normal vector of the point cloud;  (2) plane extraction using the modified ransac algorithm;  (3) delineation of the boundary of the discontinuity using the modified graham scan algorithm;  and (4) calculation of the orientation and area on the basis of the normal vector and the boundary of the discontinuity. The results and the raw data source are freely provided for reproducible research and to develop the method further. © 2020 the author(s). Published by the geological society of london. All rights reserved.","","","2020","10.1144/qjegh2020-054","","","scopus-2-s2.0-85100464179.pdf","scopus-2-s2.0-85100464179"
"Collaboratively evaluating cooperative extension educational interventions","Webb, D. And Murphy, D.j. And Kiernan, N.e.","Journal Of Extension","","The pennsylvania central region farm safety pilot program (pacrfspp) provided an opportunity to explore several questions regarding university researchers and county agents working together to design, implement, and evaluate a multifaceted education evaluation project. All agents felt that their county's intervention was successful, and that, perhaps most important, they would continue to pursue using that intervention in future programming. They plan on expanding their safety programming in the future, using the information obtained from the intervention activities. Thus the question ""can county extension benefit from participation in a formal university research project?"" Is answered in a very positive way. On the other hand, none of the agents would willingly become involved in another research project if the same recruitment process were used. Although the researchers and agents agree that farmers are generally more receptive to the request of a familiar county agent than to that of an unknown university researcher, the experience from this project suggests that recruitment of participants should remain the responsibility of researchers. Closely related to this is the issue of time commitment to the research project. Although all agents did spend the time necessary to successfully complete the project, it was not achieved without considerable sacrifice of other work responsibilities and without the researchers allowing considerable more time for activity completion. Thus the questions ""can university researchers maintain a specific, rigorous research protocol when implementation of the protocol rests largely with field educators?"" And ""are agents able to devote adequate time to experimental programs as a part of their routine work load"" were affirmed, but in a much less satisfactory manner. In the final analysis, despite some difficulties, researchers and agents did accomplish the primary goal of the research project, namely, to scientifically evaluate models of safety education. This result suggests that the cooperative extension system can successfully meet the challenge of formal program evaluation when university researchers and county agents work together.","","","2001","","","","scopus-2-s2.0-3042687862.pdf","scopus-2-s2.0-3042687862"
"Inter subject variability and reproducibility of diffusion tensor imaging within and between different imaging sessions","Veenith, T.v. And Carter, E. And Grossac, J. And Newcombe, V.f.j. And Outtrim, J.g. And Lupson, V. And Williams, G.b. And Menon, D.k. And Coles, J.p.","Plos One","","The aim of these studies was to provide reference data on intersubject variability and reproducibility of diffusion tensor imaging. Healthy volunteers underwent imaging on two occasions using the same 3t siemens verio magnetic resonance scanner. At each session two identical diffusion tensor sequences were obtained along with standard structural imaging. Fractional anisotropy, apparent diffusion coefficient, axial and radial diffusivity maps were created and regions of interest applied in normalised space. The baseline data from all 26 volunteers were used to calculate the intersubject variability, while within session and between session reproducibility were calculated from all the available data. The reproducibility of measurements were used to calculate the overall and within session 95% prediction interval for zero change. The within and between session reproducibility data were lower than the values for intersubject variability, and were different across the brain. The regional mean (range) coefficient of variation figures for within session reproducibility were 2.1 (0.9-5.5%), 1.2 (0.4-3.9%), 1.2 (0.4-3.8%) and 1.8 (0.4-4.3%) for fractional anisotropy, apparent diffusion coefficient, axial and radial diffusivity, and were lower than between session reproducibility measurements (2.4 (1.1-5.9%), 1.9 (0.7-5.7%), 1.7 (0.7-4.7%) and 2.4 (0.9-5.8%);  p<0.001). The calculated overall and within session 95% prediction intervals for zero change were similar. This study provides additional reference data concerning intersubject variability and reproducibility of diffusion tensor imaging conducted within the same imaging session and different imaging sessions. These data can be utilised in interventional studies to quantify change within a single imaging session, or to assess the significance of change in longitudinal studies of brain injury and disease. © 2013 veenith et al.","","","2013","10.1371/journal.pone.0065941","","","scopus-2-s2.0-84879521065.pdf","scopus-2-s2.0-84879521065"
"Data sharing scheme of electronic medical record based on proxy re-encryption","Niu, S. And Liu, W. And Chen, L. And Du, X.","Jisuanji Gongcheng/Computer Engineering","","Most of the existing electronic medical records can only realize data sharing between doctors and patients, so it is difficult for data users to access the electronic medical records of patients. To solve the problem, this paper proposes a data sharing scheme of electronic medical record (emr) based on proxy re-encryption. Patients can use trapdoor search to obtain encrypted emr. The data user can ask patient and cloud server to interact with each other to obtain the patient’s emr. The cloud server generates the re-encryption key, performs proxy re-encryption on the ciphertext of the emr, and after authorized by the patient, the re-encrypted ciphertext will be sent to the data user. The data user can decrypt the ciphertext with his or her private key, and finally obtain the emr data. Results of the experiments based on the random oracle model show that the proposed scheme can achieve keyword privacy security and message privacy security under the modified bilinear diffie-hellman (mbdh) assumption and q-decision bilinear diffie-hellman inversio (q-dbdhi) assumption. © 2021, editorial office of computer engineering. All rights reserved.","","","2021","10.19678/j.issn.1000-3428.0058229","","","scopus-2-s2.0-85133479795.pdf","scopus-2-s2.0-85133479795"
"Psychological distress and the role of significant others in a population of gay/bisexual men in the era of HIV","Britton P. J., Zarski J. J., Hobfoll S. E.","AIDS Care","","This study based on The Conservation of Resources Theory (COR) explores the relationship between social resources and psychological distress as reported by gay/bisexual men who are at varying degrees of risk for HIV. This study involves theory-based stress research and adds to the body of literature that addresses social support and gay men. Specific emphasis was placed on the process of social support by significant others in relationship to the devastating impact HIV has on the gay/bisexual community. The investigators employed an ex-post facto design that was guided by past and present theoretical and empirical data and by specific research hypotheses. The findings suggest that facets of social support appear to be interactively related to the perceived threat of HIV in predicting distress. In general this study supports COR theory in that resources were related to the experience of psychological distress yet it emphasizes that the relationship between support and gay men is complex and thus generalizations from findings based on research with the majority culture may not apply to a population of gay/bisexual men. Implications for future research are also provided.","","","1993","10.1080/09540129308258583","","","medline-8461360.pdf","medline-8461360"
"Rethinking success integrity and culture in research (part 2) - a multi-actor qualitative study on problems of science","Aubert Bonn N., Pinxten W.","Research Integrity & Peer Review","","BACKGROUND: Research misconduct and questionable research practices have been the subject of increasing attention in the past few years. But despite the rich body of research available few empirical works also include the perspectives of non-researcher stakeholders.\\\\\\\\rMETHODS: We conducted semi-structured interviews and focus groups with policy makers funders institution leaders editors or publishers research integrity office members research integrity community members laboratory technicians researchers research students and former-researchers who changed career to inquire on the topics of success integrity and responsibilities in science. We used the Flemish biomedical landscape as a baseline to be able to grasp the views of interacting and complementary actors in a system setting.\\\\\\\\rRESULTS: Given the breadth of our results we divided our findings in a two-paper series with the current paper focusing on the problems that affect the integrity and research culture. We first found that different actors have different perspectives on the problems that affect the integrity and culture of research. Problems were either linked to personalities and attitudes or to the climates in which researchers operate. Elements that were described as essential for success (in the associate paper) were often thought to accentuate the problems of research climates by disrupting research culture and research integrity. Even though all participants agreed that current research climates need to be addressed participants generally did not feel responsible nor capable of initiating change. Instead respondents revealed a circle of blame and mistrust between actor groups.\\\\\\\\rCONCLUSIONS: Our findings resonate with recent debates and extrapolate a few action points which might help advance the discussion. First the research integrity debate must revisit and tackle the way in which researchers are assessed. Second approaches to promote better science need to address the impact that research climates have on research integrity and research culture rather than to capitalize on individual researchers' compliance. Finally inter-actor dialogues and shared decision making must be given priority to ensure that the perspectives of the full research system are captured. Understanding the relations and interdependency between these perspectives is key to be able to address the problems of science.\\\\\\\\rSTUDY REGISTRATION: https://osf.io/33v3m.","","","2021","10.1186/s41073-020-00105-z","","","medline-33441167.pdf","medline-33441167"
"Evaluation of the discourse power in chinese academic journals: a multi-fusion perspective","Wang, X.","Data And Information Management","","Under the environment of open science, the transformation of scientific exchange and research paradigms urgently needs diversified and open scientific evaluation. This study aims to advance the construction of academic journals, reform the quantitative evaluation mechanism, and provide references for promoting the international discourse power of chinese academic journals. It also aims to enrich and improve the indicator system and evaluation theory of the discourse power of academic journals with chinese characteristics. Firstly, this paper analyzes the fundamental concerns of the discourse power evaluation of academic journals, drawing on the theory of evaluation science, discourse power theory, and communication theory. According to the characteristics and connotation of the evaluation indicators, the definition and formation process of academic journals' discourse power, this paper constructed. the evaluation indicator system. Secondly, this paper obtained 163,628 international citations and 211,150 domestic citations, and 111,496 altmetrics indicators data for 29,203 published papers from 238 chinese english-language journals. Meanwhile, 12 scientometrics indicators and 14 altmetrics indicators are selected. Thirdly, descriptive statistical analysis and an overview indexed by international databases are carried out at the macro level. Then, correlation analysis, factor analysis, entropy weight method and topsis method are adopted to evaluate and analyze the discourse influence and discourse leading in chinese english-language journals by integrating scientometrics and altmetrics indicators. Finally, two-dimensional and four quadrant method is used to evaluate academic journals' discourse power. At the same time, this paper compares and verifies the reliability of the evaluation results. The findings demonstrate that the research on the academic journals' discourse power evaluation based on the theory, method and application logic is practical, comprehensive and reliable. This paper also puts forward the countermeasures to enhance the discourse power of chinese academic journals. © 2022 the author","","","2023","10.1016/j.dim.2022.100026","","","scopus-2-s2.0-85146941652.pdf","scopus-2-s2.0-85146941652"
"Reliability of computerized perimetric threshold tests as assessed by reliability indices and threshold reproducibility in patients with suspect and manifest glaucoma","Bengtsson B.","Acta Ophthalmologica Scandinavica","","BACKGROUND: High reproducibility of test measurements is often considered an indication of high reliability of test results. The aim of the current study was to analyse the role of the traditional perimetric reliability indices False Negative and False Positive responses and Fixation Losses as indicators of test reliability in comparison with threshold reproducibility in patients with suspect or manifest glaucoma.\\\\\\\\rMETHODS: Perimetry was performed in one eye in each of 76 patients. Each eye was tested twice within approximately one week using the Humphrey II 30-2 SITA STANDARD program. Frequencies of False Positive and False Negative answers and rates of Fixation Losses were related to threshold reproducibility and to general field status as expressed by Mean Deviation from age-normal threshold values using stepwise multiple linear regression analysis.\\\\\\\\rRESULTS: Substantial field loss was associated both with low threshold reproducibility (p<0.0001) and with increased frequency of False Negative answers (p=0.047). The traditional reliability indices contributed marginally compared to amount of field loss when predicting threshold reproducibility; the coefficient of determination decreased non-significantly from 0.37 to 0.33 when excluding the three reliability indices as explanatory variables from the regression model. Frequencies of False Positive answers and Fixation Losses showed no association to field status or to threshold reproducibility.\\\\\\\\rCONCLUSION: Reliability of visual field test results in patients with glaucoma expressed as threshold reproducibility can be predicted by amount of field loss alone and traditional patient reliability indices contribute surprisingly little in this regard.","","","2000","","","","medline-11037906.pdf","medline-11037906"
"New trends in bibliometric apis: a comparative analysis","Velez-Estevez, A. And Perez, I.j. And García-Sánchez, P. And Moral-Munoz, J.a. And Cobo, M.j.","Information Processing And Management","","The science of science practice requires the analysis of large and complex bibliometric data. Traditional data exporting from companies’ websites is not sufficient, so apis are used to access a larger corpus. Therefore, this study aims not only to establish a taxonomy but also to offer a comparative analysis of 44 bibliographic apis from various non-profit and commercial organizations, analyzing their characteristics and metadata with descriptive analysis, their possible bibliometric analyses, and the interoperability of the apis across four different data categories: general, content, search, and query modes. The study found that clarivate analytics and elsevier offer highly versatile apis, while non-profit organizations, such as opencitations and ourresearch promote the open science philosophy. Most organizations offer free access to apis for non-commercial purposes, but some have limitations on metadata retrieval. However, crossref, opencitations, or openalex have no restrictions on the metadata retrieval. Co-author analysis using author names and bibliometric evaluation using citations are the types of analyses that can be done with the data provided by most apis. Doi, pubmedid, and pmcid are the most versatile identifiers for extending metadata in the apis. Semantic scholar, dimensions, orcid, and embase are the apis that offer the most extensibility. Considering the obtained results, there is no single api that gathers all the information needed to perform any bibliometric analysis. Combining two or more apis may be the most appropriate option to cover as much information as possible and enrich reports and analyses. This study contributes to advancing the understanding and use of apis in research practice. © 2023 the author(s)","","","2023","10.1016/j.ipm.2023.103385","","","scopus-2-s2.0-85159171109.pdf","scopus-2-s2.0-85159171109"
"Searchable encrypted data file sharing method using public cloud service for secure storage in cloud computing","Pitchai, R. And Jayashri, S. And Raja, J.","Wireless Personal Communications","","Data owners are used to transmit the data using cloud computing in a low cost. The cloud computing is a popular technology to transmit the data through internet and will also act as third party users. Data owners outsource the data through the cloud server, which have to encrypt the data before outsourcing due to the security and privacy issues. After encrypting the data, users have to find out the respective data using the private key. All information has to be stored in the cloud storage unit. To optimize the cloud storage unit, safety transmission, minimize the cost and searching time, here we have proposed a new scheme as searchable encrypted data file sharing technique. This technique will allocate a keyword for every data during the encryption based on which the keyword matching will accept the data of respective users. The multi keyword search is been proposed for keyword searching. Experimental results analyze the overall performance and the proposed scheme has not only increased the efficiency but also decreased the searching time. © 2016, springer science+business media new york.","","","2016","10.1007/s11277-016-3273-1","","","scopus-2-s2.0-84961615968.pdf","scopus-2-s2.0-84961615968"
"Researchers' Perspectives Regarding Ethical Issues of Biobank Research in the Arab Region","Ibrahim M. E., Adarmouch L., Elgamri A., Abd ElHafeez S., Mohammed Z., Abdelgawad F., Elsebaie E. H., Abdelhafiz A. S., Gamel E., El Rhazi K., Abdelnaby A., Ahram M., Silverman H.","Biopreservation and Biobanking","","Background: The recent expansion of genomic biobank research in the Arab region in the Middle East North Africa has raised complex ethical and regulatory issues. However there is a lack of studies regarding the views of Arab researchers involved in such research. We aimed to assess the perceptions and attitudes of Arab researchers regarding these issues in biobank research. Methods: We developed a questionnaire to assess the perceptions and attitudes regarding genetic research of researchers from Egypt Sudan Morocco and Jordan. The questionnaire requested demographic data perceptions and attitudes regarding the collection storage and use of biospecimens and data the use of broad consent data security data sharing and community engagement. We used multiple linear regressions to identify predictors of perceptions and attitudes. Results: We recruited 383 researchers. Researchers favored equally the use of broad and tiered consent (44.1% and 39.1% respectively). Most respondents agreed with the importance of confidentiality protections to ensure data security (91.8%). However lower percentages were seen regarding the importance of community engagement (64.5%) data sharing with national colleagues and international partners (60.9% and 41.1% respectively) and biospecimen sharing with national colleagues and international partners (59.9% and 36.2% respectively). Investigators were evenly split on whether the return of individual research results should depend on the availability or not of a medical intervention that can be offered to address the genetic anomaly (47.5% and 46.4% respectively). Predictors of attitudes toward biospecimen research included serving on Research Ethics Committees prior research ethics training and affiliation with nonacademic institutions. Conclusions: We recommend further exploratory research with researchers regarding the importance of community engagement and to address their concerns about data sharing with researchers within and outside their countries.","","","2023","10.1089/bio.2022.0112","","","medline-36951637.pdf","medline-36951637"
"A peer-to-peer data sharing framework for web browsers: analysis and evaluation","Pattanaik, V. And Sharvadze, I. And Draheim, D.","Sn Computer Science","","Concerns over data ownership and misuse of personal data over the web have become increasingly widespread in recent years;  especially, as most web service providers are moving towards closed silo-based platforms, making the web more and more centralized. This is concerning, because, as service providers move towards centralized data storage and management, end-users become more susceptible to loss of data ownership and misuse of personal data. While in recent years, quite a few solutions have been proposed to solve these issues, the issues themselves still prevail, primarily due to lack of acceptance. That said, in this paper, we build on our previously proposed browser-based peer-to-peer data sharing framework. We first explain the requirements and design choices which we had to keep in mind while designing the framework. And then, we provide insights into how we evaluated the functionalities and security features of the framework, through lab experiments. Finally, we elucidate the direction in which we would like to develop the framework in the near future. © 2020, springer nature singapore pte ltd.","","","2020","10.1007/s42979-020-00236-6","","","scopus-2-s2.0-85127462723.pdf","scopus-2-s2.0-85127462723"
"A scoping review: synthesizing evidence on data management instruction in academic libraries","Xu, Z. And Zhou, X. And Kogut, A. And Watts, J.","Journal Of Academic Librarianship","","The present scoping review examines empirical rdm instruction-related studies in academic libraries between 2010 and 2021. We searched three databases (lista, eric, and medline complete) and two journals (journal of escience librarianship and international journal of digital curation) and identified 124 articles for inclusion. Cohen's kappa indicated a strong to perfect inter-rater reliability on the coding between the authors. Overall, the findings indicate an increasing trend in empirical research regarding the topic of rdm instruction across many countries and regions after 2010. Also, faculty, researchers, and librarians in the higher education field were the primary audiences for the rdm instruction with few studies addressing rdm instruction for the undergraduate and graduate levels. In terms of the rdm aspects, rdm needs assessments were investigated the most among the reviewed studies, followed by data sharing and data management plans. Additionally, the face-to-face learning context was the most popular for rdm instruction, followed by online and hybrid contexts. However, few studies used an intervention research design while delivering instruction to the target audience. This study highlights the substantial characteristics and methodological designs of the rdm instruction empirical research and provides implications for approaches and techniques used to study rdm instruction in academic libraries. © 2022","","","2022","10.1016/j.acalib.2022.102508","","","scopus-2-s2.0-85126023531.pdf","scopus-2-s2.0-85126023531"
"Mutual query data sharing protocol for public key encryption through chosen-ciphertext attack in cloud environment","Lakum, T. And Rao, B.t.","International Journal Of Electrical And Computer Engineering","","In this paper, we are proposing a mutual query data sharing protocol (mqds) to overcome the encryption or decryption time limitations of exiting protocols like boneh, rivest shamir adleman (rsa), multi-bit transposed ring learning parity with noise (trlpn), ring learning parity with noise (ring-lpn) cryptosystem, key-ordered decisional learning parity with noise (ko-dlpn), and kd_cs protocol's. Titled scheme is to provide the security for the authenticated user data among the distributed physical users and devices. The proposed data sharing protocol is designed to resist the chosen-ciphertext attack (cca) under the hardness solution for the query shared-strong diffie-hellman (sdh) problem. The evaluation of proposed work with the existing data sharing protocols in computational and communication overhead through their response time is evaluated. © this is an open access article under the cc by-sa license.","","","2022","10.11591/ijece.v12i1.pp853-858","","","scopus-2-s2.0-85118937314.pdf","scopus-2-s2.0-85118937314"
"Mods: integrated framework for secured multi-owner data sharing in cloud computing","Shajina, A.r. And Varalakshmi, P.","Journal Of Computational And Theoretical Nanoscience","","Cloud computing offers an efficient and economic solution for sharing resources among different cloud users. Yet, data sharing in a multi-owner manner and simultaneously preserving data and privacy in untrusted cloud is challenging. Therefore, this paper proposed a novel concept named mods, to address the issue of multi-owner data sharing in a dynamic environment. By leveraging, dynamic novel recursive randomized attribute encryption and decryption technique, the paper proposed intelligent auto-verification algorithm (iava algorithm) to share data anonymously. In addition, the security and efficiency of our scheme was demonstrated with rigorous proof and experiments. Further, the cost for encryption and decryption of our proposed scheme, are independent with the number of revoked users operating for decrypting the rekeying message and the data. In addition, the findings showed that the proposed algorithm could efficiently solve key escrow-related security issues, user revocation and robust data access control in a data-sharing system. © 2016 american scientific publishers all rights reserved.","","","2016","10.1166/jctn.2016.5321","","","scopus-2-s2.0-84991252904.pdf","scopus-2-s2.0-84991252904"
"Effectiveness of multimodal participant recruitment in spark, a large, online longitudinal research study of autism","Daniels, A.m. And Kiely Law, J. And Snyder, L.g. And Diehl, K. And Goin-Kochel, R.p. And Feliciano, P. And Chung, W.k. And Spark Consortium","Journal Of Clinical And Translational Science","","Background: spark launched in 2016 to build a united states cohort of autistic individuals and their family members. Enrollment includes online consent to share data and optional consent to provide saliva for genomic analysis. Spark’s recruitment strategies include social media and support of a nation-wide network of clinical sites. This study evaluates spark’s recruitment strategies to enroll a core study population. Methods: individuals who joined between january 31, 2018, and may 29, 2019 were included in the analysis. Data include sociodemographic characteristics, clinical-site referral, the website url used to join, how the participant heard about spark, enrollment completion (online registration, study consents and returning saliva sample), and completion of the baseline questionnaire. Logistic regressions were performed to evaluate the odds of core-participant status (completing enrollment and baseline questionnaire) by recruitment strategy. Results: 31,715 individuals joined during the study period, including 40% through a clinical site. Overall, 88% completed online registration;  46% returned saliva;  and 38% were core participants. Those referred by a clinical site were almost twice as likely to be core participants. Those who directly visited the spark website or performed a google search were more likely to be core participants than those who joined through social media. Discussion: being a core participant may be associated with the “personal” connection and support provided by a clinical site and/or site staff, as well as greater motivation to seek research opportunities. Findings from this study underscore the value of adopting a multimodal-recruitment approach that combines social media and a physical presence. © 2023 cambridge university press. All rights reserved.","","","2023","10.1017/cts.2023.697","","","scopus-2-s2.0-85180338406.pdf","scopus-2-s2.0-85180338406"
"A centralized informatics infrastructure for the National Institute on Drug Abuse Clinical Trials Network","Pan J. J., Nahm M., Wakim P., Cushing C., Poole L., Tai B., Pieper C. F.","Clinical Trials","","BACKGROUND: Clinical trial networks (CTNs) were created to provide a sustaining infrastructure for the conduct of multisite clinical trials. As such they must withstand changes in membership. Centralization of infrastructure including knowledge management portfolio management information management process automation work policies and procedures in clinical research networks facilitates consistency and ultimately research.\\\\\\\\rPURPOSE: In 2005 the National Institute on Drug Abuse (NIDA) CTN transitioned from a distributed data management model to a centralized informatics infrastructure to support the network's trial activities and administration. We describe the centralized informatics infrastructure and discuss our challenges to inform others considering such an endeavor.\\\\\\\\rMETHODS: During the migration of a clinical trial network from a decentralized to a centralized data center model descriptive data were captured and are presented here to assess the impact of centralization.\\\\\\\\rRESULTS: We present the framework for the informatics infrastructure and evaluative metrics. The network has decreased the time from last patient-last visit to database lock from an average of 7.6 months to 2.8 months. The average database error rate decreased from 0.8% to 0.2% with a corresponding decrease in the interquartile range from 0.04%-1.0% before centralization to 0.01-0.27% after centralization. Centralization has provided the CTN with integrated trial status reporting and the first standards-based public data share. A preliminary cost-benefit analysis showed a 50% reduction in data management cost per study participant over the life of a trial.\\\\\\\\rLIMITATIONS: A single clinical trial network comprising addiction researchers and community treatment programs was assessed. The findings may not be applicable to other research settings.\\\\\\\\rCONCLUSIONS: The identified informatics components provide the information and infrastructure needed for our clinical trial network. Post centralization data management operations are more efficient and less costly with higher data quality.","","","2009","10.1177/1740774508100983","","","medline-19254937.pdf","medline-19254937"
"Natural products discovery needs improved taxonomic and geographic information. [Review]","Leal M. C., Hilario A., Munro M. H., Blunt J. W., Calado R.","","","Covering: up to 2016Marine and terrestrial organisms yield a remarkable chemical diversity and are important sources for discovery of new chemical products. In order to maximize the bioprospecting efficiency of natural products (NP) taxonomy geography and biodiversity are starting to be used to draw conclusions on which taxonomic groups and/or regions may be of interest for future research. However accurate taxonomic information and sampling location of source organisms have often been overlooked. Although these issues were already reported a few decades ago and improvements have been made such outstanding problems are still recurrent in recent peer-reviewed literature. Here we focus on the importance of taxonomic and geographic identification of source material and illustrate how taxonomic and geographic data of source organisms continues to be poorly handled. It is our opinion that this issue needs to be discussed within the NP community with the ultimate goal of improving publication standards and guaranteeing the scientific principle of research reproducibility. Moreover by doing so it will be possible to take advantage of information available in the literature to develop cross-disciplinary meta-analyses that may help to advance the state of the art of NP research and future bioprospecting endeavours.","","","2016","","","","unknown-1817.pdf","unknown-1817"
"Patient and public involvement in stroke research: a scoping review protocol","Hall P., Kroll T., Hickey J., Stokes D., Lennon O.","Hrb Open Research","","Background: Growing consensus supports public and patient involvement (PPI) in research as the lived experience of patients family carers and users of health and social care services bring unique insights to healthcare research. The impact and burden of stroke present ongoing challenges for those living with its consequences and could potentially limit PPI activity. This review aims to explore PPI in published stroke research to identify and describe the extent nature and design of PPI activities the type/s of studies involved and the profile of PPI participants engaged in stroke research. Methods: This systematic scoping review guided by the Arksey & O'Malley five step framework will be reported according to the PRISMA-ScR reporting guidelines. PPI is embedded at each stage of this proposed scoping review from conceptualisation participation contribution and collaboration. The Population Concept Context (PCC) structure defines the research question which asks - How is PPI in stroke research currently being conducted and how do the study authors report their PPI activities and its impact? A comprehensive range of electronic databases including PubMed CINAHL EMBASE PsychINFO and the Cochrane Database of Systematic Reviews will generate a broad range of studies. Grey literature (e.g. OpenGrey Leanus) and internationally recognised stroke organisation websites will be searched for additional research reports. Data extraction will adhere to the Joanna Briggs Institute guidelines with results collated and mapped to the research cycle stage/s. Conclusions: The outlined scoping review protocol will comprehensively identify and map the existing scientific literature that reports PPI in stroke research. Findings will be presented in relation to PPI conceptualisation participant profiles and activities in stroke research volume type and range of approaches. Knowledge gaps and future priorities for PPI in stroke research will be identified. Copyright: © 2021 Hall P et al.","","","2021","10.12688/hrbopenres.13449.1","","","medline-35967008.pdf","medline-35967008"
"Response to physical rehabilitation and recovery trajectories following critical illness: individual participant data meta-analysis protocol","Jones, J.r.a. And Berney, S. And Berry, M.j. And Files, D.c. And Griffith, D.m. And Mcdonald, L.a. And Morris, P.e. And Moss, M. And Nordon-Craft, A. And Walsh, T. And Gordon, I. And Karahalios, A. And Puthucheary, Z. And Denehy, L.","Bmj Open","","Introduction the number of inconclusive physical rehabilitation randomised controlled trials for patients with critical illness is increasing. Evidence suggests critical illness patient subgroups may exist that benefit from targeted physical rehabilitation interventions that could improve their recovery trajectory. We aim to identify critical illness patient subgroups that respond to physical rehabilitation and map recovery trajectories according to physical function and quality of life outcomes. Additionally, the utilisation of healthcare resources will be examined for subgroups identified. Methods and analysis this is an individual participant data meta-analysis protocol. A systematic literature review was conducted for randomised controlled trials that delivered additional physical rehabilitation for patients with critical illness during their acute hospital stay, assessed chronic disease burden, with a minimum follow-up period of 3 months measuring performance-based physical function and health-related quality of life outcomes. From 2178 records retrieved in the systematic literature review, four eligible trials were identified by two independent reviewers. Principal investigators of eligible trials were invited to contribute their data to this individual participant data meta-analysis. Risk of bias will be assessed (cochrane risk of bias tool for randomised trials). Participant and trial characteristics, interventions and outcomes data of included studies will be summarised. Meta-analyses will entail a one-stage model, which will account for the heterogeneity across and the clustering between studies. Multiple imputation using chained equations will be used to account for the missing data. Ethics and dissemination this individual participant data meta-analysis does not require ethical review as anonymised participant data will be used and no new data collected. Additionally, eligible trials were granted approval by institutional review boards or research ethics committees and informed consent was provided for participants. Data sharing agreements are in place permitting contribution of data. The study findings will be disseminated at conferences and through peer-reviewed publications. Prospero registration number crd42019152526. © © author(s) (or their employer(s)) 2020. Re-use permitted under cc by-nc. No commercial re-use. See rights and permissions. Published by bmj.","","","2020","10.1136/bmjopen-2019-035613","","","scopus-2-s2.0-85084328966.pdf","scopus-2-s2.0-85084328966"
"Do green practices really attract customers? The sharing economy from the sustainable supply chain management perspective","Hu, J. And Liu, Y.-L. And Yuen, T.w.w. And Lim, M.k. And Hu, J.","Resources, Conservation And Recycling","","The notion of the sharing economy has been introduced in many sectors and provided significant benefits to consumers and asset owners. Despite the remarkable improvement of the sharing economy in recent years, its relationship with sustainability remains insufficiently researched. This study adopts a sustainable supply chain management (sscm) perspective. A large-scale survey with 420 participants showed that investment recovery (ir) practices and corporate social responsibility (csr) conducted by sharing economy platforms significantly and positively affect customers’ intention to use sharing economy-based services/products, whereas internal green management (igm), supplier green management (sgm), eco-design (ecd) and customer green management (cgm) practices do not. A follow-up qualitative study with ten participants provided further explanations and supported the findings of the survey. This study links the sharing economy and sustainability by testing the effectiveness of sharing economy platforms’ sustainable practices and proposes the best practices for sharing economy platforms to maintain a long-term sustainable marketplace. © 2019 elsevier b.v.","","","2019","10.1016/j.resconrec.2019.05.042","","","scopus-2-s2.0-85066760029.pdf","scopus-2-s2.0-85066760029"
"Value of open data: a geoscience perspective","Wildman, G. And Lewis, E.","Geoscience Data Journal","","We are living in a data-centric society, with governments and businesses increasingly looking at what they can do to gain insight and improve the flow of data. Encouraging the release of data as ‘open data’ is one measure that would remove barriers to access, increase use and facilitate downstream data innovation. Using examples from firstly the non-geoscience and then geoscience sectors, this paper outlines three factors that can lead to a successful open data programme. These are (1) having a clear strategy with a well-articulated vision;  (2) ensuring that data are not only free but also technically accessible and delivered under an open licence;  and (3) continued investment in the programme to ensure its long-term success. However, not all data can or should be open, and organizations and governments must be careful that their interventions do not have unintended consequences that might reduce incentives to collect, maintain and share data. A primary concern is the financial sustainability of a dataset, but this also extends to other risks that would prevent the data being widely shared such as the inclusion of personal data or third-party intellectual property. In these cases, use of a data-sharing risk assessment framework, and the application of the fair principles of findable, accessible, interoperable and reusable can be used to increase data sharing and maximize the benefits that can be realized from geoscience data. © 2021 british geological survey, a component of ukri. Geoscience data journal published by royal meteorological society and john wiley & sons ltd.","","","2022","10.1002/gdj3.138","","","scopus-2-s2.0-85122960641.pdf","scopus-2-s2.0-85122960641"
"A joint industry-sponsored data monitoring committee model for observational, retrospective drug safety studies in the real-world setting","Major-Pedersen, A. And Mccullen, M.k. And Sabol, M.e. And Adetunji, O. And Massaro, J. And Neugut, A.i. And Sosa, J.a. And Hollenberg, A.n.","Pharmacoepidemiology And Drug Safety","","Purpose: to share better practice in establishing data monitoring committees (dmcs) for observational, retrospective safety studies with joint-industry sponsorship. Methods: a dmc model was created to monitor data from an observational, retrospective, post-authorization safety study investigating risk of medullary thyroid cancer in patients treated with long-acting glucagon-like peptide-1 receptor agonists (la glp-1ras) (nct01511393). Sponsors reviewed regulatory guidelines, best practice and sponsors' standard operation procedures on dmcs. Discussions were held within the four-member consortium, assessing applicability to observational, retrospective, real-world studies. A dmc charter was drafted based on a sponsor-proposed, adapted dmc model. Thereafter, a kick-off meeting between sponsors and dmc members was held to receive dmc input and finalize the charter. Results: due to this study's observational, retrospective nature, assuring participant safety – central for traditional explanatory clinical trial models – was not applicable to our dmc model. The overall strategy and key indication for our real-world model included preserving study integrity and credibility. Therefore, dmc member independence and their contribution of expert knowledge were essential. To ensure between-sponsor data confidentiality, all study committees/corporations and sponsors, besides the dmc, received blinded data only (adapted to refer to data blinding that revealed the specific marketed la glp-1ra/sponsor). Communication and blinding/unblinding of these data were facilitated by the contract research organization, which also provided crucial operational oversight. Conclusions: to our knowledge, we have established the first dmc model for joint industry-sponsored, observational, retrospective safety studies. This model could serve as a precedent for others performing similar post-marketing, joint industry-sponsored pharmacovigilance activities. © 2020 the authors. Pharmacoepidemiology and drug safety published by john wiley & sons ltd.","","","2021","10.1002/pds.5172","","","scopus-2-s2.0-85096685216.pdf","scopus-2-s2.0-85096685216"
"Development and implementation of a cyberinfrastructure framework for research in nondestructive evaluation using acoustic emission data","Zárate, B.a. And Caicedo, J.m. And Ziehl, P.","Journal Of Computing In Civil Engineering","","This paper presents the development and validation of a cyberinfrastructure architecture for research in nondestructive evaluation (nde) using acoustic emission (ae) data. Existing cyberinfrastructures for civil engineering focus in the curation and preservation of data. In contrast, the proposed cyberinfrastructure is intended to serve as a tool to enable innovation by providing a platform to prototype analysis techniques and sharing data and analysis methods among a research team while removing the burden of memory and computational cost from the user. This is achieved by streamlining the access of large and complex experimental data sets, facilitating the selection of part of the experimental data depending on data features, distributing data analysis using a distributed computing strategy, and allowing the creation of new data features that can be used for subsequent analysis. The experimental data set potentially include data from ae sensors, strain gages, load cells, clip gages, and accelerometers. The proposed framework uses a relational database to store data, web services for data communication, a condor pool for high throughput computing, and a graphical interface for interaction with the user. An example using data obtained from a compact tension fatigue test is used to show the capabilities of the developed framework. © 2014 american society of civil engineers.","","","2014","10.1061/(asce)cp.1943-5487.0000335","","","scopus-2-s2.0-84899000694.pdf","scopus-2-s2.0-84899000694"
"[On how to analyze the credibility of a clinical trial or meta-analysis whose main result is expressed in odds ratio relative risk or hazard ratio]","Escrig-Sos J.","Cirugia Espanola","","Beyond the type of design or the statistical analysis applied the credibility of a research study lies in the compatibility of its results with the intensity that the reader could accept that the phenomenon studied might have from a biological point of view. Ultimately this requires a value judgment. The present article describes a procedure that can be used to objectively approach the limits of intensity that that a biological phenomenon could have according to the data presented so that based on the reader's judgment derived from the available knowledge of the problem the study can be deemed credible. The procedure is valid when the results of the study are expressed in odds ratio relative risk or hazard ratio. Although these statistics are difficult to interpret they are probably the most widely used in clinical trials and meta-analyses that is in studies whose methodological designs provide the highest level of evidence.","","","2005","10.1016/s0009-739x(05)70953-2","","","medline-16420860.pdf","medline-16420860"
"Deconbench: a benchmarking platform dedicated to deconvolution methods for tumor heterogeneity quantification","Decamps, C. And Arnaud, A. And Petitprez, F. And Ayadi, M. And Baurès, A. And Armenoult, L. And Alcala, N. And Arnaud, A. And Avila Cobos, F. And Batista, L. And Batto, A.-F. And Blum, Y. And Chuffart, F. And Cros, J. And Decamps, C. And Dirian, L. And Doncevic, D. And Durif, G. And Bahena Hernandez, S.y. And Jakobi, M. And Jardillier, R. And Jeanmougin, M. And Jedynak, P. And Jumentier, B. And Kakoichankava, A. And Kondili, M. And Liu, J. And Maie, T. And Marécaille, J. And Merlevede, J. And Meylan, M. And Nazarov, P. And Newar, K. And Nyrén, K. And Petitprez, F. And Novella Rausell, C. And Richard, M. And Scherer, M. And Sompairac, N. And Waury, K. And Xie, T. And Zacharouli, M.-A. And Escalera, S. And Guyon, I. And Nicolle, R. And Tomasini, R. And De Reyniès, A. And Cros, J. And Blum, Y. And Richard, M. And Hadaca Consortium","Bmc Bioinformatics","","Background: quantification of tumor heterogeneity is essential to better understand cancer progression and to adapt therapeutic treatments to patient specificities. Bioinformatic tools to assess the different cell populations from single-omic datasets as bulk transcriptome or methylome samples have been recently developed, including reference-based and reference-free methods. Improved methods using multi-omic datasets are yet to be developed in the future and the community would need systematic tools to perform a comparative evaluation of these algorithms on controlled data. Results: we present deconbench, a standardized unbiased benchmarking resource, applied to the evaluation of computational methods quantifying cell-type heterogeneity in cancer. Deconbench includes gold standard simulated benchmark datasets, consisting of transcriptome and methylome profiles mimicking pancreatic adenocarcinoma molecular heterogeneity, and a set of baseline deconvolution methods (reference-free algorithms inferring cell-type proportions). Deconbench performs a systematic performance evaluation of each new methodological contribution and provides the possibility to publicly share source code and scoring. Conclusion: deconbench allows continuous submission of new methods in a user-friendly fashion, each novel contribution being automatically compared to the reference baseline methods, which enables crowdsourced benchmarking. Deconbench is designed to serve as a reference platform for the benchmarking of deconvolution methods in the evaluation of cancer heterogeneity. We believe it will contribute to leverage the benchmarking practices in the biomedical and life science communities. Deconbench is hosted on the open source codalab competition platform. It is freely available at: https://competitions.codalab.org/competitions/27453. © 2021, the author(s).","","","2021","10.1186/s12859-021-04381-4","","","scopus-2-s2.0-85117635292.pdf","scopus-2-s2.0-85117635292"
"Publication of quality report cards and trends in reported quality measures in nursing homes","Mukamel, D.b. And Weimer, D.l. And Spector, W.d. And Ladd, H. And Zinn, J.s.","Health Services Research","","Objective. To examine associations between nursing homes' quality and publication of the nursing home compare quality report card. Data sources/study settings. Primary and secondary data for 2001-2003: 701 survey responses of a random sample of nursing homes;  the minimum data set (mds) with information about all residents in these facilities, and the nursing home compare published quality measure (qm) scores. Study design. Survey responses provided information on 20 specific actions taken by nursing homes in response to publication of the report card. Mds data were used to calculate five qms for each quarter, covering a period before and following publication of the report. Statistical regression techniques were used to determine if trends in these qms have changed following publication of the report card in relation to actions undertaken by nursing homes. Principal findings. Two of the five qms show improvement following publication. Several specific actions were associated with these improvements. Conclusions. Publication of the nursing home compare report card was associated with improvement in some but not all reported dimensions of quality. This suggests that report cards may motivate providers to improve quality, but it also raises questions as to why it was not effective across the board. © health research and educational trust.","","","2008","10.1111/j.1475-6773.2007.00829.x","","","scopus-2-s2.0-42549170279.pdf","scopus-2-s2.0-42549170279"
"Miniaturization of an enclosed electrospinning process to enhance reproducibility in the fabrication of rapidly dissolving cell-based biosensors","Morkus P., Sibbald S., Choi L., Rassenberg S., Filipe C. D. M., Latulippe D. R.","Biotechnology Journal","","There is broad interest in producing electrospun films embedded with biological materials. It is well known that electrospinning requires careful control of the process conditions especially the environmental conditions such as relative humidity (RH). Given that commercial electrospinning systems are expensive (> $10000) and are typically too large to be used in standard biological safety cabinets (BSC) we designed and built a miniaturized electrospinning box (E-Box) that will fit inside a BSC and the RH can be easily controlled using simple instrumentation (gas cylinder regulator needle valve rotameter). It uses an inexpensive computerized numerical control machine to control the spinneret positioning and collector rotational speed-all the parts for the device (except the syringe pump and voltage supply) can be purchased for approximately $1000. We demonstrate the usefulness of our design in optimizing the production of Escherichia coli-embedded pullulan-trehalose films to be used as rapidly dissolving biosensors for environmental monitoring. At a fixed electrospinning recipe we showed that decreasing the RH from approximately 48% to 22% resulted in the average fiber diameter increasing from 240 (+/- 11) nm to 314 (+/- 8) nm. We also demonstrate the usefulness of our design in performing sequential electrospinning experiments to evaluate process performance reproducibility. For example from just 1 mL of a polymer solution we produced 16 electrospun films (approximately 3 cm by 8 cm each)-from those films we hole-punched approximately 80 biosensor discs which were then used in subsequent experiments to determine the amount of two different biocides (Grotan BK and triclosan) in aqueous samples. The technique developed in this study is ideal for creating electrospun materials in high quantities that are highly reproducible through the precise control of RH. Copyright © 2023 The Authors. Biotechnology Journal published by Wiley-VCH GmbH.","","","2023","10.1002/biot.202300306","","","medline-37882254.pdf","medline-37882254"
"Experimental design for gene expression analysis: Answers are easy is asking the right question difficult?","Fournier M. V., Carvalho P. C., Magee D. D., Da Carvalho M. G. C., Appasani K.","","","More and more array platforms are being used to assess gene expression in a wide range of biological and clinical models. Technologies using arrays have proven to be reliable and affordable for most of the scientific community worldwide. By typing microarrays or proteomics into a search engine such as PubMed thousands of references can be viewed. Nevertheless almost everyone in life science research has a story to tell about array experiments that were expensive did not generate reproducible data or generated meaningless data. Because considerable resources are required for any experiment using arrays it is desirable to evaluate the best method and the best design to ask a certain question. Multiple levels of technical problems such as sample preparation array spotting signal acquisition dye intensity bias normalization or sample-contamination can generate inconsistent results or misleading conclusions. Technical recommendations that offer alternatives and solutions for the most common problems have been discussed extensively in previous work. Less often discussed is the experimental design. A poor design can make array data analysis difficult even if there are no technical problems. This chapter focuses on experimental design choices in terms of controls such as replicates and comparisons for microarray and proteomics. It also covers data validation and provides examples of studies using diverse experimental designs. The overall emphasis is on design efficiency. Though perhaps obvious we also emphasize that design choices should be made so that biological questions are answered by clear data analysis. © 2007 Humana Press Inc.","","","2007","10.1007/978-1-59745-328-8_3","","","scopus-2-s2.0-67650653389.pdf","scopus-2-s2.0-67650653389"
"What about ethics? Developing qualitative research in confinement settings","Gomes, S. And Duarte, V.","European Journal Of Criminology","","The main purpose of this article is to discuss some ethical-methodological issues associated with scientific research in confinement settings, particularly those that result from the relationship with the confined individual in the framework of qualitative research. Basing the reflection on empirical research developed by both authors in portuguese confinement settings – prisons and youth educational centres – we examine the significant challenges and dilemmas this type of research entails, exploring the interface between procedural ethics and ethics in practice at three points in the analytical process: before, during and after data collection. This article illustrates the interplay between formal and informal procedures, and between the initial distancing and strangeness when making contact with confinement settings and their social actors and the institutional and relational dynamics that become ingrained in our everyday practice. Our goal is to give visibility to these institutional and relational dynamics and to reflect on the challenges experienced by those who enter confinement settings to do research, in an effort to make the research process more transparent and at the same time more reflexive. We end our reflection advocating more ethically committed and critical scientific research. © the author(s) 2018.","","","2020","10.1177/1477370818801305","","","scopus-2-s2.0-85058652910.pdf","scopus-2-s2.0-85058652910"
"A systematic review of knowledge sharing challenges and practices in global software development","Zahedi, M. And Shahin, M. And Ali Babar, M.","International Journal Of Information Management","","Context global software development (gsd) presents significant challenges to share and understand knowledge required for developing software. Organizations are expected to implement appropriate practices to address knowledge-sharing challenges in gsd. With the growing literature on gsd and its widespread adoption, it is important to build a body of knowledge to support future research and effective knowledge sharing practices. Objective we aimed at systematically identifying and synthesizing knowledge sharing challenges and practices. We also intended to classify the recurrent challenges and most frequently reported practices in different contextual settings. Method we used systematic literature review (slr) for reviewing 61 primary studies that were selected after searching the gsd literature published over the last 14 years (2000–september 2014). We applied thematic analysis method for analysing the data extracted from the reviewed primary studies. Results our findings revealed that knowledge sharing challenges and practices in gsd could be classified in 6 main themes: management, team structure, work processes/practices, team cognition, social attributes and technology. In regard to contextual settings, we found empirical studies were mainly conducted in an offshore outsourcing collaboration model distributed between two sites. Most of the studied organizations were large enterprises. Many of the studies did not report any information for several contextual attributes that made it difficult to analyse the reported challenges and practices with respect to their respective contexts. Conclusion we can conclude: (a) there is a higher tendency among researchers to report practices than challenges of knowledge sharing in gsd. (b) given our analysis, most of the reported knowledge sharing challenges and practices fall under the theme of “work practices”. (c) the technology related knowledge-sharing challenges are the least reported;  we discussed the available technologies for supporting knowledge sharing needs in gsd. (d) the organizational contextual information is missing from a large number of studies;  hence, it was not possible to investigate the potential relations between knowledge sharing challenges/practices and the contextual attributes of gsd teams. We assert the need of exploring knowledge sharing in the context of small/medium sized organizations to avoid the risk of findings being biased by specific empirical setting (e.g., large enterprises distributed between us and india). © 2016 elsevier ltd","","","2016","10.1016/j.ijinfomgt.2016.06.007","","","scopus-2-s2.0-84977627599.pdf","scopus-2-s2.0-84977627599"
"XML-BSPM: an XML format for storing Body Surface Potential Map recordings","Bond R. R., Finlay D. D., Nugent C. D., Moore G.","BMC Medical Informatics & Decision Making","","BACKGROUND: The Body Surface Potential Map (BSPM) is an electrocardiographic method for recording and displaying the electrical activity of the heart from a spatial perspective. The BSPM has been deemed more accurate for assessing certain cardiac pathologies when compared to the 12-lead ECG. Nevertheless the 12-lead ECG remains the most popular ECG acquisition method for non-invasively assessing the electrical activity of the heart. Although data from the 12-lead ECG can be stored and shared using open formats such as SCP-ECG no open formats currently exist for storing and sharing the BSPM. As a result an innovative format for storing BSPM datasets has been developed within this study.\\\\\\\\rMETHODS: The XML vocabulary was chosen for implementation as opposed to binary for the purpose of human readability. There are currently no standards to dictate the number of electrodes and electrode positions for recording a BSPM. In fact there are at least 11 different BSPM electrode configurations in use today. Therefore in order to support these BSPM variants the XML-BSPM format was made versatile. Hence the format supports the storage of custom torso diagrams using SVG graphics. This diagram can then be used in a 2D coordinate system for retaining electrode positions.\\\\\\\\rRESULTS: This XML-BSPM format has been successfully used to store the Kornreich-117 BSPM dataset and the Lux-192 BSPM dataset. The resulting file sizes were in the region of 277 kilobytes for each BSPM recording and can be deemed suitable for example for use with any telemonitoring application. Moreover there is potential for file sizes to be further reduced using basic compression algorithms i.e. the deflate algorithm. Finally these BSPM files have been parsed and visualised within a convenient time period using a web based BSPM viewer.\\\\\\\\rCONCLUSIONS: This format if widely adopted could promote BSPM interoperability knowledge sharing and data mining. This work could also be used to provide conceptual solutions and inspire existing formats such as DICOM SCP-ECG and aECG to support the storage of BSPMs. In summary this research provides initial ground work for creating a complete BSPM management system.","","","2010","10.1186/1472-6947-10-28","","","medline-20470392.pdf","medline-20470392"
"Prudence: a system for assessing privacy risk vs utility in data sharing ecosystems","Pratesi, F. And Monreale, A. And Trasarti, R. And Giannotti, F. And Pedreschi, D. And Yanagihara, T.","Transactions On Data Privacy","","Data describing human activities are an important source of knowledge useful for understanding individual and collective behavior and for developing a wide range of user services. Unfortunately, this kind of data is sensitive, because people’s whereabouts may allow re-identification of individuals in a de-identified database. Therefore, data providers, before sharing those data, must apply any sort of anonymization to lower the privacy risks, but they must be aware and capable of controlling also the data quality, since these two factors are often a trade-off. In this paper we propose prudence (privacy risk versus utility in data sharing ecosystems), a system enabling a privacy-aware ecosystem for sharing personal data. It is based on a methodology for assessing both the empirical (not theoretical) privacy risk associated to users represented in the data, and the data quality guaranteed only with users not at risk. Our proposal is able to support the data provider in the exploration of a repertoire of possible data transformations with the aim of selecting one specific transformation that yields an adequate trade-off between data quality and privacy risk. We study the practical effectiveness of our proposal over three data formats underlying many services, defined on real mobility data, i.e., presence data, trajectory data and road segment data. © 2018, university of skovde. All rights reserved.","","","2018","","","","scopus-2-s2.0-85052405543.pdf","scopus-2-s2.0-85052405543"
"A quantitative study of history in the english short-title catalogue (estc), 1470-1800","Lahti, L. And Ilomäki, N. And Tolonen, M.","Liber Quarterly","","This article analyses publication trends in the field of history in early modern britain and north america in 1470-1800, based on english short-title catalogue (estc) data.2 its major contribution is to demonstrate the potential of digitized library catalogues as an essential scholastic tool and part of reproducible research. We also introduce a novel way of quantitatively analysing a particular trend in book production, namely the publishing of works in the field of history. The study is also our first experimental analysis of paper consumption in early modern book production, and demonstrates in practice the importance of open-science principles for library and information science. Three main research questions are addressed: 1) who wrote history;  2) where history was published;  and 3) how publishing changed over time in early modern britain and north america. In terms of our main findings we demonstrate that the average book size of history publications decreased over time, and that the octavo-sized book was the rising star in the eighteenth century, which is a true indication of expanding audiences. The article also compares different aspects of the most popular writers on history, such as edmund burke and david hume. Although focusing on history, these findings may reflect more widespread publishing trends in the early modern era. We show how some of the key questions in this field can be addressed through the quantitative analysis of large-scale bibliographic data collections.3 © 2015, igitur, utrecht publishing and archiving services. All rights reserved.","","","2015","10.18352/lq.10112","","","scopus-2-s2.0-84949466572.pdf","scopus-2-s2.0-84949466572"
"An efficient edge-cloud partitioning of random forests for distributed sensor networks","Shen, T. And Mishra, C.s. And Sampson, J. And Kandemir, M.t. And Narayanan, V.","Ieee Embedded Systems Letters","","Intelligent edge sensors that augment legacy &#x201c; unintelligent&#x201d;  manufacturing systems provides cost-effective functional upgrades. However, the limited compute at these edge devices requires trade-offs in efficient edge-cloud partitioning and raises data privacy issues. This work explores policies for partitioning random forest approaches, which are widely used for inference tasks in smart manufacturing, among sets of devices with different resources and data visibility. We demonstrate, using both publicly available datasets and a real-world grinding machine deployment, that our privacy-preserving approach to partitioning and training offers superior latency-accuracy tradeoffs to purely on-edge computation while still achieving much of the benefits from data-sharing cloud offload strategies. Ieee","","","2022","10.1109/les.2022.3207968","","","scopus-2-s2.0-85141459630.pdf","scopus-2-s2.0-85141459630"
"Sharing voxelwise neuroimaging results from rhesus monkeys and other species with neurovault","Fox, A.s. And Holley, D. And Klink, P.c. And Arbuckle, S.a. And Barnes, C.a. And Diedrichsen, J. And Kwok, S.c. And Kyle, C. And Pruszynski, J.a. And Seidlitz, J. And Zhou, X. And Poldrack, R.a. And Gorgolewski, K.j.","Neuroimage","","Animal neuroimaging studies can provide unique insights into brain structure and function, and can be leveraged to bridge the gap between animal and human neuroscience. In part, this power comes from the ability to combine mechanistic interventions with brain-wide neuroimaging. Due to their phylogenetic proximity to humans, nonhuman primate neuroimaging holds particular promise. Because nonhuman primate neuroimaging studies are often underpowered, there is a great need to share data amongst translational researchers. Data sharing efforts have been limited, however, by the lack of standardized tools and repositories through which nonhuman neuroimaging data can easily be archived and accessed. Here, we provide an extension of the neurovault framework to enable sharing of statistical maps and related voxelwise neuroimaging data from other species and template-spaces. Neurovault, which was previously limited to human neuroimaging data, now allows researchers to easily upload and share nonhuman primate neuroimaging results. This promises to facilitate open, integrative, cross-species science while affording researchers the increased statistical power provided by data aggregation. In addition, the neurovault code-base now enables the addition of other species and template-spaces. Together, these advances promise to bring neuroimaging data sharing to research in other species, for supplemental data, location-based atlases, and data that would otherwise be relegated to a ""file-drawer"". As increasing numbers of researchers share their nonhuman neuroimaging data on neurovault, this resource will enable novel, large-scale, cross-species comparisons that were previously impossible. © 2020 the authors","","","2021","10.1016/j.neuroimage.2020.117518","","","scopus-2-s2.0-85095425122.pdf","scopus-2-s2.0-85095425122"
"Asynchronous shared memory search structures","Adler, M.","Theory Of Computing Systems","","We study the problem of storing an ordered set on an asynchronous shared memory parallel computer. We examine the case where we want to perform successor (least upper bound) queries efficiently on the set members that are stored. We also examine the case where processors insert and delete members of the set. Due to asynchrony, we require processors to perform queries and to maintain the structure independently. Although several such structures have been proposed, the analysis of these structures has been very limited. We here use the recently proposed qrqw pram model to provide upper and lower bounds on the performance of such data structures. In the asynchronous qrqw pram, the problem of processors concurrently and independently searching a shared data structure is very similar to the problem of routing packets through a network. Using this as a guide, we introduce the search-butterfly, a search structure that combines the efficient packet routing properties of the butterfly graph with the efficient search structure properties of the b-tree. We analyze the behavior of the search-butterfly when the following operations are performed: arbitrary searches, random searches, and random searches, insertions, and deletions. We also provide lower bounds that show that the results are within a factor of o(log n) of optimal where n is the number of keys in the structure. When the searches are random, the results are within a constant factor of optimal. Many of the proofs are derived from closely related results for packet routing. Others are of independent interest, most notably a method of adding queues to any network belonging to a large class of queuing networks with non-markovian routing in a manner that allows us to bound the delay experienced by packets in the augmented network.","","","1998","10.1007/s002240000094","","","scopus-2-s2.0-0032369486.pdf","scopus-2-s2.0-0032369486"
"Fine-grained access control with user revocation in smart manufacturing","Gómez-Marín, E. And Martintoni, D. And Senni, V. And Castillo, E. And Parrilla, L.","Electronics (Switzerland)","","Collaborative manufacturing is a key enabler of industry 4.0 that requires secure data sharing among multiple parties. However, intercompany data-sharing raises important privacy and security concerns, particularly given intellectual property and business-sensitive information collected by many devices. In this paper, we propose a solution that combines four technologies to address these challenges: attribute-based encryption for data access control, blockchain for data integrity and non-repudiation, hardware security modules for authenticity, and the interplanetary file system for data scalability. We also use openid for dynamic client identification and propose a new method for user revocation in attribute-based encryption. Our evaluation shows that the solution can scale up to 2,000,000 clients while maintaining all security guarantees. © 2023 by the authors.","","","2023","10.3390/electronics12132843","","","scopus-2-s2.0-85164772712.pdf","scopus-2-s2.0-85164772712"
"Completeness of AIDS reporting and quality of AIDS death certification in Tuscany (Italy): a linkage study between surveillance system of cases and death certificates","Barchielli A., Buiatti E., Galanti C., Giovannetti L., Acciai S., Lazzeri V.","European Journal of Epidemiology","","In Italy the AIDS cases defined according to the CDC criteria are reported to the National AIDS Registry (RAIDS compulsory surveillance system). The aim of the present study is to evaluate the completeness of AIDS cases reported and the quality of AIDS death certification in an Italian Region (Tuscany about 3500000 inhabitants). The 737 AIDS cases reported to RAIDS as residents in Tuscany (1987-91) were cross-linked (key link: name and date of birth) with the data of the Mortality Registration system of the Region (RMR). For the residents in Tuscany decreased with a 279.1 death diagnosis (the code for AIDS deaths stated by the Italian Census Bureau) and not reported to RAIDS as AIDS cases the clinical records were reviewed to check whether the diagnosis fitted the 1987-CDC diagnostic criteria. This study shows that there is a high completeness (97-98%) of the AIDS cases resident in Tuscany reported to the RAIDS. The quality of RAIDS data is not as good with regard to life status assessment (23% of under-reporting of death). In Tuscany the death certification for AIDS (code 279.1 of ICD IX) has a sensitivity of 88% and a specificity around 100% in comparison to RAIDS. About 50% of 'false negatives' in death certification are due to causes of death presumably unrelated to HIV infection. The evaluation of the quality of AIDS surveillance and mortality data is important in the assessment of the impact for AIDS epidemic in a target population.","","","1995","10.1007/bf01719302","","","medline-8549724.pdf","medline-8549724"
"Extraction and classification of dense implicit communities in the web graph","Dourisboure, Y. And Geraci, F. And Pellegrini, M.","Acm Transactions On The Web","","The world wide web (www) is rapidly becoming important for society as a medium for sharing data, information, and services, and there is a growing interest in tools for understanding collective behavior and emerging phenomena in the www. In this article we focus on the problem of searching and classifying communities in the web. Loosely speaking a community is a group of pages related to a common interest. More formally, communities have been associated in the computer science literature with the existence of a locally dense subgraph of the web graph (where web pages are nodes and hyperlinks are arcs of the web graph). The core of our contribution is a new scalable algorithm for finding relatively dense subgraphs in massive graphs. We apply our algorithm on web graphs built on three publicly available large crawls of the web (with raw sizes up to 120m nodes and 1g arcs). The effectiveness of our algorithm in finding dense subgraphs is demonstrated experimentally by embedding artificial communities in the web graph and counting how many of these are blindly found. Effectiveness increases with the size and density of the communities: it is close to 100% for communities of thirty nodes or more (even at low density). It is still about 80% even for communities of twenty nodes with density over 50% of the arcs present. At the lower extremes the algorithm catches 35% of dense communities made of ten nodes. We also develop some sufficient conditions for the detection of a community under some local graph models and not-too-restrictive hypotheses. We complete our community watch system by clustering the communities found in the web graph into homogeneous groups by topic and labeling each group by representative keywords. © 2009 acm.","","","2009","10.1145/1513876.1513879","","","scopus-2-s2.0-70349754411.pdf","scopus-2-s2.0-70349754411"
"Ultra-chaos: an insurmountable objective obstacle of reproducibility and replication","Liao, S. And Qin, S.","Advances In Applied Mathematics And Mechanics","","In this paper, a new concept, i.e., ultra-chaos, is proposed for the first time. Unlike a normal-chaos, statistical properties such as the probability density functions (pdf) of an ultra-chaos are sensitive to tiny disturbances. We illustrate that ultra-chaos is widely existed and thus has general scientific meanings. It is found that statistical non-reproducibility is an inherent property of an ultra-chaos so that an ultra-chaos is at a higher-level of disorder than a normal-chaos. Thus, it is impossible in practice to replicate experimental/numerical results of an ultra-chaos even in statistical meanings, since random environmental noises always exist and are out of control. Thus, the ultra-chaos should be an insurmountable obstacle of reproducibility and replicability. Similar to gödel's incompleteness theorem, such kind of ""incompleteness of reproducibility""reveals a limitation of our traditional scientific paradigm based on reproducible experiments, which can be traced back to galileo. The ultra-chaos opens a new door and possibility to study chaos theory, turbulence theory, computational fluid dynamics (cfd), the statistical significance, reproducibility crisis, and so on. © 2022 global science press.","","","2021","10.4208/aamm.oa-2021-0364","","","scopus-2-s2.0-85126634500.pdf","scopus-2-s2.0-85126634500"
"When the sense of place value is challenged by pandemic: value exchange in indigenous community-based tourism in sade-lombok, indonesia","Rembulan, C.l. And Kusumowidagdo, A.","Journal Of Enterprising Communities","","Purpose: the purpose of this study is to investigate problems that emerged in indigenous community-based tourism during the covid-19 pandemic, to identify the actors involved and to identify values that were exchanged between actors during the pandemic. This research is crucial given the limited studies around indigenous community-based tourism during the pandemic, especially within the perspectives of value exchange theory. Design/methodology/approach: this research used a constructionist paradigm with a qualitative case study design. Data collection included interviews with six participants, virtual observation, an open-ended questionnaire to 22 community members and 20 tourists, analysis of a book written by sade’s customary chief and social media artifacts. This study was conducted during the covid-19 pandemic, where physical distancing measures were applied, therefore most data were collected remotely. Purposive sampling was used and research credibility was increased through detailed note taking, data sources triangulation and member checking. Data analysis was conducted with a coding process, which involved continuous iterations. Findings: problems identified were decreased revenue and power disadvantage suffered by indigenous community-based tourism. The actors involved in value exchanges varied, including value supporter (i.e. government, private sector such as television, university), value creator (i.e. tourist) or secondary value provider (i.e. travel agent). Values emerged in the interaction between actors in the network. Changes in value exchanges were in terms of value types, relationship intensity between actors and ways of doing the exchange. Non-human factor (i.e. non-actor) was also involved. Research limitations/implications: due to restrictive circumstances (i.e. Covid-19 pandemic), the data collection procedure was limited to online communications and letter correspondence. Therefore, opportunities to capture the full phenomenon might be missed as the researchers could not physically meet with the participant. Practical implications: it was possible for value exchange to alter due to situational factors, including a pandemic. Business diversification is needed by indigenous community-based tourism to achieve a power advantage. Values were found in the relationship between actors, hence, meeting channels or dialogue with other actors could be optimized. Originality/value: the context of this study, which was indigenous community-based tourism during a pandemic contributed to the study’s originality. Research in this context, which used a clear theoretical framework such as value exchange theory, is scarce. Thus, opportunities for transferability are broad. © 2021, emerald publishing limited.","","","2022","10.1108/jec-02-2021-0020","","","scopus-2-s2.0-85110279636.pdf","scopus-2-s2.0-85110279636"
"Look beyond financial conflicts of interest in evaluating industry-academia collaborations in burden-of-illness and outcomes research studies in dermatology","Prendergast, M.m. And Abramovits, W. And Boguniewicz, M. And Lebwohl, M. And Tokar, M. And Tong, K.b.","Journal Of Investigative Dermatology","","Financial relationships exist among industry, scientific investigators, and academic medical centers. These relationships can foster research in the basic sciences, clinical trials, health economics evaluations, and other outcomes assessment studies. To govern the conduct of burden-of-illness and outcomes research studies involving collaborations between industry and academia, we propose voluntary standards related to: 1) the development of and adherence to standards for research conduct and reporting;  2) disclosure, discussion, and management of potential impacts of financial conflicts of interest;  and 3) transparency in research methods and open access to study results.","","","2004","10.1111/j.0022-202x.2004.09116.x","","","scopus-2-s2.0-4143070415.pdf","scopus-2-s2.0-4143070415"
"Medical data sharing scheme based on attribute cryptosystem and blockchain technology","Yang, X. And Li, T. And Pei, X. And Wen, L. And Wang, C.","Ieee Access","","Electronic medical data have significant advantages over paper-based patient records when it comes to storage and retrieval. However, most existing medical data sharing schemes have security risks, such as being prone to data tampering and forgery, and do not support the ability to verify the authenticity of the data source. To solve these problems, we propose a medical data sharing scheme based on attribute cryptosystem and blockchain technology in this paper. First, the encrypted medical data are stored in the cloud, and the storage address and medical-related information are written into the blockchain, which can ensure efficient storage and eliminate the possibility of irreversible modification of the data. Second, the proposed scheme combines attribute-based encryption (abe) and attribute-based signature (abs), which achieves the sharing of medical data in many-to-many communications. The abe achieves data privacy and fine-grained access control, and the abs verifies the authenticity of the source of the medical data while protecting the signer's identity. Moreover, the data user outsources most of the operations of medical data ciphertext decryption to the cloud service provider (csp), which can greatly reduce the computational burden. Finally, results of the analysis show that our scheme satisfies the requirements for confidentiality and unforgeability in the random oracle model, and that the proposed scheme offers higher computational performance than other similar schemes. © 2013 ieee.","","","2020","10.1109/access.2020.2976894","","","scopus-2-s2.0-85082060053.pdf","scopus-2-s2.0-85082060053"
"High variability in radiologists' reporting practices for incidental thyroid nodules detected on CT and MRI","Hoang J. K., Riofrio A., Bashir M. R., Kranz P. G., Eastwood J. D.","Ajnr: American Journal of Neuroradiology","","BACKGROUND AND PURPOSE: There are no guidelines for reporting incidental thyroid nodules seen on CT and MR imaging. We evaluated radiologists' current reporting practices for incidental thyroid nodules detected on these imaging modalities.\\\\\\\\rMATERIALS AND METHODS: Radiologists were surveyed regarding their reporting practices by using 14 scenarios of incidental thyroid nodules differing in size patient demographics and clinical history. Scenarios were evaluated for the following: 1) radiologists' most commonly selected response and 2) the proportion of radiologists selecting that response (degree of agreement). These measures were used to determine how the patient scenario and characteristics of the radiologists affected variability in practice.\\\\\\\\rRESULTS: One hundred fifty-three radiologists participated. In 8/14 scenarios the most common response was to ""recommend sonography."" For the other scenarios the most common response was to ""report in only body of report."" The overall mean agreement for the 14 scenarios was 53% and agreement ranged from 36% to 75%. Smaller nodules had lower agreement: 43%-51% for 8-mm nodules compared with 64%-75% for 15-mm nodules. Agreement was poorest for the 10-mm nodule in a 60-year-old woman (36%) and for scenarios with additional history of lung cancer (39%) and multiple nodules (36%). There was no significant difference in reporting practices and agreement when radiologists were categorized by years of practice practice type and subspecialty (P > .55).\\\\\\\\rCONCLUSIONS: The reporting practice for incidental thyroid nodules on CT or MR imaging is highly variable among radiologists especially for patients with smaller nodules (<=10 mm) and patients with multiple nodules and a history of cancer. This variability highlights the need for practice guidelines. Copyright © 2014 by American Journal of Neuroradiology.","","","2014","10.3174/ajnr.a3834","","","medline-24407274.pdf","medline-24407274"
"Critical race theory as a bridge in science training: the california state university, northridge build poder program","Saetermoe, C.l. And Chavira, G. And Khachikian, C.s. And Boyns, D. And Cabello, B.","Bmc Proceedings","","Background and purpose: unconscious bias and explicit forms of discrimination continue to pervade academic institutions. Multicultural and diversity training activities have not been sufficient in making structural and social changes leading to equity, therefore, a new form of critical consciousness is needed to train diverse scientists with new research questions, methods, and perspectives. The purpose of this paper is to describe building infrastructure leading to diversity (build);  promoting opportunities for diversity in education and research (poder), which is an undergraduate biomedical research training program based on transformative framework rooted in critical race theory (crt). Key highlights: by employing a crt-informed curriculum and training in build poder, students are empowered not only to gain access but also to thrive in graduate programs and beyond. Poder means ""power"" or ""to be able to"" in spanish. Essentially, we are ""building power"" using students' strengths and empowering them as learners. The new curriculum helps students understand institutional policies and practices that may prevent them from persisting in higher education, learn to become their own advocates, and successfully confront social barriers and instances of inequities and discrimination. To challenge these barriers and sustain campus changes in support of students, build poder works toward changing campus culture and research mentoring relationships. By joining with ongoing university structures such as the state university graduation initiative, we include crt tenets into the campus dialogue and stimulate campus-wide discussions around institutional change. Strong ties with five community college partners also enrich build poder's student body and strengthen mentor diversity. Preliminary evaluation data suggest that build poder's program has enhanced the racial/ethnic consciousness of the campus community, is effective in encouraging more egalitarian and respectful faculty-student relationships, and is a rigorous program of biomedical research training that supports students as they achieve their goals. Implications: biomedical research programs may benefit from a reanalysis of the fit between current training programs and student strengths. By incorporating the voices of talented youth, drawing upon their native strengths, we will generate a new science that links biomedical research to community health and social justice, generating progress toward health equity through a promising new generation of scholars. © 2017 the author(s).","","","2017","10.1186/s12919-017-0089-2","","","scopus-2-s2.0-85037612397.pdf","scopus-2-s2.0-85037612397"
"Information science students’ emotional response to copyright","Benson, S.r. And Ocepek, M.","Journal Of Education For Library And Information Science","","Copyright intersects with every field of library and information science (lis) from archival and preservation practices to reference services and academic librarianship. However, copyright instruction is still lacking in many information science programs across the country (cross & edwards, 2011;  schmidt & english, 2015). The sudden move to remote online education in the spring of 2020 due to a global pandemic highlighted the importance of understanding copyright exceptions and, especially, the power of fair use to quickly provide resources to a wide variety of patrons with novel needs. The need for accessible copyright education for all information professionals has never been stronger. However, engaging with copyright often provokes cognitive as well as affective uncertainty, likely due to the fear and anxiety that can come from the threat of serious financial and reputational consequences. Logically, it seems that librarians might feel less anxious about copyright if they had participated in formalized training about copyright focused on legal issues impacting library and information professionals. To understand this likely correlation, the researchers queried students using a qualitative survey both before and after taking an eight-week intensive copyright course that paired legal expertise with an everyday approach to material designed to demystify the law. Using phenomenographic methodology, the investigators asked their information science students how they attempt to answer copyright questions and how they feel about doing so. The results provide evidence supporting the need for more robust copyright education in schools of information science, as such training to help future librarians to feel more prepared to answer copyright questions and less anxious about intersections between copyright and their field of librarianship before they enter the workforce. © association for library and information science education, 2023.","","","2023","10.3138/jelis-2020-0086","","","scopus-2-s2.0-85159102032.pdf","scopus-2-s2.0-85159102032"
"Dynamic access-control policies on xml encrypted data","Bouganim, L. And Ngoc, F.d. And Pucheral, P.","Acm Transactions On Information And System Security","","The erosion of trust put in traditional database servers and in database service providers and the growing interest for different forms of selective data dissemination are different factors that lead to move the access-control from servers to clients. Different data encryption and key dissemination schemes have been proposed to serve this purpose. By compiling the access-control rules into the encryption process, all these methods suffer from a static way of sharing data. With the emergence of hardware security elements on client devices, more dynamic client-based access-control schemes can be devised. This paper proposes a tamper-resistant client-based xml access-right controller supporting flexible and dynamic access-control policies. The access-control engine is embedded in a hardware-secure device and, therefore, must cope with specific hardware resources. This engine benefits from a dedicated index to quickly converge toward the authorized parts of a potentially streaming xml document. Pending situations (i.e., where data delivery is conditioned by predicates, which apply to values encountered afterward in the document stream) are handled gracefully, skipping, whenever possible the pending elements and reassembling relevant parts when the pending situation is solved. Additional security mechanisms guarantee that (1) the input document is protected from any form of tampering and (2) no forbidden information can be gained by replay attacks on different versions of the xml document and of the access-control rules. Performance measurements on synthetic and real datasets demonstrate the effectiveness of the approach. Finally, the paper reports on two experiments conducted with a prototype running on a secured hardware platform. © 2008 acm.","","","2008","10.1145/1284680.1284684","","","scopus-2-s2.0-39149103087.pdf","scopus-2-s2.0-39149103087"
"Electronic health record sharing scheme with searchable attribute-based encryption on blockchain","Niu, S. And Chen, L. And Wang, J. And Yu, F.","Ieee Access","","With the digitization of traditional medical records, medical institutions encounter difficult problems, such as electronic health record storage and sharing. Patients and doctors spend considerable time querying the required data when accessing electronic health records, but the obtained data are not necessarily correct, and access is sometimes restricted. On this basis, this study proposes a medical data sharing scheme based on permissioned blockchains, which use ciphertext-based attribute encryption to ensure data confidentiality and access control of medical data. Under premise of ensuring patient identity privacy, a polynomial equation is used to achieve an arbitrary connection of keywords, and then blockchain technology is combined. In addition, the proposed scheme has keyword-indistinguishability against adaptive chosen keyword attacks under the random oracle model. Analysis shows that the scheme has high retrieval efficiency. © 2013 ieee.","","","2020","10.1109/access.2019.2959044","","","scopus-2-s2.0-85078364018.pdf","scopus-2-s2.0-85078364018"
"Current challenges in health economic modeling of cancer therapies: a research inquiry","Miller, J.d. And Foley, K.a. And Russell, M.w.","American Health And Drug Benefits","","Background: the demand for economic models that evaluate cancer treatments is increasing, as healthcare decision makers struggle for ways to manage their budgets while providing the best care possible to patients with cancer. Yet, after nearly 2 decades of cultivating and refining techniques for modeling the cost-effectiveness and budget impact of cancer therapies, serious methodologic and policy challenges have emerged that question the adequacy of economic modeling as a sound decision-making tool in oncology. Objectives: we sought to explore some of the contentious issues associated with the development and use of oncology economic models as informative tools in current healthcare decision-making. Our objective was to draw attention to these complex pharmacoeconomic concerns and to promote discussion within the oncology and health economics research communities. Methods: using our combined expertise in health economics research and economic modeling, we structured our inquiry around the following 4 questions: (1) are economic models adequately addressing questions relevant to oncology decision makers;  (2) what are the methodologic limitations of oncology economic models;  (3) what guidelines are followed for developing oncology economic models;  and (4) is the evolution of oncology economic modeling keeping pace with treatment innovation? Within the context of each of these questions, we discuss issues related to the technical limitations of oncology modeling, the availability of adequate data for developing models, and the problems with how modeling analyses and results are presented and interpreted. Discussion: there is general acceptance that economic models are good, essential tools for decision--making, but the practice of oncology and its rapidly evolving technologies present unique challenges that make assessing and demonstrating value especially complex. There is wide latitude for improvement in oncology modeling methodologies and how model results are presented and interpreted. Conclusion: complex technical and data availability issues with oncology economic modeling pose serious concerns that need to be addressed. It is our hope that this article will provide a framework to guide future discourse on this important topic.","","","2014","","","","scopus-2-s2.0-84901986460.pdf","scopus-2-s2.0-84901986460"
"Isometric relocation of data by sequencing of sub-clusters for privacy preservation in data mining","Rajalakshmi, V. And Mala, G.s.a.","International Journal Of Engineering And Technology","","Privacy preservation in data mining is a pioneering research area as the security of increasing amount of data is under risks. Privacy preservation in data mining [ppdm] is a delicate task as there is a trade-off between data anonymization and their utility. Existing ppdm techniques uses anonymization using randomization, generalization or suppression which reduces the utility of data. They also do not work on the data mining parameters like correlation, centroids etc., this paper provides a solution to handle this trade-off in an efficient way using isometric relocation. The work uses isometric relocation as it maintains the correlation and data mining results. The methodology is explained with the algorithm and its performance is compared using real-life datasets with existing techniques on various metrics after exhaustive experimentations.","","","2014","","","","scopus-2-s2.0-84900388995.pdf","scopus-2-s2.0-84900388995"
"Evidence for the effects of viewing visual artworks on stress outcomes: a scoping review","Law, M. And Karulkar, N. And Broadbent, E.","Bmj Open","","Objective to review the existing evidence on the effects of viewing visual artworks on stress outcomes and outline any gaps in the research. Design a scoping review was conducted based on the joanna briggs institute methodology for scoping reviews and using the preferred reporting items for systematic reviews and meta-analyses extension for scoping reviews. Two independent reviewers performed the screening and data extraction. Data sources medline, embase, apa psycinfo, cochrane central, scopus, google scholar, google, proquest theses and dissertations database, apa psycextra and opengrey.eu were searched in may 2020. Eligibility criteria studies were included if they investigated the effects of viewing at least one visual artwork on at least one stress outcome measure. Studies involving active engagement with art, review papers or qualitative studies were excluded. There were no limits in terms of year of publication, contexts or population types;  however, only studies published in the english language were considered. Data extraction and synthesis information extracted from manuscripts included: study methodologies, population and setting characteristics, details of the artwork interventions and key findings. Results 14 primary studies were identified, with heterogeneous study designs, methodologies and artwork interventions. Many studies lacked important methodological details and only four studies were randomised controlled trials. 13 of the 14 studies on self-reported stress reported reductions after viewing artworks, and all of the four studies that examined systolic blood pressure reported reductions. Fewer studies examined heart rate, heart rate variability, cortisol, respiration or other physiological outcomes. Conclusions there is promising evidence for effects of viewing artwork on reducing stress. Moderating factors may include setting, individual characteristics, artwork content and viewing instructions. More robust research, using more standardised methods and randomised controlled trial designs, is needed. Registration details a protocol for this review is registered with the open science framework (osf.io/gq5d8). © author(s) (or their employer(s)) 2021. Re-use permitted under cc by-nc. No commercial re-use. See rights and permissions. Published by bmj.","","","2021","10.1136/bmjopen-2020-043549","","","scopus-2-s2.0-85110067834.pdf","scopus-2-s2.0-85110067834"
"Prediction of stock price movements using monte carlo simulation","Nagarajan, K. And Prabhakaran, J.","International Journal Of Innovative Technology And Exploring Engineering","","Monte carlo simulation depends on random behaviour of events. When a variable takes values at random and becomes highly unpredictable due to its nature of randomness, the property of random numbers is made use of for predicting the future values that the variable may take. This property can be made use of for predicting share price movements, when the past share prices exhibit random behaviour, without exhibiting high fluctuations. This article explains the methodology of using monte carlo simulation for predicting share price movements and explains the process with the help of an illustration taking the monthly share price data of itc limited for a period of 36 months, where the share prices have moved within a narrow band. Findings of the analysis show that it works well and that the method of prediction is reasonably accurate, showing only a minor deviation from the actual prices. © beiesp.","","","2019","10.35940/ijitee.l2919.1081219","","","scopus-2-s2.0-85073676413.pdf","scopus-2-s2.0-85073676413"
"Performance analysis on voluntary geographic information systems with document-based nosql database","Maia, D.c.m. And Camargos, B.d.c. And Holanda, M.","Studies In Computational Intelligence","","With the advent of web 2.0 and mobile technology, including, smartphones equipped with gps (global positioning system) receptors, there has been an increase in the number of individuals who create and share spatial data. Consequently, the ability to store a large quantity of data, in diverse formats is made possible by geographic information systems (gis) that use voluntary data. This study presents a performance analysis of data storage architecture of a voluntary geographic information system (vgis) that uses a document-based nosql database and a relational database for comparison. To carry out the performance analysis it was necessary to remodel the application database from a relational database to a non-relational model. Furthermore, insertion and reading tests were needed, and performed in local and clustered environments using a simulator that generates random data on a large scale. The test results have sought to analyze the performance and feasibility of using a document-based database from data storage architecture for vgis. © springer international publishing ag 2018.","","","2018","10.1007/978-3-319-58965-7_13","","","scopus-2-s2.0-85026299016.pdf","scopus-2-s2.0-85026299016"
"Balancing access to health data and privacy: a review of the issues and approaches for the future. [Review]","Lane J., Schur C.","Health Services Research","","BACKGROUND: There has been a dramatic increase in the types of microdata and this holds great promise for health services research. However legislative efforts to protect individual privacy have reduced the flow of health care data for research purposes and increased costs and delays affecting the quality of analysis. AIM: This paper provides an overview of the challenges raised by concerns about data confidentiality in the context of health services research the current methodologies used to ensure data security and a description of one successful approach to balancing access and privacy. Materials and Methods. We analyze the issues of access and privacy using a conceptual framework based on balancing the risk of reidentification with the utility associated with data analysis. The guiding principle should be to generate released data that are as close to the maximum acceptable risk as possible. HIPAA and other privacy measures can perhaps be seen as having had the effect of lowering the ""maximum acceptable risk"" level and rendering some data unreleasable. RESULTS: We discuss the levels of risk and utility associated with different types of data used in health services research and the ability to link data from multiple sources as well as current models of data sharing and their limitations. DISCUSSION: One particularly compelling approach is to establish a remote access ""data enclave"" where statistical protections are applied to the data technical protections ensure compliance with data-sharing requirements and operational controls limit researchers' access to the data they need for their specific research questions. CONCLUSION: We recommend reducing delays in access to data for research increasing the use of remote access data enclaves and disseminating knowledge and promulgating standards for best practices related to data protection.","","","2010","10.1111/j.1475-6773.2010.01141.x","","","medline-21054366.pdf","medline-21054366"
"Vertical coordination, antitrust law, and international trade","Hamilton, S.f. And Stiegert, K.","Journal Of Law And Economics","","This paper demonstrates that vertically aligned private or public organizations are capable of generating strategic trade advantage similar to that acquired through direct government export subsidization. The model considers two forms of vertical coordination that lead to advantageous trade positions in international markets: up-stream vertical restraint and downstream equity sharing. Such practices are commonly employed both by state trading agencies and by private firms in nations with lenient antitrust laws. The finding has important implications under new world trade organization (wto) rules intended to reduce government intervention in international transactions. Recent reforms in the wto favor nations that sanction highly refined vertical linkages between firms, while nations with stringent antitrust legislation have an incentive to negotiate for greater harmonization of international laws.","","","2000","10.1086/467450","","","scopus-2-s2.0-0034354978.pdf","scopus-2-s2.0-0034354978"
"A scalable two-phase top-down specialization approach for data anonymization using mapreduce on cloud","Zhang, X. And Yang, L.t. And Liu, C. And Chen, J.","Ieee Transactions On Parallel And Distributed Systems","","A large number of cloud services require users to share private data like electronic health records for data analysis or mining, bringing privacy concerns. Anonymizing data sets via generalization to satisfy certain privacy requirements such as $(k)$-anonymity is a widely used category of privacy preserving techniques. At present, the scale of data in many cloud applications increases tremendously in accordance with the big data trend, thereby making it a challenge for commonly used software tools to capture, manage, and process such large-scale data within a tolerable elapsed time. As a result, it is a challenge for existing anonymization approaches to achieve privacy preservation on privacy-sensitive large-scale data sets due to their insufficiency of scalability. In this paper, we propose a scalable two-phase top-down specialization (tds) approach to anonymize large-scale data sets using the mapreduce framework on cloud. In both phases of our approach, we deliberately design a group of innovative mapreduce jobs to concretely accomplish the specialization computation in a highly scalable way. Experimental evaluation results demonstrate that with our approach, the scalability and efficiency of tds can be significantly improved over existing approaches. © 1990-2012 ieee.","","","2014","10.1109/tpds.2013.48","","","scopus-2-s2.0-84891751231.pdf","scopus-2-s2.0-84891751231"
"Potential Bias in Image-Guided Procedure Research: A Retrospective Analysis of Disclosed Conflicts of Interest and Open Payment Records","Hsieh L. J., Madadi S. R., Shore K. T., Keller E. J., Makary M. S.","Journal of Vascular & Interventional Radiology","","PURPOSE: To assess the prevalence of positive conflicts of interest (COI) disclosures in United States-based interventional radiology (IR) research as well as the level of agreement between disclosed financial relationships and Open Payment Data for top-cited image-guided procedure research.\\\\\\\\rMATERIALS AND METHODS: All publications in volume 30 (2019) of the Journal of Vascular and Interventional Radiology (JVIR) were reviewed to estimate the prevalence of COI disclosures in IR research. Publications were categorized as primary research systematic review or other. The prevalence was subsequently compared across JVIR publication subtypes and categories and on the basis of whether they were device-focused publications using chi2 tests. Additionally the Web of Science database was searched for the top 10 most cited studies of 10 common image-guided procedures with available U.S. physician payment data. The payments were categorized as historical (>1 year prior to publication) or active (<1 year prior to publication) and compared with the disclosed financial COIs using 1-way analysis of variance.\\\\\\\\rRESULTS: Positive COI disclosures were present in 114 (29%) of the 397 publications in JVIR volume 30. Positive COI disclosures were most prevalent in standards of practice (50% P = .01) and more prevalent in device-focused publications (54% vs 23% P < .01). Among the 396 authors of 100 United States-based top-cited image-guided procedure publications 383 (97%) failed to disclose at least 1 active financial relationship with an average of $57937 in undisclosed payments per publication.\\\\\\\\rCONCLUSIONS: COI are prevalent in IR similar to other areas of healthcare research and COI in top-cited image-guided procedure research are often underreported. Copyright © 2021 SIR. Published by Elsevier Inc. All rights reserved.","","","2022","10.1016/j.jvir.2021.08.026","","","medline-34756998.pdf","medline-34756998"
"Integrating radiology and hospital information systems: the advantage of shared data","Haug, P.j. And Pryor, T.a. And Frederick, P.r.","Proceedings / The ... Annual Symposium On Computer Application [Sic] In Medical Care. Symposium On Computer Applications In Medical Care","","Information management is central to modern patient care. Computerization of information management has resulted in both departmental systems which serve information needs in locations such as the radiology department and in hospital-wide information systems which seek to integrate management of clinical data from many departments. For each of these systems to achieve the goal of maximizing both the effectiveness of health care workers and the quality of patient care, they need to share the data that they capture. Below we discuss a variety of applications, both currently available and in the realm of research protocols, that depend on a high level of communication between radiology information systems and hospital information systems. These examples suggest the benefits of integrating the medically relevant data collected by all of the computer-based information systems in the hospital setting.","","","1992","","","","scopus-2-s2.0-0027033559.pdf","scopus-2-s2.0-0027033559"
"The sharing economy and its paradoxes: a sociological study of sharing communities in russia","Shmidt, M.","Mir Rossii","","Over the past decade there has been an enormous rise in alternative forms of economic organization, such as the sharing economy - an under-theorized and contradictory empirical phenomenon. The paper studies the variety of interaction practices and motivations for participation and identifies common and specific features of self-organization by comparing three platforms: darudar (sharing goods), bank vremeni [time bank] (sharing time and services) and couchsurfing (sharing accommodation and leisure). The data, which was triangulated, includes: (i) 25 in-depth interviews conducted with experts and active users of the platforms, (ii) ethnography from participant observation of users' offline meetings, (iii) systematic online observation. This study employs a blended ethnography/ netnography approach - studying the sharing economy communities both online and face-to-face to provide 'thick' description of community-building. We theorize that sharing in the sharing economy is a separate principle of resource allocation, which is characterized by the priority of goods over the structure of relations between parties. In contrast to the reciprocity principle, the recipient in sharing is selected with respect to a fixed amount of resources which the donor possesses. Sharing is moving far beyond the boundaries of kindred, friend, partner or other personal relationships, as far as the counterparty is selected among the participants of an extended network of social contacts. The circle of people who can enjoy the benefits of a joint resource expands to the many thousands of users of the virtual sharing platform. What motivates the well-resourced users of the sharing economy platforms, who possess economic and cultural capital, to become practitioners of sharing? Aspiration for communitybuilding, deriving from the extrapolation of the self to the aggregate level: the 'extended self'. Sharing contributes to a sense of an imaginary community, making ourselves an integral part. Practically, sharing transforms into a ritual chain: from the preparation of resources for exchange to the choice of counteragent, communication before the act of sharing, during and after, all of which create a full part of social life. When offering to share material and immaterial objects, participants of the platforms offer a part of themselves - talents and opportunities, communication and empathy, belonging to cultural tradition. In return, they receive a means of reducing loneliness and overcoming social alienation. © hse, 1992-2018. В фокусе исследования находится экономика совместного потребления (sharing economy) - явление, получившее неоднозначную трактовку в существующей ли- тературе. То, что выводит экономику совместного потребления на совершенно новый уровень - это диджитализация. Интернет-платформы - медиаторы между частными пользователями - анонимизируют участников сделок и переносят обмен в мир расширенных сетей, соединяющих людей с большим количеством незна- комцев, тем самым создавая сообщество, в котором никто не знает друг друга по- именно, но обладает правом вкладывать ресурс и пользоваться ресурсами других. Вопрос, которым мы задаемся в предложенном исследовании, - почему при всех рисках, связанных с декоммерциализацией рыночных отношений в экономике со- вместного потребления, количество ее пользователей неуклонно увеличивается? Что мотивирует ресурсообеспеченных пользователей, обладающих высоким уров- нем не только экономического, но и культурного капитала, включаться в экономи- ку совместного потребления? Мы ставим перед собой следующую цель: сравнить разнообразие практик взаимодействия и мотивацию пользователей трех платформ совместного потребления (дарудар, банк времени, couchsurfing), а также выявить общие и специфические черты самоорганизации сообществ. Исследование опирается на методологию этнографического подхода и нет- нографии, использующейся для анализа культур цифровых сообществ. Методом сбора данных является проведение 25 глубинных интервью, а также включенное наблюдение на общих встречах участников сообществ. Стремясь уйти от конвенциональной рамки рассмотрения внеэкономических форм обмена через стратегию выживания, основанную на подключении личных связей, мы предположили, что «совместность» в экономике совместного потребле- ния - это обособленный принцип распределения ресурсов, характеризующийся первичностью блага, а не характерных особенностей отношений между донором и реципиентом. Входным билетом в сообщества становится предложение соб- ственности или труда. Три кейса, которые мы отобрали для полевого исследова- ния, отвечают этой специфике: дарудар, площадка встречи спроса и предложения на отчуждаемое от себя благо;  couchsurfing, платформа, создающая глобальный «жилищный фонд», временный доступ к которому получает любой зарегистри- рованный участник;  и, наконец, банк времени, способ организации трудовой дея- тельности на безвозмездной основе. Качественно разные по своей организации случаи показали: тесное перепле- тение формальных правил и неформальных практик определяет индивидуальные стратегии взаимодействия. Принцип совместности приводится в жизнь тремя структурными категориями: первая - это накопление критической массы, точки, в которой система становится достаточно инертной для того, чтобы поддержи- ваться за счет достаточного количества участников и разнообразия ресурсного по- тенциала;  вторая - гетерогенный (с точки зрения стиля жизни) социальный пор- трет участия;  третья - способность к саморегулированию. Участники четко осознают свою позицию в сообществе, понимая, что ситу- ация обмена, в которую они себя поставили, отличается как от рынка, так и от дачного кооператива. Что мотивирует ресурсообеспеченных пользователей ста- новиться практиками совместного потребления? Очевидно, что это стремление к сообществлению, заключающемуся в выводу своего «я» на агрегатный уро- вень, включению в него того, с кем участник разделяет благо. И акт разделения, и чувство совместного обладания совершенствуют ощущение принадлежности к воображаемому сообществу потребления, делают наше «я» его неотъемлемой ча- стью. В практическом смысле совместное потребление превращается в цепочку повторяющихся манипуляций: подготовку ресурсов к обмену, выбору реципиента, а также коммуникацию до, во время и после непосредственного обмена, форми- рующих полноценную часть социальной жизни. Делая предложение поделиться материальными и нематериальными объектами, участник движения предлагает реципиентам часть себя - таланты и возможности, способность к коммуникации, эмпатию, принадлежность к куль урной традиции, взамен получая способ скра- сить одиночество и укрепить чувство единения.","","","2019","10.17323/1811-038x-2019-28-2-148-171","","","scopus-2-s2.0-85065098886.pdf","scopus-2-s2.0-85065098886"
"Reproducible detection of disease-associated markers from gene expression data","Omae, K. And Komori, O. And Eguchi, S.","Bmc Medical Genomics","","Background: detection of disease-associated markers plays a crucial role in gene screening for biological studies. Two-sample test statistics, such as the t-statistic, are widely used to rank genes based on gene expression data. However, the resultant gene ranking is often not reproducible among different data sets. Such irreproducibility may be caused by disease heterogeneity. Results: when we divided data into two subsets, we found that the signs of the two t-statistics were often reversed. Focusing on such instability, we proposed a sign-sum statistic that counts the signs of the t-statistics for all possible subsets. The proposed method excludes genes affected by heterogeneity, thereby improving the reproducibility of gene ranking. We compared the sign-sum statistic with the t-statistic by a theoretical evaluation of the upper confidence limit. Through simulations and applications to real data sets, we show that the sign-sum statistic exhibits superior performance. Conclusion: we derive the sign-sum statistic for getting a robust gene ranking. The sign-sum statistic gives more reproducible ranking than the t-statistic. Using simulated data sets we show that the sign-sum statistic excludes hetero-type genes well. Also for the real data sets, the sign-sum statistic performs well in a viewpoint of ranking reproducibility. © 2016 the author(s).","","","2016","10.1186/s12920-016-0214-5","","","scopus-2-s2.0-84982108604.pdf","scopus-2-s2.0-84982108604"
"Analysis of methodological deficiencies of studies reporting surgical outcome following cemented total-joint arthroplasty of trapezio-metacarpal joint of the thumb","Sambandam S. N., Gul A., Priyanka P.","International Orthopaedics","","Cemented total-joint arthroplasty has been increasingly used in the treatment of end stage arthritis of the thumb trapeziometacarpal joint. Evidence supporting its use in the treatment of trapeziometacarpal disorders in the literature is very limited. Most hand surgeons agree that there are concerns about the methodological quality of the limited literature available. In this study we analysed the methodological quality of the outcome studies on cemented total-joint arthroplasty of the thumb. We included all the outcome studies published in the English literature on cemented total-joint arthroplasty of the trapeziometacarpal joint of thumb. We analysed these studies for methodological deficiencies and quality of outcome reporting based on the recommendations given by Coleman et al. Our study revealed that there were no uniform standards of outcome reporting. The mean Coleman score for the studies dealing with cemented total-joint arthroplasty of the thumb was 42.9. Major deficiencies were identified in areas like subject selection criteria (0/15) type of study (5.7/15) description of surgical procedure (3.7/5) description of the rehabilitation protocol (2/10) outcome measures (4.4/10) and outcome assessment (3.9/15). The methodological quality of the studies published within the last 10 years (49.9+/-9.7) was found to be slightly better than the studies published over 10 years ago (39.7+/-7.8). Our study highlights the need for more evidence in the form of randomised controlled prospective studies conducted with good methodological quality comparing the cemented total-joint arthroplasty of the thumb to other procedures available for the treatment of disorders of the thumb. Further to improve the standards of reporting journal editors should try to standardise the outcome of the reporting by following the surgical procedures on the thumb.","","","2007","10.1007/s00264-006-0240-6","","","medline-17021833.pdf","medline-17021833"
"Mixed method evaluation of a community-based physical activity program using the RE-AIM framework: practical application in a real-world setting","Koorts H., Gillison F.","BMC Public Health","","BACKGROUND: Communities are a pivotal setting in which to promote increases in child and adolescent physical activity behaviours. Interventions implemented in these settings require effective evaluation to facilitate translation of findings to wider settings. The aims of this paper are to i) present findings from a RE-AIM evaluation of a community-based physical activity program and ii) review the methodological challenges faced when applying RE-AIM in practice.\\\\\\\\rMETHODS: A single mixed-methods case study was conducted based on a concurrent triangulation design. Five sources of data were collected via interviews questionnaires archival records documentation and field notes. Evidence was triangulated within RE-AIM to assess individual and organisational-level program outcomes.\\\\\\\\rRESULTS: Inconsistent availability of data and a lack of robust reporting challenged assessment of all five dimensions. Reach Implementation and setting-level Adoption were less successful Effectiveness and Maintenance at an individual and organisational level were moderately successful. Only community-level Adoption was highly successful reflecting the key program goal to provide community-wide participation in sport and physical activity.\\\\\\\\rCONCLUSIONS: This research highlighted important methodological constraints associated with the use of RE-AIM in practice settings. Future evaluators wishing to use RE-AIM may benefit from a mixed-method triangulation approach to offset challenges with data availability and reliability.","","","2015","10.1186/s12889-015-2466-y","","","medline-26545582.pdf","medline-26545582"
"Deterministic attribute-based encryption","Shi, Y. And Liu, J. And Han, Z. And Qiu, S.","International Journal Of High Performance Computing And Networking","","Attribute-based encryption enables data owners to share their information by specifying access control policies while outsourcing their encrypted data to the cloud. However, there are no efficient searchable schemes over encrypted data in attribute-based setting. In this paper, we propose a novel primitive called deterministic attribute-based encryption (dabe), which simultaneously supports data sharing and retrieving in time logarithmic in the size of the database. We formalise the security properties for dabe with respect to auxiliary inputs. Furthermore, we propose a generic construction in the random oracle model and a selectively secure concrete key-policy dabe in the standard model under decisional bilinear diffie-hellman assumption. Copyright © 2016 inderscience enterprises ltd.","","","2016","10.1504/ijhpcn.2016.080417","","","scopus-2-s2.0-84999816185.pdf","scopus-2-s2.0-84999816185"
"Gan-based approaches for generating structured data in the medical domain","Abedi, M. And Hempel, L. And Sadeghi, S. And Kirsten, T.","Applied Sciences (Switzerland)","","Modern machine and deep learning methods require large datasets to achieve reliable and robust results. This requirement is often difficult to meet in the medical field, due to data sharing limitations imposed by privacy regulations or the presence of a small number of patients (e.g., rare diseases). To address this data scarcity and to improve the situation, novel generative models such as generative adversarial networks (gans) have been widely used to generate synthetic data that mimic real data by representing features that reflect health-related information without reference to real patients. In this paper, we consider several gan models to generate synthetic data used for training binary (malignant/benign) classifiers, and compare their performances in terms of classification accuracy with cases where only real data are considered. We aim to investigate how synthetic data can improve classification accuracy, especially when a small amount of data is available. To this end, we have developed and implemented an evaluation framework where binary classifiers are trained on extended datasets containing both real and synthetic data. The results show improved accuracy for classifiers trained with generated data from more advanced gan models, even when limited amounts of original data are available. © 2022 by the authors.","","","2022","10.3390/app12147075","","","scopus-2-s2.0-85137361846.pdf","scopus-2-s2.0-85137361846"
"Synchronization of diverging versions of a controlled medical terminology","Oliver D. E.","Proceedings / AMIA ..","","To share clinical data and to build interoperable computer systems that permit data entry data retrieval and data analysis users and systems at multiple sites need a shared clinical terminology. However local sites that adopt a shared terminology have local needs that prompt local-terminology maintainers to make changes to the local version. Meanwhile maintainers of the shared terminology make changes to the shared version and the two terminologies diverge. I propose a formal model for managing change with additional features included for the local site. If terminology maintainers follow such a model the local-terminology maintainer can synchronize the local version with the shared version at periodic intervals. I am implementing a prototype which I will use to assess the model and to study the synchronization process.","","","1998","","","","medline-9929339.pdf","medline-9929339"
"Dynamic verification for hybrid concurrent programming models","Mutlu, E. And Gajinov, V. And Cristal, A. And Tasiran, S. And Unsal, O.s.","Lecture Notes In Computer Science (Including Subseries Lecture Notes In Artificial Intelligence And Lecture Notes In Bioinformatics)","","We present a dynamic verification technique for a class of concurrent programming models that combine dataflow and shared memory programming. In this class of hybrid concurrency models, programs are built from tasks whose data dependencies are explicitly defined by a programmer and used by the runtime system to coordinate task execution. Differently from pure dataflow, tasks are allowed to have shared state which must be properly protected using synchronization mechanisms, such as locks or transactional memory (tm). While these hybrid models enable programmers to reason about programs, especially with irregular data sharing and communication patterns, at a higher level, they may also give rise to new kinds of bugs as they are unfamiliar to the programmers. We identify and illustrate a novel category of bugs in these hybrid concurrency programming models and provide a technique for randomized exploration of program behaviors in this setting. © springer international publishing switzerland 2014.","","","2014","10.1007/978-3-319-11164-3_13","","","scopus-2-s2.0-84921718632.pdf","scopus-2-s2.0-84921718632"
"The use of mass spectrometry imaging to predict treatment response of patient-derived xenograft models of triple-negative breast cancer","Mascini N. E., Eijkel G. B., ter Brugge P., Jonkers J., Wesseling J., Heeren R. M.","Journal of Proteome Research","","In recent years mass spectrometry imaging (MSI) has been shown to be a promising technique in oncology. The effective application of MSI however is hampered by the complexity of the generated data. Bioinformatic approaches that reduce the complexity of these data are needed for the effective use in a (bio)medical setting. This holds especially for the analysis of tissue microarrays (TMA) which consist of hundreds of small tissue cores. Here we present an approach that combines MSI on tissue microarrays with principal component linear discriminant analysis (PCA-LDA) to predict treatment response. The feasibility of such an approach was evaluated on a set of patient-derived xenograft models of triple-negative breast cancer (TNBC). PCA-LDA was used to classify TNBC tumor tissues based on the proteomic information obtained with matrix-assisted laser desorption ionization (MALDI) MSI from the TMA surface. Classifiers based on two different tissue microarrays from the same tumor models showed overall classification accuracies between 59 and 77% as determined by cross-validation. Reproducibility tests revealed that the two models were similar. A clear effect of intratumor heterogeneity of the classification scores was observed. These results demonstrate that the analysis of MALDI-MSI data by PCA-LDA is a valuable approach for the classification of treatment response and tumor heterogeneity in breast cancer.","","","2015","10.1021/pr501067z","","","medline-25553735.pdf","medline-25553735"
"Interlaboratory comparison of results of susceptibility testing with caspofungin against Candida and Aspergillus species","Odds F. C., Motyl M., Andrade R., Bille J., Canton E., Cuenca-Estrella M., Davidson A., Durussel C., Ellis D., Foraker E., Fothergill A. W., Ghannoum M. A., Giacobbe R. A., Gobernado M., Handke R., Laverdiere M., Lee-Yang W., Merz W. G., Ostrosky-Zeichner L., Peman J., Perea S., Perfect J. R., Pfaller M. A., Proia L., Rex J. H., Rinaldi M. G., Rodriguez-Tudela J. L., Schell W. A., Shields C., Sutton D. A., Verweij P. E., Warnock D. W.","Journal of Clinical Microbiology","","Seventeen laboratories participated in a study of interlaboratory reproducibility with caspofungin microdilution susceptibility testing against panels comprising 30 isolates of Candida spp. and 20 isolates of Aspergillus spp. The laboratories used materials supplied from a single source to determine the influence of growth medium (RPMI 1640 with or without glucose additions and antibiotic medium 3 [AM3]) the same incubation times (24 h and 48 h) and the same end point definition (partial or complete inhibition of growth) for the MIC of caspofungin. All tests were run in duplicate and end points were determined both spectrophotometrically and visually. The results from almost all of the laboratories for quality control and reference Candida and Aspergillus isolates tested with fluconazole and itraconazole matched the NCCLS published values. However considerable interlaboratory variability was seen in the results of the caspofungin tests. For Candida spp. the most consistent MIC data were generated with visual ""prominent growth reduction"" (MIC(2)) end points measured at 24 h in RPMI 1640 where 73.3% of results for the 30 isolates tested fell within a mode +/- one dilution range across all 17 laboratories. MIC(2) at 24 h in RPMI 1640 or AM3 also gave the best interlaboratory separation of Candida isolates of known high and low susceptibility to caspofungin. Reproducibility of MIC data was problematic for caspofungin tests with Aspergillus spp. under all conditions but the minimal effective concentration end point defined as the lowest caspofungin concentration yielding conspicuously aberrant hyphal growth gave excellent reproducibility for data from 14 of the 17 participating laboratories.","","","2004","","","","medline-15297486.pdf","medline-15297486"
"Laboratory extruder results - their evaluation and relevance to pvc processing","Barth, Hansjochen","Kunststoffe - German Plastics","","The results obtained with laboratory extruders become clearer and more informative if one processes and evaluates the primary results read off the instruments before actually presenting them. To this end, the author describes influencing factors, data, reproducibility and various methods of evluation and representation of results and explains these with the aid of two examples.","","","1979","","","","scopus-2-s2.0-0018492875.pdf","scopus-2-s2.0-0018492875"
"Didactic explanation and school mathematical discourse: the case of variation","Balderas, E.r. And Cantoral, R.","Acta Scientiae","","Context: an important area of research in educational mathematics is social communicative practices in classroom organization. Objective: to locate and analyse the forms of introduction and development of variation in teaching situations. Design: using a qualitative-interpretive approach, specifically an ethnographic study, for the analysis of socially shared practices among teachers, when they use explanation in the classroom and its correlation in the extended classroom. Environment and participants: the research participants were three professors (one physicist and two mathematicians) who taught the subject mathematics i. On average, their groups consisted of 37 students. Data collection and analysis: information was collected through audio-recorded and transcribed classroom observations. A detailed sequential study was carried out on teaching situations to describe the work done in each intervention that precedes or proceeds to yet another situation and thus construct the categories of analysis. Results: due to the interactive nature, the construction of explanations is seen as an object of analysis and this implies that the minimum units are sequences of interactions, since the construction of discursive resources and meanings for variation was addressed. Conclusions: during the classes we recorded different types of explanation, models in which the notion of variation is modelled, the teaching representations when explaining the contents through numerical, algebraic, and natural language representation. © 2021 lutheran university of brazil. All rights reserved.","","","2021","10.17648/acta.scientiae.6578","","","scopus-2-s2.0-85115999307.pdf","scopus-2-s2.0-85115999307"
"Reforms to improve reproducibility and quality must be coordinated across the research ecosystem: the view from the UKRN Local Network Leads","Stewart S. L. K., Pennington C. R., da Silva G. R., Ballou N., Butler J., Dienes Z., Jay C., Rossit S., Samara A.","BMC Research Notes","","Many disciplines are facing a ""reproducibility crisis"" which has precipitated much discussion about how to improve research integrity reproducibility and transparency. A unified effort across all sectors levels and stages of the research ecosystem is needed to coordinate goals and reforms that focus on open and transparent research practices. Promoting a more positive incentive culture for all ecosystem members is also paramount. In this commentary we-the Local Network Leads of the UK Reproducibility Network-outline our response to the UK House of Commons Science and Technology Committee's inquiry on research integrity and reproducibility. We argue that coordinated change is needed to create (1) a positive research culture (2) a unified stance on improving research quality (3) common foundations for open and transparent research practice and (4) the routinisation of this practice. For each of these areas we outline the roles that individuals institutions funders publishers and Government can play in shaping the research ecosystem. Working together these constituent members must also partner with sectoral and coordinating organisations to produce effective and long-lasting reforms that are fit-for-purpose and future-proof. These efforts will strengthen research quality and create research capable of generating far-reaching applications with a sustained impact on society. Copyright © 2022. The Author(s).","","","2022","10.1186/s13104-022-05949-w","","","medline-35168675.pdf","medline-35168675"
"Estandares Consolidados de Reporte de Evaluaciones Economicas Sanitarias: Version en Espanol de la Lista de Comprobacion CHEERS","Augustovski F., Garcia Marti S., Pichon-Riviere A.","Value in Health Regional Issues","","OBJECTIVE: It is important to have adequate and updated guides for reporting health economic evaluations (HEE). Due to their nature and methodological complexity HEE have particular challenges for adequate reporting which can be greater than more traditional study designs such as randomized controlled trials. CHEERS (Consolidated Health Economic Evaluation Reporting Standards) have recently been published in English. Our objectives were to adapt the CHEERS list to Spanish.\\\\\\\\rMETHODS AND RESULTS: We followed the recommended methods of the Equator (Enhancing the Quality and Transparency Of health Research) network. We made an initial translation to Spanish a back translation to English and an initial Spanish version that was circulated through ISPOR and REDETSA. Finally a final Spanish version was consolidated. The list contains 24 items grouped in Title and Abstract; Introduction; Methods; Results; Discussion; and Other (which included conflict of interest reporting). The scope of use is independent of methodological vehicle (either single-study or evidence synthesis-based HEE); type of strategies to evaluate (clinical or public health; preventive diagnostic curative palliative). Most of the items are generic and apply to any study design; while some of them are particularly oriented to single-study or evidence-synthesis/modeling studies.\\\\\\\\rCONCLUSIONS: Diffusion and use of the CHEERS checklist in Spanish will contribute to a more consistent and transparent reporting of health economic evaluations in Spanish speaking contexts. Copyright © 2013 International Society for Pharmacoeconomics and Outcomes Research (ISPOR) Published by International Society for Pharmacoeconomics and Outcomes Research (ISPOR) All rights reserved.","","","2013","10.1016/j.vhri.2013.10.004","","","medline-29702767.pdf","medline-29702767"
"In-depth analysis of patterns in selection of different physiologically-based pharmacokinetic modeling tools: Part II - Assessment of model reusability and comparison between open and non-open source-code software","Aldibani H. K. A., Rajput A. J., Rostami-Hodjegan A.","Biopharmaceutics and Drug Disposition.","","Whilst the reproducibility of models in the area of systems biology and quantitative systems pharmacology has been the focus of attention lately the concept of 'reusability' is not addressed. With the advent of the 'Model Master File' dominating some regulatory discussions on pharmaceutical applications of physiologically-based pharmacokinetic (PBPK) models reusability becomes a vital aspect of confidence in their use. Herein we define 'reusability' specifically in the context of PBPK models and investigate the influence of open versus non-open source-code (NOSC) nature of the software on the extent of 'reusability'. Original articles (n = 145) that were associated with the development of novel PBPK models were identified as source models and citations to these reports which involved further PBPK model development were explored (n > 1800) for reuse cases of the source PBPK model whether in full or partial form. The nature of source-code was a major determinant of external reusability for PBPK models (>50% of the NOSC models as opposed <25% of open source-code [OSC]). Full reusability of the models was not common and mostly involved internal reuse of the OSC model (by the group who had previously developed the original model). The results were stratified by the software utilised (various) organisations involved (academia industry regulatory) and type of reusability (full vs. partial). The clear link between external reuse of models and NOSC PBPK software might stem from many elements related to quality and trust that require further investigation and challenges the unfounded notion that OSC models are associated with higher uptake for reuse. Copyright © 2023 The Authors. Biopharmaceutics & Drug Disposition published by John Wiley & Sons Ltd.","","","2023","10.1002/bdd.2360","","","medline-37083940.pdf","medline-37083940"
"A note on the time series behaviour of earnings per share data of taiwanese firms","Bao, B.-H. And Bao, D.-H. And Firth, M.","Journal Of Business Finance And Accounting","","The time series properties of earnings per share data of taiwanese firms are investigated. The data come from the 48 firms that had a stock exchange quotation throughout the period 1970/1972 to 1985. The statistical characteristics of the time series are compared against those of four standard stochastic processes. The results indicate that a random walk process best models the time series nature of the earnings per share data. © q blackwell publishers ltd 1996.","","","1996","10.1111/j.1468-5957.1996.tb01030.x","","","scopus-2-s2.0-77951447462.pdf","scopus-2-s2.0-77951447462"
"Traumatic dental injuries as reported during school hours in Bergen","Skeie M. S., Evjensvold T., Hoff T. H., Bardsen A.","Dental Traumatology","","AIMS: To identify existing guidelines for managing traumatic dental injuries (TDIs) in the schools of Bergen to ascertain the frequency of occurrence of such injuries and to estimate the need for further information among teachers and school administrators.\\\\\\\\rMATERIAL AND METHODS: The study undertaken among teachers and school administrators of elementary and lower secondary schools in Bergen municipality was questionnaire-based and included a cross section of staff. The structured short questionnaire included items registering TDIs during 2009 existence of routines or guidelines for managing TDIs previous relevant training and request for TDI education or information. The statistical methods included frequency tables and logistic regression analysis.\\\\\\\\rRESULTS: The response rate was 73%. The incidence proportion of TDIs was measured to 0.74% of children at risk varying according to children's classes (peak at third class: 1.68% of children in the population). No schools had adequate written guidelines for handling TDIs. Previous education on the subject was scarce. In 20 schools there was no perceived need for TDI-related education or information. The schools' routines for TDI reporting who was in charge of the reporting acquired TDI education and expressed need for TDI information or education did not influence the number of reported TDI cases.\\\\\\\\rCONCLUSION: This study has produced reliable information that schools in the municipality of Bergen could improve ways of reporting and managing TDIs. As teachers with skills in handling TDIs could help to improve the prognosis for injured teeth some types of educational intervention in schools should be launched. Copyright © 2014 The Authors Dental Traumatology Published by John Wiley & Sons Ltd.","","","2015","10.1111/edt.12146","","","medline-25311526.pdf","medline-25311526"
"Challenges in the evaluation of observational data trustworthiness from a data producers viewpoint (fair+)","Koedel, U. And Schuetze, C. And Fischer, P. And Bussmann, I. And Sauer, P.k. And Nixdorf, E. And Kalbacher, T. And Wichert, V. And Rechid, D. And Bouwer, L.m. And Dietrich, P.","Frontiers In Environmental Science","","Recent discussions in many scientific disciplines stress the necessity of “fair” data. Fair data, however, does not necessarily include information on data trustworthiness, where trustworthiness comprises reliability, validity and provenience/provenance. This opens up the risk of misinterpreting scientific data, even though all criteria of “fair” are fulfilled. Especially applications such as secondary data processing, data blending, and joint interpretation or visualization efforts are affected. This paper intends to start a discussion in the scientific community about how to evaluate, describe, and implement trustworthiness in a standardized data evaluation approach and in its metadata description following the fair principles. It discusses exemplarily different assessment tools regarding soil moisture measurements, data processing and visualization and elaborates on which additional (metadata) information is required to increase the trustworthiness of data for secondary usage. Taking into account the perspectives of data collectors, providers and users, the authors identify three aspects of data trustworthiness that promote efficient data sharing: 1) trustworthiness of the measurement 2) trustworthiness of the data processing and 3) trustworthiness of the data integration and visualization. The paper should be seen as the basis for a community discussion on data trustworthiness for a scientifically correct secondary use of the data. We do not have the intention to replace existing procedures and do not claim completeness of reliable tools and approaches described. Our intention is to discuss several important aspects to assess data trustworthiness based on the data life cycle of soil moisture data as an example. Copyright © 2022 koedel, schuetze, fischer, bussmann, sauer, nixdorf, kalbacher, wichert, rechid, bouwer and dietrich.","","","2022","10.3389/fenvs.2021.772666","","","scopus-2-s2.0-85124087032.pdf","scopus-2-s2.0-85124087032"
"Bridging the gap: multidisciplinary collaboration in medicine and architecture","Viets-Schmitz, E.a. And Anderson, D.c.","University Of Toronto Medical Journal","","As the world becomes increasingly connected and information is freely shared, a trend toward interdisciplinary collaboration is taking place in both industry and education. This trend is highlighted by recent collaboration between clinicians and architects in both research and design. In the design of healthcare spaces, architects are working with clinicians and researchers to employ an evidencebased approach to making design decisions. The advent of evidence-based design represents a shift from basing design decisions solely on tradition or opinion to an approach that emphasizes the importance of using credible research to inform design decisions. The research expertise of clinicians is vital to the practice of evidence-based design, which traces its origins to the well-established concepts of evidence-based medicine. In the context of healthcare, evidence-based design focuses on design interventions that help make hospitals safer and more comfortable for patients and staff, that promote healing, and that are fiscally sustainable. Through case studies and other examples, this paper will illustrate how the growing body of credible research regarding the impact of the built environment on people creates unique opportunities for architects and clinicians to work together toward a common goal of evidence-based practice.","","","2011","","","","scopus-2-s2.0-79957638857.pdf","scopus-2-s2.0-79957638857"
"Applying collaborative learning and quality improvement to public health: lessons from the collaborative improvement and innovation network (coiin) to reduce infant mortality","Ghandour, R.m. And Flaherty, K. And Hirai, A. And Lee, V. And Walker, D.k. And Lu, M.c.","Maternal And Child Health Journal","","Objectives: infant mortality remains a significant public health problem in the u.s. The collaborative improvement & innovation network (coiin) model is an innovative approach, using the science of quality improvement and collaborative learning, which was applied across 13 southern states in public health regions iv and vi to reduce infant mortality and improve birth outcomes. We provide an in-depth discussion of the history, development, implementation, and adaptation of the model based on the experience of the original coiin organizers and participants. In addition to the political genesis and functional components of the initiative, 8 key lessons related to staffing, planning, and implementing future coiins are described in detail. Methods: this paper reports the findings from a process evaluation of the model. Data on the states’ progress toward reducing infant mortality and improving birth outcomes were collected through a survey in the final months of a 24-month implementation period, as well as through ongoing team communications. Results: the peer-to-peer exchange and platform for collaborative learning, as well as the sharing of data across the states, were major strengths and form the foundation for future coiin efforts. A lasting legacy of the initiative is the unique application and sharing of provisional “real time” data to inform “real time” decision-making. Conclusion: the coiin model of collaborative learning, qi, and innovation offers a promising approach to strengthening partnerships within and across states, bolstering data systems to inform and track progress more rapidly, and ultimately accelerating improvement toward healthier communities, states, and the nation as a whole. © 2017, springer science+business media new york (outside the usa).","","","2017","10.1007/s10995-016-2235-2","","","scopus-2-s2.0-85009822257.pdf","scopus-2-s2.0-85009822257"
"The m6A-regulation and single cell effect pattern in sunitinib resistance on clear cell renal cell carcinoma: Identification and validation of targets","Deng Y., Wang F., Wu X., Du K., Yang Q., Xia T.","Frontiers in Pharmacology","","Background: Sunitinib is the main target drug for clear cell renal cell carcinoma. However the effect of sunitinib is often limited by acquired drug resistance. Methods: The open-accessed data used in this study were obtained from different online public databases which were analyzed using the R software. The RNA level of specific genes was detected using quantitative Real-Time PCR. Sunitinib-resistant cell lines were constructed based on protocol get from the previous study. Colony formation and Cell Counting Kit-8 assays were applied to detect cell proliferation ability. Results: In this study through publicly available data and high-quality analysis we deeply explored the potential biological mechanisms that affect the resistance of sunitinib. Detailed data from GSE64052 GSE76068 and The Cancer Genome Atlas were extracted. We identified the IFITM1 IL6 MX2 PCOLCE2 RSAD2 and SLC2A3 were associated with sunitinib resistance. Single-cell analysis prognosis analysis and m6A regulatory network were conducted to investigate their role. Moreover the MX2 was selected for further analysis including its biological role and effect on the ccRCC microenvironment. Interestingly we noticed that MX2 might be an immune-related gene that could affect the response rate of immunotherapy. Then in vitro experiments validated the overexpression of MX2 in sunitinib-resistance cells. Colony formation assay indicated that the knockdown of MX2 could remarkably inhibit the proliferation ability of 786-O-Res and Caki-1-Res when exposed to sunitinib. Conclusion: In summary through publicly available data and high-quality analysis we deeply explored the potential biological mechanisms that affect the resistance of sunitinib. MX2 was selected for further analysis including its biological role and effect on the ccRCC microenvironment. Finally in vitro experiments were used to validate its role in ccRCC. Copyright © 2023 Deng Wang Wu Du Yang and Xia.","","","2023","10.3389/fphar.2023.1131610","","","medline-37063301.pdf","medline-37063301"
"Current state of microplastic pollution research data: trends in availability and sources of open data","Jenkins, T. And Persaud, B.d. And Cowger, W. And Szigeti, K. And Roche, D.g. And Clary, E. And Slowinski, S. And Lei, B. And Abeynayaka, A. And Nyadjro, E.s. And Maes, T. And Thornton Hampton, L. And Bergmann, M. And Aherne, J. And Mason, S.a. And Honek, J.f. And Rezanezhad, F. And Lusher, A.l. And Booth, A.m. And Smith, R.d.l. And Van Cappellen, P.","Frontiers In Environmental Science","","The rapid growth in microplastic pollution research is influencing funding priorities, environmental policy, and public perceptions of risks to water quality and environmental and human health. Ensuring that environmental microplastics research data are findable, accessible, interoperable, and reusable (fair) is essential to inform policy and mitigation strategies. We present a bibliographic analysis of data sharing practices in the environmental microplastics research community, highlighting the state of openness of microplastics data. A stratified (by year) random subset of 785 of 6,608 microplastics articles indexed in web of science indicates that, since 2006, less than a third (28.5%) contained a data sharing statement. These statements further show that most often, the data were provided in the articles’ supplementary material (38.8%) and only 13.8% via a data repository. Of the 279 microplastics datasets found in online data repositories, 20.4% presented only metadata with access to the data requiring additional approval. Although increasing, the rate of microplastic data sharing still lags behind that of publication of peer-reviewed articles on environmental microplastics. About a quarter of the repository data originated from north america (12.8%) and europe (13.4%). Marine and estuarine environments are the most frequently sampled systems (26.2%);  sediments (18.8%) and water (15.3%) are the predominant media. Of the available datasets accessible, 15.4% and 18.2% do not have adequate metadata to determine the sampling location and media type, respectively. We discuss five recommendations to strengthen data sharing practices in the environmental microplastic research community. Copyright © 2022 jenkins, persaud, cowger, szigeti, roche, clary, slowinski, lei, abeynayaka, nyadjro, maes, thornton hampton, bergmann, aherne, mason, honek, rezanezhad, lusher, booth, smith and van cappellen.","","","2022","10.3389/fenvs.2022.912107","","","scopus-2-s2.0-85134236394.pdf","scopus-2-s2.0-85134236394"
"Can citizen science increase trust in research? A case study of delineating polish metropolitan areas","Bedessem, B. And Gawrońska-Novak, B. And Lis, P.","Journal Of Contemporary European Research","","We assess the relationship between citizens’ participation in scientific research and public trust in research results within social sciences. We conduct an online citizen science quasiexperiment concerning the delineation of metropolitan areas of poland’s two major cities. It consists of two stages. In stage one, participants in one region are exposed to citizen science and directly involved in delineating the boundaries of their local metropolitan area. In stage two, we add another region in which participants are not involved in the research process. In both regions we ask the participants to evaluate the level of their trust in the presented maps of respective metropolitan areas: based on citizen science in one region and historical data regression analysis in the other region. Our contribution to the literature lies in two areas. First, we demonstrate how citizen science can be used in urban studies to delineate boundaries of urban and metropolitan areas exhibiting strong functional connections. Second, we show that the participation of local residents in the research process increases public trust in the study results compared to non-participatory ‘traditional academic’ research. These results confirm that citizen science programs deserve to be strongly supported by european institutions as a possible means to resolving the credibility crisis of science, research and evidence-based policies. © 2021, journal of contemporary european research. All rights reserved.","","","2021","10.30950/jcer.v17i2.1185","","","scopus-2-s2.0-85109433137.pdf","scopus-2-s2.0-85109433137"
"Consensus recommendations to promote and advance predictive systems toxicology and toxicogenomics","Waters M., Yauk C.","Environmental & Molecular Mutagenesis","","The number of high throughput -omics technologies continues to grow. Toxicogenomic application of these technologies is poised to greatly influence current regulatory toxicology. However many changes are needed before a systems biology level approach can be effectively incorporated into the regulatory toxicology framework. A workshop was held at the Annual Environmental Mutagen Society meeting in Vancouver British Columbia on advances in -omics applications. A number of recommendations emerged from the workshop discussion (beyond what activities are currently ongoing) aimed at advancing the ultimate goal of predictive systems toxicology from the present formative state of toxicogenomics. Recommendations include: (1) encouraging investigators to embrace open-access data sharing (2) increasing current database and curation capacity (3) establishment of large collaborative projects investigating multiple -omics endpoints within the same groups of animals (4) mechanisms to encourage collaborative science including increasing the value of junior authorship on multi-authored papers and changes in the promotion process (5) further development of standardized protocols and (6) investment from the funding agencies and toxicology community to build the required infrastructure.","","","2007","","","","medline-17567851.pdf","medline-17567851"
"Participant acceptability of digital footprint data collection strategies: an exemplar approach to participant engagement and involvement in the alspac birth cohort study","Shiells, K. And Di Cara, N. And Skatova, A. And Davis, O.s.p. And Haworth, C.m.a. And Skinner, A.l. And Thomas, R. And Tanner, A.r. And Macleod, J. And Timpson, N.j. And Boyd, A.","International Journal Of Population Data Science","","Introduction digital footprint records - the tracks and traces amassed by individuals as a result of their interactions with the internet, digital devices and services - can provide ecologically valid data on individual behaviours. These could enhance longitudinal population study databanks;  but few uk longitudinal studies are attempting this. When using novel sources of data, study managers must engage with participants in order to develop ethical data processing frameworks that facilitate data sharing whilst safeguarding participant interests. Objectives this paper aims to summarise the participant involvement approach used by the alspac birth cohort study to inform the development of a framework for using linked participant digital footprint data, and provide an exemplar for other data linkage infrastructures. Methods the paper synthesises five qualitative forms of inquiry. Thematic analysis was used to code transcripts for common themes in relation to conditions associated with the acceptability of sharing digital footprint data for longitudinal research. Results we identified six themes: participant understanding;  sensitivity of location data;  concerns for third parties;  clarity on data granularity;  mechanisms of data sharing and consent;  and trustworthiness of the organisation. For cohort members to consider the sharing of digital footprint data acceptable, they require information about the value, validity and risks;  control over sharing elements of the data they consider sensitive;  appropriate mechanisms to authorise or object to their records being used;  and trust in the organisation. Conclusion realising the potential for using digital footprint records within longitudinal research will be subject to ensuring that this use of personal data is acceptable;  and that rigorously controlled population data science benefiting the public good is distinguishable from the misuse and lack of personal control of similar data within other settings. Participant co-development informs the ethical-governance framework for these novel linkages in a manner which is acceptable and does not undermine the role of the trusted data custodian. © the authors.","","","2020","10.23889/ijpds.v5i3.1728","","","scopus-2-s2.0-85128392043.pdf","scopus-2-s2.0-85128392043"
"The state of social and personality science: rotten to the core, not so bad, getting better, or getting worse?","Motyl M. And Demos A.p. And Carsel T.s. And Hanson B.e. And Melton Z.j. And Mueller A.b. And Prims J.p. And Sun J. And Washburn A.n. And Wong K.m. And Yantis C. And Skitka L.j.","J Pers Soc Psychol","","The scientific quality of social and personality psychology has been debated at great length in recent years. Despite research on the prevalence of questionable research practices (qrps) and the replicability of particular findings, the impact of the current discussion on research practices is unknown. The current studies examine whether and how practices have changed, if at all, over the last 10 years. In study 1, we surveyed 1,166 social and personality psychologists about how the current debate has affected their perceptions of their own and the field's research practices. In study 2, we coded the research practices and critical test statistics from social and personality psychology articles published in 2003-2004 and 2013-2014. Together, these studies suggest that (a) perceptions of the current state of the field are more pessimistic than optimistic;  (b) the discussion has increased researchers' intentions to avoid qrps and adopt proposed best practices, (c) the estimated replicability of research published in 2003-2004 may not be as bad as many feared, and (d) research published in 2013-2014 shows some improvement over research published in 2003-2004, a result that suggests the field is evolving in a positive direction. (Psycinfo database recordcopyright (c) 2017 apa, all rights reserved).","","","2017","10.1037/pspa0000084","","","embase-623063127.pdf","embase-623063127"
"Sharing business partner behavior","Perko, I. And Primec, A. And Horvat, R.","Kybernetes","","Purpose – the new concept of business partner behavior sharing practice is addressed from three perspectives: technical/technological, legal and ethical/moral with the aim to elaborate its sharing feasibility, value added, legal restrictions and moral considerations. Research results are synthetized to present an overview on business partners behavior sharing direct and indirect value added, costs and risks and proposing mitigation strategies. The paper aims to discuss these issues. Design/methodology/approach – to evaluate technical feasibility, a real-life sharing experiment is conducted. Using a sharing agency data are collected, summarized and reported. For the purpose of legal evaluation, relevant legislation is analyzed. Ethicality/morality is assessed utilizing theoretical applied-ethics analysis. Two major normative moral theories – teleology and deontology – are selected for this purpose. The synthesis of the research results is represented in system dynamics model. Findings – results show no significant technical obstacles for the systematic business partner behavior sharing. Also, no major legal or ethical arguments against it are found, although some important conditions are identified that have to be met in order for the practice to be performed legally and to be qualified as ethical/moral. Research limitations/implications – analysis of legality is limited to the eu and legislation of the republic of slovenia. Ethicality of the practice is assessed from the utilitarian and rights perspectives. Practical implications – important technical, legal and ethical insights into business partner behavior sharing concepts and practices are provided. Originality/value – to the authors’ knowledge, this is the first time that the practice of business partner behavior sharing is addressed simultaneously from technical, legal and ethical perspectives using a real-life experiment. Therefore it is an important contribution to a more holistic account/insight of/into such a business practice. © 2015, emerald group publishing limited.","","","2015","10.1108/k-12-2014-0282","","","scopus-2-s2.0-84942740464.pdf","scopus-2-s2.0-84942740464"
"Services offered in scientific journal portals: beyond access, towards democratization","Anna, J.s.","Ciencia Da Informacao","","This study deals with one of the largest strategies for fostering open access to the institutions’ periodical publications: the construction of scientific journal portals. The proposal is to identify the availability of services in portals of federal universities and reinforce the potential of this offer for the consolidation of open science. For this, they were consulted to the information science database (brapci) and the peri database, in order to find books and scientific articles published in annals of events and journals in the areas of library and information science that contained subjects related to the theme. Eighty-six papers were retrieved, of which only twenty-two were selected for analysis, since many were repeated or unrelated to the theme. The reading of the works aimed to present characteristics about scientific journals, journal portals, services offered to users, and the role of institutions in the management of these environments. After the bibliographic research, with the acquired knowledge about characteristics and services offered in portals of journals of university institutions, the portal website was analyzed. Only the portals of five federal universities located in the state of minas gerais (federal university of minas gerais, ouro preto, juiz de fora, são joão del rei and triângulo mineiro) were chosen for analysis, considering that of the 11 universities in this state state, only these five cluster their journals in an institutional portal. Regarding the services provided by the portal, the literature review showed that these services are limited to the activities that are available to the various users, whether editors, researchers and consultants, inserted in the university environment in general. Among the services described in the literature, contact channels, discussion forums, search engines, and training represent some categories or types of services that can be offered to structure a portal. The analysis of each portal showed that only the ufmg portal offers all four types of services sought, such as: contact channels: telephone, e-mail and link to social networks;  forums;  search engines: by alphabetical order, by academic unit and by area of knowledge;  and training: offering lectures, various trainings and workshops, the latter aim to enable the user community, specifically the editors, given an improvement in the editorial processes and management of journals. After the ufmg, the ufop, ufsj and uftm portal appears. The first features the following services: electronic mail, scheduled attendance and contact via telephone;  while the others have a search engine performed by identifying textual characters of articles in the incorporated journals. In turn, no information was found about services provided on the ufjf portal, and the journals are listed in alphabetical order, with direct link to the pages of these journals. Regarding the search engine inserted in the platform of these journals, it is important to reinforce that there is no thematic treatment related to the textual content of the articles, ie, no indexing by keywords or other metadata, therefore, there is no of terms or expressions that provide control of vocabulary, making it impossible for the user to broaden search strategies in order to find specific information of interest in the articles published in the journals.the results revealed that portals may offer different services, such as contact channels, discussion forums, search engines, and training, although not all of these services were undetected in the analyzed portals. Thus, it can be concluded that the absence of these services tends to disqualify the portals, impacting the visibility and prestige of the journals and maintaining institutions, which requires the adoption of interventional measures to qualify these environments.the data analyzed lead to conclusions about the importance and contribution of information policies to support the portal management work, as well as recommendations for conducting use studies, especially with the journal editors and portal managers, in order to establish continuous improvements to these environments. By providing a journal portal with free access to content and complementary services that facilitate the localization of journals, allow the integration of users, through the exchange of information, encourage the user community to participate in discussions through interaction channels., among other services that can be offered, certainly, the supporting institution is contributing to the qualification of the portal. © 2019, brazilian institute for information in science and technology. All rights reserved.","","","2019","","","","scopus-2-s2.0-85086041938.pdf","scopus-2-s2.0-85086041938"
"Input sensitivity on the performance of configurable systems an empirical study","Lesoil, L. And Acher, M. And Blouin, A. And Jézéquel, J.-M.","Journal Of Systems And Software","","Widely used software systems such as video encoders are by necessity highly configurable, with hundreds or even thousands of options to choose from. Their users often have a hard time finding suitable values for these options (i.e., finding a proper configuration of the software system) to meet their goals for the tasks at hand, e.g., compress a video down to a certain size. One dimension of the problem is of course that performance depends on the input data: e.g., a video as input to an encoder like x264 or a file fed to a tool like xz. To achieve good performance, users should therefore take into account both dimensions of (1) software variability and (2) input data. This paper details a large study over 8 configurable systems that quantifies the existing interactions between input data and configurations of software systems. The results exhibit that (1) inputs fed to software systems can interact with their configuration options in non-monotonous ways, significantly impacting their performance properties (2) input sensitivity can challenge our knowledge of software variability and question the relevance of performance predictive models for a field deployment. Given the results of our study, we call researchers to address the problem of input sensitivity when tuning, predicting, understanding, and benchmarking configurable systems. Please refer to https://www.sciencedirect.com/science/article/pii/s0164121221002168 as an example of where to place this statement. “Editor s note: open science material was validated by the journal of systems and software open science board.” © 2023","","","2023","10.1016/j.jss.2023.111671","","","scopus-2-s2.0-85151798480.pdf","scopus-2-s2.0-85151798480"
"Mapping the evidence on health equity considerations in economic evaluations of health interventions: a scoping review protocol","Sa'aid, H.b. And Mathew, S. And Richardson, M. And Bielecki, J.m. And Sander, B.","Systematic Reviews","","Background : equity in health has become an important policy agenda around the world, prompting health economists to advance methods to enable the inclusion of equity in economic evaluations. Among the methods that have been proposed to explicitly include equity are the weighting analysis, equity impact analysis, and equity trade-off analysis. This is a new development and a comprehensive overview of trends and concepts of health equity in economic evaluations is lacking. Thus, our objective is to map the current state of the literature with respect to how health equity is considered in economic evaluations of health interventions reported in the academic and gray literature. Methods: we will conduct a scoping review to identify and map evidence on how health equity is considered in economic evaluations of health interventions. We will search relevant electronic, gray literature and key journals. We developed a search strategy using text words and medical subject headings terms related to health equity and economic evaluations of health interventions. Articles retrieved will be uploaded to reference manager software for screening and data extraction. Two reviewers will independently screen the articles based on their titles and abstracts for inclusion, and then will independently screen a full text to ascertain final inclusion. A simple numerical count will be used to quantify the data and a content analysis will be conducted to present the narrative;  that is, a thematic summary of the data collected. Discussion: the results of this scoping review will provide a comprehensive overview of the current evidence on how health equity is considered in economic evaluations of health interventions and its research gaps. It will also provide key information to decision-makers and policy-makers to understand ways to include health equity into the prioritization of health interventions when aiming for a more equitable distribution of health resources. Systematic review registration: this protocol was registered with open science framework (osf) registry on august 14, 2019 (https://osf.io/9my2z/registrations). © 2020 the author(s).","","","2020","10.1186/s13643-019-1257-4","","","scopus-2-s2.0-85077700280.pdf","scopus-2-s2.0-85077700280"
"A privacy-protecting and resource-saving scheme for data sharing in smart home","Yang, H. And Zheng, W. And Zhou, T. And Jin, X. And Wang, A.","Journal Of Internet Technology","","With the development of the internet and communication technology, people have requirements for smart home automation, the flexible control of home devices and the convenient access of security data in home network. However, the data’s address paths of data are exposed by the frequently access operations that the same or similar data in data storage servers has been required by users. Besides, the content of encrypted data which is based on the accessed address sequence can be inferred by the malicious servers. Thus, how to protect the privacy data during data sharing and save the resources in servers are challenges to be settled in smart home. In this paper, an efficient and security oblivious random access memory (oram) structure scheme is proposed to achieve data sharing in smart home, in which the privacy data can be protected by combining the doubly-linked circular info table with confusion operation. In addition, the proxy re-encryption technology implements data sharing between multi-users. The security analysis shows that the proposed scheme meets the security requirements of oram and is secure for data sharing in smart home. The performance analysis shows that the structure effectively reduces the communication overhead. © 2019 taiwan academic network management committee. All rights reserved.","","","2019","10.3966/160792642019032002028","","","scopus-2-s2.0-85071182452.pdf","scopus-2-s2.0-85071182452"
"Neuromorpho.org: an exemplary neuroinformatics resource for cellular neuroscience","Halavi, Maryam","Dissertation Abstracts International: Section B: The Sciences And Engineering","","Neuroinformatics is defined by the adoption of computational approaches and analytical tools to facilitate neuroscience data management and processing. Following its start two decades ago in response to the massive outburst of heterogeneous neuroscience information, neuroinformatics has substantially contributed to recent research progress. Web-accessible digital resources, enabling electronic access to on-line experimental and model results, constitute core elements of neuroinformatics by catalyzing the transformation of ""data"" to ""knowledge"". Successfully creating and maintaining such resources are technically challenging, time consuming, and costly. Identifying the limiting factors, sensible solutions, and best practices in this process is very important. This dissertation describes the development and maturation of neuromorpho.org as an exemplary neuroinformatics success story. Neuromorpho.org is the largest repository of 3d digital reconstructions of neuronal morphologies. Since morphology is a key determinant of neuronal function, quantitative neuromorphological data are crucial to understanding structure-activity relationships in the brain. 3d digital reconstructions are computationally parsimonious representations of neuronal morphologies and may take several weeks each to acquire experimentally. Neuromorpho.org contains >5000 such reconstructions from 39 labs worldwide, 11 animal species, 15 brain regions, and 40 cell classes. The site offers dynamic browsing and searching based on metadata, morphometrics content, and keywords. To date, more than 20,000 visitors from 68 countries have downloaded over half-million files. Neuromorpho.org is also linked to an extensively annotated custom-designed database of peer-reviewed literature reporting digital reconstructions. This research showed that leveraging the power of common computational technologies in a flexible and interoperable fashion, choosing a valuable and well-defined data type, providing dense coverage, and actively accelerating data sharing, all extensively contribute to success. After covering ~65% of all relevant publications by extensive literature mining, follow-up communication with authors of the 698 positively identified articles indicated that only 24% of the reported reconstructions will eventually become available for sharing. The accessible neuromorpho.org content is representative of these data. More than 70 papers published in relation to neuromorpho.org, including modeling studies, comparative studies, and studies of the cellular elements required in reverse-engineering the brain, vetted this resource as a reliable test-bed for developing new tools, encouraging scientific collaboration, and fostering neuroscience discovery. (Psycinfo database record (c) 2021 apa, all rights reserved)","","","2011","","","","psychinfo-2011-99060-494.pdf","psychinfo-2011-99060-494"
"Reducing publication bias through trial registration","Abaid L. N., Grimes D. A., Schulz K. F.","Obstetrics & Gynecology","","Publication bias is the systematic preferential publication of studies with statistically significant positive results over indeterminate studies (frequently researchers inappropriately term these ""negative"" studies) or studies that show a statistically significant negative outcome. Over time this practice distorts the medical literature potentially compromising the validity of systematic reviews. Publication bias primarily stems from investigators but data suppression can occur by pharmaceutical companies universities and regulatory agencies. Registration at inception of all clinical trials in a centralized searchable database can reduce publication bias by enabling researchers to identify all studies related to a particular intervention. Prior attempts to encourage voluntary trial registration have been largely unsuccessful. Hence the International Committee of Medical Journal Editors recently adopted a policy of mandatory clinical trial registration before consideration of manuscripts for publication. Trial registration and the development of comprehensive computerized databases will promote transparency in research and help reduce publication bias.","","","2007","","","","medline-17540818.pdf","medline-17540818"
"An ensemble random forest algorithm for privacy preserving distributed medical data mining","Hassan, M. And Butt, M.a. And Zaman, M.","International Journal Of E-Health And Medical Communications","","A voluminous amount of data is generated because of the inexorably widespread proliferation of electronic data maintained using the electronic health records (ehrs). Medical health facilities have great potential to discern patterns from this data and utilize them in diagnosing specific diseases or predicting the outbreak of an epidemic. This discerning of patterns might reveal sensitive information about individuals, and this information is vulnerable to misuse. This is, however, a challenging task to share such sensitive data as it compromises the privacy of patients. In this paper, a random forestbased distributed data mining approach is proposed. Performance of the proposed model is evaluated using accuracy, f-measure, and kappa statistics analyses. Experimental results reveal that the proposed model is efficient and scalable enough in both performance and accuracy within the imbalanced data and also in maintaining the privacy by sharing only useful healthcare knowledge in the form of local models without revealing and sharing sensitive data. © 2008 association for computational linguistics and chinese language processing. All rights reserved.","","","2021","10.4018/ijehmc.20211101.oa8","","","scopus-2-s2.0-85122796610.pdf","scopus-2-s2.0-85122796610"
"Acupuncture and manual therapy for rotator cuff tears: A protocol for systematic review and meta analysis","Tang H., Luo F., Fan H., Huang L., Liao S., Yu W., Chen Y., Qin X., Chen J.","Medicine","","BACKGROUND: The tears of rotator cuff is caused by the tears or aseptic inflammation of tendon tissue such as subscapular muscle supraspinatus muscle infraspinatus muscle teres minor muscle and so on which make up the rotator cuff. Managements of rotator cuff disease often include acupuncture and manual therapy usually delivered together. The aim of this review is to assess the effectiveness and safety of such interventions in patients with pain and dysfunction caused by rotator cuff tears.\\\\\\\\rMETHODS: We will search the EMBASE the Cochrane Library Ovid MEDLINE PubMed Web of Science Chinese Biomedical Literature Database Chinese National Knowledge Infrastructure Wanfang Database the Chongqing VIP the US National Institute of Health the NIH clinical registry Clinical Trials the International Clinical Trials Registry Platform the Australian New Zealand Clinical Trials Registry and the Chinese clinical registry from their inception to April 1 2020. Randomized controlled trials that include patients with rotator cuff tears receiving acupuncture and manual therapy versus a control group will be included. The selection of studies data extraction and risk of bias assessment will be conducted by 2 independent researchers. A third review author will resolve disagreements. The dichotomous data will be presented as risk ratios with 95% CIs and the continuous data will be presented as weighted mean differences or standardized mean differences with 95% CIs. Evidence quality will be evaluated using the Grading of Recommendations Assessment Development and Evaluation system.\\\\\\\\rDISCUSSION: This systematic review will provide updated evidence of various types of acupuncture and manual therapy specifically focuses on its effectiveness and safety for patients' pain and dysfunction caused by rotator cuff tears.\\\\\\\\rETHICS AND DISSEMINATION: Ethical approval is not necessary as this review will not require data from individual patients. The results of this will be published through peer-reviewed journal articles or conference presentations.\\\\\\\\rREGISTRATION: Open Science Framework Preregistration. Registration number 10.17605/OSF.IO/M3NKV.","","","2020","10.1097/md.0000000000020377","","","medline-32481335.pdf","medline-32481335"
"Effect of large dosage of Fuling on urinary protein of diabetic nephropathy: A protocol of systematic review and meta-analysis of randomized clinical trials","Xia J., Zhang L., Zhang X., Wang L., Yang B., Chen Q., Zhong M., Tang X., Zhou J.","Medicine","","INTRODUCTION: Diabetic nephropathy (DN) is one of the most common and serious microvascular complications in patients with diabetes which seriously affects their life quality and survival time. large dose herb Fuling or compound prescription contain large dose Fuling for treatment of DN has already been confirmed. However due to the lack of evidence there is no specific method or suggestion so it is necessary to carry out systematic evaluation on Fuling and provide effective evidence for further research.\\\\\\\\rMETHODS AND ANALYSIS: The following databases will be searched from their inception to June 2020: Electronic database includes PubMed Embase Cochrane Library Web of Science Nature Science online Chinese Biomedical Database WangFang VIP medicine information and China National Knowledge Infrastructure (CNKI). Primary outcomes:24-hurinary-albumin Urinary albumin-to-creatinine ratio. Additional outcomes: Serum creatinine Blood urea nitrogen Glomerular filtration rate Endogenous creatinine clearance rate. Data will be extracted by 2 researchers independently risk of bias of the meta-analysis will be evaluated based on the Cochrane Handbook for Systematic Reviews of Interventions. All data analysis will be conducted by data statistics software Review Manager V.5.3. and Stata V.12.0.\\\\\\\\rRESULTS: The results of this study will systematically evaluate the effectiveness and safety of large dose Fuling intervention for people with DN.\\\\\\\\rCONCLUSION: The systematic review of this study will summarize the current published evidence of large dose Fuling for the treatment of DN which can further guide the promotion and application of it.\\\\\\\\rETHICS AND DISSEMINATION: This study is a systematic review the outcomes are based on the published evidence so examination and agreement by the ethics committee are not required in this study. We intend to publish the study results in a journal or conference presentations.\\\\\\\\rOPEN SCIENCE FRAMEWORK (OSF) REGISTRATION NUMBER: August 24 2020. osf.io/ym2c6. (https://osf.io/ym2c6).","","","2020","10.1097/md.0000000000022377","","","medline-33019413.pdf","medline-33019413"
"An accessible seismological dataset of 2021 yangbi ms6.4 earthquake","Wang, S. And Yang, H. And Wang, W. And Wang, F. And Liu, Z. And Yang, W. And Wang, W. And Zhang, Y. And Li, L. And Hu, J. And Li, X. And Cha, W. And Ye, B. And Zhu, H. And Yang, J.","Earthquake Science","","A ms 6.4 earthquake occurred on 21 may 2021 in yangbi county, dali prefecture, yunnan, china, at 21: 48 beijing time (13: 48 utc). Earthquakes with an m3.0 or higher occurred before and after the main shock. Seismic data analysis is essential for the in-depth investigation of the 2021 yangbi ms 6.4 earthquake sequence and the seismotectonics of northwestern yunnan. Institute of geophysics, china earthquake administration (cea), has compiled a dataset of seismological observations from 157 broadband stations located within 500 km of the epicenter, and has made this dataset available to the earthquake science research community. The dataset (total file size: 329 gb) consists of event waveforms with a sampling frequency of 100 sps collected from 18 to 28 may 2021, 20-hz and 100-hz continuous waveforms collected from 12 to 31 may 2021, and seismic instrument response files. To promote data sharing, the dataset also includes the seismic event waveforms from 20 to 22 may 2021 recorded at 50 stations of the ongoing binchuan active source geophysical observation project, for which the data protection period has not expired. Sample waveforms of the main shock are included in the appendix of this article and can be downloaded from the earthquake science website. The event and continuous waveforms are available from the earthquake science data center website (www.esdc.ac.cn) on application. © the seismological society of china and institute of geophysics, china earthquake administration 2021.","","","2021","10.29382/eqs-2021-0026","","","scopus-2-s2.0-85131526989.pdf","scopus-2-s2.0-85131526989"
"Complexity analysis of gravitational waves","Bianciardi, G. And Miller, J.d.","Journal Of High Energy Astrophysics","","The recent observations of gravitational waves during the coalescence of black holes has confirmed various predictions of general relativity. However, some concerns have been raised that these putative waves are artifacts. We have analyzed the ten confident gravitational waves detected in observation run 1 (o1) and observation run 2 (o2) and the gravitational wave emitted by the single known example of a neutron star coalescence, all of which have been verified by the advanced laser interferometer gravitational wave observatory and/or the advanced virgo collaboration. On three occasions both advanced ligo and advanced virgo detected the same event (abbott et al., 2019). Whitening of the hanford data (gravitational wave open science center) was employed in this study to reduce colored non-transient noise, but template matching was not employed. In each of the ten events mentioned above we verified the presence of such waves by the application of non-stationary data analysis via the morlet wavelet. We examined the strain data before, during and after each wave. In each case we employed seven measures of complexity or information before, and during each wave and analyzed these data using doubly multivariate manova, the appropriate statistical test for repeated measures (pre-wave vs wave). In addition we compared the strain data before and after the putative event to see if there was persistence of any effect of the event. In each case the information content was significantly elevated during the wave compared to similar time samples taken before the wave. No persistent effects on the strain data were noted after the event. We conclude our analysis is consistent with the actual detection of gravitational waves by the ligo and virgo collaboration. Our results suggest black hole coalescence generates mathematically complex gravitational waves which may elucidate aspects of such coalescence. © 2021 elsevier b.v.","","","2021","10.1016/j.jheap.2021.05.002","","","scopus-2-s2.0-85108416615.pdf","scopus-2-s2.0-85108416615"
"Enhanced privacy preservation with perturbed data using feature selection","Prakash, V.s. And Shanmugam, A.","Journal Of Theoretical And Applied Information Technology","","In data mining applications, privacy plays an imperative role. This has triggered the development of many privacy preserving data mining techniques. To facilitate privacy preservation in data mining or machine learning algorithms over horizontally partitioned or vertically partitioned data, many protocols have been proposed using smc and various secure building blocks. Our previous works focused on preserving privacy by adapting individually adaptable perturbation model, which enables the individuals to choose their own privacy levels. But the downside is that it does not discover the computational results for privacy properly. This paper proposed a feature selection with privacy preservation in multi-partitioned dataset. Data can be sealed for privacy by perturbation technique as pseudonym name. In multi-partitioned data evaluation, it creates classification of data and selection of feature for data mining decision model which construct the structural information of model in this paper. The purpose of gain ratio method has taken in this paper to enhance the privacy in multi-partitioned data set. All features don't require protecting the confidential data for best model. The data representation for privacy preserving data mining has taken to increase the data mining technique to construct finest model without breaking the privacy individuals. An experimental evaluation is conducted to estimate the performance of the proposed enhanced privacy preservation with perturbed data using feature selection [eppdfs] in multi-partitioned datasets demonstrated by diverse experiments conducted on both synthetic and real-world data sets. © 2005 - 2013 jatit & lls. All rights reserved.","","","2013","","","","scopus-2-s2.0-84891713117.pdf","scopus-2-s2.0-84891713117"
"Research on Intelligent Recommendation of Science and Technology Resource Data Based on Semantic Intelligence Analysis","Su H., Di J., Yin X., Li X.","","","Aiming at the practical problems such as imperfect semantic analysis function of recommendation service and low sharing degree among scientific data in the existing science and technology resources sharing the center of knowledge association algorithm with intelligence is built through the mutual reflection evidence among different data subjects such as talents enterprises platforms industries and scientific payoffs to realize multi-angle multi-dimensional and multi-association data portrait. Through business understanding data extraction data processing feature extraction model construction model deduction model application model evaluation and other mining steps the data mining algorithm center with intelligence is established. Based on knowledge graph an intelligent recommendation model for scientific data is proposed and we construct vector model bank through machine learning and realize intelligent recommendation and accurate pushing of scientific resources based on massive data of scientific research such as papers patents projects and scientific reports. The problems of data centralization and unification data systematization mapping data application convenience and data multiform and multi-scene application are effectively solved in the actual research work. By summarizing the theories technologies and methods related to data sharing and application of S&T resources this study aims to provide useful references for the wisdom upgrading of S&T resource sharing services and scientific and technical information service model innovation under the big data environment. © 2022 ACM.","","","2022","10.1145/3545801.3545806","","","scopus-2-s2.0-85138428111.pdf","scopus-2-s2.0-85138428111"
"LapOntoSPM: an ontology for laparoscopic surgeries and its application to surgical phase recognition","Katic D., Julliard C., Wekerle A. L., Kenngott H., Muller-Stich B. P., Dillmann R., Speidel S., Jannin P., Gibaud B.","International Journal of Computer Assisted Radiology & Surgery","","PURPOSE: The rise of intraoperative information threatens to outpace our abilities to process it. Context-aware systems filtering information to automatically adapt to the current needs of the surgeon are necessary to fully profit from computerized surgery. To attain context awareness representation of medical knowledge is crucial. However most existing systems do not represent knowledge in a reusable way hindering also reuse of data. Our purpose is therefore to make our computational models of medical knowledge sharable extensible and interoperational with established knowledge representations in the form of the LapOntoSPM ontology. To show its usefulness we apply it to situation interpretation i.e. the recognition of surgical phases based on surgical activities.\\\\\\\\rMETHODS: Considering best practices in ontology engineering and building on our ontology for laparoscopy we formalized the workflow of laparoscopic adrenalectomies cholecystectomies and pancreatic resections in the framework of OntoSPM a new standard for surgical process models. Furthermore we provide a rule-based situation interpretation algorithm based on SQWRL to recognize surgical phases using the ontology.\\\\\\\\rRESULTS: The system was evaluated on ground-truth data from 19 manually annotated surgeries. The aim was to show that the phase recognition capabilities are equal to a specialized solution. The recognition rates of the new system were equal to the specialized one. However the time needed to interpret a situation rose from 0.5 to 1.8 s on average which is still viable for practical application.\\\\\\\\rCONCLUSION: We successfully integrated medical knowledge for laparoscopic surgeries into OntoSPM facilitating knowledge and data sharing. This is especially important for reproducibility of results and unbiased comparison of recognition algorithms. The associated recognition algorithm was adapted to the new representation without any loss of classification power. The work is an important step to standardized knowledge and data representation in the field on context awareness and thus toward unified benchmark data sets.","","","2015","10.1007/s11548-015-1222-1","","","medline-26062794.pdf","medline-26062794"
"Evaluating public management reform: designing a 'joined up' approach to researching the local government modernisation agenda","Bovaird, T. And Martin, S.","Local Government Studies","","This article examines the major programme of research on the 'local government modernisation agenda' which is currently being funded by the uk's office of the deputy prime minister. It argues that this heralds a new approach to government-funded research which seeks to address some of the weakness of previous evaluations. In particular it involves longer-term studies than have been conducted in the past and an attempt to achieve a much greater degree of collaboration between research teams. It is also trying to ensure effective application of the learning derived from evaluations. This new approach raises a number of practical and methodological problems, including in particular the need for effective data sharing among research teams and with other agencies. If this can be achieved there is though a real prospect that the research will provide useful insights that help to inform current and future policy and practice at both national and local levels.","","","2003","10.1080/03003930308559387","","","scopus-2-s2.0-0348225163.pdf","scopus-2-s2.0-0348225163"
"Research on information resource sharing and big data of sports industry in the background of openstack cloud platform","Mou, C. And Cheng, Y.","Security And Communication Networks","","The rapid development of information technology and internet makes the sports information resources retrieval service more convenient and quick;  sports policy in recent years lays a foundation for the development of the internet + sports, the development of sports industry in the process of our country economy level of development status, and the development of sports industry into the era of information and big data. This paper takes openstack cloud platform as the research basis (1) to realize the sharing of sports industry information resources in openstack cloud technology and (2) to realize big data analysis of sports industry and (3) empirical research on big data of sports industry. The main content is to realize the construction of sports resources informatization based on the openstack cloud platform. Through the analysis and empirical study of the big data of the sports industry, the influence of the development of the sports industry in the process of china's economic development is discussed. In this paper, the experimental results show that the sports industry showed a positive impact in the process of economic development, the sports economy for the development of the economy, the contribution rate reached 11.77%, the sports industry for the development of the economy, the pull rate of 1.056%, based on the cloud platform of information resources sharing of data analysis, sports industry for the development of the economy has a positive role in promoting. © 2021 chuan mou and ye cheng.","","","2021","10.1155/2021/2824146","","","scopus-2-s2.0-85113794556.pdf","scopus-2-s2.0-85113794556"
"openSNP--a crowdsourced web resource for personal genomics","Greshake B., Bayer P. E., Rausch H., Reda J.","PLoS ONE [Electronic Resource]","","Genome-Wide Association Studies are widely used to correlate phenotypic traits with genetic variants. These studies usually compare the genetic variation between two groups to single out certain Single Nucleotide Polymorphisms (SNPs) that are linked to a phenotypic variation in one of the groups. However it is necessary to have a large enough sample size to find statistically significant correlations. Direct-To-Consumer (DTC) genetic testing can supply additional data: DTC-companies offer the analysis of a large amount of SNPs for an individual at low cost without the need to consult a physician or geneticist. Over 100000 people have already been genotyped through Direct-To-Consumer genetic testing companies. However this data is not public for a variety of reasons and thus cannot be used in research. It seems reasonable to create a central open data repository for such data. Here we present the web platform openSNP an open database which allows participants of Direct-To-Consumer genetic testing to publish their genetic data at no cost along with phenotypic information. Through this crowdsourced effort of collecting genetic and phenotypic information openSNP has become a resource for a wide area of studies including Genome-Wide Association Studies. openSNP is hosted at http://www.opensnp.org and the code is released under MIT-license at http://github.com/gedankenstuecke/snpr.","","","2014","10.1371/journal.pone.0089204","","","medline-24647222.pdf","medline-24647222"
"Mental health of new and recent graduates during the university-to-work transition: a scoping review protocol","Zayts O., Edmonds D. M., Kong B. C. K., Fortune Z.","BMJ Open","","INTRODUCTION: University students face challenges when starting their careers and entering the workforce after tertiary education is associated with negative psychological outcomes. The planned scoping review will synthesise the literature on the impact of university-to-work transitions on the mental health of new and recent graduates. We will describe the characteristics and main findings of the studies and will examine the variables associated with and the theories used to explain the relationship between transitions to work and graduates' mental health.\\\\\\\\rMETHODS: We will search the following databases: Scopus Web of Science ERIC PSYCINFO Social Sciences Citation Index CINAHL Plus Ovid MEDLINE and Google Scholar to locate published and unpublished literature. The included studies will focus on undergraduate and postgraduate university students during planned or current university-to-work transitions as well as early-career workers. We will include studies involving people who have left or are in their final year of study are undergoing career transition preparation or have worked for no longer than 3 years since graduation. Studies from all countries those published in English and since 2000 will be included. We will use a set of predefined search terms and we will extract studies using the EndNote V.20 reference management software. Two reviewers will screen and assess the identified studies using the Covidence software. Finally we will present the data in a summary table and will qualitatively analyse the studies using thematic analysis.\\\\\\\\rETHICS AND DISSEMINATION: Our scoping review does not require ethical approval. The scoping review's findings will be disseminated in peer-reviewed journal articles and conference presentations and will inform the development of training resources for different stakeholders as part of a wider research project.\\\\\\\\rTRIAL REGISTRATION NUMBER: The study has been registered with the Open Science Framework (https://osf.io/gw86x). Copyright © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.","","","2023","10.1136/bmjopen-2022-071357","","","medline-37105690.pdf","medline-37105690"
"Using rules and data dependencies for the recovery of concurrent processes in a service-oriented environment","Xiao, Y. And Urban, S.","Ieee Transactions On Services Computing","","This paper presents a recovery algorithm for service execution failure in the context of concurrent process execution. The recovery algorithm was specifically designed to support a rule-based approach to user-defined correctness in execution environments that support a relaxed form of isolation for service execution. Data dependencies are analyzed from data changes that are extracted from database transaction log files and generated as a stream of deltas from delta-enabled grid services. The deltas are merged by time stamp to create a global schedule of data changes that, together with the process execution context, are used to identify processes that are read and write dependent on failed processes. Process interference rules are used to express semantic conditions that determine if a process that is dependent on a failed process should recover or continue execution. The recovery algorithm integrates a service composition model that supports nested processes, compensation, contingency, and rollback procedures with the data dependency analysis process and rule execution procedure to provide a new approach for addressing consistency among concurrent processes that access shared data. We present the recovery algorithm and also discuss our results with simulation and evaluation of the concurrent process recovery algorithm. © 2008 ieee.","","","2012","10.1109/tsc.2011.25","","","scopus-2-s2.0-84857165265.pdf","scopus-2-s2.0-84857165265"
"Terminal digits and the examination of questioned data","Mosimann, J.e. And Dahlberg, J.e. And Davidian, N.m. And Krueger, J.w.","Accountability In Research","","Our objective is to illustrate the use of statistical methods to examine the authenticity of data in the investigation of research misconduct. We present examples of statistical analyses of questioned data from several cases that illustrate the experience of the office of research integrity. We show that the statistical examination of numbers that are normally unrepeatable when experiments are repeated, or otherwise are of inconsequential meaning, may reveal substantial clues as to the authenticity of questioned data when compared with numbers in data that are unquestioned. We illustrate the occurrence of the uniform distribution of nonleading (insignificant rightmost) digits in unquestioned numbers, along with examples of deviation from such uniformity for fabricated or falsified numbers. (Most people are unable to choose digits randomly.) We describe several cases in which a variety of anomalies in data sets provided the impetus for the examination of rightmost digits. The anomalous behavior of rightmost digits, when added to testimony and other physical evidence, can greatly enhance or decrease the credibility of witnesses. The cases discussed involve: 1 and 2, anomalous behavior of terminal digits in published or recorded numbers;  3, terminal odd digits in event times that should have exhibited only even digits (and why);  and 4, data that were falsified by calculations from computer spreadsheets (detected by the inclusion of an additional digit of accuracy). Copyright © 2002, taylor & francis.","","","2002","10.1080/08989620212969","","","scopus-unknown-accession-6699600.pdf","scopus-unknown-accession-6699600"
"Systemic building blocks for creating and capturing value from circular economy","Hopkinson, P. And De Angelis, R. And Zils, M.","Resources, Conservation And Recycling","","The idea of a circular economy has generated widespread academic, policy and business interest for its potential to address economic, ecological and societal concerns posed by current production and consumption systems. The growth in the number of academic publications reflects a period of critique, clarification and validation leading to research challenges, questions and a call for real world evidence of how the ideas translate into practice, evidence of outcomes and operational effectiveness. Whilst there has been extensive research into the classifications of circular business models, these are rarely linked to a discussion of actual circular value realisation within real world settings. In this paper we draw on three illustrative examples used within a global executive education programme to reflect on the locus of circular value creation and capture. Specifically, we explore the role and interplay of four configurable ‘building blocks’: circular design, business models, reverse network management and system enablers, as a potentially useful heuristic to describe how businesses are realising value from their circular economy practices. These cases illustrate that the success of large scale value creation and capture derives from the iteration of multiple, boundary spanning activities emerging over time in varying configurations. There is now a need to move from classification and description to quantification and testing of how value is created and captured from circular economy in different contexts. Circular economy validation requires rapid growth in building a credible research evidence base of successful case examples. © 2019 elsevier b.v.","","","2020","10.1016/j.resconrec.2019.104672","","","scopus-2-s2.0-85077171430.pdf","scopus-2-s2.0-85077171430"
"Patient-reported outcomes: instrument development and selection issues","Turner R. R., Quittner A. L., Parasuraman B. M., Kallich J. D., Cleeland C. S.","Value in Health","","At its most elemental patient-reported outcomes (PRO) assessment involves asking the patients questions and evaluating their answers. Instrument developers need to be clear about what they want to know from whom they want to know it and why whether what they learned is credible and whether they can interpret what they learned in the context of the research objectives. Because credible instrument development is neither inexpensive nor technically trivial researchers must first determine that no available measure meets their research objectives. We suggest that the tasks of either reviewing current instruments or developing new ones originate from the same basic premise: PRO assessment requires a well-articulated conceptual framework. Once defined in the context of the research objectives the conceptual framework needs to be adapted to the population of interest. We discuss how qualitative methods enrich the conceptual framework and facilitate the technical measurement tasks of item development testing and reduction. We recognize that PRO assessment stands at a technological crossroads with the increasingly frequent application of ""modern"" psychometric methods and discuss how innovations such as item banks and computer-adaptive testing will influence PRO instrument development. Although items are the essential building blocks for instruments scales are the primary unit of analysis for PRO assessment and we discuss methods for scoring and combining them. Finally PRO assessment is meaningless if the key figure chooses not to cooperate. We consider how respondent burden influences the quality of PRO assessment.","","","2007","","","","medline-17995478.pdf","medline-17995478"
"Diverse data supports the transition of filamentous fungal model organisms into the post-genomics era","McCluskey K., Baker S. E.","Mycology","","Filamentous fungi have been important as model organisms since the beginning of modern biological inquiry and have benefitted from open data since the earliest genetic maps were shared. From early origins in simple Mendelian genetics of mating types parasexual genetics of colony colour and the foundational demonstration of the segregation of a nutritional requirement the contribution of research systems utilising filamentous fungi has spanned the biochemical genetics era through the molecular genetics era and now are at the very foundation of diverse omics approaches to research and development. Fungal model organisms have come from most major taxonomic groups although Ascomycete filamentous fungi have seen the most major sustained effort. In addition to the published material about filamentous fungi shared molecular tools have found application in every area of fungal biology. Similarly shared data has contributed to the success of model systems. The scale of data supporting research with filamentous fungi has grown by 10 to 12 orders of magnitude. From genetic to molecular maps expression databases and finally genome resources the open and collaborative nature of the research communities has assured that the rising tide of data has lifted all of the research systems together.","","","2017","10.1080/21501203.2017.1281849","","","medline-30123633.pdf","medline-30123633"
"Empirical evaluation of ethical practices and digitalization of agricultural system with the mediation of user behavior: a case study of pakistan","Manzoor, F. And Wei, L. And Chen, J.","Frontiers In Environmental Science","","Pakistan is one developing country and 70% of the population is depending on agriculture and faces a lack of innovation in the agriculture sector overall. the main objectives of our study were to i) identify ethical practices (knowledge-sharing, trustworthiness in loan providing, loyalty in professionalism, responsibility of actions, and accountability) of the agriculture departments and institutions or government towards improving digital technology in the agriculture sector. ii) quantify the user behavior in the digitalization of the agricultural system. iii) identify the intervening role of user behavior in the relation to ethical practices and agricultural technology development. The study examined 490 users of farming technologies who work in the agriculture sector in two provinces of pakistan. Using the baron and kenny framework, this research confirmed the prediction that user behavior mediated the relationship between ethical practices and agricultural technology in a four-step process. The main outcomes of the study have revealed a positive and significant impact of ethical practices on the development of the digitalization of the agricultural system. Specifically, the study indicated that “user behavior” significantly mediates the association between ethical practices and agricultural technology development. Furthermore, this study proposes that it is essential for pakistan’s agriculture sector to nurture circumstances dedicated to better practices as it will not only attract more residents to agricultural growth but also help the agriculture sector achieve its eventual goal of increased productivity. Implications of this research study are deliberated and provide directions for future research in the area. Copyright © 2023 manzoor, wei and chen.","","","2023","10.3389/fenvs.2023.1099008","","","scopus-2-s2.0-85148084194.pdf","scopus-2-s2.0-85148084194"
"A manifesto for reproducible science","Munafo M.r. And Nosek B.a. And Bishop D.v.m. And Button K.s. And Chambers C.d. And Du Sert N.p. And Simonsohn U. And Wagenmakers E.-J. And Ware J.j. And Ioannidis J.p.a.","Nat Hum Behav","","Improving the reliability and efficiency of scientific research will increase the credibility of the published scientific literature and accelerate discovery. Here we argue for the adoption of measures to optimize key elements of the scientific process: methods, reporting and dissemination, reproducibility, evaluation and incentives. There is some evidence from both simulations and empirical studies supporting the likely effectiveness of these measures, but their broad adoption by researchers, institutions, funders and journals will require iterative evaluation and improvement. We discuss the goals of these measures, and how they can be implemented, in the hope that this will facilitate action toward improving the transparency, reproducibility and efficiency of scientific research.","","","2017","10.1038/s41562-016-0021","","","embase-634978887.pdf","embase-634978887"
"Access to linked administrative healthcare utilization data for pharmacoepidemiology and pharmacoeconomics research in Canada: anti-viral drugs as an example","Rawson N. S.","Pharmacoepidemiology & Drug Safety","","PURPOSE: Administrative healthcare utilization data from Canadian provinces have been used for pharmacoepidemiology and pharmacoeconomics research but limited transparency exists about opportunities for data access who can access them and processes to obtain data. An attempt was made to obtain data from all 10 provinces to evaluate access and its complexity.\\\\\\\\rMETHODS: An initial enquiry about the process and requirements to obtain data on individual anonymized patients dispensed any of four anti-viral drugs in the ambulatory setting linked with data from hospital and physician service claims was sent to each province. Where a response was encouraging a technical description of the data of interest was submitted.\\\\\\\\rRESULTS: Data were unavailable from the provinces of New Brunswick Newfoundland and Labrador and Prince Edward Island and inaccessible from British Columbia Manitoba and Ontario due to policies that prohibit collaborative work with pharmaceutical industry researchers. In Nova Scotia patient-level data were available but only on site. Data were accessible in Alberta Quebec and Saskatchewan although variation exists in the currency of the data time to obtain data approval requirements and insurance coverage eligibility.\\\\\\\\rCONCLUSIONS: As Canada moves towards a life-cycle management approach to drug regulation more post-marketing studies will be required potentially using administrative data. Linked patient-level drug and healthcare data are presently accessible to pharmaceutical industry researchers in four provinces although only logistically realistic in three and limited to seniors and low-income individuals in two. Collaborative endeavours to improve access to provincial data and to create other data resources should be encouraged. Copyright (c) 2009 John Wiley & Sons Ltd.","","","2009","10.1002/pds.1822","","","medline-19650154.pdf","medline-19650154"
"The 3rd workshop on active internet measurements (aims-3) report","Claffy, K.c.","Computer Communication Review","","On february 10-12, 2011, caida hosted the third work- shop on active internet measurements (aims-3) as part of our series of internet statistics and metrics analysis (isma) workshops as with the previous two aims workshops, the goals were to further our understanding of the potential and limitations of active measurement research and infrastruc- ture in the wide-area internet, and to promote cooperative solutions and coordinated strategies to address future data needs of the network and security research communities for three years, the workshop has fostered interdisciplinary con- versation among researchers, operators, and government, fo- cused on analysis of goals, means, and emerging issues in ac- tive internet measurement projects the first workshop em- phasized discussion of existing hardware and software plat- forms for macroscopic measurement and mapping of internet properties, in particular those related to cybersecurity the second workshop included more performance evaluation and data-sharing approaches this year we expanded the work- shop agenda to include active measurement topics of more recent interest: broadband performance;  gauging ipv6 de- ployment;  and measurement activities in international re- search networks.","","","2011","10.1145/2002250.2002257","","","scopus-2-s2.0-84872924560.pdf","scopus-2-s2.0-84872924560"
"Quality assessment of conventional x-ray diagnostic equipment by measuring x-ray exposure and tube output parameters in great khorasan province, iran","Hashemi, M. And Bayani, S. And Shahedi, F. And Momennezhad, M. And Zare, H. And Gholamhosseinian, H.","Iranian Journal Of Medical Physics","","Introduction: regular implementation of quality control (qc) program in diagnostic x-ray facilities may affect both image quality and patient radiation dose due to the changes in exposure parameters. Therefore, this study aimed to investigate the status of randomly selected conventional radiographic x-ray devices installed in radiology centers of great khorasan province, iran, to produce the data needed to formulate qc policies, which are essential to ensure the accuracy of the diagnosis while minimizing the radiation dose. Material and methods: this cross-sectional study was performed using a calibrated piranha multi-purpose detector to measure qc parameters in order to unify x-ray imaging practices using international guidelines. The qc parameters included voltage accuracy, voltage reproducibility, exposure time accuracy, exposure time reproducibility, tube output linearity with time and milliampere (ma), and tube output reproducibility. Data analysis procedures were performed based on the type of an x-ray generator, which has not been reported in previous studies. Results: the results showed that the implementation of high-frequency x-ray generators were more advantageous compared to alternative current generators, due to their efficient, better accuracy, linearity, and reproducibility. Conclusion: the survey revealed that the qc program was not conducted at regular intervals in some of the investigated radiology centers, mostly because of inadequate enforcement by national regulatory authorities for implementation of qc program. © 2019, mashhad university of medical sciences.","","","2019","10.22038/ijmp.2018.33719.1417","","","scopus-2-s2.0-85062180696.pdf","scopus-2-s2.0-85062180696"
"A new lightweight data security system for data security in the cloud computing","Mohammed, S. And Nanthini, S. And Bala Krishna, N. And Srinivas, I.v. And Rajagopal, M. And Ashok Kumar, M.","Measurement: Sensors","","In recent decades, data has proved indispensable to all facets of human existence. The development of several applications has resulted in the exponential expansion of data. This information can be encrypted and stored in secure areas. Cloud computing is the technology that can be used to store these massive data sets. The article suggests a cloud-based data security system (c-dss) that employs a five-tiered trust model for cloud-edge data-sharing architectures. The data owner can select an appropriate trust level and cyber threat information (cti) sanitization procedure before releasing cti for analytic strategy. In addition, this cleansing method is conducted either by an end device or by the cloud service supplier, based on the organization's degree of confidence in latter. Research presents the trust architecture, cloud architecture, and installation methodology, all of which are intended to meet widest variety of needs for exchanging secret cti information. The testing findings high degree of data security and an evident improvement in terms of cypher processing time and security services when compared to the encryption systems that are most often employed in cloud technology. In conclusion, research briefly outlines development and evaluation performed so far by pilot applications confirming the architecture. © 2023 the authors","","","2023","10.1016/j.measen.2023.100856","","","scopus-2-s2.0-85164998542.pdf","scopus-2-s2.0-85164998542"
"Supramolecular Integration of Multifunctional Nanomaterial by Mannose-Decorated Azocalixarene with Ginsenoside Rb1 for Synergistic Therapy of Rheumatoid Arthritis","Li S., Li J. J., Zhao Y. Y., Chen M. M., Su S. S., Yao S. Y., Wang Z. H., Hu X. Y., Geng W. C., Wang W., Wang K. R., Guo D. S.","Acs Nano","","The complexity and progressive nature of diseases require the exploitation of multifunctional materials. However introducing a function inevitably increases the complexity of materials which complicates preparation and decreases reproducibility. Herein we report a supramolecular integration of multifunctional nanomaterials based on mannose-modified azocalix[4]arene (ManAC4A) and ginsenoside Rb1 (Rb1) which showed advances of simplicity and reproducibility. ManAC4A possesses reactive oxygen species (ROS) scavenging capacity and hypoxia-responsiveness together with macrophage-targeting and induction functionality. Collectively the Rb1@ManAC4A assembly simply prepared by two components is integrated with multifunction including triple targeting (ELVIS targeting macrophage-targeting and hypoxia-targeted release) and triple therapy (ROS scavenging macrophage polarization and the anti-inflammatory effect of Rb1). The spontaneous assembly and recognition of ManAC4A with its precise structure and molecular weight facilitated the simple and straightforward preparation of Rb1@ManAC4A leading to excellent batch consistency. Progress in simplicity and reproducibility as directed by this research will catalyze the clinical translation of multifunctional materials.","","","2023","10.1021/acsnano.3c09140","","","medline-38096153.pdf","medline-38096153"
"Ranking by relevance and citation counts, a comparative study: google scholar, microsoft academic,wos and scopus","Rovira, C. And Codina, L. And Guerrero-Solé, F. And Lopezosa, C.","Future Internet","","Search engine optimization (seo) constitutes the set of methods designed to increase the visibility of, and the number of visits to, a web page by means of its ranking on the search engine results pages. Recently, seo has also been applied to academic databases and search engines, in a trend that is in constant growth. This new approach, known as academic seo (aseo), has generated a field of study with considerable future growth potential due to the impact of open science. The study reported here forms part of this new field of analysis. The ranking of results is a key aspect in any information system since it determines the way in which these results are presented to the user. The aim of this study is to analyze and compare the relevance ranking algorithms employed by various academic platforms to identify the importance of citations received in their algorithms. Specifically, we analyze two search engines and two bibliographic databases: google scholar and microsoft academic, on the one hand, and web of science and scopus, on the other. A reverse engineering methodology is employed based on the statistical analysis of spearman's correlation coefficients. The results indicate that the ranking algorithms used by google scholar and microsoft are the two that are most heavily influenced by citations received. Indeed, citation counts are clearly the main seo factor in these academic search engines. An unexpected finding is that, at certain points in time, web of science (wos) used citations received as a key ranking factor, despite the fact that wos support documents claim this factor does not intervene. © 2019 by the authors.","","","2019","10.3390/fi11090202","","","scopus-2-s2.0-85073798236.pdf","scopus-2-s2.0-85073798236"
"Knowledge sharing practices in non-profit sector: a case of an intergovernmental organisation","Le, Q.n. And Tuamsuk, K.","International Journal Of Knowledge And Learning","","This paper aims to present findings of knowledge sharing practices from professional employees in a case study of non-profit sector. The study includes both qualitative and quantitative approaches. Firstly, a survey was conducted in an intergovernmental organisation operating in thailand. Secondly, an in-depth interview identified the understanding of knowledge management and knowledge sharing and what factors should be considered to promote sharing the knowledge among others. Quantitative data analysis revealed that lack of time is the most significant barrier for knowledge sharing practices. Regarding knowledge sharing behaviours, the finding also confirmed that professional staff in the organisation only considered sharing their colleagues voluntarily. Qualitative data analysis reported highly positive perceptions regarding knowledge management and knowledge sharing and revealed some additional factors affecting knowledge sharing practices in non-profit contexts. Copyright © 2023 inderscience enterprises ltd.","","","2023","10.1504/ijkl.2023.129902","","","scopus-2-s2.0-85153890302.pdf","scopus-2-s2.0-85153890302"
"The impact of the national heart, lung, and blood institute data: analyzing published articles that used biolincc open access data","Alryalat S.a. And El Khatib O. And Al-Qawasmi O. And Alkasrawi H. And Al Zu'bi R. And Abu-Halaweh M. And Alkanash Y. And Habash I.","F1000res","","Background: data sharing is now a mandatory prerequisite for several major funders and journals, where researchers are obligated to deposit the data resulting from their studies in an openly accessible repository. Biomedical open data are now widely available in almost all disciplines, where researchers can freely access and reuse these data in new studies. We aim to assess the impact of open data in terms of publications generated using open data and citations received by these publications, where we will analyze publications that used the biologic specimen and data repository information coordinating center (biolincc) as an example. Method(s): as of july 2019, there was a total of 194 datasets stored in biolincc repository and accessable through their portal. We requested the full list of publications that used these datasets from biolincc, and we also performed a supplementary pubmed search for other publications. We used web of science (wos) to analyze the characteristics of publications and the citations they received. Result(s): 1,086 published articles used data from biolincc repository, but only 987 (90.88%) articles were wos indexed. The number of publications has steadily increased since 2002 and peaked in 2018 with a total number of 138 publications on that year. The 987 open data publications received a total of 34,181 citations up to 1 st october 2019. The average citation per item for the open data publications was 34.63. The total number of citations received by open data publications per year has increased from only 2 citations in 2002, peaking in 2018 with 2361 citations. Conclusion(s): the vast majority of studies that used biolincc open data were published in wos indexed journals and are receiving an increasing number of citations.copyright: © 2020 alryalat sa et al.","","","2020","10.12688/f1000research.21884.1","","","embase-636323017.pdf","embase-636323017"
"Reducing sources of variance in experimental procedures in in vitro research","Fischer I. And Martinez-Dominguez M.v. And Hanggi D. And Kahlert U.","F1000 Res","","Background: lack of reproducibility in preclinical research poses ethical and economic challenges for biomedical science. Various institutional activities by society stakeholders of leading industrialised nations are currently underway with the aim of improving the situation. Such initiatives are usually concerned with high-level organisational issues and typically do not focus on improving experimental approaches per se. Addressing these is necessary in order to increase consistency and success rates of lab-to-lab repetitions. Method(s): in this project, we statistically evaluated repetitive data of a very basic and widely applied lab procedure, namely quantifying the number of viable cells. The purpose of this was to assess the impact of different parameters and instrumentations which may constitute sources of variance in this procedure. Conclusion(s): by comparing the variability of data acquired under two different procedures, featuring improved stringency of protocol adherence, our project attempts to identify the sources and propose guidelines on how to reduce such fluctuations. We believe our work can contribute to tackling the repeatability crisis in biomedical research.copyright © 2022 fischer i et al.","","","2022","10.12688/f1000research.73497.2","","","embase-636890039.pdf","embase-636890039"
"Inksight: leveraging sketch interaction for documenting chart findings in computational notebooks","Lin, Y. And Li, H. And Yang, L. And Wu, A. And Qu, H.","Ieee Transactions On Visualization And Computer Graphics","","Computational notebooks have become increasingly popular for exploratory data analysis due to their ability to support data exploration and explanation within a single document. Effective documentation for explaining chart findings during the exploration process is essential as it helps recall and share data analysis. However, documenting chart findings remains a challenge due to its time-consuming and tedious nature. While existing automatic methods alleviate some of the burden on users, they often fail to cater to users&#x0027;  specific interests. In response to these limitations, we present inksight, a mixed-initiative computational notebook plugin that generates finding documentation based on the user&#x0027; s intent. Inksight allows users to express their intent in specific data subsets through sketching atop visualizations intuitively. To facilitate this, we designed two types of sketches, i.e., open-path and closed-path sketch. Upon receiving a user&#x0027; s sketch, inksight identifies the sketch type and corresponding selected data items. Subsequently, it filters data fact types based on the sketch and selected data items before employing existing automatic data fact recommendation algorithms to infer data facts. Using large language models (gpt-3.5), inksight converts data facts into effective natural language documentation. Users can conveniently fine-tune the generated documentation within inksight. A user study with 12 participants demonstrated the usability and effectiveness of inksight in expressing user intent and facilitating chart finding documentation. Ieee","","","2023","10.1109/tvcg.2023.3327170","","","scopus-2-s2.0-85168742636.pdf","scopus-2-s2.0-85168742636"
"Research and design in unified coding architecture for smart grids","Han, G. And Zhang, J. And Chu, X.","Telkomnika","","Standardized and sharing information platform is the foundation of the smart grids. In order to improve the dispatching center information integration of the power grids and achieve efficient data exchange, sharing and interoperability, a unified coding architecture is proposed. The architecture includes coding management layer, coding generation layer, information models layer and application system layer. Hierarchical design makes the whole coding architecture to adapt to different application environments, different interfaces, loosely coupled requirements, which can realize the integration model management function of the power grids. The life cycle and evaluation method of survival of unified coding architecture is proposed. It can ensure the stability and availability of the coding architecture. Finally, the development direction of coding technology of the smart grids in future is prospected.","","","2013","10.12928/telkomnika.v11i3.951","","","scopus-2-s2.0-84888861262.pdf","scopus-2-s2.0-84888861262"
"The World Health Organization and global health estimates: improving collaboration and capacity","Boerma T., Mathers C. D.","BMC Medicine","","Global regional and country statistics on population and health indicators are important for assessing development and health progress and for guiding resource allocation; however data are often lacking especially in low- and middle-income countries. To fill the gaps statistical modelling is frequently used to produce comparable health statistics across countries that can be combined to produce regional and global statistics. The World Health Organization (WHO) in collaboration with other United Nations agencies and academic experts regularly updates estimates for key indicators and involves its Member States in the process. Academic institutions also publish estimates independent from the WHO using different methods. The use of sophisticated statistical estimation methods to fill missing values for countries can reduce the pressures on governments and development agencies to improve information systems. Efforts to improve estimates must be accompanied by concerted attempts to address data gaps common standards for documentation sharing of data and methods and regular interaction and collaboration among all groups involved.","","","2015","10.1186/s12916-015-0286-7","","","medline-25858025.pdf","medline-25858025"
"Low-intensity extracorporeal shockwave therapy for erectile dysfunction: an overview of systematic reviews","Yuan F., Wang Y., Ma Z., Jing M., You Y., Yu X., Chang D., Zhang P.","Translational Andrology & Urology","","BACKGROUND: Low-intensity extracorporeal shockwave therapy (LI-ESWT) may be a successful complementary treatment approach for erectile dysfunction (ED). In this study we aimed to review and summarize the research evidence from systematic reviews (SRs)/meta-analyses (MAs) regarding the clinical effectiveness of LI-ESWT for ED.\\\\\\\\rMETHODS: Studies on LI-ESWT for ED were searched using eight electronic databases from establishment of each database to 31 June 2021 with the language restrictions of Chinese and English. All articles were screened and qualifying data were recorded based on the inclusion criteria. Methods including: the Assessing the Methodological Quality of Systematic Reviews 2 (AMSTAR-2); the Risk of Bias in Systematic Reviews (ROBIS); the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA); and Grading of Recommendations Assessment Development and the Evaluation (GRADE) were used by two independent raters to assess methodological quality risk of bias reporting quality and SR evidence of quality respectively.\\\\\\\\rRESULTS: Eight SRs/MAs met all inclusion criteria. Seven reviews were rated as critically low on overall confidence and one review was low on confidence based on the AMSTAR-2 appraisal tool. While most PRISMA criteria were met the major reporting flaws were in relation the financial statements not being included along with no protocol registrations. Three SRs/MAs were classed as low risk regarding bias as measured by the ROBIS tool. Based on the GRADE method only one SRs/MAs of high-quality evidence and seven SRs/MAs of moderate-quality evidence were found. The present research results supported LI-ESWT as a complementary therapy for ED patients but the evidence should be considered carefully due to the methodological flaws identified.\\\\\\\\rDISCUSSION: Our results showed that LI-ESWT as an adjunctive therapy has benefits for ED patients. There were no obvious side effects and the number of shockwave treatments and energy flux density (EFD) would affect the IIEF-EF EHS and PSV scores. However due to the limited sample size and the quality of reporting evidence our conclusions may not be fully representative. Copyright 2021 Translational Andrology and Urology. All rights reserved.","","","2021","10.21037/tau-21-730","","","medline-34733663.pdf","medline-34733663"
"A re-evaluation of a case-control model with contaminated controls for resource selection studies","Rota C. T., Millspaugh J. J., Kesler D. C., Lehman C. P., Rumble M. A., Jachowski C. M.","Journal of Animal Ecology","","1. A common sampling design in resource selection studies involves measuring resource attributes at sample units used by an animal and at sample units considered available for use. Few models can estimate the absolute probability of using a sample unit from such data but such approaches are generally preferred over statistical methods that estimate a relative probability of use. 2. The case-control model that allows for contaminated controls proposed by Lancaster & Imbens (1996) and Lele (2009) can estimate the absolute probability of using a sample unit from use-availability data. However numerous misconceptions have likely prevented the widespread application of this model to resource selection studies. We address common misconceptions regarding the case-control model with contaminated controls and demonstrate its ability to estimate the absolute probability of use prevalence and parameters associated with categorical covariates from use-availability data. 3. We fit the case-control model with contaminated controls to simulated data with varying prevalence (defined as the average probability of use across all sample units) and sample sizes (n1 = 500 used and na = 500 available samples; n1 = 1000 used and na = 1000 available samples). We then applied this model to estimate the probability Ozark hellbenders (Cryptobranchus alleganiensis bishopi) would use a location within a stream as a function of covariates. 4. The case-control model with contaminated controls provided unbiased estimates of all parameters at N = 2000 sample size simulation scenarios particularly at low prevalence. However this model produced increasingly variable maximum likelihood estimates of parameters as prevalence increased particularly at N = 1000 sample size scenarios. We thus recommend at least 500-1000 used samples when fitting the case-control model with contaminated controls to use-availability data. Our application to hellbender data revealed selection for locations with coarse substrate that are close to potential sources of cover. 5. This study unites a disparate literature addresses and clarifies many commonly held misconceptions and demonstrates that the case-control model with contaminated controls is a viable alternative for estimating the absolute probability of use from use-availability data. Copyright © 2013 The Authors. Journal of Animal Ecology © 2013 British Ecological Society.","","","2013","10.1111/1365-2656.12092","","","medline-23701233.pdf","medline-23701233"
"User interfaces for computational science: a domain specific language for oommf embedded in python","Beg, M. And Pepper, R.a. And Fangohr, H.","Aip Advances","","Computer simulations are used widely across the engineering and science disciplines, including in the research and development of magnetic devices using computational micromagnetics. In this work, we identify and review different approaches to configuring simulation runs: (i) the re-compilation of source code, (ii) the use of configuration files, (iii) the graphical user interface, and (iv) embedding the simulation specification in an existing programming language to express the computational problem. We identify the advantages and disadvantages of different approaches and discuss their implications on effectiveness and reproducibility of computational studies and results. Following on from this, we design and describe a domain specific language for micromagnetics that is embedded in the python language, and allows users to define the micromagnetic simulations they want to carry out in a flexible way. We have implemented this micromagnetic simulation description language together with a computational backend that executes the simulation task using the object oriented micromagnetic framework (oommf). We illustrate the use of this python interface for oommf by solving the micromagnetic standard problem 4. All the code is publicly available and is open source. © 2017 author(s).","","","2017","10.1063/1.4977225","","","scopus-2-s2.0-85013766135.pdf","scopus-2-s2.0-85013766135"
"Electronic Lab Notebooks and Experimental Design Assistants","Gerlach B., Untucht C., Stefan A.","Handbook of Experimental Pharmacology","","Documentation of experiments is essential for best research practice and ensures scientific transparency and data integrity. Traditionally the paper lab notebook (pLN) has been employed for documentation of experimental procedures but over the course of the last decades the introduction of electronic tools has changed the research landscape and the way that work is performed. Nowadays almost all data acquisition analysis presentation and archiving are done with electronic tools. The use of electronic tools provides many new possibilities as well as challenges particularly with respect to documentation and data quality. One of the biggest hurdles is the management of data on different devices with a substantial amount of metadata. Transparency and integrity have to be ensured and must be reflected in documentation within LNs. With this in mind electronic LNs (eLN) were introduced to make documentation of experiments more straightforward with the development of enhanced functionality leading gradually to their more widespread use. This chapter gives a general overview of eLNs in the scientific environment with a focus on the advantages of supporting quality and transparency of the research. It provides guidance on adopting an eLN and gives an example on how to set up unique Study-IDs in labs in order to maintain and enhance best practices. Overall the chapter highlights the central role of eLNs in supporting the documentation and reproducibility of experiments. Copyright © The Author(s) 2019.","","","2020","10.1007/164_2019_287","","","medline-31541321.pdf","medline-31541321"
"Reproducibility of interfraction lung motion probability distribution function using dynamic MRI: statistical analysis","Cai J., Read P. W., Larner J. M., Jones D. R., Benedict S. H., Sheng K.","International Journal of Radiation Oncology Biology Physics","","PURPOSE: To investigate the statistical reproducibility of craniocaudal probability distribution function (PDF) of interfraction lung motion using dynamic magnetic resonance imaging.\\\\\\\\rMETHODS AND MATERIALS: A total of 17 subjects 9 healthy volunteers and 8 lung tumor patients underwent two to three continuous 300-s magnetic resonance imaging scans in the sagittal plane repeated 2 weeks apart. Three pulmonary vessels from different lung regions (upper middle and lower) in the healthy subjects and lung tumor patients were selected for tracking and the displacement PDF reproducibility was evaluated as a function of scan time and frame rate.\\\\\\\\rRESULTS: For both healthy subjects and patients the PDF reproducibility improved with increased scan time and converged to an equilibrium state during the 300-s scan. The PDF reproducibility at 300 s (mean 0.86; range 0.70-0.96) were significantly (p < 0.001) increased compared with those at 5 s (mean 0.65; range 0.25-0.79). PDF reproducibility showed less sensitivity to imaging frame rates that were >2 frames/s.\\\\\\\\rCONCLUSION: A statistically significant improvement in PDF reproducibility was observed with a prolonged scan time among the 17 participants. The confirmation of PDF reproducibility over times much shorter than stereotactic body radiotherapy delivery duration is a vital part of the initial validation process of probability-based treatment planning for stereotactic body radiotherapy for lung cancer.","","","2008","10.1016/j.ijrobp.2008.07.028","","","medline-18954717.pdf","medline-18954717"
"Reproducibility of reading echocardiographic parameters to assess severity of mitral regurgitation. Insights from a French multicentre study","Coisne A., Aghezzaf S., Edme J. L., Bernard A., Ma I., Bohbot Y., Di Lena C., Nicol M., Lavie Badie, Eyharts D., Seemann A., Falaise C., Ternacle J., Nguyen A., Montier G., Hubert A., Montaigne D., Donal E., Dreyfus J.","Archives of cardiovascular diseases","","BACKGROUND: Poor reproducibility in assessment of mitral regurgitation (MR) has been reported. AIM: To investigate the robustness of echocardiographic MR assessment in 2019 based on improvements in technology and the skill of echocardiographists regarding MR quantification. METHODS: Reproducibility in parameters of MR severity and global rating were tested using transthoracic echocardiography in 25 consecutive patients independently analysed by 16 junior and senior cardiologists specialized in echocardiography (400 analyses per parameter). RESULTS: Overall interobserver agreement for mechanism definition effective regurgitant orifice area (EROA) and regurgitant volume (RVol) was moderate and was lower in secondary MR. Interobserver agreement was substantial for EROA [0.61 95% confidence interval (CI) 0.45-0.75] and moderate for RVol with the PISA method (0.50 95% CI 0.33-0.56) in senior physicians and was fair in junior physicians (0.33 95% CI 0.19-0.51 and 0.36 95% CI 0.36-0.43 respectively). Using a multiparametric approach overall interobserver agreement for grading MR severity was fair (0.30) was slightly better in senior than in junior physicians (0.31 vs. 0.28 respectively) with substantial or almost perfect agreement more frequently observed in senior versus junior physicians (52% vs. 36% respectively). CONCLUSION: Reproducible transthoracic echocardiography MR quantification remains challenging in 2019 despite the expected high skills of echocardiographers regarding MR at the time of dedicated percutaneous intervention. The multiparametric approach does not entirely alleviate the substantial dispersion in measurement of MR severity parameters whereas reader experience seems to partially address the issue. Our study emphasizes the continuing need for multimodality imaging and education in the evaluation of MR among cardiologists.","","","2020","10.1016/j.acvd.2020.02.004","","","medline-32994143.pdf","medline-32994143"
"Combining individual and collective employee incentives to enhance organizational performance","Klindžić, M. And Galetić, L.","Drustvena Istrazivanja","","A large body of literature provides empirical evidence of a positive relationship between reward practices and performance. However, little has been said about different combinations of individual and group incentives as drivers of organizational competitiveness. This paper examines bundles of nine individual and group pfp practices and their joint effect on selected financial and non-financial indicators of organizational performance (op). Our empirical research study included 61 middle-and large-sized companies in croatia in order to analyze the aforementioned relationships. The categorical principal component analysis generated two factors of pfp practices that were subsequently used as independent variables in a multiple regression analysis. The first pfp bundle consisted of individual subjectively-based bonus and two shared-ownership practices and was found to positively influence non-financial indicators of op, i.e. quality of services or products and innovativeness. The second factor consisted of individual performance appraisal and profit-sharing and it positively influenced financial indicators of op, i.e. productivity and, to a lesser extent, profitability. Implications for theory and practice are also discussed. © 2020, institute of social sciences ivo pilar. All rights reserved.","","","2020","10.5559/di.29.1.04","","","scopus-2-s2.0-85082103600.pdf","scopus-2-s2.0-85082103600"
"Avoiding questionable research practices in applied psychology","O'donohue, William [Ed] And Masuda, Akihiko [Ed] And Lilienfeld, Scott [Ed]","","","This authoritative volume presents a detailed analysis of the replication crisis and the use of questionable research practices (qrps) in psychology, as well as recommended practices for combatting these problems. Ultimately, the book aims to provide a comprehensive, current, and accessible account of the adverse effects of qrps. The replication crisis in psychology and allied fields has exposed critical flaws in the standard views of research methods, which allow for extensive flexibility in data analysis by investigators and permit the widespread use of qrps. Chapters examine the intentional use of qrps such as data fabrication and falsification, along with subtler, unintentional practices such as p-hacking and harking (hypothesizing after results are known). Drawing on the growing awareness of these problems, contributors also highlight potential strategies to detect qrps and minimize their negative impact through open data practices, preregistration of hypotheses and analyses, and adversarial collaborations, in which investigators holding opposing positions on a scientific issue agree to work together on a study in an effort to counteract their respective biases. Among the topics covered: history of controversies in statistics and replication;  embracing intellectual humility while designing research;  confirmatory vs. exploratory analyses;  publication bias and negative results;  promoting honest and transparent report writing. Avoiding questionable research practices in applied psychology provides a deeper understanding of how qrps impede the reliability and trustworthiness of findings in psychology and the social sciences. It will be a practical, useful resource for students and instructors in graduate and advanced undergraduate level research methods classes, along with psychological researchers interested in improving their own research. (Psycinfo database record (c) 2023 apa, all rights reserved)","","","2022","10.1007/978-3-031-04968-2","","","psychinfo-2023-11526-000.pdf","psychinfo-2023-11526-000"
"Balancing privacy and utility in cross-company defect prediction","Peters, F. And Menzies, T. And Gong, L. And Zhang, H.","Ieee Transactions On Software Engineering","","Background: cross-company defect prediction (ccdp) is a field of study where an organization lacking enough local data can use data from other organizations for building defect predictors. To support ccdp, data must be shared. Such shared data must be privatized, but that privatization could severely damage the utility of the data. Aim: to enable effective defect prediction from shared data while preserving privacy. Method: we explore privatization algorithms that maintain class boundaries in a dataset. Cliff is an instance pruner that deletes irrelevant examples. Morph is a data mutator that moves the data a random distance, taking care not to cross class boundaries. Cliff+morph are tested in a ccdp study among 10 defect datasets from the promise data repository. Results: we find: 1) the cliffed+morphed algorithms provide more privacy than the state-of-the-art privacy algorithms;  2) in terms of utility measured by defect prediction, we find that cliff+morph performs significantly better. Conclusions: for the oo defect data studied here, data can be privatized and shared without a significant degradation in utility. To the best of our knowledge, this is the first published result where privatization does not compromise defect prediction. © 1976-2012 ieee.","","","2013","10.1109/tse.2013.6","","","scopus-2-s2.0-84880074823.pdf","scopus-2-s2.0-84880074823"
"Comparison of SYTO9 and SYBR Green I for real-time polymerase chain reaction and investigation of the effect of dye concentration on amplification and DNA melting curve analysis","Monis P. T., Giglio S., Saint C. P.","Analytical Biochemistry","","Following the initial report of the use of SYBR Green I for real-time polymerase chain reaction (PCR) in 1997 little attention has been given to the development of alternative intercalating dyes for this application. This is surprising considering the reported limitations of SYBR Green I which include limited dye stability dye-dependent PCR inhibition and selective detection of amplicons during DNA melting curve analysis of multiplex PCRs. We have tested an alternative to SYBR Green I and report the first detailed evaluation of the intercalating dye SYTO9. Our findings demonstrate that SYTO9 produces highly reproducible DNA melting curves over a broader range of dye concentrations than does SYBR Green I is far less inhibitory to PCR than SYBR Green I and does not appear to selectively detect particular amplicons. The low inhibition and high melting curve reproducibility of SYTO9 means that it can be readily incorporated into a conventional PCR at a broad range of concentrations allowing closed tube analysis by DNA melting curve analysis. These features simplify the use of intercalating dyes in real-time PCR and the improved reproducibility of DNA melting curve analysis will make SYTO9 useful in a diagnostic context.","","","2005","10.1016/j.ab.2005.01.046","","","medline-15802126.pdf","medline-15802126"
"Bayesian estimation of the random coefficients logit from aggregate count data","Zenetti, G. And Otter, T.","Quantitative Marketing And Economics","","The random coefficients logit model is a workhorse in marketing and empirical industrial organizations research. When only aggregate data are available, it is customary to calibrate the model based on market shares as data input, even if the data are available in the form of aggregate counts. However, market shares are functionally related to model primitives in the random coefficients model whereas finite aggregate counts are only probabilistic functions of these model primitives. A recent paper by park and gupta (journal of marketing research, 46(4), 531-543 2009) stresses this distinction but is hamstrung by numerical problems when demonstrating its potential practical importance. We develop bayesian inference for the likelihood function proposed by park and gupta (journal of marketing research, 46(4), 531-543 2009), sidestepping the numerical problem encountered by these authors. We show how taking account of the amount of information about shares by modeling counts directly results in improved inference. © 2013 springer science+business media new york.","","","2014","10.1007/s11129-013-9140-4","","","scopus-2-s2.0-84897598314.pdf","scopus-2-s2.0-84897598314"
"Blockchain-empowered secure and privacy-preserving health data sharing in edge-based iomt","Nie, X. And Zhang, A. And Chen, J. And Qu, Y. And Yu, S.","Security And Communication Networks","","Health data sharing, as a booming demand, enables the patients with similar symptoms to connect with each other and doctors to obtain the medical history of patients. Health data are usually collected from edge-based internet of medical things (iomt) with devices such as smart wearable devices, smart watches, and smartphones. Since health data are highly private and have great financial value, adversaries ceaselessly launch diverse attacks to obtain private information. All these issues pose great challenges to health data sharing in edge-based iomt scenarios. Existing research either lacks comprehensive consideration of privacy and security protection or fails to provide a proper incentive mechanism, which expels users from sharing data. In this study, we propose a novel blockchain-assisted data sharing scheme, which allows secure and privacy-preserving profile matching. A bloom filter with hash functions is designed to verify the authenticity of keyword ciphertext. Key-policy attribute-based encryption (kp-abe) algorithm and smart contracts are employed to achieve secure profile matching. To incentivize users actively participating in profile matching, we devise an incentive mechanism and construct a two-phase stackelberg game to address pricing problems for data owners and accessing problems of data requesters. The optimal pricing mechanism is specially designed for encouraging more users to participate in health data sharing and maximizing users’ profit. Moreover, security analysis illustrates that the proposed protocol is capable of satisfying various security goals, while performance evaluation shows high scalability and feasibility of the proposed scheme in edge-based iomt scenarios. Copyright © 2022 xueli nie et al.","","","2022","10.1155/2022/8293716","","","scopus-2-s2.0-85126357356.pdf","scopus-2-s2.0-85126357356"
"Current ethical and social issues in epidemiology","Salerno J., Coughlin S. S., Goodman K. W., Hlaing W. M.","Annals of Epidemiology","","PURPOSE: The American College of Epidemiology held its 2021 Annual Meeting virtually September 8-10 with a conference theme of 'From Womb to Tomb: Insights from Health Emergencies'. The American College of Epidemiology Ethics Committee hosted a symposium session in recognition of the ethical and social challenges brought to light by the coronavirus disease 2019 pandemic and on the occasion of the publication of the third edition of the classic text Ethics and Epidemiology. The American College of Epidemiology Ethics Committee invited the book editor and contributing authors to present at the symposium session titled 'Current Ethical and Social Issues in Epidemiology.' The purpose of this paper is to further highlight the ethical challenges and presentations.\\\\\\\\rMETHODS: Three speakers with expertise in ethics health law health policy global health health information technology and translational research in epidemiology and public health were selected to present on the social and ethical issues in the current landscape. Dr. S Coughlin presented on the 'Ethical and Social Issues in Epidemiology' Dr. L Beskow presented on 'Ethical Challenges in Genetic Epidemiology' and Dr. K Goodman presented on the 'Ethics of Health Informatics'.\\\\\\\\rRESULTS: New digital sources of data and technologies are driving the ethical challenges and opportunities in epidemiology and public health as it relates to the three emerging topic areas identified: (1) digital epidemiology (2) genetic epidemiology and (3) health informatics. New complexities such as the reliance on social media to control infectious disease outbreaks and the introduction of computing advancements are requiring re-evaluation of traditional bioethical frameworks for epidemiology research and public health practice. We identified several cross-cutting ethical and social issues related to informed consent benefits risks and harms and privacy and confidentiality and summarized these alongside more nuanced ethical considerations such as algorithmic bias group harms related to data (mis)representation risks of misinformation return of genomic research results maintaining data security and data sharing. We offered an integrated synthesis of the stages of epidemiology research planning and conduct with the ethical issues that are most relevant in these emerging topic areas.\\\\\\\\rCONCLUSIONS: New realities exist for epidemiology and public health as professional groups who are faced with addressing population health and especially given the recent pandemic and the widespread use of digital tools and technologies. Many ethical issues can be understood in the context of existing ethical frameworks; however they have yet to be clearly identified or connected with the new technical and methodological applications of digital tools and technologies currently in use for epidemiology research and public health practice. To address current ethical challenges we offered a synthesis of traditional ethical principles in public health science alongside more nuanced ethical considerations for emerging technologies and aligned these with lifecycle stages of epidemiology research. By critically reflecting on the impact of new digital sources of data and technologies on epidemiology research and public health practice specifically in the control of infectious outbreaks we offered insights on cultivating these new areas of professional growth while striving to improve population health. Copyright © 2023 Elsevier Inc. All rights reserved.","","","2023","10.1016/j.annepidem.2023.02.001","","","medline-36758845.pdf","medline-36758845"
"A blockchain-enabled deduplicatable data auditing mechanism for network storage services","Xu, Y. And Zhang, C. And Wang, G. And Qin, Z. And Zeng, Q.","Ieee Transactions On Emerging Topics In Computing","","Since network storage services achieve widespread adoption, security and performance issues are becoming primary concerns, affecting the scalability of storage systems. Countermeasures like data auditing mechanisms and deduplication techniques are widely studied. However, the existing data auditing mechanism with deduplication cannot solve the problems such as high cost and reliance on trusted third parties in traditional approaches, and it also faces the problem of repeated auditing of data shared by multiple-tenant. This article proposes a blockchain-based deduplicatable data auditing mechanism. We first design a client-side data deduplication scheme based on bilinear-pair techniques to reduce the burden on users and service providers. On this basis, we achieve a trustworthy and efficient data auditing mechanism that helps to check data integrity by using both the blockchain technique and bilinear pairing cryptosystem. The blockchain system is used to record the behaviors of entities in both data outsourcing and auditing processes so that the corresponding immutable records can be used to not only ensure the credibility of audit results but also help to monitor unreliable third-party auditors. Finally, theoretical analysis and experiments reveal the effectiveness and performance of our scheme. © 2013 ieee.","","","2021","10.1109/tetc.2020.3005610","","","scopus-2-s2.0-85087494673.pdf","scopus-2-s2.0-85087494673"
"A geotechnical database for utah (geodu) enabling quantification of geotechnical properties of surficial geologic units for geohazard assessments","Sharifi-Mood, M. And Gillins, D.t. And Olsen, M.j. And Franke, K.w. And Bartlett, S.f.","Earthquake Spectra","","Geotechnical borehole information is often used for liquefaction hazard mapping, but can be highly variable in terms of quantity and quality. In addition, geotechnical borehole logs are often provided as images in reports rather than delivered in a structured, queryable database, which makes the logs and supplementary information difficult to organize particularly across a large geographic area. In contrast, surficial geologic mapping is generally available and often accessible in geographic information systems (gis) format. This article’s objective is to describe the compilation of a geotechnical database for regional mapping purposes and to demonstrate the value of documenting geotechnical data into a consistent data format. Specifically, this article describes the development of three geotechnical borehole databases compiled in utah, which has been coined the geotechnical database for utah (geodu). The database is used to quantify geotechnical properties for subsequent liquefaction evaluations of surficial geologic units comprising similar depositional environment and age. The resulting geodu is an important resource for future efforts with many applications including community data sharing and planning for preliminary geotechnical site investigations. © the author(s) 2020.","","","2020","10.1177/8755293019878197","","","scopus-2-s2.0-85088972359.pdf","scopus-2-s2.0-85088972359"
"Assessing Open Science practices in physical activity behaviour change intervention evaluations","Norris E., Sulevani I., Finnerty A. N., Castro O.","BMJ Open Sport & Exercise Medicine","","Objectives: Concerns on the lack of reproducibility and transparency in science have led to a range of research practice reforms broadly referred to as 'Open Science'. The extent that physical activity interventions are embedding Open Science practices is currently unknown. In this study we randomly sampled 100 reports of recent physical activity randomised controlled trial behaviour change interventions to estimate the prevalence of Open Science practices.\\\\\\\\rMethods: One hundred reports of randomised controlled trial physical activity behaviour change interventions published between 2018 and 2021 were identified as used within the Human Behaviour-Change Project. Open Science practices were coded in identified reports including: study pre-registration protocol sharing data materials and analysis scripts sharing replication of a previous study open access publication funding sources and conflict of interest statements. Coding was performed by two independent researchers with inter-rater reliability calculated using Krippendorff's alpha.\\\\\\\\rResults: 78 of the 100 reports provided details of study pre-registration and 41% provided evidence of a published protocol. 4% provided accessible open data 8% provided open materials and 1% provided open analysis scripts. 73% of reports were published as open access and no studies were described as replication attempts. 93% of reports declared their sources of funding and 88% provided conflicts of interest statements. A Krippendorff's alpha of 0.73 was obtained across all coding.\\\\\\\\rConclusion: Open data materials analysis and replication attempts are currently rare in physical activity behaviour change intervention reports whereas funding source and conflict of interest declarations are common. Future physical activity research should increase the reproducibility of their methods and results by incorporating more Open Science practices. Copyright © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY. Published by BMJ.","","","2022","10.1136/bmjsem-2021-001282","","","medline-35722044.pdf","medline-35722044"
"Methodological and ethical issues in research using social media: a metamethod of Human Papillomavirus vaccine studies","Gustafson D. L., Woodworth C. F.","BMC Medical Research Methodology","","BACKGROUND: Online content is a primary source of healthcare information for internet-using adults and a rich resource for health researchers. This paper explores the methodological and ethical issues of engaging in health research using social media.\\\\\\\\rMETHODS: A metamethod was performed on systematically selected studies that used social media as a data source for exploring public awareness and beliefs about Human Papillomaviruses (HPV) and HPV vaccination. Seven electronic databases were searched using a variety of search terms identified for each of three concepts: social media HPV vaccine and research method. Abstracts were assessed for eligibility of inclusion; six studies met the eligibility criteria and were subjected to content analysis. A 10-item coding scheme was developed to assess the clarity congruence and transparency of research design epistemological and methodological underpinnings and ethical considerations.\\\\\\\\rRESULTS: The designs of the six selected studies were sound although most studies could have been more transparent about how they built in rigor to ensure the trustworthiness and credibility of findings. Statistical analysis that intended to measure trends and patterns did so without the benefit of randomized sampling and other design elements for ensuring generalizability or reproducibility of findings beyond the specified virtual community. Most researchers did not sufficiently engage virtual users in the research process or consider the risk of privacy incursion. Most studies did not seek ethical approval from an institutional research board or permission from host websites or web service providers.\\\\\\\\rCONCLUSIONS: The metamethod exposed missed opportunities for using the dialogical character of social media as well as a lack of attention to the unique ethical issues inherent in operating in a virtual community where social boundaries and issues of public and private are ambiguous. This suggests the need for more self-conscious and ethical research practices when using social media as a data source. Given the relative newness of virtual communities researchers and ethics review boards must work together to develop expertise in evaluating the design of studies undertaken with virtual communities. We recommend that the principles of concern for welfare respect for person and justice to be applied in research using social media.","","","2014","10.1186/1471-2288-14-127","","","medline-25468265.pdf","medline-25468265"
"How religiosity influences the consumption of luxury goods: exploration of the moral halo effect","Geiger-Oneto, S. And Minton, E.a.","European Journal Of Marketing","","Purpose: the purpose of this paper is to explore the role of religion, morality and mindset in influencing perceptions of luxury products. Design/methodology/approach: the study uses three experimental studies to investigate this relationship. Findings: study 1 shows that religiosity influences negative moral emotions (but not positive moral emotions), which then negatively influence luxury consumption and morality evaluations. Study 2 replicates the effects of study 1 and shows that priming a moral (marketplace) mindset decreases negative moral emotions and increases luxury consumption evaluations for highly (less) religious consumers. Study 3 explains the effects found in studies 1 and 2 as driven by moral licensing, such that priming a moral (marketplace) mindset decreases (increases) the negative moral emotions experienced by those primed (not primed) with religiosity. Study 3 also improves the external validity of findings by including a social media sample of regular luxury purchases. Implications for theory and marketing practice are discussed. Research limitations/implications: the present research is limited by samples conducted in western culture with a predominantly western, christian religious audience. Future research should examine how moral vs marketplace mindsets differentially influence the consumption of luxury products for eastern religious consumers (e.g. Hindus, buddhists and confucianists). Additionally, this research was conducted using allport and ross’ (1967) religiosity measure. Some could argue that the measure is not the most representative for atheists or agnostics or is outdated, so further research would benefit from replicating and extending the findings in this paper with other, newer religiosity measures better adapted to measure all belief systems. Practical implications: marketers of luxury products should realize the potential of a new target audience – religious consumers. While religiosity is positively correlated with negative moral emotions toward luxury products in study 1, studies 2 and 3 reveal that priming a moral mindset can reduce negative affect and increase evaluations of luxury products. Thus, marketers could seek out ways to emphasize morality in messaging. For example, a marketer may incorporate words such as virtues, ethics and/or noble, when describing attributes of their brand in advertising, thereby resulting in a moral licensing effect. Research suggests advertising content has the potential to influence consumers’ perceived moral obligation, inclusive of the moral or immoral nature of the consumption of luxury brands. Originality/value: while the link between religion and luxury goods is evident in popular culture, previous research has yet to empirically explore this relationship. This study fills this gap by investigating the role of religiosity on the perceived morality and ultimately the purchase of luxury branded goods. © 2019, emerald publishing limited.","","","2019","10.1108/ejm-01-2018-0016","","","scopus-2-s2.0-85074044479.pdf","scopus-2-s2.0-85074044479"
"P-values - a chronic conundrum","Gao, J.","Bmc Medical Research Methodology","","Background: in medical research and practice, the p-value is arguably the most often used statistic and yet it is widely misconstrued as the probability of the type i error, which comes with serious consequences. This misunderstanding can greatly affect the reproducibility in research, treatment selection in medical practice, and model specification in empirical analyses. By using plain language and concrete examples, this paper is intended to elucidate the p-value confusion from its root, to explicate the difference between significance and hypothesis testing, to illuminate the consequences of the confusion, and to present a viable alternative to the conventional p-value. Main text: the confusion with p-values has plagued the research community and medical practitioners for decades. However, efforts to clarify it have been largely futile, in part, because intuitive yet mathematically rigorous educational materials are scarce. Additionally, the lack of a practical alternative to the p-value for guarding against randomness also plays a role. The p-value confusion is rooted in the misconception of significance and hypothesis testing. Most, including many statisticians, are unaware that p-values and significance testing formed by fisher are incomparable to the hypothesis testing paradigm created by neyman and pearson. And most otherwise great statistics textbooks tend to cobble the two paradigms together and make no effort to elucidate the subtle but fundamental differences between them. The p-value is a practical tool gauging the ""strength of evidence""against the null hypothesis. It informs investigators that a p-value of 0.001, for example, is stronger than 0.05. However, p-values produced in significance testing are not the probabilities of type i errors as commonly misconceived. For a p-value of 0.05, the chance a treatment does not work is not 5%;  rather, it is at least 28.9%. Conclusions: a long-overdue effort to understand p-values correctly is much needed. However, in medical research and practice, just banning significance testing and accepting uncertainty are not enough. Researchers, clinicians, and patients alike need to know the probability a treatment will or will not work. Thus, the calibrated p-values (the probability that a treatment does not work) should be reported in research papers. © 2020 the author(s).","","","2020","10.1186/s12874-020-01051-6","","","scopus-2-s2.0-85087097769.pdf","scopus-2-s2.0-85087097769"
"Do payments for environmental services affect forest access and social preferences in the long run? Experimental evidence from uganda","Vorlaufer, T. And De Laat, J. And Engel, S.","Journal Of The Association Of Environmental And Resource Economists","","Conservation policies and programs may trigger unintended, potentially irreversible, changes that were initially not anticipated. Concerns have been raised that the introduction of payments for environmental services (pes) fosters the pri-vatization of natural ecosystems to the detriment of marginalized groups. We assess the long-term impacts of pes on sharing of access to natural resources, associated norms, and social preferences. The studied pes program was implemented as a randomized control trial in western uganda. Using survey and experimental data collected six years after the last payments were made, we find that the pes program did not lead to a lasting shift in resource sharing practices but did induce stronger social norms for resource sharing. Moreover, landowners in former pes villages exhibit more egalitarian social preferences than landowners in control villages. These results highlight that de-spite introducing unequal conservation benefits to communities, long-lasting negative spillovers of pes could be avoided. © 2023 the association of environmental and resource economists. All rights reserved.","","","2023","10.1086/721440","","","scopus-2-s2.0-85146361774.pdf","scopus-2-s2.0-85146361774"
"Proxy re-encryption-based traceability and sharing mechanism of the power material data in blockchain environment","Song, J. And Yang, Y. And Mei, J. And Zhou, G. And Qiu, W. And Wang, Y. And Xu, L. And Liu, Y. And Jiang, J. And Chu, Z. And Tan, W. And Lin, Z.","Energies","","The need to accelerate the innovation and application of the supply chain has been suggested by the state council of china. To solve the problem of data isolation caused by privacy protection in the power material supply chain, a data traceability and sharing mechanism based on blockchain is designed in this paper. Firstly, the existing problems of the power material supply chain are introduced, and the applicability of blockchain in the power material supply chain in view of these problems is analyzed. Secondly, blockchain-based power material supply deployment and application structures are proposed. Then, considering the problem of data isolation in the material inspection and distribution links between suppliers and the material company, a data traceability mechanism based on blockchain is designed to provide evidence for the data authenticity and a proxy re-encryption method is used to ensure security and privacy in data sharing. Finally, the effectiveness of the proposed data traceability and sharing mechanism is verified using the hyperledger fabric platform for power material case studies. The simulation results show that the combination of proxy re-encryption and blockchain technology in the power material supply chain can confirm the validity of the historical data and keep the private data of the material company confidential, so as to realize the traceability and sharing of the power material supply data. © 2022 by the authors. Licensee mdpi, basel, switzerland.","","","2022","10.3390/en15072570","","","scopus-2-s2.0-85128007865.pdf","scopus-2-s2.0-85128007865"
"Analysis of long non-coding rna expression profiles in neonatal rats with hypoxic-ischemic brain damage","Zhou, H. And Wang, X. And Cheng, R. And Hou, X. And Chen, Y. And Feng, Y. And Qiu, J.","Journal Of Neurochemistry","","Hypoxic-ischemic brain damage (hibd) which is a common cause of acute mortality and neurological dysfunction in neonates still lacks effective therapeutic methods. Long non-coding rnas (lncrnas) were demonstrated to play a crucial role in many diseases. To give a foundation for subsequent functional studies of lncrnas in hibd, we investigated the profiling of lncrnas and messenger rnas (mrnas) using neonatal hibd rat model. Six neonatal rats were divided into sham-operated group (n = 3) and hibd group (n = 3) randomly. Deep rna sequencing was implemented to find out the meaningful lncrnas and mrnas. Quantitative real-time pcr was used to validate expressions of lncrnas and mrnas. The gene ontology (go) and kyoto encyclopedia of genes a genomes (kegg) database were used to predict functions of lncrnas. A total of 328 differentially expressed lncrnas (177 down-regulated vs 151 up-regulated) and 7157 differentially expressed mrnas (2552 down-regulated vs 4605 up-regulated) were identified. The quantitative real-time pcr results showed significant differential expressions of five lncrnas and five mrnas which were consistent with the rna-seq data. Gene ontology and kegg analysis showed these lncrnas and their expression-correlated mrnas were closely related to the janus tyrosine kinase-signal transducer and activator of transcription (jak-stat) signaling pathway, nf-kappa b signaling pathway, toll-like receptor signaling pathway, calcium signaling pathway, notch signaling pathway, mitogen activated protein kinase signaling pathway, neuroactive ligand-receptor interaction pathway and more. The results of our study identified the characterization and expression profiles of lncrnas in neonatal hibd and may be a basis for further therapeutic research. Open science badges: this article has received a badge for *open materials* and *open data* because it provided all relevant information to reproduce the study in the manuscript and because it made the data publicly available. The data can be accessed at https://osf.io/yf3da/. The complete open science disclosure form for this article can be found at the end of the article. More information about the open practices badges can be found at https://cos.io/our-services/open-science-badges/. (Figure presented.). © 2019 international society for neurochemistry","","","2019","10.1111/jnc.14689","","","scopus-2-s2.0-85063451342.pdf","scopus-2-s2.0-85063451342"
"Privacy challenges and research opportunities for genomic data sharing","Bonomi L., Huang Y., Ohno-Machado L.","Nature Genetics","","The sharing of genomic data holds great promise in advancing precision medicine and providing personalized treatments and other types of interventions. However these opportunities come with privacy concerns and data misuse could potentially lead to privacy infringement for individuals and their blood relatives. With the rapid growth and increased availability of genomic datasets understanding the current genome privacy landscape and identifying the challenges in developing effective privacy-protecting solutions are imperative. In this work we provide an overview of major privacy threats identified by the research community and examine the privacy challenges in the context of emerging direct-to-consumer genetic-testing applications. We additionally present general privacy-protection techniques for genomic data sharing and their potential applications in direct-to-consumer genomic testing and forensic analyses. Finally we discuss limitations in current privacy-protection methods highlight possible mitigation strategies and suggest future research opportunities for advancing genomic data sharing. Copyright © 2020 Springer Nature America Inc.","","","2020","10.1038/s41588-020-0651-0","","","medline-32601475.pdf","medline-32601475"
"Dynamically adjusting case reporting policy to maximize privacy and public health utility in the face of a pandemic","Brown J. T., Yan C., Xia W., Yin Z., Wan Z., Gkoulalas-Divanis A., Kantarcioglu M., Malin B. A.","Journal of the American Medical Informatics Association","","OBJECTIVE: Supporting public health research and the public's situational awareness during a pandemic requires continuous dissemination of infectious disease surveillance data. Legislation such as the Health Insurance Portability and Accountability Act of 1996 and recent state-level regulations permits sharing deidentified person-level data; however current deidentification approaches are limited. Namely they are inefficient relying on retrospective disclosure risk assessments and do not flex with changes in infection rates or population demographics over time. In this paper we introduce a framework to dynamically adapt deidentification for near-real time sharing of person-level surveillance data.\\\\\\\\rMATERIALS AND METHODS: The framework leverages a simulation mechanism capable of application at any geographic level to forecast the reidentification risk of sharing the data under a wide range of generalization policies. The estimates inform weekly prospective policy selection to maintain the proportion of records corresponding to a group size less than 11 (PK11) at or below 0.1. Fixing the policy at the start of each week facilitates timely dataset updates and supports sharing granular date information. We use August 2020 through October 2021 case data from Johns Hopkins University and the Centers for Disease Control and Prevention to demonstrate the framework's effectiveness in maintaining the PK11 threshold of 0.01.\\\\\\\\rRESULTS: When sharing COVID-19 county-level case data across all US counties the framework's approach meets the threshold for 96.2% of daily data releases while a policy based on current deidentification techniques meets the threshold for 32.3%.\\\\\\\\rCONCLUSION: Periodically adapting the data publication policies preserves privacy while enhancing public health utility through timely updates and sharing epidemiologically critical features. Copyright © The Author(s) 2022. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved. For permissions please email: journals.permissions@oup.com.","","","2022","10.1093/jamia/ocac011","","","medline-35182149.pdf","medline-35182149"
"Semantic web technologies applied to software accessibility evaluation: a systematic literature review","Estrada-Martínez, F.j. And Hilera, J.r. And Otón, S. And Aguado-Delgado, J.","Universal Access In The Information Society","","Software accessibility is a current field of interest. Governments and organizations boost initiatives and legislations to assure universal access. On the other hand, the semantic web is the evolution of the internet from a web of pages to a web of data. It enables the linked data engineering. It facilitates search of information, data analysis and data sharing. Some studies have applied semantic web technologies to improve software accessibility. Their methods, goals and results are heterogeneous. This systematic literature review aims to review how the application of semantic web technologies has evolved in software accessibility evaluation. First, we defined some main and secondary research questions that would set the context for the review. Then, we defined a search strategy and selection criteria which allowed us to get a set of primary studies related to our research question. We measured the quality of the studies and performed a qualitative analysis. A lack of studies in some of the sub-areas included was revealed. A low impact level was also detected in most cases, so this research field needs to be explored further. Semantic web has a direct application on software accessibility evaluation. However, this review reveals a lack of studies in some important sub-areas. A very low impact of the studies was also detected compared with other studies in the accessibility field. The evolution of this area is slow, so we recommend exploring further the different research branches and trying to generate studies with more impact. © 2020, springer-verlag gmbh germany, part of springer nature.","","","2022","10.1007/s10209-020-00759-y","","","scopus-2-s2.0-85092399473.pdf","scopus-2-s2.0-85092399473"
"Mapping from disease-specific to generic health-related quality-of-life scales: a common factor model","Lu G., Brazier J. E., Ades A. E.","Value in Health","","OBJECTIVES: To develop a coherent method for estimating mappings between treatment effects on disease-specific measurement (DSM) instruments and generic health-related quality-of-life (QOL) measures when both are subject to measurement errors.\\\\\\\\rMETHODS: We identified three properties that must be satisfied for mappings to be logically coherent: invertability transitivity and invariance to linear transformation. Of the common regressions ordinary least squares (OLS) geometric mean (GM) and orthogonal regression only GM has all these properties and then only in special cases. We developed a common factor model of how DSM and generic QOL scales are related and derived expressions for coherent mapping coefficients. We showed that these are equivalent to adjusted forms of OLS or GM regressions. Where cohort data are available on just one DSM and one QOL measure external data on the reproducibility of the DSM are required. In some circumstances the mappings can be estimated without external data. We illustrated the estimation of mapping coefficients by using data on EuroQol five-dimensional (EQ-5D) questionnaire 12-item short form health survey (SF-12) Mental Component Summary and the Beck Depression Inventory (BDI) from a trial of treatments for depression.\\\\\\\\rRESULTS: OLS underestimates and GM overestimates mappings from DSMs to generic QOL measures. Mappings estimated by using external data on reliability were similar to those estimated by using internal data suggesting approximate adequacy of the common factor model.\\\\\\\\rCONCLUSIONS: Neither OLS nor GM regression unless corrected is suitable for estimating mappings between disease-specific and generic QOL scales. OLS systematically underestimates mappings but it can be adjusted by using external information on test-retest reliability. Copyright © 2013 International Society for Pharmacoeconomics and Outcomes Research (ISPOR). Published by Elsevier Inc. All rights reserved.","","","2013","10.1016/j.jval.2012.07.003","","","medline-23337229.pdf","medline-23337229"
"Compliance with the national athletic trainers’ association inter-association task force preseason heat-acclimatization guidelines in high school football","Kerr, Z.y. And Register-Mihalik, J.k. And Pryor, R.r. And Hosokawa, Y. And Scarneo-Miller, S.e. And Casa, D.j.","Journal Of Athletic Training","","Context: in 2009, the national athletic trainers’ association inter-association task force (nata-iatf) released preseason heat-acclimatization guidelines for gradually acclimatizing high school (hs) athletes to the environment during the first 2 weeks of the preseason and reducing the risk of exertional heat illness. However, researchers who studied the 2011 preseason found a low level of overall compliance. Objective: to assess compliance with the nata-iatf guidelines during the 2017 preseason and compare the findings with 2011 preseason data and between states mandating and not mandating the guidelines. Design: cross-sectional study. Setting: preseason hs football, 2017. Patients or other participants: a total of 1023 athletic trainers working with hs football (14.2% response rate). Main outcome measure(s): using a survey, we acquired information from athletic trainers on their hs football programs, including location and compliance with 17 nata-iatf guidelines during the 2017 football preseason. The outcome measures were full compliance with all 17 nata-iatf guidelines and compliance with 10 nata-iatf guidelines. Prevalence ratios (prs) with 95% confidence intervals (cis) compared findings between (1) the 2017 and 2011 preseasons and (2) states whose hs athletic associations imposed a full or partial or no mandate to follow the nata-iatf guidelines. Results: overall, 3.9% reported full compliance with nata-iatf guidelines;  73.9% complied with 10 guidelines. The proportion reporting full compliance was higher in 2017 than in 2011 but not statistically different (3.9% versus 2.5%;  pr ¼ 1.54;  95% ci ¼ 0.96, 2.46). However, the proportion reporting compliance with 10 guidelines was higher in 2017 (73.9% versus 57.9%;  pr ¼ 1.28;  95% ci ¼ 1.20, 1.36). The proportion of respondents reporting their hss were fully compliant was highest among the with-mandate group (9.4%), followed by the partial-mandate group (4.6%) and the without-mandate group (0.6%). Group differences retained significance when we examined compliance with 10 guidelines. Conclusions: although full compliance with nata-iatf guidelines remained low, many hs football programs complied with 10 guidelines. Ó by the national athletic trainers’ association, inc","","","2019","10.4085/1062-6050-373-18","","","scopus-2-s2.0-85071230044.pdf","scopus-2-s2.0-85071230044"
"Knowledge sharing and innovation capability at both individual and organizational levels: an empirical study from vietnam's telecommunication companies","Nham, T.p. And Tran, N.h. And Nguyen, H.a.","Management And Marketing","","This paper aims at investigating the relationship between knowledge sharing activities and innovation capability at both individual and organizational levels. By reviewing extensive literature, a conceptual framework is built with integrating three factors: knowledge sharing, individual innovation capability and firm innovation capability. This study applies structural equation modeling (sem) to analyze the data collected from 392 employees working at major vietnam's telecommunication companies. Empirical results show that knowledge sharing including knowledge donating, knowledge collecting play an important role in improving individual innovation capability. There is no direct link between knowledge collecting and organizational innovation capability, while knowledge donating has direct positive impact on product and managerial innovation. Furthermore, the individual innovation capability acts as a mediating variable between knowledge sharing practices and firm innovation capability. Implications for academics and practitioners are provided in this study. © 2020 tuan phong nham et al., published by sciendo 2020.","","","2020","10.2478/mmcks-2020-0017","","","scopus-2-s2.0-85088937748.pdf","scopus-2-s2.0-85088937748"
"Interventions for the prevention of overweight and obesity in preschool children: a systematic review of randomized controlled trials","Monasta, L. And Batty, G.d. And Macaluso, A. And Ronfani, L. And Lutje, V. And Bavcar, A. And Van Lenthe, F.j. And Brug, J. And Cattaneo, A.","Obesity Reviews","","The objective of this study was to analyse interventions for the prevention of overweight and obesity in children under 5 years of age. We carried out a systematic review focusing exclusively on randomized controlled trials (rcts). Data sources include medline, cochrane library, embase, cinhal, psychinfo and web of science. Data were extracted from seventeen articles describing seven rcts identified through electronic search, screening of references in systematic reviews, own files and contact with authors. Rcts were assessed with the jadad scale. Four trials were carried out in preschool settings, one with an exclusive educational component, two with an exclusive physical activity component and one with both. Two trials were family-based, with education and counselling for parents and children. The remaining trial was carried out in maternity hospitals, with a training intervention on breastfeeding. None of the interventions had an effect in preventing overweight and obesity. The failure to show an effect may be due to the choice of outcomes, the quality of the rcts, the suboptimal implementation of the interventions, the lack of focus on social and environmental determinants. More rigorous research is needed on interventions and on social and environmental factors that could impact on lifestyle. © 2010 the authors. obesity reviews © 2010 international association for the study of obesity.","","","2011","10.1111/j.1467-789x.2010.00774.x","","","scopus-2-s2.0-79955035683.pdf","scopus-2-s2.0-79955035683"
"Inter-examiner reproducibility of the segmental motion palpation springing test for side bending at level c2-c3","Bakhtadze, M.a. And Patijn, J. And Galaguza, V.n. And Bolotov, D.a. And Popov, A.a.","International Musculoskeletal Medicine","","Aim: reproducibility of the cervical segmental examination has become increasingly important to fulfill indications for the therapeutic interventions common in manual/musculoskeletal medicine. Previous reproducibility studies concerning this topic showed low kappa values, suggesting a low to absent clinical applicability. Due to methodological flaws in previous studies, our objective was to test for reproducibility of our technique of examination of the c2/3 segment using an accepted international protocol. Method: we used a protocol for reproducibility studies developed by the international academy for manual/musculoskeletal medicine. The reproducibility of a cervical segmental mobility test at the level c2/c3 was evaluated in a population with cervicogenic headache. Results: the kappa value for the cervical segmental test on the right side was 0.77 (overall agreement 0.90, prevalence index 0.44) and on the left side was 0.72 (overall agreement 0.86, prevalence index 0.49). Conclusion: our study, using an accepted international protocol for reproducibility, guaranteed a proper conclusion about the reproducibility and therefore clinical application of the segmental motion palpation springing test for side bending at level c2-c3. Further studies have to focus on anatomical validation of our test and on developing gold standards for validity studies with respect to the segmental mobility aspect of our clinical examination. © the society of orthopaedic medicine and the british institute of musculoskeletal medicine 2011.","","","2011","10.1179/1753615411y.0000000001","","","scopus-2-s2.0-84857055011.pdf","scopus-2-s2.0-84857055011"
"Better utilisation and transparency of bird data collected by powerline companies","Kettel, E.f. And Thaxter, C. And Oppel, S. And Carryer, A. And Innis, L. And Pearce-Higgins, J.w.","Journal Of Environmental Management","","There is in an ongoing expansion of powerlines as a result of an increasing global demand for energy. Powerlines have the potential to negatively impact wild bird populations through collisions and/or electrocution, and reducing bird powerline collision and electrocution risk is a priority for companies running high-voltage powerlines (known as transmission system operators (tsos)). Most tsos are legally required to assess any potentially significant impacts via enivronmental impact assessments, and so potentially collect a significant amount of data on the presence of species, species behaviour, and observed mortality rates. The value of such data, if available, for reducing and preventing bird casualties could be enhanced by increasing availability across tsos and other decision-makers. We review the extent to which the sharing of data is happening across europe, and how the quality, scope and availability of bird data collected by european tsos could be improved, through use of a questionnaire and workshop with tsos, conservationists and academics. Sixteen european tsos responded to the questionnaire and 30 stakeholders attended the workshop. There was wide recognition of the value of different types of data on birds at powerlines, and a positive attitude to working together to share and enhance data across stakeholders to achieve the shared goal of reducing bird mortalities. Key barriers to the sharing of data included a lack of a centralised database, the lack of standardised methods to collect bird data and concerns over the confidentiality of data and reports. In order to overcome these barriers and develop a collaborative approach to data sharing, and ultimately inform best practice to reduce significant negative impacts on bird populations, we suggest a stepwise approach that (1) develops guidance around the field methods and data to be collected for mitigation effectiveness and (2) shares meta-data/bibliography of studies of powerline impacts/mitigation effectiveness for birds. In time, a more structured approach to the sharing of data and information could be developed, to make data findable, accessible, interoperable and reusable. © 2021 elsevier ltd","","","2022","10.1016/j.jenvman.2021.114063","","","scopus-2-s2.0-85118584415.pdf","scopus-2-s2.0-85118584415"
"Surveillance cameras and crime: a review of randomized and natural experiments","Alexandrie, G.","Journal Of Scandinavian Studies In Criminology And Crime Prevention","","Research on the effectiveness of surveillance cameras in reducing crime suffers from potential threats to causal validity. This paper reviews seven studies that address some of these problems using the rigorous research designs of randomized and natural experiments. Included studies that reported changes in total crime found crime reductions ranging from 24 to 28% in public streets and urban subway stations, but no desirable effects in parking facilities or suburban subway stations. Moreover, surveillance cameras may help reduce unruly behaviour in football stadiums and theft in supermarkets/mass merchant stores. These findings indicate that video surveillance can reduce crime in several settings. © 2017 the scandinavian research council for criminology.","","","2017","10.1080/14043858.2017.1387410","","","scopus-2-s2.0-85031919836.pdf","scopus-2-s2.0-85031919836"
"Standardization and quality control for high-dimensional mass cytometry studies of human samples","Kleinsteuber K. And Corleis B. And Rashidi N. And Nchinda N. And Lisanti A. And Cho J.l. And Medoff B.d. And Kwon D. And Walker B.d.","Cytometry A","","Mass cytometry (cytof), a mass spectrometry-based single cell phenotyping technology, allows utilization of over 35 antibodies in a single sample and is a promising tool for translational human immunology studies. Although several analysis tools are available to interpret the complex data sets generated, a robust method for standardization and quality control within and across studies is needed. Here we report an efficient and easily adaptable method to monitor quality of individual samples in human immunology studies and to facilitate reproducible data analysis. Samples to be assessed are spiked with a defined amount of reference peripheral blood mononuclear cells from a healthy donor, derived from a single large blood draw. The presence of known standardized numbers and phenotypic profiles of these reference cells greatly facilitates sample analysis by allowing for: 1) quality control for consistent staining of each antibody in the panel, 2) identification of potential batch effects, and 3) implementation of a robust gating strategy. We demonstrate the utility of this method using peripheral blood and bronchoalveolar lavage samples from hiv+ patients by characterizing their cd8+ t-cell phenotypes and cytokine expression, respectively. Our results indicate that this method allows quality control of experimental conditions and results in highly reproducible population frequencies through a robust gating strategy. © 2016 international society for advancement of cytometry.","","","2016","10.1002/cyto.a.22935","","","embase-618852472.pdf","embase-618852472"
"The impact of changing norms on creativity in psychological science","Wai, J. And Halpern, D.f.","Perspectives On Psychological Science","","The open science or credibility revolution has divided psychologists on whether and how the “policy” change of preregistration and similar requirements will affect the quality and creativity of future research. We provide a brief history of how norms have rapidly changed and how news and social media are beginning to “disrupt” academic science. We note a variety of benefits, including more confidence in research findings, but there are possible costs as well, including a reduction in the number of studies conducted because of an increased workload required by new policies. We begin to craft a study to evaluate the short- and long-term impacts of these changing norms on creativity in psychological science, run into some possible roadblocks, and hope others will build on this idea. This policy change can be evaluated in the short term but will ultimately need to be evaluated decades from now. Long-term evaluations are rare, yet this is the ultimate measure of creative scientific advance. Our conclusion supports the goals and procedures for creating a more open science. © 2018, the author(s) 2018.","","","2018","10.1177/1745691618773326","","","scopus-2-s2.0-85049892031.pdf","scopus-2-s2.0-85049892031"
"Merging data diversity of clinical medical records to improve effectiveness","Helgheim, B.i. And Maia, R. And Ferreira, J.c. And Martins, A.l.","International Journal Of Environmental Research And Public Health","","Medicine is a knowledge area continuously experiencing changes. Every day, discoveries and procedures are tested with the goal of providing improved service and quality of life to patients. With the evolution of computer science, multiple areas experienced an increase in productivity with the implementation of new technical solutions. Medicine is no exception. Providing healthcare services in the future will involve the storage and manipulation of large volumes of data (big data) from medical records, requiring the integration of different data sources, for a multitude of purposes, such as prediction, prevention, personalization, participation, and becoming digital. Data integration and data sharing will be essential to achieve these goals. Our work focuses on the development of a framework process for the integration of data from different sources to increase its usability potential. We integrated data from an internal hospital database, external data, and also structured data resulting from natural language processing (npl) applied to electronic medical records. An extract-transform and load (etl) process was used to merge different data sources into a single one, allowing more effective use of these data and, eventually, contributing to more efficient use of the available resources. © 2019 by the authors. Licensee mdpi, basel, switzerland.","","","2019","10.3390/ijerph16050769","","","scopus-2-s2.0-85062382829.pdf","scopus-2-s2.0-85062382829"
"Simulating toxicokinetic variability to identify susceptible and highly exposed populations","Breen M., Wambaugh J. F., Bernstein A., Sfeir M., Ring C. L.","Journal of Exposure Science & Environmental Epidemiology","","BACKGROUND: Toxicokinetic (TK) data needed for chemical risk assessment are not available for most chemicals. To support a greater number of chemicals the U.S. Environmental Protection Agency (EPA) created the open-source R package ""httk"" (High Throughput ToxicoKinetics). The ""httk"" package provides functions and data tables for simulation and statistical analysis of chemical TK including a population variability simulator that uses biometrics data from the National Health and Nutrition Examination Survey (NHANES).\\\\\\\\rOBJECTIVE: Here we modernize the ""HTTK-Pop"" population variability simulator based on the currently available data and literature. We provide explanations of the algorithms used by ""httk"" for variability simulation and uncertainty propagation.\\\\\\\\rMETHODS: We updated and revised the population variability simulator in the ""httk"" package with the most recent NHANES biometrics (up to the 2017-18 NHANES cohort). Model equations describing glomerular filtration rate (GFR) were revised to more accurately represent physiology and population variability. The model output from the updated ""httk"" package was compared with the current version.\\\\\\\\rRESULTS: The revised population variability simulator in the ""httk"" package now provides refined more relevant and better justified estimations.\\\\\\\\rSIGNIFICANCE: Fulfilling the U.S. EPA's mission to provide open-source data and models for evaluations and applications by the broader scientific community and continuously improving the accuracy of the ""httk"" package based on the currently available data and literature. Copyright © 2022. This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply.","","","2022","10.1038/s41370-022-00491-0","","","medline-36329211.pdf","medline-36329211"
"Multibac: a strategy to remove batch effects between different omic data types","Ugidos M. And Tarazona S. And Prats-Montalban J.m. And Ferrer A. And Conesa A.","Stat. Methods Med. Res","","Diversity of omic technologies has expanded in the last years together with the number of omic data integration strategies. However, multiomic data generation is costly, and many research groups cannot afford research projects where many different omic techniques are generated, at least at the same time. As most researchers share their data in public repositories, different omic datasets of the same biological system obtained at different labs can be combined to construct a multiomic study. However, data obtained at different labs or moments in time are typically subjected to batch effects that need to be removed for successful data integration. While there are methods to correct batch effects on the same data types obtained in different studies, they cannot be applied to correct lab or batch effects across omics. This impairs multiomic meta-analysis. Fortunately, in many cases, at least one omics platform-i.e. gene expression- is repeatedly measured across labs, together with the additional omic modalities that are specific to each study. This creates an opportunity for batch analysis. We have developed multibac (multiomic multiomics batch-effect correction correction), a strategy to correct batch effects from multiomic datasets distributed across different labs or data acquisition events. Our strategy is based on the existence of at least one shared data type which allows data prediction across omics. We validate this approach both on simulated data and on a case where the multiomic design is fully shared by two labs, hence batch effect correction within the same omic modality using traditional methods can be compared with the multibac correction across data types. Finally, we apply multibac to a true multiomic data integration problem to show that we are able to improve the detection of meaningful biological effects.copyright © the author(s) 2020.","","","2020","10.1177/0962280220907365","","","embase-2004451351.pdf","embase-2004451351"
"Semantic Annotation of Predictive Modelling Experiments","Tolovski I., Džeroski S., Panov P., Appice A., Tsoumakas G., Manolopoulos Y., Matwin S.","","","In this paper we address the task of representation semantic annotation storage and querying of predictive modelling experiments. We introduce OntoExp an OntoDM module which gives a more granular representation of a predictive modeling experiment and enables annotation of the experiment’s provenance algorithm implementations parameter settings and output metrics. This module is incorporated in SemanticHub an online system that allows execution annotation storage and querying of predictive modeling experiments. The system offers two different user scenarios. The users can either define their own experiment and execute it or they can browse the repository of completed experimental workflows across different predictive modelling tasks. Here we showcase the capabilities of the system with executing multi-target regression experiment on a water quality prediction dataset using the Clus software. The system and created repositories are evaluated based on the FAIR data stewardship guidelines. The evaluation shows that OntoExp and SemanticHub provide the infrastructure needed for semantic annotation execution storage and querying of the experiments. © 2020 The Author(s).","","","2020","10.1007/978-3-030-61527-7_9","","","scopus-2-s2.0-85094142012.pdf","scopus-2-s2.0-85094142012"
"Secondary use of electronic health records: Availability aspects in two Nordic countries","Vikstrom A., Moen H., Moosavi S. R., Salakoski T., Salantera S.","Health Information Management","","BACKGROUND: The potential for the secondary use of electronic health records (EHRs) is underused due to restrictions in national legislation. For privacy purposes legislative restrictions limit the availability and content of EHR data provided to secondary users. These limitations do not encourage healthcare organisations to develop procedures to promote the secondary use of EHRs. OBJECTIVE: The objective of this study is to identify factors that restrict the secondary use of unstructured EHRs in academic research in Finland and Sweden. METHOD: A study was conducted to identify these availability-restricting issues that pertain to the academic secondary use of unstructured EHRs. Using semi-structured interviews 14 domain experts in science hospital management and business were interviewed to evaluate the efficiency of procedures and technologies that are implemented in secondary use processes. RESULTS: The results demonstrate three aspects that restrict the availability of unstructured EHRs for secondary purposes: (i) the management and (ii) privacy preservation of such data as well as (iii) potential secondary users. CONCLUSION: Based on these categories two approaches for the secondary use of unstructured EHRs are identified: the protected processing environment and altered data. IMPLICATIONS: The protected processing environment ensures patient privacy by providing unstructured EHRs for exclusive user groups that have preferred use intentions. Compared to the use of such processing environments data alteration enables the secondary use of unstructured EHRs for a larger user group with various use intentions but that yield less valuable content.","","","2019","10.1177/1833358318817473","","","medline-30554532.pdf","medline-30554532"
"Employee's learning commitment and selfefficacy","Qureshi, T.m.","Academy Of Strategic Management Journal","","Purpose of the study: the study is designed to investigate the relationship between employee learning commitments leading to employee self-efficacy that in turn leads to other positive outcomes. The study is built around employee learning commitment, knowledge sharing practices, and self-efficacy. Design/methodology/approach: this mixed method cross-sectional study shall empirically test the hypothesis based on the research questions on the sample drawn from the higher education sector. Findings: analysis revealed that employee learning commitment is significantly related to employee self-efficacy. The mediation of employee skills and abilities is also proven significant in the same relationship. Moreover, the findings also indicate that employee adaptability & responsiveness and employee skills, knowledge & abilities mediate the relationship between employee learning commitment and employee self-efficacy. Research limitations: the findings of this study cannot be generalized with much confidence in non-educational based work settings since it is built around the higher education system in the middle east. Practical implications: the major implications of the study are to lead to better training resources developed for employees to enhance their skills, improve their understanding of abilities and enable them to use their skills for the best of their interests in the education sector. Such implications will directly impact economic and community development. Originality/value: previously published research work focused on knowledge sharing and its outcomes. However, there has not been sufficient exploration in the knowledge sharing and learning process leading to employee self- efficacy specifically in the education sector of the middle east affected by employees' diverse skills, abilities and adaptability of new methods and teaching approaches. © 2019 allied academies.","","","2019","","","","scopus-2-s2.0-85068476806.pdf","scopus-2-s2.0-85068476806"
"Mapping the mooc research landscape: insights from empirical studies","Costello, E. And Soverino, T. And Bolger, R.","International Journal Of Emerging Technologies In Learning","","Several reviews have been conducted of empirical studies of mooc learners and teachers. The scope and foci of such reviews has varied, as has the reporting of the details of how they were conducted. This study analysed 1,435 published articles, determining 922 to be empirical studies. We analysed the full text of 826 of these articles to which the research team had access using the scientometric tool scival, manual researcher evaluation and topic modelling to determine: the impact as measured by citations;  geographic and institutional publishing patterns;  and the themes and types of mooc research. We found that mooc research is mostly clustered in the discipline of computer science. Learner persistence and self-regulated learning continue to be a focus of study and most impactful finding respectively as studies of previous periods have found. Research is carried out worldwide, with the most influential studies and researchers clustered in particular institutions and countries. Implications of this study are that mooc research is clustered in certain ways which may give rise to particular biases, that researchers should consider more interdisciplinary approaches in their research and greater awareness and use of open science principles and practices in their work. © 2022. All rights reserved.","","","2022","10.3991/ijet.v17i14.28721","","","scopus-2-s2.0-85135263766.pdf","scopus-2-s2.0-85135263766"
"The modified leukocytosis promoting factor (LPF)-test: a valuable supplement to the mouse weight gain (MWG)-test in toxicity control of whole cell pertussis vaccine","van Straaten-van de Kappelle I., Wiertz E. J., Marsman F. R., Borsboom D. J., van de Donk H. J., Kreeftenberg J. G.","Biologicals","","For the safety testing of pertussis vaccine many in vivo assays have been developed but none of these assays except the Mouse Weight Gain (MWG)-test are obligatory. Leukocytosis Promoting Factor (LPF) test performed in mice is one of the tests to examine the toxicity. However due to lack of standardization this test has not been implemented in the regular safety testing of the vaccine. Our investigations demonstrate that the LPF-test becomes more reproducible and sensitive if preparations are administered subcutaneously on day 0 and and counting of the leukocytes are done on day 6. Therefore it is suggested to include the revised LPF-test in the quality control panel for the assessment of the toxicity of whole-cell pertussis vaccine.","","","1992","","","","medline-1305404.pdf","medline-1305404"
"Special problems of adverse reaction assessment in Indonesia","Sihombing M. P., Gan V. H., Widya R.","Medical Toxicology","","Limited experience with adverse drug reaction (ADR) monitoring in Indonesia is one of the difficulties faced in the developing programme. Problems which arise are related to data collection quality of reporting reaction-type reported and assessment of cause-effect relationships in addition to problems related to personnel and other factors.","","","1986","","","","medline-3821434.pdf","medline-3821434"
"Determination of biomass burning emission factors: Methods and results","Delmas R., Lacaux J. P., Brocard D.","Environmental Monitoring & Assessment","","Biomass burning in a broad sense encompasses different burning practices including open and confined burnings and different types of vegetation. Emission factors of gaseous or particulate trace compounds are directly dependent both on the fuel type and the combustion process. Emission factors are generally calculated by stoichiometric considerations using the carbon mass balance method applied either to combustion chamber experiments or to field experiments based on ground-level measurements or aircraft sampling in smoke plumes. There have been a number of experimental studies in the last 10 years to investigate wildfires in tropical temperate or boreal regions. This article presents an overview of measurement methods and experimental data on emission factors of reactive or radiatively active trace compounds including trace gases and particles. It focuses on fires in tropical regions that is forest and savanna fires agricultural burns charcoal production use of fuelwood and charcoal combustion.","","","1995","10.1007/bf00546762","","","medline-24197944.pdf","medline-24197944"
"Longitudinal reproducibility of optical coherence tomography measurements in children","Prakalapakorn S. G., Freedman S. F., Lokhnygina Y., Gandhi N. G., Holgado S., Chen B. B., El-Dairi M. A.","Journal of Aapos: American Association for Pediatric Ophthalmology & Strabismus","","PURPOSE: To evaluate the longitudinal reproducibility of optical coherence tomography (OCT) measurements in normal and glaucomatous eyes of children.\\\\\\\\rMETHODS: In this 2-setting prospective study OCT-3 was used to obtain fast retinal nerve fiber layer (RNFL) and macular thickness scans. In the first study setting the normal eyes of healthy children were scanned on presentation at 2 weeks and 3 years with axial length measured at the first and last examinations. In the second setting OCT scans of patients in the pediatric glaucoma clinic were performed over 4 years as clinically indicated. Eyes were classified as ""normal"" (normal eyes and those with physiologic cupping but normal intraocular pressure [IOP]); ""mild glaucoma"" (increased IOP and a normal optic nerve appearance); or ""advanced glaucoma"" (severe cupping or progressive glaucoma). Intraclass correlation coefficients were used to evaluate the reproducibility of measurements on the same day and over time.\\\\\\\\rRESULTS: In the first setting 8 normal eyes were included. Axial length increased 0.11 +/- 0.04 mm/year over an average of 3.3 years (P = 0.03); there was no statistically significant change in RNFL thickness (P = 0.30). In our second setting 27 normal eyes and 37 eyes with glaucoma were included. Intraclass correlation coefficients across the 3 visits for total macular volume were 0.80-0.91 and for average RNFL were 0.73-0.95.\\\\\\\\rCONCLUSIONS: Global OCT measurements in children were reproducible over years and were not affected by normal increase in axial length. OCT shows promise as an objective tool for longitudinal assessment of children. Copyright © 2012 American Association for Pediatric Ophthalmology and Strabismus. Published by Mosby Inc. All rights reserved.","","","2012","10.1016/j.jaapos.2012.08.011","","","medline-23237748.pdf","medline-23237748"
"Collaborative e-learning systems using semantic data interoperability","Masud, M.","Computers In Human Behavior","","In a collaborative e-learning content management environment, the heterogeneity of data in different learning management systems presents many difficulties for data sharing;  some of these difficulties are how to integrate data, produce results for user queries, and find the correct data from heterogeneous learning management systems. Over the last few years, numerous e-learning system architectures have been proposed;  however, issues related to sharing and integrating data from different e-learning systems have been given less attention. Considering this need, this paper presents solutions for semantic data interoperability, distributed metadata management, and an agent-based query processing approach for supporting the exchange of learning content from different e-learning systems. The paper presents an empirical evaluation of the user acceptability of the proposed solutions to find qualitative measures of the users' acceptability and satisfaction;  our proposed solutions resulted in high user satisfaction. © 2016 elsevier ltd. All rights reserved.","","","2016","10.1016/j.chb.2016.02.094","","","scopus-2-s2.0-84960950973.pdf","scopus-2-s2.0-84960950973"
"The risks to patient privacy from publishing data from clinical anesthesia studies","O'neill, L. And Dexter, F. And Zhang, N.","Anesthesia And Analgesia","","In this article, we consider the privacy implications of posting data from small, randomized trials, observational studies, or case series in anesthesia from a few (e.g., 1-3) hospitals. Prior to publishing such data as supplemental digital content, the authors remove attributes that could be used to re-identify individuals, a process known as ""anonymization."" Posting health information that has been properly ""de-identified"" is assumed to pose no risks to patient privacy. Yet, computer scientists have demonstrated that this assumption is flawed. We consider various realistic scenarios of how the publication of such data could lead to breaches of patient privacy. Several examples of successful privacy attacks are reviewed, as well as the methods used. We survey the latest models and methods from computer science for protecting health information and their application to posting data from small anesthesia studies. To illustrate the vulnerability of such published data, we calculate the ""population uniqueness"" for patients undergoing one or more surgical procedures using data from the state of texas. For a patient selected uniformly at random, the probability that an adversary could match this patient's record to a unique record in the state external database was 42.8% (se < 0.1%). Despite the 42.8% being an unacceptably high level of risk, it underestimates the risk for patients from smaller states or provinces. We propose an editorial policy that greatly reduces the likelihood of a privacy breach, while supporting the goal of transparency of the research process. © 2016 international anesthesia research society.","","","2016","10.1213/ane.0000000000001331","","","scopus-2-s2.0-84966702150.pdf","scopus-2-s2.0-84966702150"
"Research of transparency of government investment and its influencing factors","Zenglian, Z.","Biotechnology: An Indian Journal","","To improve transparency is an important factor in government investment project supervision. By building index system of government investment transparency evaluation, using manual scoring to evaluate provincial government investment transparency, we found that government investment transparency could differ drastically in each province. To identify the specific reasons for the differences, empirical analysis in influencing factors are conducted-we found that real estate development projects invested by government, population and consumer spending have a significant impact on the transparency of government investment. © 2014 trade science inc. - india.","","","2014","","","","scopus-2-s2.0-84902975679.pdf","scopus-2-s2.0-84902975679"
"Identification of tools used to assess the external validity of randomized controlled trials in reviews: a systematic review of measurement properties","Jung, A. And Balzer, J. And Braun, T. And Luedtke, K.","Bmc Medical Research Methodology","","Background: internal and external validity are the most relevant components when critically appraising randomized controlled trials (rcts) for systematic reviews. However, there is no gold standard to assess external validity. This might be related to the heterogeneity of the terminology as well as to unclear evidence of the measurement properties of available tools. The aim of this review was to identify tools to assess the external validity of rcts. It was further, to evaluate the quality of identified tools and to recommend the use of individual tools to assess the external validity of rcts in future systematic reviews. Methods: a two-phase systematic literature search was performed in four databases: pubmed, scopus, psycinfo via ovid, and cinahl via ebsco. First, tools to assess the external validity of rcts were identified. Second, studies investigating the measurement properties of these tools were selected. The measurement properties of each included tool were appraised using an adapted version of the consensus based standards for the selection of health measurement instruments (cosmin) guidelines. Results: 38 publications reporting on the development or validation of 28 included tools were included. For 61% (17/28) of the included tools, there was no evidence for measurement properties. For the remaining tools, reliability was the most frequently assessed property. Reliability was judged as “sufficient” for three tools (very low certainty of evidence). Content validity was rated as “sufficient” for one tool (moderate certainty of evidence). Conclusions: based on these results, no available tool can be fully recommended to assess the external validity of rcts in systematic reviews. Several steps are required to overcome the identified difficulties to either adapt and validate available tools or to develop a better suitable tool. Trial registration: prospective registration at open science framework (osf): https://doi.org/10.17605/osf.io/ptg4d. © 2022, the author(s).","","","2022","10.1186/s12874-022-01561-5","","","scopus-2-s2.0-85127691556.pdf","scopus-2-s2.0-85127691556"
"The lack of cross-validation can lead to inflated results and spurious conclusions: a re-analysis of the macarthur violence risk assessment study","Bokhari, E. And Hubert, L.","Journal Of Classification","","Cross-validation is an important evaluation strategy in behavioral predictive modeling;  without it, a predictive model is likely to be overly optimistic. Statistical methods have been developed that allow researchers to straightforwardly cross-validate predictive models by using the same data employed to construct the model. In the present study, cross-validation techniques were used to construct several decision-tree models with data from the macarthur violence risk assessment study (monahan et al., 2001). The models were then compared with the original (non-cross-validated) classification of violence risk assessment tool. The results show that the measures of predictive model accuracy (auc, misclassification error, sensitivity, specificity, positive and negative predictive values) degrade considerably when applied to a testing sample, compared with the training sample used to fit the model initially. In addition, unless false negatives (that is, incorrectly predicting individuals to be nonviolent) are considered more costly than false positives (that is, incorrectly predicting individuals to be violent), the models generally make few predictions of violence. The results suggest that employing cross-validation when constructing models can make an important contribution to increasing the reliability and replicability of psychological research. © 2018, classification society of north america.","","","2018","10.1007/s00357-018-9252-3","","","scopus-2-s2.0-85044436708.pdf","scopus-2-s2.0-85044436708"
"Critical quality appraisal of randomized controlled trials with traditional Chinese medicines for the coronavirus disease 2019","Zhou H., Zhu H., Jia Y.","Phytomedicine","","OBJECTIVE: Traditional Chinese medicines (TCM) play an indispensable role during the pandemic of coronavirus disease 2019 (COVID-19) with an increasing number of randomized controlled trials (RCTs) designed and performed to evaluate the efficacy and safety of TCM for COVID-19. This study aimed to critically appraise the quality of currently available RCTs of TCM for COVID-19.\\\\\\\\rMETHODS: RCTs of TCM for COVID-19 were searched from three databases by two investigators and selected according to pre-established inclusion and exclusion criteria. General information of included studies was presented by applying descriptive statistics. The methodological and reporting quality of eligible RCTs was critically evaluated based on the risk of bias assessment tool 2 (RoB2) and CONSORT Extension for TCM (CONSORT-CHM Formulas 2017) respectively. The differences of risks and main general information were compared between RCTs published in English and Chinese journals. Microsoft Excel 2019 and SPSS were used for the statistical analysis. A result with p < 0.05 was considered statistically significant.\\\\\\\\rRESULTS: This study finally included 64 RCTs with a total of 10858 participants investigating TCM for COVID-19. All 64 RCTs were evaluated as moderate-to-low RoB including 27 RCTs with high bias 26 RCTs with some concerns and 11 with low bias. Results of reporting quality appraisal by CONSORT-CHM Formulas 2017 showed that 61 (95%) RCTs reported more than 18 (50%) items and 14 (22%) RCTs reported more than 26 (70%) items among all 38 items. Forty-two RCTs were approved by ethics committees and 47 RCTs reported the informed consent information. Twenty-five RCTs and 39 RCTs provided information on trial registration and funding resources respectively. The quality of 44 RCTs published in Chinese was significantly worse than that of 20 RCTs published in English especially in the following considerations including the overall RoB ethics approved informed consent trial register and reporting quality with CONSORT-CHM Formulas 2017.\\\\\\\\rCONCLUSION: The overall quality of RCTs investigating TCM for COVID-19 was appraised as moderate-to-high that was substandard and needs to be continuously improved especially for RCTs published in Chinese in the future. Copyright © 2023 The Author(s). Published by Elsevier GmbH.. All rights reserved.","","","2023","10.1016/j.phymed.2023.155038","","","medline-37647671.pdf","medline-37647671"
"The role of trait-based approaches in understanding stream fish assemblages","Pyron, M. And Williams, L. And Beugly, J. And Jacquemin, S.j.","Freshwater Biology","","The use of trait-based approaches to examine the ecology of stream fish assemblages is increasing. However, selection of traits that will be useful in testing spatial or temporal hypotheses about ecological organisation is currently limited by availability of data, rather than empirical evaluation. We analysed two data sets of stream fish assemblages to compare taxonomy and trait-based approaches. The wabash river temporal data set is based on 25years of boat electrofishing collections over a 230-km river distance. The indiana department of environmental management data set of stream collections in the state of indiana was selected to represent a spatial database. We compared several trait-based approaches: reproductive guilds, life history variables, biomonitoring metrics, ecosystem-based functional guilds and feeding and ecosystem interaction guilds. Analyses of fish assemblages that are designed to detect how environmental variation structures fish assemblages can expect similar results using taxonomic or trait-based approaches. Results of trait-based approaches will vary according to the spatial extent of the region and the number of unique entities of trait groups for a given data set. However, taxonomic analyses accounted for more variation than any trait-based analyses. © 2011 blackwell publishing ltd.","","","2011","10.1111/j.1365-2427.2011.02596.x","","","scopus-2-s2.0-79959992222.pdf","scopus-2-s2.0-79959992222"
"Tb-pacts: a fresh emphatic data sharing approach","Khusro, A. And Aarti, C.","Asian Pacific Journal Of Tropical Disease","","Tuberculosis (tb) is a leading dreadful tropical disease which causes 1.5 million mortalities per year and nearly one-third of all tb cases are unreported annually. Keeping in view of the therapeutic properties of mycobactericidal agents, at present there are 20 new diagnostic test platforms, 4 anti-tubercular agents in phase iii, 7 in phase ii clinical trials, 5 in preclinical development and 3 mycobactericidal agents in good laboratory practice toxicity evaluation. The end tb strategy of world health organization paved a way to aggregate clinical trials reports in a unique platform. The neoteric introduction of tb-platform for aggregation of clinical tb studies (tb-pacts) showed a great white hope of the scientific community which would ultimately benefit tb patients. In fact, tb-pacts is an extremely important tool to combat tb by making clinical trials data easily available. The present study summarized not only the concise current status of tb but also substantial glimpse of tb-pacts recently launched in a nutshell. © 2017 by the asian pacific journal of tropical disease. All rights reserved.","","","2017","10.12980/apjtd.7.2017d6-357","","","scopus-2-s2.0-85020272117.pdf","scopus-2-s2.0-85020272117"
"Improving the performance of automatic short answer grading using transfer learning and augmentation","Bonthu, S. And Rama Sree, S. And Krishna Prasad, M.h.m.","Engineering Applications Of Artificial Intelligence","","The task of grading answers ranging from one phrase to one paragraph using computational techniques is known as automated short answer grading (asag). The performance of existing systems is not good enough due to limited data and the lack of availability of data in many domains. Many asag systems were developed as an outcome of the active research in this field. This study builds an effective system for grading short answers in the programming domain by leveraging pre-trained language models and text augmentation. We fine-tuned three-sentence transformer models on the sprag corpus with five different augmentation techniques: viz., random deletion, synonym replacement, random swap, backtranslation, and nlpaug. The sprag corpus contains student responses involving keywords and special symbols. We experimented with four different data sizes with the augmented data to determine the impact of training data on the fine-tuned sentence transformer model. this paper provides an exhaustive analysis of fine-tuning pretrained sentence transformer models with varying sizes of data by applying text augmentation techniques. we found that applying random swap and synonym replacement techniques together while fine-tuning has given a significant improvement, with a 4.91% increase in accuracy and a 3.36% increase in the f1-score. All the trained models are publicly available1. © 2023 elsevier ltd","","","2023","10.1016/j.engappai.2023.106292","","","scopus-unknown-accession-4657946.pdf","scopus-unknown-accession-4657946"
"Methodology and reporting of mobile heath and smartphone application studies for schizophrenia","Torous John, Firth Joseph, Mueller Nora, Onnela J., Baker Justin T.","Harvard Review of Psychiatry","","[Correction Notice: An Erratum for this article was reported in Vol 25(4) of Harvard Review of Psychiatry (see record 2017-30914-006). The title of original article should has been printed as ""Methodology and Reporting of Mobile Health and Smartphone Application Studies for Schizophrenia.""] The increasing prevalence of mobile devices among patients of all demographic groups has the potential to transform the ways we diagnose monitor treat and study mental illness. As new tools and technologies emerge clinicians and researchers are confronted with an increasing array of options both for clinical assessment through digital capture of the essential behavioral elements of a condition and for intervention through formalized treatments coaching and other technology-assisted means of patient communication. And yet as with any new set of tools for the assessment or treatment of a medical condition establishing and adhering to reporting guidelines-that is what works and under what conditions-is an essential component of the translational research process. Here using the recently published World Health Organization mHealth Evaluation Reporting and Assessment guidelines for evaluating mobile health applications we review the methodological strengths and weaknesses of existing studies on smartphones and wearables for schizophrenia. While growing evidence supports the feasibility of using mobile tools in severe mental illness most studies to date failed to adequately report accessibility interoperability costs scalability replicability data security usability testing or compliance with national guidelines or regulatory statutes. Future research efforts addressing these specific gaps in the literature will help to advance our understanding and to realize the clinical potential of these new tools of psychiatry. (PsycInfo Database Record (c) 2021 APA all rights reserved)","","","2017","10.1097/hrp.0000000000000133","","","medline-28234658.pdf","medline-28234658"
"The development, inter-rater agreement and performance of a hierarchical procedure for setting the rest-interval in actigraphy data","Follesø, H.s. And Austad, S.b. And Olsen, A. And Saksvik-Lehouillier, I.","Sleep Medicine","","The aim of this study was to develop and empirically test a hierarchical procedure for defining rest intervals in actigraphy data. Background: this is a two-part study. The aim of study 1 was to identify common practices for setting rest intervals in actigraphy research and investigate whether standardized guidelines for setting the rest interval exist, as a base to develop a new procedure for defining rest intervals in actigraphy. The aim of study 2 was to empirically test this procedure (the rest interval setting, rise procedure). The rise procedure was applied to a dataset of 537 nights from the sleep study sleepic. Participants: participants (n = 55) were aged 19–33 (m = 22.7, sd = 3.0). Methods: study 1: structured overview of the methods used to correct actigraphy data. Study 2: three scorers independently applied the rise procedure to the dataset. Results: study 1 demonstrated that methods and reporting practices are inconsistent and that there is a need for a standardized procedure for setting the rest interval. The results in study 2 revealed that using the new procedure for setting rest intervals provided high agreement between scorers for both rest onsets (α= 0.975) and offsets (α= 0.998). Applying the procedure to the dataset resulted in a shortening of the rest interval by 36 min and 19 s on average. There were significant changes (p < 0.001) in all sleep estimate outcomes after applying the rise procedure. Conclusion: methods for processing and reporting actigraphy data are highly inconsistent across studies. Here we present empirical support for a new standardized procedure for setting the rest interval, which is likely to improve transparency and reproducibility in achigraphy research. © 2021 the authors","","","2021","10.1016/j.sleep.2021.07.025","","","scopus-2-s2.0-85111831790.pdf","scopus-2-s2.0-85111831790"
"In situ preservation and restoration of architectural tiles, materials and procedures: results of an international survey","Mendes, M.t. And Pereira, S. And Ferreira, T. And Mirão, J. And Candeias, A.","International Journal Of Conservation Science","","In order to aid research, improve preservation actions and develop better options for future interventions it is important to know the preservation materials and procedures adopted throughout the past and especially the ones being adopted nowadays. A survey to specialists working in situ in preservation and restoration of glazed decorative tiles has been performed aiming at getting insight on their type of training, work portfolio, opinions, the current materials and procedures used in the diverse phases of a preservation intervention (diagnosis, cleaning, consolidation, bonding fragments and fixing of glazed layer, volumetric and chromatic reintegration, final coating, resetting of tiles and manufacture of replicas) and the criteria/factors that support the specialists choices.","","","2015","","","","scopus-2-s2.0-84924649621.pdf","scopus-2-s2.0-84924649621"
"Ethics of trial drug use: to give or not to give?","Ebunoluwa O. O., Kareem F. A.","BEOnline : Journal Of The West African Bioethics Training Program","","The 2014 outbreak of Ebola viral disease in some West African countries which later spread to the USA and Spain has continued to be a subject of global public health debate. While there is no approved vaccine or drug for Ebola cure yet moral questions of bioethical significance are emerging even as vaccine studies are at different clinical trial phases. This paper through a normative and critical approach focuses on the question of whether it is ethical to give any experimental drugs to Ebola victims in West Africa or not. Given the global panic and deadly contagious nature of Ebola this paper argues on three major compassionate grounds that it is ethical to use experimental drugs on the dying African victims of Ebola. Besides respecting patients and family consent in the intervention process this paper argues that the use of Ebola trial drugs on West African population will be ethical if it promotes the common good and does not violate the fundamental principles of transparency and integrity in human research ethics. Using Kantian ethical framework of universality as a basis for moral defense of allowing access to yet approved drugs. This paper provides argument to strengthen the compassionate ground provisional recommendation of the WHO's Strategic Advisory Group of Experts on Immunization (SAGE) on Ebola vaccines and vaccination.","","","2016","","","","medline-28367458.pdf","medline-28367458"
"The kinematics of motion palpation and its effect on the reliability for cervical spine rotation","Marcotte J., Normand M. C., Black P.","Journal of Manipulative & Physiological Therapeutics","","BACKGROUND: The reliability of a test depends on its standardization. Instrumental measurement of the reproducibility of the test is an effective way to evaluate the level of standardization obtained. Improved standardization is believed to yield greater reliability.\\\\\\\\rOBJECTIVE: The objectives of this study were to measure the technical ability of an examiner to reproduce the kinematics of motion palpation for cervical spine rotation and to evaluate the effect of standardization on the reliability of the test.\\\\\\\\rDESIGN: A study of reproducibility of the kinematics of the test for cervical spine rotation was conducted by means of a computerized system of analysis of movement. The reliability when reproducibility was achieved was compared with reliability when it failed.\\\\\\\\rRESULTS: The data collected enable us to establish a standardized protocol for the execution of the test. The standardized palpation is executed within 6 of inclination from the pure plane of rotation. The successful reproduction of the kinematics of the test raises its reliability to detect the presence of fixations (kappa raising from 0.337 and 0.352 to 0.682).\\\\\\\\rCONCLUSIONS: A greater reliability arising from a high level of reproducibility enables us to document the advantages of the standardization of motion palpation in chiropractic.","","","2002","","","","medline-12214190.pdf","medline-12214190"
"Wormhole attack mitigation strategies and their impact on wireless sensor network performance: a literature survey","Shahid, H. And Ashraf, H. And Ullah, A. And Band, S.s. And Elnaffar, S.","International Journal Of Communication Systems","","Wireless sensor networks (wsns) consist of hundreds of small sensors that collect and report data. During data sharing, these wsns become vulnerable to numerous security threats, including the deadly ones. Mitigating this risk is a real challenge, especially in a low-resource environment such as a wsn. In this work, using a systematic literature review, we surveyed a large body of research (28 studies) that focused on mitigating wormhole security attacks. Through this study, we evaluate the impact of many proposed security schemes and their impact on the wsn's performance. We compare schemes for effectiveness and pinpoint the limitations. We also analyze the various parameters and metrics used in them and highlight the open research challenges in the field. © 2022 john wiley & sons ltd.","","","2022","10.1002/dac.5311","","","scopus-2-s2.0-85135227012.pdf","scopus-2-s2.0-85135227012"
"Development and Evaluation of Intraoperative Ultrasound Segmentation with Negative Image Frames and Multiple Observer Labels","Chalcroft L. F., Qu J., Martin S. A., Gayo I. J., Minore G. V., Singh I. R., Saeed S. U., Yang Q., Baum Z. M. C., Altmann A., Hu Y., Noble J. A., Aylward S., Grimwood A., Min Z., Lee S. L., Hu Y.","","","When developing deep neural networks for segmenting intraoperative ultrasound images several practical issues are encountered frequently such as the presence of ultrasound frames that do not contain regions of interest and the high variance in ground-truth labels. In this study we evaluate the utility of a pre-screening classification network prior to the segmentation network. Experimental results demonstrate that such a classifier minimising frame classification errors was able to directly impact the number of false positive and false negative frames. Importantly the segmentation accuracy on the classifier-selected frames that would be segmented remains comparable to or better than those from standalone segmentation networks. Interestingly the efficacy of the pre-screening classifier was affected by the sampling methods for training labels from multiple observers a seemingly independent problem. We show experimentally that a previously proposed approach combining random sampling and consensus labels may need to be adapted to perform well in our application. Furthermore this work aims to share practical experience in developing a machine learning application that assists highly variable interventional imaging for prostate cancer patients to present robust and reproducible open-source implementations and to report a set of comprehensive results and analysis comparing these practical yet important options in a real-world clinical application. © 2021 Springer Nature Switzerland AG.","","","2021","10.1007/978-3-030-87583-1_3","","","scopus-2-s2.0-85116447520.pdf","scopus-2-s2.0-85116447520"
"Evaluating crisis intervention teams: possible impediments and recommendations","Blevins, K.r. And Lord, V. And Bjerregaard, B.","Policing","","Purpose – extant literature resoundingly praises crisis intervention team (cit) programs for the multitude of benefits they provide for law enforcement agencies and individuals with mental illnesses. The majority of cit research is based on perceived benefits of this approach. Most of the goals of cit programs are readily amenable to empirical study, yet there are few outcome evaluations of the programs. The purpose of this paper is to examine why empirical studies examining the effectiveness of cit programs are nominal. Design/methodology/approach – structural and practical impediments to the collection of empirical data for cit programs were identified through including examinations of the types of data routinely collected, interviews with cit participants, and the researchers’ own observations of hindrances to the data collection processes. By triangulating these methods, the authors were able to observe a number of impediments to the collection of empirical data on this topic. Findings – the multi-jurisdictional cit program under review had several data problems. First, there was a lack of official data concerning cit calls. Second, it was virtually impossible to follow a person with mental illness throughout the system from first contact to final disposition. Third, data sharing was hindered by a lack of memorandums of understanding. Fourth, important information was not being properly recorded. Originality/value – this manuscript provides recommendations to address data concerns for cit evaluations. Suggestions are intended to help facilitate more robust data for analysis and evaluation purposes, helping to grow the literature on the effectiveness and efficiency of cit programs. © emerald group publishing limited.","","","2014","10.1108/pijpsm-08-2012-0083","","","scopus-2-s2.0-84927512616.pdf","scopus-2-s2.0-84927512616"
"ProjectFlow: a configurable workflow management application for point of care research","Dhond R., Elbers D., Majahalme N., Dipietro S., Goryachev S., Acher R., Leatherman S., Anglin-Foote T., Liu Q., Su S., Seerapu R., Hall R., Ferguson R., Brophy M. T., Ferraro J., DuVall S. L., Do N. V.","JAMIA Open","","OBJECTIVE: To best meet our point-of-care research (POC-R) needs we developed ProjectFlow a configurable clinical research workflow management application. In this article we describe ProjectFlow and how it is used to manage study processes for the Diuretic Comparison Project (DCP) and the Research Precision Oncology Program (RePOP). MATERIALS AND METHODS: The Veterans Health Administration (VHA) is the largest integrated health care system in the United States. ProjectFlow is a flexible web-based workflow management tool specifically created to facilitate conduct of our clinical research initiatives within the VHA. The application was developed using the Grails web framework and allows researchers to create custom workflows using Business Process Model and Notation. RESULTS: As of January 2021 ProjectFlow has facilitated management of study recruitment enrollment randomization and drug orders for over 10 000 patients for the DCP clinical trial. It has also helped us evaluate over 3800 patients for recruitment and enroll over 370 of them into RePOP for use in data sharing partnerships and predictive analytics aimed at optimizing cancer treatment in the VHA. DISCUSSION: The POC-R study design embeds research processes within day-to-day clinical care and leverages longitudinal electronic health record (EHR) data for study recruitment monitoring and outcome reporting. Software that allows flexibility in study workflow creation and integrates with enterprise EHR systems is critical to the success of POC-R. CONCLUSIONS: We developed a flexible web-based informatics solution called ProjectFlow that supports custom research workflow configuration and has ability to integrate data from existing VHA EHR systems.","","","2021","10.1093/jamiaopen/ooab074","","","pubmed-34485848.pdf","pubmed-34485848"
"Spase 2.0: a standard data model for space physics","King, T. And Thieman, J. And Roberts, D.a.","Earth Science Informatics","","Spase-for space physics archive search and extract-is a group with a charter to promote collaboration and sharing of data for the space plasma physics community. A major activity is the definition of the spase data model which defines the metadata necessary to describe resources in the broader heliophysics data environment. The spase data model is primarily a controlled vocabulary with hierarchical relationships and with the ability to form associations between described resources. It is the result of many years of effort by an international collaboration (see http://www. spase-group. org) to unify and improve on existing space and solar physics data models. The genesis of the spase group can be traced to 1998 when a small group of individuals saw a need for a data model. Today spase has a large international participation from many of the major space research organizations. The design of the data model is based on a set of principles derived from evaluation of the existing heliophysics data environment. The development guidelines for the data model are consistent with iso-2788 (expanded in ansi/niso z39.19) and the administration for the data model is comparable to that described in the iso standards iso-11179 and iso-20943. Since the release of version 1.0 of the data model in 2005, the model has undergone a series of evolutions. Spase released version 2.0 of its data model in april 2009. This version presents a significant change from the previous release. It includes the capability to describe a wider range of data products and to describe expert annotations which can be associated with a resource. Additional improvements include an enhanced capability to describe resource associations and a more unified approach to describing data products. Version 2.0 of the spase data model provides a solid foundation for continued integration of worldwide research activities and the open sharing of data. © 2010 springer-verlag.","","","2010","10.1007/s12145-010-0053-4","","","scopus-2-s2.0-77955677172.pdf","scopus-2-s2.0-77955677172"
"Reproducibility of small-format laboratory cells","Luc, P.-M. And Buchwald, F. And Kowal, J.","Energies","","For the research and development of new battery materials, achieving high reproducibility of the performance parameters in the laboratory test cells is of great importance. Therefore, in the present work, three typical small-format lithium-ion cells (coin cell, swagelok cell and el-cell ecc-pat-core) were tested and compared with regard to the reproducibility of their performance parameters (discharge capacity, internal resistance and coulombic efficiency). A design of experiments (doe) with the two factors separator type and anode–cathode ratio (n/p ratio) was carried out for all cells. For the quality features discharge capacity, internal resistance and coulombic efficiency, the coefficient of variation is used as a measure of reproducibility. The statistical evaluation shows that in 83% of all cases, higher reproducibility is achieved when the freudenberg separator is used instead of the celgard separator. In addition, higher reproducibility is achieved in 78% of all cases if the anode and cathode are the same size. A general statement about which test cell format has the highest reproducibility cannot be made. Rather, the format selection should be adapted to the requirements. The examined factors seem to have an influence on the reproducibility but are more insignificant than other still-unknown factors. Since the production of small-format test cells is a manual process, the competence of the assembler seems to prevail. In order to mitigate the influence of as many unknown variables as possible, assembly instructions are proposed for each cell type. © 2022 by the authors.","","","2022","10.3390/en15197333","","","scopus-2-s2.0-85139907516.pdf","scopus-2-s2.0-85139907516"
"Yarn and ply twist - testex twist statistics","Freitag, R. And Lupica, B.","Melliand Textilberichte","","As the uster statistics have for a long time been providing a valuable aid in assessing yarn quality but without considering twist, it was decided to evaluate the test results of the swiss textile testing institute, zurich, and to establish twist statistics with these data. These testex twist statistics are based on the evaluation of the spread of the twist within a yarn batch, represented by the factor cv% twist t/m. They are reproducible and contain data about yarns and plied yarns produced in different countries and serve to provide a comparison for monitoring the regularity of twist.","","","1992","","","","scopus-2-s2.0-0026805668.pdf","scopus-2-s2.0-0026805668"
"Sharing confidential and sensitive data","Boruch, Robert F And Reiss, Albert Jr. And Garner, Joel And Larntz, Kinley And Freels, Sally","","","Deals with issues, options, and policy in sharing data that bear on criminal and civil justice research / main vehicle for illustration is the spouse assault replication program, a set of randomized field experiments . . . to understand how to reduce domestic violence topical coverage includes: (1) the spouse assault replication program and data sharing;  (2) privacy of research participants;  (3) data sharing, privacy, and the proprietary interests of researchers;  (4) data sharing and the interests of police departments and other agencies;  [and] (5) data sharing issues and their priorities in longitudinal surveys versus experiments (psycinfo database record (c) 2022 apa, all rights reserved)","","","1991","10.4135/9781483325620.n4","","","psychinfo-1991-97523-003.pdf","psychinfo-1991-97523-003"
"Construction of college students’ physical health data sharing system based on django framework","Li, H.-C. And Shen, S.-F.","Journal Of Sensors","","In view of the current situation of college students’ physical health affected by the learning environment and living environment, which leads to the low level of students’ physical health and the lack of understanding of students’ physical health, this paper puts forward the construction of college students’ physical health data sharing system based on django framework. By analyzing the feasibility of constructing the data sharing system of college students’ physical health, this paper constructs the organizational framework of the data sharing system of college students’ physical health and constructs the data sharing system of college students’ physical health according to the implementation process of the data sharing system of college students’ physical health management service. Through the student’s physical health test on education intervention and exercise intervention, it is concluded that college students’ physical health data sharing system based on the django framework can cultivate students’ interest in sports and improve their athletic ability and physical fitness. Copyright © 2021 hui-chao li and shun-fa shen. This is an open access article distributed under the creative commons attribution license, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.","","","2021","10.1155/2021/3859351","","","scopus-2-s2.0-85123024237.pdf","scopus-2-s2.0-85123024237"
"Introduction of medical literature monitoring of adverse drug reaction in european union and its enlightenment for china","Yuhan, Y. And Tianyi, Y. And Li, Z. And Haibo, S. And Honghui, W. And Yalu, W. And Jukai, H. And Rumeng, T. And Xiaohui, Y.","Drug Evaluation Research","","Medical literature monitoring (mlm) refers to screening, processing and reporting active substances that are monitored in a certain range to improve the efficiency and quality of adr reports, which closely connect adr management and reporting process. European medicines agency (ema) is one of the first institutions to monitor the medical literature. After continuous exploration and reform, a standardized scheme and mature mlm evaluation system has been established. With the introduction and analysis of mlm system, combining with the current situation and existing problems of it in china, this paper puts forward policy suggestions in several aspects, such as formulating supporting technical guidelines to standardize monitoring details of each step, formulating mlm quality management standards to strengthen the supervising process, and promoting the disclosure of adverse reaction information to improve data sharing mechanism. © 2021 tianjin press of chinese herbal medicines. All rights reserved.","","","2021","10.7501/j.issn.1674-6376.2021.06.005","","","scopus-2-s2.0-85132352236.pdf","scopus-2-s2.0-85132352236"
"An alleviation of cloud congestion analysis of fluid retrial user on matrix analytic method in iot-based application","Nandhini, K. And Vidhya, V.","Journal Of The Nigerian Society Of Physical Sciences","","Cloud computing (cc) and internet of things (iot) are upgrowing human intervention to enhance the daily lifestyle. Currently, the heavy loaded traffc congestion is a very big challenge over iot-based applications. For that purpose, the researchers approached various ways to overcome the congestion mechanism in recent years. Even though, they have futile to acheive the best resource storage accessing capacity expectation other than, cloud computing. Data sharing is a key impediment of cloud computing as well as internet of things. These are the constituent that give rise to the combination of the iot and cloud computing paradigm as iot cloud. Though, preserving the missed data during the execution time is a key factor to indulge the retrial queueing theory (rqt), who is facing issue upon accessing cloud service provider (csp) enter into virtual pool to preserve the data for reuse. The paper imposes markov fluid analysis with matrix analytic method (mam) allows the data as continuous length of data rather than individual data to avoid the congestion. The virtual orbit queue follow constant retrial rate discipline, that is, head of the orbital users makes attempt to occupy the server are assumed to be independent and identically distributed (i.i.d). Steady-state expression presented to study the behaviour of congestion. An illustrative analysis is produced to gain deep perception into the system model. © 2023 the author(s).","","","2023","10.46481/jnsps.2023.1148","","","scopus-2-s2.0-85164413194.pdf","scopus-2-s2.0-85164413194"
"Efficient identity-based public integrity auditing of shared data in cloud storage with user privacy preserving","Yan, H. And Gui, W.","Ieee Access","","Provable data possession (pdp) model provides an efficient means for people to audit the integrity of data stored in cloud storage. When sensitive data is shared among multiple users based on cloud storage, it is critical to preserve the anonymity of the data uploader against the auditor. That is, the auditor should not get data uploader's identity through the data audition. To address this problem, many pdp schemes with user identity privacy-persevering are proposed. However, most proposed schemes are designed based on pki technique which suffers from big burden of certificate management. Moreover, data auditors in most proposed schemes bear heavy computation cost which results to the lower efficiency of the scheme. To overcome the shortcomings, we present a novel identity-based pdp protocol to audit efficiently the integrity of group shared data with uploader's privacy-preserving. Due to the inherent structural advantage of identity-based crypto mechanism, our pdp scheme is able to avoid the problem of certificate management. Different from previous works, our scheme ensures the relationship of the data and the data uploader in the phase of proof generation not the phase of integrity audition. Therefore, the data auditor does not know the relationship at all as well as the extract data uploader of the challenged data. At the same time, establishing the relationship by cloud server in proof generation step can reduce the computational cost of data auditor greatly. Furthermore, the relationship of data uploader and challenged data in the proof is randomized so as to strength the security of the scheme. All these efforts are made in our scheme to efficiently realize the anonymity protection of the data uploader. We give the detailed security proof of our scheme under the computational diffie-hellman assumption. Many experiments are performed to evaluate the efficiency of our scheme, the results show that our new scheme is efficient and feasible. © 2013 ieee.","","","2021","10.1109/access.2021.3066497","","","scopus-2-s2.0-85103166908.pdf","scopus-2-s2.0-85103166908"
"A qualitative study of big data and the opioid epidemic: recommendations for data governance","Evans, E.a. And Delorme, E. And Cyr, K. And Goldstein, D.m.","Bmc Medical Ethics","","Background: the opioid epidemic has enabled rapid and unsurpassed use of big data on people with opioid use disorder to design initiatives to battle the public health crisis, generally without adequate input from impacted communities. Efforts informed by big data are saving lives, yielding significant benefits. Uses of big data may also undermine public trust in government and cause other unintended harms. Objectives: we aimed to identify concerns and recommendations regarding how to use big data on opioid use in ethical ways. Methods: we conducted focus groups and interviews in 2019 with 39 big data stakeholders (gatekeepers, researchers, patient advocates) who had interest in or knowledge of the public health data warehouse maintained by the massachusetts department of public health. Results: concerns regarding big data on opioid use are rooted in potential privacy infringements due to linkage of previously distinct data systems, increased profiling and surveillance capabilities, limitless lifespan, and lack of explicit informed consent. Also problematic is the inability of affected groups to control how big data are used, the potential of big data to increase stigmatization and discrimination of those affected despite data anonymization, and uses that ignore or perpetuate biases. Participants support big data processes that protect and respect patients and society, ensure justice, and foster patient and public trust in public institutions. Recommendations for ethical big data governance offer ways to narrow the big data divide (e.g., prioritize health equity, set off-limits topics/methods, recognize blind spots), enact shared data governance (e.g., establish community advisory boards), cultivate public trust and earn social license for big data uses (e.g., institute safeguards and other stewardship responsibilities, engage the public, communicate the greater good), and refocus ethical approaches. Conclusions: using big data to address the opioid epidemic poses ethical concerns which, if unaddressed, may undermine its benefits. Findings can inform guidelines on how to conduct ethical big data governance and in ways that protect and respect patients and society, ensure justice, and foster patient and public trust in public institutions. © 2020, the author(s).","","","2020","10.1186/s12910-020-00544-9","","","scopus-2-s2.0-85093843316.pdf","scopus-2-s2.0-85093843316"
"Creating an academic research organization to efficiently design conduct coordinate and analyze clinical trials: The Center for Clinical Trials & Data Coordination","Abebe K. Z., Althouse A. D., Comer D., Holleran K., Koerbel G., Kojtek J., Weiss J., Spillane S.","Contemporary Clinical Trials Communications","","When properly executed the randomized controlled trial is one of the best vehicles for assessing the effectiveness of one or more interventions. However numerous challenges may emerge in the areas of study startup recruitment data quality cost and reporting of results. The use of well-run coordinating centers could help prevent these issues but very little exists in the literature describing their creation or the guiding principles behind their inception. The Center for Clinical Trials & Data Coordination (CCDC) was established in 2015 through institutional funds with the intent of 1) providing relevant expertise in clinical trial design conduct coordination and analysis; 2) advancing the careers of clinical investigators and CCDC-affiliated faculty; and 3) obtaining large data coordinating center (DCC) grants. We describe the organizational structure of the CCDC as well as the homegrown clinical trial management system integrating nine crucial elements: electronic data capture eligibility and randomization drug and external data tracking safety reporting outcome adjudication data and safety monitoring statistical analysis and reporting data sharing and regulatory compliance. Lastly we share numerous lessons that can be taken from our experience. Specifically we focus on 1) funding for DCCs 2) the importance of DCCs to clinical researchers 3) the expertise of DCC personnel and 4) continually striving to improve. In conclusion the CCDC strives to provide high-quality support for the design conduct coordination and analyses of clinical trials and we hope this paper will serve as a blueprint for future clinical trialists involved in DCCs.","","","2019","10.1016/j.conctc.2019.100488","","","pubmed-31763494.pdf","pubmed-31763494"
"Weaving transnational feminist(s) methodologies: (re)examining early childhood linguistic diversity teacher training and research","Saavedra, C.m. And Chakravarthi, S. And Lower, J.k.","Journal Of Early Childhood Research","","The purpose of this article is to engender a space where a variety of critical feminist(s) lenses are interwoven to problematize current discursive practices in linguistic diversity training and to (re)imagine nueavas posibilidades for linguistic diversity research/training for pre-kindergarten teachers. Transnational feminists' projects have the potential to illuminate and connect larger global issues with, and that pertain to, local and specific radical projects by incorporating critical reflexive methodological tools. In this article we propose to a) discuss language as a monocultural construction that limits conceptions of language and learning for younger human beings;  b) examine the discursive practices of teachers of students who are english as second/third language learners;  c) discuss the discourse of sharing codes of power;  and finally d) scrutinize interventionist assumptions of educational research. © the author(s), 2009.","","","2009","10.1177/1476718x09336973","","","scopus-2-s2.0-70350532145.pdf","scopus-2-s2.0-70350532145"
"Evaluation of utilization of satellite remote sensing data for drought monitoring","Won, J. And Son, Y.-S. And Lee, S. And Kang, L. And Kim, S.","Korean Journal Of Remote Sensing","","As the frequency of drought increases due to climate change, it is very important to have a monitoring system that can accurately determine the situation of widespread drought. However, while ground-based meteorological data has limitations in identifying all the complex droughts in korea, satellite remote sensing data can be effectively used to identify the spatial characteristics of drought in a wide range of regions and to detect drought. This study attempted to analyze the possibility of using remote sensing data for drought identification in south korea. In order to monitor various aspects of drought, remote sensing and ground observation data of precipitation and potential evapotranspiration, which are major variables affecting drought, were collected. The evaluation of the applicability of remote sensing data was conducted focusing on the comparison with the observation data. First, to evaluate the applicability and accuracy of remote sensing data, the correlations with observation data were analyzed, and drought indices of various aspects were calculated using precipitation and potential evapotranspiration for meteorological drought monitoring. Then, to evaluate the drought monitoring ability of remote sensing data, the drought reproducibility of the past was confirmed using the drought index. Finally, a highresolution drought map using remote sensing data was prepared to evaluate the possibility of using remote sensing data for actual drought in south korea. Through the application of remote sensing data, it was judged that it would be possible to identify and understand various drought conditions occurring in all regions of south korea, including unmeasured watersheds in the future. © 2021 korean society of remote sensing. All rights reserved.","","","2021","10.7780/kjrs.2021.37.6.2.3","","","scopus-2-s2.0-85127119467.pdf","scopus-2-s2.0-85127119467"
"Verifiable searchable encryption with aggregate keys for data sharing system","Liu, Z. And Li, T. And Li, P. And Jia, C. And Li, J.","Future Generation Computer Systems","","In a secure data sharing system, the keyword search over encrypted files is a basic need of a user with appropriate privileges. Although the traditional searchable encryption technique can provide the privacy protection, two critical issues still should be considered. Firstly, a cloud server may be selfish in order to save its computing resources, and thus returns only a fragment of results to reply a search query. Moreover, since different keys are always used for different document sets, making a search query over massive sets and verifying the search results are both impractical for a user with massive keys. In this paper, we propose a scheme named “verifiable searchable encryption with aggregate keys”. In the scheme, a data owner need only distribute a single aggregate key to other users to selectively share both search and verification privileges over his/her document sets. After obtaining such a key, a user can use it not only for generating a single trapdoor as a keyword search query, but for verifying whether the server just conducts a part of computing for the search request. Then, we give an advance scheme under the multi-owner setting. Finally, our analysis and performance evaluation demonstrate that the scheme are both practical and secure. © 2017","","","2018","10.1016/j.future.2017.02.024","","","scopus-2-s2.0-85015916813.pdf","scopus-2-s2.0-85015916813"
"Data as social capital and the gift culture in research","Klump, J.","Data Science Journal","","The value of making research data available is broadly accepted. Policies concerning the open access to research data try to implement new norms calling for researchers to make their data more openly available. These policies either appeal to the common good or focus on publication and citation as an incentive to bring about a cultural change in how researchers share their data with their peers. But when we compare the total number of publications in the fields of science, technology and medicine with the number data publications from the same time period, the number of openly available datasets is rather small. This indicates that current policies on data sharing are not effective in changing behaviours and bringing about the wanted cultural change. By looking at research communities that are more open to data sharing we can study the social patterns that influence data sharing and point us to possible points for intervention and change. © 2017 the author(s).","","","2017","10.5334/dsj-2017-014","","","scopus-2-s2.0-85024364121.pdf","scopus-2-s2.0-85024364121"
"Data security sharing and storage based on a consortium blockchain in a vehicular ad-hoc network","Zhang, X. And Chen, X.","Ieee Access","","A vehicular ad-hoc network (vanet) can improve the flow of traffic to facilitate intelligent transportation and to provide convenient information services, where the goal is to provide self-organizing data transmission capabilities for vehicles on the road to enable applications, such as assisted vehicle driving and safety warnings. Vanets are affected by issues such as identity validity and message reliability when vehicle nodes share data with other nodes. The method used to allow the vehicle nodes to upload sensor data to a trusted center for storage is susceptible to security risks, such as malicious tampering and data leakage. To address these security challenges, we propose a data security sharing and storage system based on the consortium blockchain (dsscb). This digital signature technique based on the nature of bilinear pairing for elliptic curves is used to ensure the reliability and integrity when transmitting data to a node. The emerging consortium blockchain technology provides a decentralized, secure, and reliable database, which is maintained by the entire network node. In dsscb, smart contracts are used to limit the triggering conditions for preselected nodes when transmitting and storing data and for allocating data coins to vehicles that participate in the contribution of data. The security analysis and performance evaluations demonstrated that our dsscb solution is more secure and reliable in terms of data sharing and storage. Compared with the traditional blockchain system, the time required to confirm the data block was reduced by nearly six times and the transmission efficiency was improved by 83.33%. © 2019 ieee.","","","2019","10.1109/access.2018.2890736","","","scopus-2-s2.0-85065896246.pdf","scopus-2-s2.0-85065896246"
"Online Data Articles: The Language of Intersubjective Stance in a Rhetorical Hybrid","Pérez-Llantada Carmen","Written Communication","","The data article is a digital genre that has emerged in response to new exigencies namely to make data more transparent and research processes more trustable and reproducible. Following White's framework of intersubjective stance this article draws upon statistical tools and collocational and discourse analyses to examine the linguistic resources deployed by authors to respond to both exigencies. The results show a high presence of dialogically contractive resources (above all passive constructions and only in one data article section inanimate subjects) by which authors do not fully engage with dialogic alternatives (heteroglossic disengagement). Dialogically expansive resources (anticipatory ""it""-subjects and ""we""-pronouns) are extremely rare corroborating that the authors' stance is neither monoglossic (undialogized) nor heteroglossically engaged. Further the discourse functions and ensuing pragmatic effects of the prevailing intersubjective stance resources significantly different between and among the data article sections including their associated abstracts reveal the construal of very distinct dialogic spaces for writer-reader interaction within this article type. Such intra-generic variation may be explained by the social (and rhetorical) action that the genre fulfills namely to describe and highlight the value of the research data.","","","2022","10.1177/07410883221087486","","","eric-ej1347408.pdf","eric-ej1347408"
"Trust in teams: a taxonomy of perceived trustworthiness factors and risk-taking behaviors in face-to-face and virtual teams","Breuer, C. And Hüffmeier, J. And Hibben, F. And Hertel, G.","Human Relations","","Do we really need personal meetings to develop trust within teams? Which factors impact trust emergence within face-to-face and virtual teams? How do high-trust teams interact compared with teams with low team trust? Trust is seen as an important predictor of behavior in teams. However, the psychological mechanisms linking team trust to both its antecedents and its behavioral consequences are not well understood. The present study introduces a new taxonomy of team trust mechanisms by integrating results from a qualitative interview study with prior theoretical and empirical research on team trust. We conducted exploratory interviews based on the critical incident technique with 55 professionals who had substantial teamwork experience. Altogether, 776 behavioral items were collected stemming from 127 team events that were perceived as critical for the emergence of trust in teams. A content analysis revealed five main categories of perceived trustworthiness factors in teams as antecedents of team trust and three main categories of risk-taking behaviors as behavioral consequences in teams. The findings contribute to a better understanding of team trust emergence and related behaviors in teams. Future research should validate the derived taxonomy of team trust with quantitative data. © the author(s) 2019.","","","2020","10.1177/0018726718818721","","","scopus-2-s2.0-85061925869.pdf","scopus-2-s2.0-85061925869"
"Information and consumer credit in central and eastern europe","Rona-Tas, A. And Guseva, A.","Journal Of Comparative Economics","","We present a critique of behavioral economics, the dominant approach to reforming the regulation of retail credit, and propose a new approach to managing uncertainty in consumer lending. This new approach draws on a different model of decision-making, distributed cognition, to improve contract origination, and it takes inspiration from the legal theory of finance with respect to contract enforcement. We develop a set of stylized arguments about information-related problems and their possible solutions in central and east european markets, discussing separately measures to protect lenders, such as requiring collateral, collection, screening and data sharing, and those to protect consumers, including disclosure, data privacy and regulation of automated individual decisions. Then we move to enforcement and using the empirical case of the hungarian foreign exchange mortgage crisis we illustrate the importance of elasticity of law. © 2013 association for comparative economic studies.","","","2013","10.1016/j.jce.2013.03.012","","","scopus-2-s2.0-84892431308.pdf","scopus-2-s2.0-84892431308"
"In-memory staging and data-centric task placement for coupled scientific simulation workflows","Zhang, F. And Jin, T. And Sun, Q. And Romanus, M. And Bui, H. And Klasky, S. And Parashar, M.","Concurrency And Computation: Practice And Experience","","Coupled scientific simulation workflows are composed of heterogeneous component applications that simulate different aspects of the physical phenomena being modeled and that interact and exchange significant volumes of data at runtime. As the data volumes and generation rates keep growing, the traditional disk i/o–based data movement approach becomes cost prohibitive, and workflow requires more scalable and efficient approach to support the data movement. Moreover, the cost of moving large volume of data over system interconnection network becomes dominating and significantly impacts the workflow execution time. Minimize the amount of network data movement and localize data transfers are critical for reducing such cost. To achieve this, workflow task placement should exploit data locality to the extent possible and move computation closer to data. In this paper, we investigate applying in-memory data staging and data-centric task placement to reduce the data movement cost in large-scale coupled simulation workflows. Specifically, we present a distributed data sharing and task execution framework that (1) co-locates in-memory data staging on application compute nodes to store data that needs to be shared or exchanged and (2) uses data-centric task placement to map computations onto processor cores that a large portion of the data exchanges can be performed using the intra-node shared memory. We also present the implementation of the framework and its experimental evaluation on titan cray xk7 petascale supercomputer. Copyright © 2017 john wiley & sons, ltd.","","","2017","10.1002/cpe.4147","","","scopus-2-s2.0-85018571086.pdf","scopus-2-s2.0-85018571086"
"How undergraduate students learn atmospheric science: characterizing the current body of research","Mcneal, P. And Flynn, W. And Kirkpatrick, C. And Kopacz, D. And Ladue, D. And Maudlin, L.c.","Bulletin Of The American Meteorological Society","","Educators can enrich their teaching with best practices, share resources, and contribute to the growing atmospheric science education research community by reading and participating in the scholarship of teaching and learning in atmospheric science. This body of scholarship has grown, particularly over the past 15 years, and is now a sizable literature base that documents and exemplifies numerous teaching innovations in undergraduate atmospheric science education. This literature base benefits the entire atmospheric science community because graduates of atmospheric science programs are better prepared to enter the workforce. This literature base has not yet been examined, however, to see how well the evidence supports education practices in the atmospheric science education literature. In this study, we characterized that evidence and show that the majority of papers we reviewed share education innovations with anecdotal or correlational evidence of effectiveness. While providing useful practitioner knowledge and preliminary evidence of the effectiveness of numerous innovative teaching practices, opportunities exist for increasing readers' confidence that the innovations caused the learning gains. Additional studies would also help move conclusions toward generalizability across academic institutions and student populations. We make recommendations for advancing atmospheric science education research and encourage atmospheric science educators to actively use the growing body of education literature as well as contribute to advancing atmospheric science education research. © 2022 american meteorological society for information regarding reuse of this content and general copyright information, consult the ams copyright policy.","","","2022","10.1175/bams-d-20-0023.1","","","scopus-2-s2.0-85123516601.pdf","scopus-2-s2.0-85123516601"
"A guide for the cultivation of onion under controlled environment conditions","Macknight, R. And Khosa, J. And Lee, R. And Joshi, S. And Shaw, M. And Mccallum, J.","Hortscience","","Bulb onion (allium cepa l.) is a challenging subject for experimental studies because of its slow growth, genetic heterogeneity, and sensitivity to environmental and biotic stresses. Sharing of common germplasm and controlled propagation practices has underpinned research on model plants, such as arabidopsis and tomato, but not in onion. To encourage wider evaluation of onion for physiological and molecular studies in controlled environments, we describe the growing practices we have developed over two decades of research on adaptive and nutrient assimilation traits. Key aspects covered include choice of germplasm, propagation media, nutrition, and environmental control. Adopting common onion genetics and cultivation techniques across laboratories will allow researchers to answer deeper research questions and increase the reproducibility of the research. © 2019, american society for horticultural science. All rights reserved.","","","2018","10.21273/hortsci13515-18","","","scopus-2-s2.0-85059337791.pdf","scopus-2-s2.0-85059337791"
"Developing an extension of the right statement for clinical practice guidelines on acupuncture: right for acupuncture – a protocol","Tang, C. And Lu, L. And Duan, Y. And Zhang, Y. And Zhou, Q. And Luo, X. And Chen, Y. And Xu, N.","European Journal Of Integrative Medicine","","Introduction: the 2017 international standard for reporting items for practice guideline in healthcare (right) published reporting guidelines to enhance transparency and clarity in the process of developing clinical practice guidelines (cpgs). As there are some barriers in the applicability of these guidelines to acupuncture due to its specificity in terms of manipulations, locations and channels compared to other health care interventions, we aim to develop a specific reporting checklist for the development of cpgs on acupuncture. Methods: the study design will refer to the methodology recommended by the enhancing the quality and transparency of health research (equator) network and will be modified as appropriate. We will conduct a literature review and establish an international multidisciplinary team, including a development group, a delphi panellists group and an advisory group. We will run three rounds of modified delphi surveys, face-to-face consensus meetings, consultations with advisors, pilot tests of the draft list of reports and promotion of the checklist. We plan to update regularly. Results: the study is ongoing and there are no complete results. We will update it in time if there is any result. Conclusions: this work will be relevant to a broad range of cpgs addressing questions of reporting standards on cpgs on acupuncture, which will have the following advantages: 1) to provide regulations for guideline developers;  2) to obtain more precise and clear guidelines for readers and clinical practitioners;  and 3) to evaluate reporting quality of cpgs on acupuncture and improve transparency of research reports for editors and reviewers. © 2019","","","2019","10.1016/j.eujim.2019.04.002","","","scopus-2-s2.0-85066927237.pdf","scopus-2-s2.0-85066927237"
"Building a community of practice for engaging pharmacy students to learn in a collaborative research environment","Elshaer, A. And Calabrese, G. And Casanova, D. And Huet, I.","Currents In Pharmacy Teaching And Learning","","Background conventional research project supervision is not always compatible with current challenges facing higher education, such as students’ diverse backgrounds, increasing demands, and multidisciplinary research interests. Additionally, research students may experience isolation at different stages of research. To help students coping with these challenges, approaches such as progress reports, departmental presentations, and co-supervision have been introduced. Community of practices (cop) are alternative approaches that if successfully adopted may improve the students’ learning experience. These communities were developed as knowledge-based social structures between groups of people sharing goals and interests. Considering the importance of cops as a strategy to engage students and researchers to work collaboratively;  this study aims to investigate the impact of a formal cop on the students’ learning experience at different levels of study. Methods six months qualitative evaluation study. Participants included two phd, five master, and two undergraduate students (level 6) from the school of pharmacy at a british university. Participants were asked to interact face-to-face and online using diigo as a virtual learning environment to share and discuss problems and questions related to their on-going work, including the finding of research articles. Qualitative data were gathered from two focus groups and an in-depth thematic analysis of the online interactions was carried out. Results all participants at undergraduate and master level felt that their learning experience was boosted by the sharing of knowledge and resources. Closer look at the data reveal that most of the production and interactions were made by the largest group (i.e., master students). This group believed that diigo helped them in building up their research knowledge by sharing information online, which also enriched their face-to-face (f2f) discussions. In contrast, phd students felt that the cop did not significantly help them to develop their knowledge. Conclusions the development of a small cop helps students to gain knowledge and improves their research productivity by sharing experience and skills. The cop was effectively supported by diigo, which provided a good platform for data’ sharing and a culture of collaboration. The cop had an overall positive impact on the students’ learning experience and research. © 2016 elsevier inc.","","","2016","10.1016/j.cptl.2016.05.001","","","scopus-2-s2.0-84978790772.pdf","scopus-2-s2.0-84978790772"
"Increasing capacity for innovation in bureaucratic primary care organizations: a whole system participatory action research project","Thomas, P. And Mcdonnell, J. And Mcculloch, J. And While, A. And Bosanquet, N. And Ferlie, E.","Annals Of Family Medicine","","Purpose: we wanted to identify what organizational features support innovation in primary care groups (pcgs). Methods: our study used a whole system participatory action research model. Four research teams provided complementary insights. Four case study pcgs were analyzed. Two had an intervention to help local facilitators reflect on their work. Data included 70 key informant interviews, observations of clinical governance interventions and committee meetings, analysis of written materials, surveys and telephone interviews of london primary care organizations, interviews with 20 nurses, and interviews with 6 finance directors. A broad range of stakeholders reviewed data at annual conferences and formed conclusions about trustworthy principles. Sequential research phases were refocused in the light of these conclusions and in response to the changing political context. Results: five features were associated with increased organizational capacity for innovation: (1) clear structures and a vision for corporate and clinical governance;  (2) multiple opportunities for people to reflect and learn at all levels of the organization, and connections between these ""learning spaces"";  (3) both clinicians and managers in leadership roles that encourage participation;  (4) the right timing for an initiative and its adaptation to the local context;  and (5) external facilitation that provides opportunities for people to make sense of their experiences. Low morale was commonly attributed to 3 features: (1) overwhelming pace of reform, (2) inadequate staff experience and supportive infrastructure, and (3) financial deficits. Conclusions: these features together may support innovation in other primary care bureaucracies. The research methodology enabled people from different backgrounds to make sense of diverse research insights.","","","2005","10.1370/afm.309","","","scopus-2-s2.0-20344374527.pdf","scopus-2-s2.0-20344374527"
"Island dwellings at 60° north: new evidence for crannogs in iron age shetland","Stratigos, M.j.","Oxford Journal Of Archaeology","","Re-evaluation of recorded sites and new field survey have identified 30 island dwellings in shetland which are argued to be part of the wider scottish iron age crannog building tradition. Four were subject to field survey above and below water and found to be at least partly artificial. The morphology, distribution and chronology of shetland’s artificial islands are discussed and compared to the rest of scotland emphasizing their parallels. The results support the recent move towards considering islet duns and brochs as crannogs. These newly identified sites in shetland underline the ubiquity of the crannog building tradition in scotland. Through discussion of the morphology, distribution and chronology of crannogs in shetland and the rest of scotland, it is argued that artificial island dwelling is a widely shared cultural practice and an underlying principle of scottish iron age settlement. © 2021 the authors. Oxford journal of archaeology published by john wiley & sons ltd.","","","2021","10.1111/ojoa.12225","","","scopus-2-s2.0-85109319825.pdf","scopus-2-s2.0-85109319825"
"Fostering communities of practice among community college science faculty","Eddy, P.l. And Hao, Y. And Iverson, E. And Macdonald, R.h.","Community College Review","","Objective/research question: this paper reports on data collected in a multi-year national science foundation grant project involving a professional development (pd) model built to support community college faculty as change agents (cas). The research question was: how do disciplinary communities of practice (cop) emerge among community college faculty working in teams? Methods: this research employed a mixed-method design. Data collection included interviews, focus-group sessions, reflective journals, observations, end-of-workshop evaluations, survey data with the 23 geoscience faculty ca, and data from a national survey. Data analysis used the principles of cop. Results: when compared to other community college geoscience faculty nationally, the participants in our study reported greater levels of behaviors characteristic of cop. The cop emerged due to network building and resource sharing within the pd. The findings highlight the significance of structured pd on the development of robust disciplinary cop. The initial orientation of cas, existing institutional structures, and cultures of community colleges influenced the cop. Putting lessons learned into practice, sharing outcomes, and leading regional pd for others contributed to strengthening of the cop. Conclusions/contributions: intentional pd catalyzed the emergence of strong cop among the community college geoscience faculty participants. The opportunities to connect with disciplinary colleagues teaching in community colleges who shared an interest in supporting student success and improving teaching practices and the opportunity to share lessons learned contributed to the cop. Structured interactions, critical reflection, and leading colleagues in pd supported developing, maintaining, and growing the cop. © the author(s) 2022.","","","2022","10.1177/00915521221111474","","","scopus-2-s2.0-85135160938.pdf","scopus-2-s2.0-85135160938"
"A guideline for reporting performance metrics with electrochemical capacitors: from electrode materials to full devices","Balducci, A. And Belanger, D. And Brousse, T. And Long, J.w. And Sugimoto, W.","Journal Of The Electrochemical Society","","Over the past decade, interest in electrochemical capacitors as an energy-storage technology has increased enormously, spurring the development and evaluation of a large number of new materials and device configurations. This perspective article aims to propose guidelines by which new materials and devices should be evaluated, and how resulting data should be reported with respect to critical metrics such as capacitance, energy and power. © the author(s) 2017. Published by ecs. All rights reserved.","","","2017","10.1149/2.0851707jes","","","scopus-2-s2.0-85019985604.pdf","scopus-2-s2.0-85019985604"
"Balancing privacy and flexibility of cloud-based personal health records sharing system","Zhang, Y. And Guo, F. And Susilo, W. And Yang, G.","Ieee Transactions On Cloud Computing","","The internet of things and cloud services have been widely adopted in many applications, and personal health records (phr) can provide tailored medical care. The phr data is usually stored on cloud servers for sharing. Weighted attribute-based encryption (abe) is a practical and flexible technique to protect phr data. Under a weighted abe policy, the data user's attributes will be 'scored', if and only if the score reaches the threshold value, he/she can access the data. However, while this approach offers a flexible access policy, the data owners have difficulty controlling their privacy, especially sharing phr data in collaborative e-health systems. This article aims to find a balance between privacy and flexibility and proposes an and-weighted abe scheme in cloud-based personal health records sharing systems. The proposed scheme can meet both privacy and flexibility. Only when the data user satisfies the scored-based policy and is in the specified organization(s), can the data user access the phr data. Besides, we give the security proof and the performance evaluation of the proposed scheme. The security proof and performance analysis show that the proposed scheme can efficiently and securely share phr data in cloud service. © 2013 ieee.","","","2023","10.1109/tcc.2022.3208168","","","scopus-2-s2.0-85139404644.pdf","scopus-2-s2.0-85139404644"
"A semi-automatic metadata extraction model and method for video-based e-learning contents","Pal, S. And Pramanik, P.k.d. And Majumdar, T. And Choudhury, P.","Education And Information Technologies","","Video-based learning offers a learner a self-paced, lucid, memorizable, and a flexible way of learning. The availability of abundant educational video materials on the web has certainly abetted an individual’s learning means. But the lack of necessary information about the videos makes it difficult for the learner to search and select the exact video as per his/her requirement and suitability in terms of the learner’s learning capability and the material’s relevancy, difficulty level, etc. Educational video recommendation systems also suffer from a similar problem. Extracting the required metadata, by different means, from the learning videos is a plausible solution. Despite the credible research efforts on video metadata extraction, the problem of educational video metadata extraction has been overlooked. This paper proposes a comprehensive approach to extract educational metadata from a learning video. A semiautomatic mechanism that includes manual and computational approaches is introduced for metadata extraction and to evaluate the values of these metadata. Along with identifying a set of specific metadata attributes from ieee lom, few additional attributes are suggested which are imperative to assess the suitability of a video-based learning object in terms of the personalized preference and suitability of a learner. The test results are validated by comparing with the manually extracted metadata by experts, on the same videos. The outcome establishes the promising effectiveness of the approach. © 2019, springer science+business media, llc, part of springer nature.","","","2019","10.1007/s10639-019-09926-y","","","scopus-2-s2.0-85072101024.pdf","scopus-2-s2.0-85072101024"
"No study is ever perfectly flawless: exploring research limitations in theses and dissertations of iranian higher education institutes","Shahriari, P. And Rasuli, B.","Iranian Journal Of Information Processing And Management","","Reporting research limitations in academic literature is very important for understanding and utilizing research findings. This study aims to assess the extent to which and how research limitations acknowledged in persian theses and dissertations (tds). 664 persian tds published from 2009 to 2018 selected randomly through cluster sampling technique from irandoc’s tds database and the last chapter of 578 tds analyzed. Through content analysis method, reported limitations analyzed and coded. Around 17% of tds (99/578) addressed at least one limitation in their reports, while 64% of them had a specific heading for this section. The trend of reporting limitations has increased during current decades and students in humanities areas have paid more attentions to this section. Overall, 22 key limitations have been repeated 268 times in the tds and “sampling bias” is more frequent with 29 repeats among them. Addressing research limitations in tds is very incomplete. Transparent addressing of research limitations may help readers and stakeholders understand and apply research findings more effectively. The role of educators and academic institutes to inform newcomer researchers about the importance and structure of research limitations section in their reports is vital. This is the first study to examine research limitations in persian academic literature and can inspire more research on this subject. The stakeholders of research, such as faculties, students, universities, research centers, readers/beneficiaries, and sponsors will be informed about key research limitations in tds. © 2020 iranian research institute for scientific information and documentation. All rights reserved.","","","2020","","","","scopus-2-s2.0-85095785293.pdf","scopus-2-s2.0-85095785293"
"A common data model for harmonization in the nordic pregnancy drug safety studies (norpress)","Cohen, J.m. And Cesta, C.e. And Kjerpeseth, L. And Leinonen, M.k. And Hálfdánarson, Ó. And Karlstad, Ø. And Karlsson, P. And Andersen, M. And Furu, K. And Hjellvik, V.","Norsk Epidemiologi","","It is necessary to carry out large observational studies to generate robust evidence about the safety of drugs used during pregnancy. In the nordic countries, nationwide population-based health registers that document all births and dispensed prescribed drugs are valuable resources for such studies. A common data model (cdm) is a data harmonization and structuring tool that enables a unified and streamlined analytic approach for studies including data from multiple countries or databases. We describe a cdm developed for the nordic pregnancy drug safety studies (norpress), including details on data sources and structure of the data tables. We also provide an overview of the advantages and disadvantages of the approach (e.g. sharing of data analysis programs versus extra initial work to create cdm datasets from raw data). © 2021, norwegian epidemiological society. All rights reserved.","","","2021","10.5324/nje.v29i1-2.4053","","","scopus-2-s2.0-85113346235.pdf","scopus-2-s2.0-85113346235"
"Risk of bias for randomized controlled trials in Journal of Clinical Monitoring and Computing","Sung J. M., Kim J. Y., Kwon B. S., Kim K. N.","Journal of Clinical Monitoring & Computing","","PURPOSE: Well-designed randomized controlled trials (RCTs) are considered to represent a high level of evidence and influence medical decision-making in evidence-based medicine. When biases occur in study design processing and reporting of RCTs however it is difficult to interpret results and judge the impact of interventions. Accordingly we evaluate the quality of RCT reporting published in the Journal of Clinical Monitoring and Computing (JCMC) using three assessment tools.\\\\\\\\rMETHODS: Reporting quality of RCTs published in the JCMC was evaluated through December 31 2020 using Jadad and van Tulder scales and the Cochrane Collaboration's risk of bias tool (CCRBT). Stepwise regression analysis was performed to identify factors associated with reporting quality.\\\\\\\\rRESULTS: Database searches confirmed 132 RCTs in 1507 original articles. The numbers of RCTs meeting criteria for high reporting quality were 97 (73.5%) using the Jadad scale 99 (75.0%) using the van Tulder scale and 19 (14.4%) with the CCRBT. Jadad scores [median score (interquartile range) = 3.0 (2.0-5.0) coefficients (95% CI) = 0.08 (0.04 0.11) p < 0.001] van Tulder scores [median score (interquartile range) = 7.0 (5.0-8.75) coefficients (95% CI) = 0.15 (0.11 0.20) p < 0.001] and CCRBT assessment [coefficients (95% CI) = 0.04 (0.02 0.06) p < 0.001] increased significantly with publication year. The median score (interquartile range) of the last 5 years were 4.0 (3.0-5.0) in Jadad scores and 8.0 (6.0-9.0) in van Tulder scores. Only 33.3% and 37.1% of articles described detailed blinding and allocation methods respectively.\\\\\\\\rCONCLUSIONS: Reporting quality increased over time with consistently high reporting quality in recently published JCMC RCTs. Copyright © 2022. The Author(s) under exclusive licence to Springer Nature B.V.","","","2023","10.1007/s10877-022-00864-8","","","medline-35471715.pdf","medline-35471715"
"Suppression of mir-150-5p attenuates the anti-inflammatory effect of glucocorticoids in mice with ulcerative colitis","Wang Y., Qin J., Dong L., He C., Zhang D., Wu X., Li T., Yue H., Mu L., Wang Q., Yang J.","Molecular Immunology","","Glucocorticoids have been widely used in the treatment of ulcerative colitis but not all patients benefit from this therapy due to hormone resistance. Mir-150-5p has been reported to enhance the efficacy of glucocorticoids and low serum mir-150-5p expression has been linked to glucocorticoid resistance in ulcerative colitis patients. The aim of this study was to elucidate the mechanisms of mir-150-5p regulation on glucocorticoid resistance. An ulcerative colitis mouse model was used to evaluate changes in ulcerative colitis symptoms inflammatory factors and glucocorticoid resistance-related gene expression. The results showed that mir-150-5p suppression with antagomirs did not significantly interfere with or enhance the induction of ulcerative colitis symptoms by dextran sulfate sodium but it did attenuate the inflammation inhibitory effect of dexamethasone by abnormally regulating the expression of IL-17a IL-10 IL-2 and IL-6 levels and myeloperoxidase activity. Mir-150-5p inhibition also induced a glucocorticoid-resistant gene expression profile in colon tissues of ulcerative colitis mice with upregulation of p-ERK p-JNK and HSP90 and downregulation of p-GRa FKBP4 and HDAC2 expression. Our results indicate that mir-150-5p suppression attenuates the anti-inflammatory effect of glucocorticoids and may function as a driver element in ulcerative colitis glucocorticoid resistance. AVAILABILITY OF DATA AND MATERIALS: All data and figures analyzed in this study are available from the corresponding author by request. Copyright © 2023 The Authors. Published by Elsevier Ltd.. All rights reserved.","","","2023","10.1016/j.molimm.2023.09.002","","","medline-37729776.pdf","medline-37729776"
"Geospatial data infrastructure for natural disaster management","Shorbi, M. And Wan Hussin, W.m.a.","Advances In Environmental Biology","","One of the priorities for organizations related to natural disaster management is the facilitation and improvement in decision-making on coping with natural disasters. This requires real-time (up-to-date) and accurate geospatial data. The main goal of this study is to describe the conduction of organizational evaluation of natural disaster management in the community of yazd, as seen from technical and non-technical viewpoint, which is the primary requirement for the expansionof geospatial data infrastructure (gdi) for natural disaster management. The evaluation has been made with regard to geospatial data and sharing environment, leading towards an organizational behavior model which takes into account the social and technical characteristics of natural disaster management in the community. Regarding data which is spatial in nature, the current status with regard to access including availability, accessibility, applicability and usability were evaluated. The results of organizational evaluation showed that natural disaster management in the community of yazd need to have a clear policy for partnership in data production and sharing which is a matter of social, technical, technological, institutional and economic challenge. These challenges were the principal obstacle in the expansion of gdi, described in this study, for natural disaster management in yazd. © 2014 aensi publisher all rights reserved.","","","2014","","","","scopus-2-s2.0-85063817281.pdf","scopus-2-s2.0-85063817281"
"Data-driven thread execution on heterogeneous processors","Arandi, S. And Matheou, G. And Kyriacou, C. And Evripidou, P.","International Journal Of Parallel Programming","","In this paper we report our experience in implementing and evaluating the data-driven multithreading (ddm) model on a heterogeneous multi-core processor. Ddm is a non-blocking multithreading model that decouples the synchronization from the computation portions of a program, allowing them to execute asynchronously in a dataflow manner. Thread dependencies are determined by the compiler/programmer while thread scheduling is done dynamically at runtime based on data availability. The target processor for this implementation is the cell processor. We call this implementation the data-driven multithreading virtual machine for the cell processor (ddm-vm c). Thread scheduling is handled in software by the power processing element core of the cell while the synergistic processing element cores execute the program threads. Ddm-vm c virtualizes the parallel resources of the cell, handles the heterogeneity of the cores, manages the cell memory hierarchy efficiently and supports distributed execution across a cluster of cell nodes. Ddm-vm c has been implemented on a single cell processor with six computation cores, as well as, on a four cell processor cluster with 24 computation cores. We present an in-depth performance analysis of ddm-vm c, using a suite of standard computational benchmarks. The evaluation shows that ddm-vm c scales well and tolerates scheduling overheads, memory and communication latencies effectively. Furthermore, ddm-vm c compares favorably with other platforms targeting the cell processor, such as, the cellss and sequoia. © 2017, springer science+business media new york.","","","2018","10.1007/s10766-016-0486-6","","","scopus-2-s2.0-85011880092.pdf","scopus-2-s2.0-85011880092"
"Non-coding rna detection methods combined to improve usability, reproducibility and precision","Raasch, P. And Schmitz, U. And Patenge, N. And Vera, J. And Kreikemeyer, B. And Wolkenhauer, O.","Bmc Bioinformatics","","Background: non-coding rnas gain more attention as their diverse roles in many cellular processes are discovered. At the same time, the need for efficient computational prediction of ncrnas increases with the pace of sequencing technology. Existing tools are based on various approaches and techniques, but none of them provides a reliable ncrna detector yet. Consequently, a natural approach is to combine existing tools. Due to a lack of standard input and output formats combination and comparison of existing tools is difficult. Also, for genomic scans they often need to be incorporated in detection workflows using custom scripts, which decreases transparency and reproducibility.results: we developed a java-based framework to integrate existing tools and methods for ncrna detection. This framework enables users to construct transparent detection workflows and to combine and compare different methods efficiently. We demonstrate the effectiveness of combining detection methods in case studies with the small genomes of escherichia coli, listeria monocytogenes and streptococcus pyogenes. With the combined method, we gained 10% to 20% precision for sensitivities from 30% to 80%. Further, we investigated streptococcus pyogenes for novel ncrnas. Using multiple methods--integrated by our framework--we determined four highly probable candidates. We verified all four candidates experimentally using rt-pcr.conclusions: we have created an extensible framework for practical, transparent and reproducible combination and comparison of ncrna detection methods. We have proven the effectiveness of this approach in tests and by guiding experiments to find new ncrnas. The software is freely available under the gnu general public license (gpl), version 3 at http://www.sbi.uni-rostock.de/moses along with source code, screen shots, examples and tutorial material. © 2010 raasch et al;  licensee biomed central ltd.","","","2010","10.1186/1471-2105-11-491","","","scopus-2-s2.0-77957129677.pdf","scopus-2-s2.0-77957129677"
"Distinct antigen delivery systems induce dendritic cells' divergent transcriptional response: new insights from a comparative and reproducible computational analysis","Costa V. And Righelli D. And Russo F. And De Berardinis P. And Angelini C. And D'apice L.","Int. J. Mol. Sci","","Vaccination is the most successful and cost-effective method to prevent infectious diseases. However, many vaccine antigens have poor in vivo immunogenic potential and need adjuvants to enhance immune response. The application of systems biology to immunity and vaccinology has yielded crucial insights about how vaccines and adjuvants work. We have previously characterized two safe and powerful delivery systems derived from non-pathogenic prokaryotic organisms: e2 and fd filamentous bacteriophage systems. They elicit an in vivo immune response inducing cd8+ t-cell responses, even in absence of adjuvants or stimuli for dendritic cells' maturation. Nonetheless, a systematic and comparative analysis of the complex gene expression network underlying such activation is missing. Therefore, we compared the transcriptomes of ex vivo isolated bone marrow-derived dendritic cells exposed to these antigen delivery systems. Significant differences emerged, especially for genes involved in innate immunity, co-stimulation, and cytokine production. Results indicate that e2 drives polarization toward the th2 phenotype, mainly mediated by irf4, ccl17, and ccr4 over-expression. Conversely, fd-scalphadec-205 triggers th1 t cells' polarization through the induction of il12b, il12rb, il6, and other molecules involved in its signal transduction. The data analysis was performed using rnaseqgui, hence, addressing the increasing need of transparency and reproducibility of computational analysis.copyright © 2017 by the authors. Licensee mdpi, basel, switzerland.","","","2017","10.3390/ijms18030494","","","embase-614569174.pdf","embase-614569174"
"Corporate social responsibility reporting of international oil companies in nigeria: an historical materialism analysis","Odera, O. And James, K. And Scott, A. And Gow, J.","International Journal Of Ethics And Systems","","Purpose: this study aims to identify factors influencing corporate social responsibility reporting (csrr) practices of international oil companies (iocs) in nigeria. It aims at distinguishing csrr levels by examining both the quantity and quality of reporting. Design/methodology/approach: the paper analyses annual reports through content analysis. Csrr extent and type are measured by the number of sentences. Csrr are further classified into three subcategories according to whether they are negative, neutral or positive reports and then their proportions compared through descriptive analysis. Findings: for the extent and quality of csrr, community was the most reported category. The majority of the total csrr in the iocs is positive with little evidence of negative news. None of the iocs in the sample reported on the environment in their annual reports. Research limitations/implications: the measurement of csrr focuses only on annual reports, without consideration of other reporting media such as standalone reports and corporate websites. Csrr are assumed to be voluntary for the companies and they may choose not to report any information in annual reports, as there are no regulations or reporting guidelines in nigeria to be followed. Practical implications: the results reveal the absence of environmental reporting in the csrr of iocs in nigeria suggests that they are less concerned with meeting local demands for accountability. The study recommends the need for regulatory intervention on the part of the nigerian government. Social implications: the findings of study indicate that predominant existence of positive csrr news among all the iocs suggests there’s an attempt to encourage stakeholders and the public to believe that they are conscious of society and the environment. Originality/value: the main contribution of this study lies in identifying the factors that have led to diversity and uniqueness in csrr in iocs. As such, this study seeks to contribute to the development of understanding multiple factors that could give rise to changing patterns of csrr. © 2020, emerald publishing limited.","","","2020","10.1108/ijoes-04-2019-0071","","","scopus-2-s2.0-85078248457.pdf","scopus-2-s2.0-85078248457"
"Novel Analysis of Immune Cells from Nasal Microbiopsy Demonstrates Reliable Reproducible Data for Immune Populations and Superior Cytokine Detection Compared to Nasal Wash","Jochems S. P., Piddock K., Rylance J., Adler H., Carniel B. F., Collins A., Gritzfeld J. F., Hancock C., Hill H., Reine J., Seddon A., Solorzano C., Sunny S., Trimble A., Wright A. D., Zaidi S., Gordon S. B., Ferreira D. M.","PLoS ONE [Electronic Resource]","","The morbidity and mortality related to respiratory tract diseases is enormous with hundreds of millions of individuals afflicted and four million people dying each year. Understanding the immunological processes in the mucosa that govern outcome following pathogenic encounter could lead to novel therapies. There is a need to study responses at mucosal surfaces in humans for two reasons: (i) Immunological findings in mice or other animals often fail to translate to humans. (ii) Compartmentalization of the immune system dictates a need to study sites where pathogens reside. In this manuscript we describe two novel non-invasive nasal mucosal microsampling techniques and their use for measuring immunological parameters: 1) using nasal curettes to collect cells from the inferior turbinate and; 2) absorptive matrices to collect nasal lining fluid. Both techniques were well tolerated and yielded reproducible and robust data. We demonstrated differences in immune populations and activation state in nasal mucosa compared to blood as well as compared to nasopharyngeal lumen in healthy adults. We also found superior cytokine detection with absorptive matrices compared to nasal wash. These techniques are promising new tools that will facilitate studies of the immunological signatures underlying susceptibility and resistance to respiratory infections.","","","2017","10.1371/journal.pone.0169805","","","medline-28107457.pdf","medline-28107457"
"A benchmarking protocol for pansharpening: dataset, preprocessing, and quality assessment","Vivone, G. And Dalla Mura, M. And Garzelli, A. And Pacifici, F.","Ieee Journal Of Selected Topics In Applied Earth Observations And Remote Sensing","","Comparative evaluation is a requirement for reproducible science and objective assessment of new algorithms. Reproducible research in the field of pansharpening of very high resolution images is a difficult task due to the lack of openly available reference datasets and protocols. The contribution of this article is threefold, and it defines a benchmarking framework to evaluate pansharpening algorithms. First, it establishes a reference dataset, named pairmax, composed of 14 panchromatic and multispectral image pairs collected over heterogeneous landscapes by different satellites. Second, it standardizes various image preprocessing steps, such as filtering, upsampling, and band coregistration, by providing a reference implementation. Third, it details the quality assessment protocols for reproducible algorithm evaluation. © 2008-2012 ieee.","","","2021","10.1109/jstars.2021.3086877","","","scopus-2-s2.0-85111069980.pdf","scopus-2-s2.0-85111069980"
"A web-based pilot study of inter-pathologist reproducibility using the ISHLT 2004 working formulation for biopsy diagnosis of cardiac allograft rejection: the European experience","Angelini A., Andersen C. B., Bartoloni G., Black F., Bishop P., Doran H., Fedrigo M., Fries J. W., Goddard M., Goebel H., Neil D., Leone O., Marzullo A., Ortmann M., Paraf F., Rotman S., Turhan N., Bruneval P., Frigo A. C., Grigoletto F., Gasparetto A., Mencarelli R., Thiene G., Burke M.","Journal of Heart & Lung Transplantation","","BACKGROUND: The aim of this study was to assess at the European level and using digital technology the inter-pathologist reproducibility of the ISHLT 2004 system and to compare it with the 1990 system We also assessed the reproducibility of the morphologic criteria for diagnosis of antibody-mediated rejection detailed in the 2004 grading system.\\\\\\\\rMETHODS: The hematoxylin-eosin-stained sections of 20 sets of endomyocardial biopsies were pre-selected and graded by two pathologists (A.A. and M.B.) and digitized using a telepathology digital pathology system (Aperio ImageScope System; for details refer to http://aperio.com/). Their diagnoses were considered the index diagnoses which covered all grades of acute cellular rejection (ACR) early ischemic lesions Quilty lesions late ischemic lesions and (in the 2005 system) antibody-mediated rejection (AMR). Eighteen pathologists from 16 heart transplant centers in 7 European countries participated in the study. Inter-observer reproducibility was assessed using Fleiss's kappa and Krippendorff's alpha statistics.\\\\\\\\rRESULTS: The combined kappa value of all grades diagnosed by all 18 pathologists was 0.31 for the 1990 grading system and 0.39 for the 2005 grading system with alpha statistics at 0.57 and 0.55 respectively. Kappa values by grade for 1990/2005 respectively were: 0 = 0.52/0.51; 1A/1R = 0.24/0.36; 1B = 0.15; 2 = 0.13; 3A/2R = 0.29/0.29; 3B/3R = 0.13/0.23; and 4 = 0.18. For the 2 cases of AMR 6 of 18 pathologists correctly suspected AMR on the hematoxylin-eosin slides whereas in each of 17 of the 18 AMR-negative cases a small percentage of pathologists (range 5% to 33%) overinterpreted the findings as suggestive for AMR.\\\\\\\\rCONCLUSIONS: Reproducibility studies of cardiac biopsies by pathologists in different centers at the international level were feasible using digitized slides rather than conventional histology glass slides. There was a small improvement in interobserver agreement between pathologists of different European centers when moving from the 1990 ISHLT classification to the ""new"" 2005 ISHLT classification. Morphologic suspicion of AMR in the 2004 system on hematoxylin-eosin-stained slides only was poor highlighting the need for better standardization of morphologic criteria for AMR. Ongoing educational programs are needed to ensure standardization of diagnosis of both acute cellular and antibody-mediated rejection. Copyright 2011 International Society for Heart and Lung Transplantation. All rights reserved.","","","2011","10.1016/j.healun.2011.05.011","","","medline-21816625.pdf","medline-21816625"
"Data access and regime competition: a case study of car data sharing in china","Martens, B. And Zhao, B.","Big Data And Society","","We study the case of a chinese industrial policy, implemented in shanghai that makes it mandatory for car manufacturers to share electro-mechanical performance and real time navigation data from their entire fleet of electric and hybrid vehicles with local and central government authorities. This policy seeks to prevent fraud in state subsidies, reduce emissions, assess the performance of new energy vehicles and strengthen the competitiveness of chinese manufacturers of these vehicles. We argue that economies of scope in data aggregation may provide traditional market failure arguments in favor of government intervention and mandatory data pooling. Our paper illustrates how data access regimes could be used for economic competition. The eu and china pursue similar data sharing and pooling policy goals that hinge on economies of scope in data aggregation. However, they follow very different political processes to achieve these goals. © the author(s) 2021.","","","2021","10.1177/20539517211046374","","","scopus-2-s2.0-85117939137.pdf","scopus-2-s2.0-85117939137"
"What drives developing countries to select free open source software for national spatial data infrastructure?","Choi, J. And Hwang, M.-H. And Kim, H. And Ahn, J.","Spatial Information Research","","While there are many discussions that free open source software for geospatial could provide a cost-effective solution for the construction and management of national spatial data infrastructures, little empirical evidence exists of what actually leads developing countries to adopt such software. To fill this void in the literature, this study fulfills an empirical assessment of the main factors that affect the adoption of free open source geospatial software in developing countries. In particular, the study uses the analytical hierarchy process method to evaluate how the functional, economic and public values of free open source geospatial software contribute to the software selection of developing countries. A survey for 10 respondents from 9 asian and latin american countries revealed that economic values were the most important, functional values the second most, and public values the least important factor. The survey also showed that the adoption rate of free open source geospatial software would be similar for different purposes of national spatial data infrastructures such as data management, sharing, utilization, and servicing. The results of the study mean that developing countries, to date, want to introduce free open source software for national spatial data infrastructures mainly from economic motivations. This finding was possible since the study took a comprehensive approach to the adoption of free open source geospatial software, in contrast to other studies that often focused only on software engineering aspects. © 2016, korean spatial information society.","","","2016","10.1007/s41324-016-0051-9","","","scopus-2-s2.0-85080857846.pdf","scopus-2-s2.0-85080857846"
"Challenges in bridging the gap between protein structure prediction and functional interpretation","Varadi M., Tsenkov M., Velankar S.","Proteins","","The rapid evolution of protein structure prediction tools has significantly broadened access to protein structural data. Although predicted structure models have the potential to accelerate and impact fundamental and translational research significantly it is essential to note that they are not validated and cannot be considered the ground truth. Thus challenges persist particularly in capturing protein dynamics predicting multi-chain structures interpreting protein function and assessing model quality. Interdisciplinary collaborations are crucial to overcoming these obstacles. Databases like the AlphaFold Protein Structure Database the ESM Metagenomic Atlas and initiatives like the 3D-Beacons Network provide FAIR access to these data enabling their interpretation and application across a broader scientific community. Whilst substantial advancements have been made in protein structure prediction further progress is required to address the remaining challenges. Developing training materials nurturing collaborations and ensuring open data sharing will be paramount in this pursuit. The continued evolution of these tools and methodologies will deepen our understanding of protein function and accelerate disease pathogenesis and drug development discoveries. Copyright © 2023 The Authors. Proteins: Structure Function and Bioinformatics published by Wiley Periodicals LLC.","","","2023","10.1002/prot.26614","","","medline-37850517.pdf","medline-37850517"
"Development of a data collection and management system in West Africa: challenges and sustainability","Shaffer J. G., Doumbia S. O., Ndiaye D., Diarra A., Gomis J. F., Nwakanma D., Abubakar I., Ahmad A., Affara M., Lukowski M., Valim C., Welty J. C., Mather F. J., Keating J., Krogstad D. J.","Infectious Diseases of Poverty","","BackgroundDeveloping and sustaining a data collection and management system (DCMS) is difficult in malaria-endemic countries because of limitations in internet bandwidth computer resources and numbers of trained personnel. The premise of this paper is that development of a DCMS in West Africa was a critically important outcome of the West African International Centers of Excellence for Malaria Research. The purposes of this paper are to make that information available to other investigators and to encourage the linkage of DCMSs to international research and Ministry of Health data systems and repositories.MethodsWe designed and implemented a DCMS to link study sites in Mali Senegal and The Gambia. This system was based on case report forms for epidemiologic entomologic clinical and laboratory aspects of plasmodial infection and malarial disease for a longitudinal cohort study and included on-site training for Principal Investigators and Data Managers. Based on this experience we propose guidelines for the design and sustainability of DCMSs in environments with limited resources and personnel.ResultsFrom 2012 to 2017 we performed biannual thick smear surveys for plasmodial infection mosquito collections for anopheline biting rates and sporozoite rates and year-round passive case detection for malarial disease in four longitudinal cohorts with 7708 individuals and 918 households in Senegal The Gambia and Mali. Major challenges included the development of uniform definitions and reporting assessment of data entry error rates unstable and limited internet access and software and technology maintenance. Strengths included entomologic collections linked to longitudinal cohort studies on-site data centres and a cloud-based data repository.ConclusionsAt a time when research on diseases of poverty in low and middle-income countries is a global priority the resources available to ensure accurate data collection and the electronic availability of those data remain severely limited. Based on our experience we suggest the development of a regional DCMS. This approach is more economical than separate data centres and has the potential to improve data quality by encouraging shared case definitions data validation strategies and analytic approaches including the molecular analysis of treatment successes and failures.","","","2018","10.1186/s40249-018-0494-4","","","medline-30541626.pdf","medline-30541626"
"A design-based approach to support and nurture open educational practices","Karunanayaka, S.p. And Naidu, S.","Asian Association Of Open Universities Journal","","Purpose: a critical attribute of open educational practices (oep) is the pursuit of open scholarship which comprises the release of educational resources under an open licence scheme that permits no-cost access, use, reuse, adaptation, retention and redistribution to others. The degree of openness in relation to this attribute will depend on the context and culture of the place and the people in it. When left to chance, the adoption and practice of open scholarship by educators is at best sketchy. For optimum impact, a design-based approach is essential. A central focus of such an approach will need to target educators’ belief systems and practices about their scholarship. Any such work will involve researchers collaborating with practitioners in real-life settings to improve educational practices through iterative analysis, design, development and implementation. The purpose of this paper is to report on how the development and use of such a design-based approach, implemented by the open university of sri lanka, impacted the adoption and uptake of open scholarship among teachers in the sri lankan school system in terms of changes in their use of instructional resources, pedagogical thinking and pedagogical practices. Design/methodology/approach: the study adopted a design-based research (dbr) approach (reeves, 2006), which involved researchers collaboratively working with practitioners in real-life settings to improve their educational practices along three aspects – instructional resource use, pedagogical perspectives and pedagogical practices. Based on the four stages of the dbr approach – analysis, solution, testing and refinement, and reflection, a professional development intervention programme was designed and implemented to support teachers on the integration of open educational resources (oer) and adoption of oep in their teaching-learning process. Data collected throughout the process using multiple strategies such as questionnaire surveys, concept mapping, lesson plans, focus group interviews, self-reflections and “stories”, were analyzed using both qualitative and quantitative methods. Findings: by the end of the intervention, significant changes were observed in teachers’ use of instructional resources, their pedagogical thinking and pedagogical practices. While resource usage has shifted from no or low usage of oer to reuse, revise, remix and creation of oer, the pedagogical thinking and practices of teachers moved from a content-centric and individualized patterns to more constructivist, context centric and collaborative ways. The diffusion of oep was prominent along two dimensions – enhancements in the individual practices in innovative oer use as well as collaborative practices of sharing of resources, knowledge and good practices. Practical implications: the systematic and flexible methodology adopted based on the dbr approach via a framework designed as a contextualized, process oriented and a self-reflective enquiry has been very useful to support changes in oep among practitioners over time. Originality/value: this iterative process allowed the researchers to function as “designers”, while investigating real-life issues in collaboration with the practitioners through reflective enquiry to further refine innovative practices towards oep. This provides valuable insights for improved design solutions for future interventions in similar contexts. © 2017, shironica p. Karunanayaka and som naidu.","","","2017","10.1108/aaouj-01-2017-0010","","","scopus-2-s2.0-85030319512.pdf","scopus-2-s2.0-85030319512"
"Information technology principles for management reporting and research. [Review] [51 refs]","Gillam M., Rothenhaus T., Smith V., Kanhouwa M.","","","Information technology holds the promise to enhance the ability of individuals and organizations to manage emergency departments improve data sharing and reporting and facilitate research. The Society for Academic Emergency Medicine (SAEM) Consensus Committee has identified nine principles to outline a path of optimal features and designs for current and future information technology systems. The principles roughly summarized include the following: utilize open database standards with clear data dictionaries provide administrative access to necessary data appoint and recognize individuals with emergency department informatics expertise allow automated alert and proper identification for enrollment of cases into research provide visual and statistical tools and training to analyze data embed automated configurable alarm functionality for clinical and nonclinical systems allow multiexport standard and format configurable reporting strategically acquire mission-critical equipment that is networked and capable of automated feedback regarding functional status and location and dedicate resources toward informatics research and development. The SAEM Consensus Committee concludes that the diligent application of these principles will enhance emergency department management reporting and research and ultimately improve the quality of delivered health care. [References: 51]","","","2004","","","","unknown-1537.pdf","unknown-1537"
"Source: sea observations utility for reprocessing, calibration and evaluation","Oliveri, P. And Simoncelli, S. And Di Pietro, P. And Fratianni, C. And Mattia, G. And Delrosso, D. And Guarnieri, A.","Frontiers In Marine Science","","Source utility for reprocessing, calibration, and evaluation is a software designed for web applications that permits to calibrate and validate ocean models within a selected spatial domain using in-situ observations. Nowadays, in-situ observations can be freely accessed online through several marine data portals together with the metadata information about the data provenance and its quality. Metadata information and compliance with modern data standards allow the user to select and filter the data according to the level of quality required for the intended use and application. However, the available data sets might still contain anomalous data, bad data flagged as good, due to several reasons, i.e., the general quality assurance procedures adopted by the data infrastructure, the selected data type, the timeliness of delivery, etc. In order to provide accurate model skill scores, the source utility performs a secondary quality check, or re-processing, of observations through gross check tests and a recursive statistical quality control. This first and basic source implementation uses near real time moored temperature and salinity observations distributed by the copernicus marine environment and monitoring service (cmems) and two model products from istituto nazionale di geofisica e vulcanologia (ingv), the first an analysis and the second a reanalysis, distributed during cmems phase i for the mediterranean sea. The source tool is freely available to the scientific community through the zenodo open access repository, consistent with the open science principles and for that it has been designed to be relocatable, to manage multiple model outputs, and different data types. Moreover, its observation reprocessing module provides the possibility to characterize temperature and salinity variability at each mooring site and continuously monitor the ocean state. Highest quality mooring time series at 90 sites and the corresponding model values have been obtained and used to compute model skill scores. The source output also includes mooring climatologies, trends, probability density functions and averages at different time scales. Model skill scores and site statistics can be used to visually inspect both model and sensor performance in near real time at the single site or at the basin scale. The source utility uptake allows the interested user to adapt it to its specific purpose or domain, including for example additional parameters and statistics for early warning applications. Copyright © 2022 oliveri, simoncelli, di pietro, fratianni, mattia, delrosso and guarnieri.","","","2022","10.3389/fmars.2021.750387","","","scopus-2-s2.0-85124548832.pdf","scopus-2-s2.0-85124548832"
"The effectiveness of champions in implementing innovations in health care: a systematic review","Santos W. J., Graham I. D., Lalonde M., Demery Varin, Squires J. E.","Implementation Science Communications","","BACKGROUND: Champions have been documented in the literature as an important strategy for implementation yet their effectiveness has not been well synthesized in the health care literature. The aim of this systematic review was to determine whether champions tested in isolation from other implementation strategies are effective at improving innovation use or outcomes in health care. METHODS: The JBI systematic review method guided this study. A peer-reviewed search strategy was applied to eight electronic databases to identify relevant articles. We included all published articles and unpublished theses and dissertations that used a quantitative study design to evaluate the effectiveness of champions in implementing innovations within health care settings. Two researchers independently completed study selection data extraction and quality appraisal. We used content analysis and vote counting to synthesize our data. RESULTS: After screening 7566 records titles and abstracts and 2090 full text articles we included 35 studies in our review. Most of the studies (71.4%) operationalized the champion strategy by the presence or absence of a champion. In a subset of seven studies five studies found associations between exposure to champions and increased use of best practices programs or technological innovations at an organizational level. In other subsets the evidence pertaining to use of champions and innovation use by patients or providers or at improving outcomes was either mixed or scarce. CONCLUSIONS: We identified a small body of literature reporting an association between use of champions and increased instrumental use of innovations by organizations. However more research is needed to determine causal relationship between champions and innovation use and outcomes. Even though there are no reported adverse effects in using champions opportunity costs may be associated with their use. Until more evidence becomes available about the effectiveness of champions at increasing innovation use and outcomes the decision to deploy champions should consider the needs and resources of the organization and include an evaluation plan. To further our understanding of champions' effectiveness future studies should (1) use experimental study designs in conjunction with process evaluations (2) describe champions and their activities and (3) rigorously evaluate the effectiveness of champions' activities. REGISTRATION: Open Science Framework ( https://osf.io/ba3d2 ). Registered on November 15 2020.","","","2022","10.1186/s43058-022-00315-0","","","pubmed-35869516.pdf","pubmed-35869516"
"Factors conditioning insufficient scientific productivity in nursing professionals from quemado de güines, 2018","Abrahantes, T.n.r. And González, Y.g. And Abrahantes, A.r. And Escobar, D.h.","Revista Cubana De Educacion Medica Superior","","Introduction: accurate and transparent communication of research has become an increasingly relevant issue of university knowledge. Objective: to determine the factors that condition the insufficient scientific productivity in the nursing professionals from quemado de güines municipality in the first trimester of 2018. Methods: a descriptive cross-sectional study was carried out during the first trimester of 2018, with a population of 34 nursing professionals with the status of masters in science, specialists and graduates incorporated into the research potential. We worked with a sample of 28, selected through non-probabilistic sampling, out of which 17 were graduates and/or specialists and 11 were masters. A data collection form was applied as an instrument to each nurse during the exchanges. In the statistical analysis, the percentage and the mean were used as summary measures in the information processing. Results: the greatest interest in researching and/or publishing was expressed through the fact of maintaining their scientific degree and having a satisfactory yearly evaluation of the worker. Lack of time, selflessness and the pressure of care were the individual limiting reasons, both for research and publication. More than 80% had no knowledge of the existing ways or mechanisms for sending a work to be published and more than 89% recognized their lack of ability to use the scientific method, as well as their inaccuracies to acquire and analyze the data.conclusions: it was noted that factors depending on nurses were present in the low scientific productivity of nursing professionals in the institution. © 2019, editorial ciencias medicas. All rights reserved.","","","2019","","","","scopus-2-s2.0-85075806848.pdf","scopus-2-s2.0-85075806848"
"Managing knowledge work: specialization and collaboration of engineering problem-solving","Kim, J. And King, J.","Journal Of Knowledge Management","","In this paper we investigate the exploratory nature of knowledge creation and sharing practice in high-technology industry. Traditional approaches in knowledge management focus on the storage and retrieval of knowledge, but they do not address the tacit dimension of knowledge process. Using data gathered at three semiconductor manufacturers in japan and korea, we examine the social processes by which expert teams cooperate across team boundaries despite differing points of view resulting from increasing team specialization. Three engineering teams are studied: design, process, and process integration. They are responsible for trouble management in the production of dynamic random access memory (dram), a class of integrated circuit semiconductor devices. Trouble management is the handling of problems that require exploratory, yet routine problem-solving practice. The findings suggest that the crucial challenge in achieving effective control of the knowledge management process rests not in strategies for collecting and classifying relevant problem/solution information. Rather, it is in the management of “problematization”, a political process involving the articulation behaviors of different teams of engineers. © 2004, emerald group publishing limited","","","2004","10.1108/13673270410529109","","","scopus-2-s2.0-84993012305.pdf","scopus-2-s2.0-84993012305"
"Federated Learning for Electronic Health Records","Dang T. K., Lan X., Weng J. S., Feng M. L.","Acm Transactions on Intelligent Systems and Technology","","In data-driven medical research multi-center studies have long been preferred over single-center ones due to a single institute sometimes not having enough data to obtain sufficient statistical power for certain hypothesis testings as well as predictive and subgroup studies. The wide adoption of electronic health records (EHRs) has made multi-institutional collaboration much more feasible. However concerns over infrastructures regulations privacy and data standardization present a challenge to data sharing across healthcare institutions. Federated Learning (FL) which allows multiple sites to collaboratively train a global model without directly sharing data has become a promising paradigm to break the data isolation. In this study we surveyed existing works on FL applications in EHRs and evaluated the performance of current state-of-the-art FL algorithms on two EHR machine learning tasks of significant clinical importance on a real world multi-center EHR dataset.","","","2022","10.1145/3514500","","","wos-000877952100004.pdf","wos-000877952100004"
"Evaluation of anti-inflammatory nutraceuticals in lps-induced mouse neuroinflammation model: an update","Catorce, M.n. And Gevorkian, G.","Current Neuropharmacology","","It is known that peripheral infections, accompanied by inflammation, represent signifi cant risk factors for the development of neurological disorders by modifying brain development or affecting normal brain aging. The acute effects of systemic inflammation on progressive and persistent brain damage and cognitive impairment are well documented. Anti-inflammatory therapies may have beneficial effects on the brain, and the protective properties of a wide range of synthetic and natural compounds have been extensively explored in recent years. In our previous review, we provided an extensive analysis of one of the most important and widely-used animal models of peripherally induced neuroinflammation and neurodegeneration-lipopolysaccharide (lps)-treated mice. We addressed the data reproducibility in published research and summarized basic features and data on the therapeutic potential of various natural products, nutraceuticals, with known antiinflammatory effects, for reducing neuroinflammation in this model. Here, recent data on the suitability of the lps-induced murine neuroinflammation model for preclinical assessment of a large number of nutraceuticals belonging to different groups of natural products such as flavonoids, terpenes, non-flavonoid polyphenols, glycosides, heterocyclic compounds, organic acids, organosulfur compounds and xanthophylls, are summarized. Also, the proposed mechanisms of action of these molecules are discussed. © 2020 bentham science publishers.","","","2020","10.2174/1570159x18666200114125628","","","scopus-2-s2.0-85088496232.pdf","scopus-2-s2.0-85088496232"
"The development and evaluation of a PDA-based method for public health surveillance data collection in developing countries","Yu P., de Courten M., Pan E., Galea G., Pryor J.","International Journal of Medical Informatics","","BACKGROUND AND PURPOSE: EpiData and Epi Info are often used together by public health agencies around the world particularly in developing countries to meet their needs of low-cost public health data management; however the current open source data management technology lacks a mobile component to meet the needs of mobile public health data collectors. The goal of this project is to explore the opportunity of filling this gap through developing and trial of a personal digital assistant (PDA) based data collection/entry system. It evaluated whether such a system could increase efficiency and reduce data transcription errors for public surveillance data collection in developing countries represented by Fiji.\\\\\\\\rMETHODS: A generic PDA-based data collection software eSTEPS was developed. The software and the data collected using it directly interfaces with EpiData. A field trial was conducted to test the viability of public health surveillance data collection using eSTEPS. The design was a randomised controlled trial with cross-over design. 120 participants recruited from the Fiji School of Medicine were randomly assigned to be interviewed by one of six interviewers in one of the two ways: (1) paper-based survey followed by PDA survey and (2) PDA survey followed by paper-based survey. Data quality was measured by error rates (logical range errors/inconsistencies skip errors missing values date or time field errors and incorrect data type). Work flow and cost were evaluated in three stages of the survey process: (1) preparation of data collection instrument (2) data collection and (3) data entry validation and cleaning. User acceptance was also evaluated in the two groups of participants: (1) data collectors and (2) survey participants.\\\\\\\\rRESULTS: None of the errors presented in 20.8% of the paper questionnaires was found in the data set collected using PDA. Sixty-two percent of the participants perceived that the PDA-based questionnaire took less time to complete. Data entry validation and cleaning for the PDA-based data collection from 120 participants took a total of 1.5h a 93.26% reduction of time from 20.5h required using paper and pen. The cost is also significantly reduced with PDA-based protocol. Both data collectors and participants prefer to use PDA instead of paper for data collection. The trial results prove that eSTEPS is a feasible solution for public health surveillance data collection in the field. Several deficiencies of the software were also identified and would be addressed in the next version.\\\\\\\\rCONCLUSION: eSTEPS offers the potential to meet the need for an effective mobile public health data collection tool for use in the field. The eSTEPS field trial proves that PDA was more efficient than paper for public health survey data collection. It also significantly reduced errors in data entry. The later benefit was derived from the software providing its users with the flexibility of building their own constraints to control the data type range and logic of data entry.","","","2009","10.1016/j.ijmedinf.2009.03.002","","","medline-19369114.pdf","medline-19369114"
"But what do participants want? Comment on the ""data sharing in psychology"" special section (2018)","Cummings J.a. And Day T.e.","Am Psychol","","This commentary addresses a recent special section on data sharing (i.e., open data) in the february-march 2018 american psychologist. In 4 articles, the authors outline how open data can positively impact psychology and provide guidelines for adopting open data practices, which we believe is to be commended. However, this special issue has not acknowledged a crucial concern in the open data debate: the views and desires of participants. Participants are the backbone of psychological research and an important stakeholder in open data issues. We review research that has studied participants' opinions of open data and outline concerns regarding open data raised by some groups of participants. We conclude with recommendations, including a call to psychological researchers to move beyond opinion and instead to empirically examine the impact of open data. We believe psychology is a discipline uniquely poised to execute these recommendations and guide researchers' understandings of how to appropriately and ethically implement open data practices across multiple disciplines. (Psycinfo database record (c) 2019 apa, all rights reserved).","","","2019","10.1037/amp0000408","","","embase-626376832.pdf","embase-626376832"
"Evaluation of dose delivery based on a comparison of dosimetry calculations using open beam and wedged beam depth dose data","Ho A. K., Podgorsak M. B., Sibata C. H., Shin K. H.","Medical Dosimetry","","The purpose of this study is to evaluate the magnitude of the error in dose delivery caused by the use of open beam depth dose data in dosimetry calculations for wedged photon beams. Isodose plans were calculated for treatments given in a 3-field isocentric prostate or rectal setup using an open AP beam with two lateral wedged beams. The dose distributions were first calculated using open beam depth dose data for all three fields. Next the open beam data was used only for the AP field and true wedged beam depth dose data was substituted for the two lateral wedged fields. The magnitude of the depth dose variations for wedged vs open beams depends on the nominal beam energy the wedge angle and the depth of measurement. Consequently isodose distributions calculated for wedged fields were found to be different when true wedged beam depth dose data was used instead of open beam data as is commonly done. Monitor unit calculations using a field size specific wedge factor show that dose delivery errors up to 4% can result from the use of open beam depth dose data in wedged beam dose distribution calculations for a 6-MV photon beam. Accurate treatment planning for wedged fields requires the use of wedged beam depth dose data specific to each wedge. Simply using open beam depth dose data in dose calculations for wedged beams will result in dose delivery errors the magnitude of which depends on the combination of wedge angle field size and nominal beam energy.","","","1995","","","","medline-8703325.pdf","medline-8703325"
"Assessing consequences of component sharing across brands in the vertical product line in the automotive market","Verhoef, P.c. And Pauwels, K.h. And Tuk, M.a.","Journal Of Product Innovation Management","","Component sharing may look great in the boardroom but not in the showroom. Indeed, savings on research and development and production costs could be offset by a plunge in customer brand attractiveness. The central objective of this paper is to investigate consumer and market responses toward component sharing between brands. More specifically, by combining experimental with econometric studies, this paper investigates the impact of component sharing on customer evaluation of luxury, volume, and economy brands offered in a car manufacturer's vertical product line. An experimental study in which component sharing between automotive brands was made explicit aimed to understand the impact of brand combinations and type of sourcing on the evaluations of the two brands sharing components. This experimental study shows that the evaluation of luxury brands sharing with a volume brand suffers more than when a volume brand shares components with an economy brand. This experimental study was executed for two different brand combinations including one luxury, one volume, and one economy brand: (1) audi, volkswagen, and skoda;  and (2) lexus, toyota, and suzuki. The evaluation of an economy brand benefits more from sharing with a volume brand than a volume brand suffers from sharing with an economy brand. The magnitude of these effects depends on several factors, such as component type, the source of the component sharing, and the salience of component sharing to the consumers. One important limitation of the experiment is that component sharing is made rather salient, and no behavioral effects of component sharing are studied. Therefore, a second was executed in which market share data on brands of the volkwagen company (i.e., audi, volkswagen, seat, and skoda) were collected, while also data on the component-sharing practices between these brands were gathered. A market share model was estimated in which market shares of the four studied brands were explained by component-sharing practices and some control variables (i.e., price, model changes) in an exploratory fashion. The explorative examination of market share effects confirms that luxury brands may suffer, while economy brands may benefit from component sharing. In sum, this research suggests that component sharing between brands has negative effects for the higher-end, and positive effects for the lower-end brand. However, it also shows that sourcing matters. This study is considered as the first study investigating the phenomenon of component sharing, and it points to multiple future research issues, such as studying this phenomenon in other markets. © 2012 product development & management association.","","","2012","10.1111/j.1540-5885.2012.00925.x","","","scopus-2-s2.0-84862134677.pdf","scopus-2-s2.0-84862134677"
"Radiographers' experiences and perspectives of forensic imaging in australia: a qualitative study","Smith, B. And Makanjee, C.r. And Lee, H. And Hayre, C.m. And Lewis, S.","Radiography","","Introduction: forensic imaging plays a pivotal role regarding medico-legal issues by investigating the cause(s) of injuries to living or deceased individuals. There is currently a gap in the literature on forensic imaging due to limited national and international guidelines, protocols and scope of duties and responsibilities of radiographers undertaking forensic imaging. Thus, this study aimed to investigate the gap by exploring the experiences and perspectives of radiographers on forensic imaging in australia. Methods: a qualitative approach collected data from fifteen purposively sampled qualified australian radiographers through individual in-depth interviews. The verbatim transcribed data were thematically analysed. Results: two themes were identified: 1) radiographers' experiences of forensic imaging;  2) radiographers' perceptions of forensic imaging within the job scope of a qualified radiographer. Conclusions: participants' experiences of forensic imaging ranged from anxiety to a positive experience, and others posed ethical and situational dilemmas heightened by the lack of dedicated forensic imaging protocols. While some radiographers expressed that every radiographer should conduct forensic imaging, others felt it was not mandatory. Implications for practice: radiographers' shared subjective experiences, thoughts and feelings provided insight into forensic imaging and the need for more significant support from educational and governing bodies. © 2022 the college of radiographers","","","2022","10.1016/j.radi.2022.08.008","","","scopus-2-s2.0-85137582890.pdf","scopus-2-s2.0-85137582890"
"""Using Crowd-Sourced Data to Explore Police-Related-Deaths in the United States (2000-2017): The Case of Fatal Encounters""","Finch B. K., Beck A., Burghart D. B., Johnson R., Klinger D., Thomas K.","Open Health Data","","Objectives: We evaluated the Fatal Encounters (FE) database as an open-source surveillance system for tracking police-related deaths (PRDs).\\\\\\\\rMethods: We compared the coverage of FE data to several known government sources of police-related deaths and police homicide data. We also replicated incident selection from a recent review of the National Violent Death Reporting System.\\\\\\\\rResults: FE collected data on n = 23578 PRDs from 2000-2017. A pilot study and ongoing data integration suggest greater coverage than extant data sets. Advantages of the FE data include circumstance of death specificity incident geo-locations identification of involved police-agencies and near immediate availability of data. Disadvantages include a high rate of missingness for decedent race/ethnicity potentially higher rates of missing incidents in older data and the exclusion of more comprehensive police use-of-force and nonlethal use-of-force data-a critique applicable to all extant data sets.\\\\\\\\rConclusions: FE is the largest collection of PRDs in the United States and remains as the most likely source for historical trend comparisons and police-department level analyses of the causes of PRDs.","","","2019","10.5334/ohd.30","","","medline-37073367.pdf","medline-37073367"
"How to protect the credibility of articles published in predatory journals","Yamada, Y.","Publications","","Predatory journals often prey on innocent researchers who are unaware of the threat they pose. This paper discusses what researchers can do if they unintentionally publish a paper in a predatory journal, including measures to take before submission, during peer review, and after the journal has accepted a manuscript. The specific recommendations discussed are pre-registration, pre-submission peer-review, open peer-review, topping up reviewers, post-publication peer review, open recommendation, and treatment as unrefereed. These measures may help to ensure the credibility of the article, even if it is published in a predatory journal. The present article suggests that an open and multi-layered assessment of research content enhances the credibility of all research articles, even those published in non-predatory journals. If applied consistently by researchers in various fields, the suggested measures may enhance reproducibility and promote the advancement of science. © 2021 by the authors.","","","2021","10.3390/publications9010004","","","scopus-2-s2.0-85100340503.pdf","scopus-2-s2.0-85100340503"
"Constructing a secure encryption and secret sharing mechanism for taiwan biobank of a medical center","Lee, T.-F. And Gao, T.-L. And Chang, C.-C.","Journal Of Technology","","The rapid development of dna sequencing technology has generated enormous amounts of individual genome data. Consequently, biological databases have become a crucial part in the study of personalized healthcare. However, research on encryption and secret sharing mechanisms for database security is still scarce. To solve this problem, this study proposes a secret sharing mechanism based on the human biobank management act to access databases to prevent privacy infringements. The mechanism then undergoes system performance and security evaluations. Research results show that the secret sharing mechanism introduced herein has higher data confidentiality, overall system security, and number of secure keys than traditional system security mechanisms. Furthermore, compared to encryption methods used in earlier systems, the security of our mechanism is significantly improved while maintaining similar computing time required for encryption. This study introduces a secret sharing mechanism into existing biological database systems with practical operability in mind. The mechanism requires using and sharing of data to implement physical, personnel, and technical protection measures in personal data encryption and decryption to prevent privacy infringements. Our mission is to improve the quality and quantity of data in modern biodata databases. Therefore, this study complies with information security standards and best practices. The goal is to help further in-depth systematic research on biobank databases to achieve better results. © 2022, national taiwan university of science and technology. All rights reserved.","","","2022","","","","scopus-2-s2.0-85138230593.pdf","scopus-2-s2.0-85138230593"
"Data standards can boost metabolomics research and if there is a will there is a way","Rocca-Serra P., Salek R. M., Arita M., Correa E., Dayalan S., Gonzalez-Beltran A., Ebbels T., Goodacre R., Hastings J., Haug K., Koulman A., Nikolski M., Oresic M., Sansone S. A., Schober D., Smith J., Steinbeck C., Viant M. R., Neumann S.","Metabolomics","","Thousands of articles using metabolomics approaches are published every year. With the increasing amounts of data being produced mere description of investigations as text in manuscripts is not sufficient to enable re-use anymore: the underlying data needs to be published together with the findings in the literature to maximise the benefit from public and private expenditure and to take advantage of an enormous opportunity to improve scientific reproducibility in metabolomics and cognate disciplines. Reporting recommendations in metabolomics started to emerge about a decade ago and were mostly concerned with inventories of the information that had to be reported in the literature for consistency. In recent years metabolomics data standards have developed extensively to include the primary research data derived results and the experimental description and importantly the metadata in a machine-readable way. This includes vendor independent data standards such as mzML for mass spectrometry and nmrML for NMR raw data that have both enabled the development of advanced data processing algorithms by the scientific community. Standards such as ISA-Tab cover essential metadata including the experimental design the applied protocols association between samples data files and the experimental factors for further statistical analysis. Altogether they pave the way for both reproducible research and data reuse including meta-analyses. Further incentives to prepare standards compliant data sets include new opportunities to publish data sets but also require a little ""arm twisting"" in the author guidelines of scientific journals to submit the data sets to public repositories such as the NIH Metabolomics Workbench or MetaboLights at EMBL-EBI. In the present article we look at standards for data sharing investigate their impact in metabolomics and give suggestions to improve their adoption. Copyright © 2015 The Author(s).","","","2016","10.1007/s11306-015-0879-3","","","pubmed-26612985.pdf","pubmed-26612985"
"Semantics-aware recommender systems exploiting linked open data and graph-based features","Musto, Cataldo And Lops, Pasquale And De Gemmis, Marco And Semeraro, Giovanni","Knowledge-Based Systems","","The recent spread of linked open data (lod) fueled the research in the area of recommender systems, since the (semantic) data points available in the lod cloud can be exploited to improve the performance of recommendation algorithms by enriching item representations with new and relevant features. In this article we investigate the impact of the features gathered from the lod cloud on a hybrid recommendation framework based on three classification algorithms, random forests, naive bayes and logistic regression. Specifically, we extend the representation of the items by introducing two new types of features: lod-based features, structured data extracted from the lod cloud, as the genre of a movie or the writer of a book, and graph-based features, computed on the ground of the topological characteristics of both the bipartite graph-based representation connecting users and items, and the tripartite representation connecting users, items and properties in the lod cloud. In the experimental session we assess the effectiveness of these novel features;  results show that the use of information coming from the lod cloud could improve the overall accuracy of our recommendation framework. Finally, our approach outperform several state-of-the-art recommendation techniques, thus confirming the insights behind this research. (Psycinfo database record (c) 2023 apa, all rights reserved)","","","2017","10.1016/j.knosys.2017.08.015","","","psychinfo-2017-37133-001.pdf","psychinfo-2017-37133-001"
"A Practical Approach to Governance and Optimization of Structured Data Elements","Collins S. A., Gesner E., Morgan S., Mar P., Maviglia S., Colburn D., Tierney D., Rocha R.","Studies in Health Technology & Informatics","","Definition and configuration of clinical content in an enterprise-wide electronic health record (EHR) implementation is highly complex. Sharing of data definitions across applications within an EHR implementation project may be constrained by practical limitations including time tools and expertise. However maintaining rigor in an approach to data governance is important for sustainability and consistency. With this understanding we have defined a practical approach for governance of structured data elements to optimize data definitions given limited resources. This approach includes a 10 step process: 1) identification of clinical topics 2) creation of draft reference models for clinical topics 3) scoring of downstream data needs for clinical topics 4) prioritization of clinical topics 5) validation of reference models for clinical topics and 6) calculation of gap analyses of EHR compared against reference model 7) communication of validated reference models across project members 8) requested revisions to EHR based on gap analysis 9) evaluation of usage of reference models across project and 10) Monitoring for new evidence requiring revisions to reference model.","","","2015","","","","medline-26261999.pdf","medline-26261999"
"Protein separations","Chow A. W.","Methods in Molecular Biology","","This chapter describes the use of two types of commercialized microfluidic chips for protein separation suitable for personal scale and high-throughput use. Compared with conventional approaches such as sodium dodecyl sulfate-polyacrylamide gel electrophoresis (SDS-PAGE) and capillary electrophoresis (CE) these devices offer the advantages of faster separation times better data reproducibility greater ease of use labor savings in quantitative analysis and ease in data archiving and data sharing owing to the digital data format. With some simple precautions taken to keep bubbles and particulates out of the microchannels Lab-on-a-Chip devices have been adopted by many researchers in protein processing protein engineering and proteomics research laboratories to increase their productivity.","","","2006","","","","medline-16790872.pdf","medline-16790872"
"The compact city and sustainable transport: another look at the data","Mees, P.","Australian Planner","","The suite of policies known as the 'compact city' has emerged as the most popular prescription for reducing automobile dependence. The evidentiary base for the compact city draws on previous studies that compared population density and automobile use in a range of metropolitan areas, and that concluded that density is strongly related to automobile use. This paper re-examines the data on transport and density in us, canadian and australian cities, using census data on mode share for the journey to work, and on the density of 'urbanised areas'. This comparison is possible because the three countries' census agencies collect density and mode share data on a comparable basis, although the australian and canadian agencies only publicly released density data following their 2006 censuses. These data allow cross-city and cross-national comparisons to be performed on a more accurate basis than was possible at the time of the earlier studies. Standard statistical techniques are used to examine the relationship between density and the mode share for automobiles, public transport and walking/cycling. The relationship turns out to be different from that reported in previous studies: public transport and automobile use are only weakly correlated with density, while walking and cycling show no correlation at all. The significance of these results is discussed in light of equivalent british and european density and travel data, and some figures on centralisation of employment. The conclusion is that the effectiveness of the compact city model has been overstated, and the effectiveness of transport policy itself understated. © 2011 planning institute australia.","","","2011","","","","scopus-2-s2.0-80052667816.pdf","scopus-2-s2.0-80052667816"
"Knowledge sharing in multicultural organizations: evidence from pakistan","Raza, I. And Awang, Z.","Higher Education, Skills And Work-Based Learning","","Purpose: taking higher educational institutes (heis) operating in islamabad metropolitan, and pakistan as research context, the purpose of this paper is to identify the antecedents of knowledge sharing behavior (ksb) and to check their causal effect in perspective of culturally diverse academic staff. In addition, the authors suggest certain policies for heis that can raise knowledge sharing practices in multicultural environment. Design/methodology/approach: it is a cross-sectional study, quantitative in nature, and has used a self-administered questionnaire for data collection. With proportionate stratified random sampling technique, 278 academic employees working in three faculties from six public sector universities operating in islamabad metropolitan have recorded their responses. This research also applied confirmatory factor analysis and structural equation modeling to examine the proposed hypothesis of this inquiry. Findings: the empirical results indicate significant and positive effect of cultural diversity management, interpersonal trust, and leader-empowering behavior on ksb, whereas knowledge technology has insignificant effect on ksb of culturally diverse academic staff. Moreover, proposed model has explained 54 percent variation in endogenous construct. Practical implications: the present research aids academic leadership in designing policies and strategies to enhance knowledge sharing among faculty members and to create a supportive knowledge sharing culture. Originality/value: this study fills the empirical gap that exists in literature by exploring the antecedents and their effect on ksb of multicultural academic staff associated in public sector heis in islamabad metropolitan, pakistan. © 2019, emerald publishing limited.","","","2020","10.1108/heswbl-09-2019-0114","","","scopus-2-s2.0-85079172406.pdf","scopus-2-s2.0-85079172406"
"AERA Editorial Policies Regarding Statistical Significance Testing: Three Suggested Reforms","Thompson Bruce","Educational Researcher","","Reviews practices regarding tests of statistical significance and policies of the American Educational Research Association (AERA). Decades of misuse of statistical significance testing are described and revised editorial policies to improve practice are highlighted. Correct interpretation of statistical tests interpretation of effect sizes and exploration of research replicability are essential. (SLD)","","","1996","","","","eric-ej525478.pdf","eric-ej525478"
"A blockchain-based trading system for big data","Hu, D. And Li, Y. And Pan, L. And Li, M. And Zheng, S.","Computer Networks","","Data are an extremely important asset. Governments around the world encourage big data sharing and trading to promote the big data economy. However, existing data trading platforms are not fully trusted. Such platforms face the problems of a single point of failure (spof), opaque transactions, uncontrollability, untraceability, and issues of data privacy. Several blockchain-based big data trading methods have been proposed;  however, they do not adequately address the security issues introduced by dishonesty in the data provider and data agent or the fairness of data revenue distribution and price bargaining. In this paper, we propose a blockchain-based decentralized data trading system in which data trading is completed by smart contract-based data matching, price negotiation, and reward assigning. Moreover, the proposed data trading system evaluates the data quality on the basis of three metrics, records the evaluation results in a side-chain, and distributes the data users’ application revenue to the data provider according to the evaluated data quality. We verify the security, usability, and efficiency of the proposed big data trading system. © 2021 elsevier b.v.","","","2021","10.1016/j.comnet.2021.107994","","","scopus-2-s2.0-85102589631.pdf","scopus-2-s2.0-85102589631"
"Perspectives on Open Science and Scholarly Publishing: a Survey Study Focusing on Early Career Researchers in Europe","Berezko O., Medina L. M. P., Malaguarnera G., Almeida I., Zyra A., Seang S., Bjornmalm M., Hnatkova E., Tata M.","F1000Research","","Background: The value of Open Science (OS) for the academic community and society has been becoming more evident recently especially during the COVID-19 pandemic. Nevertheless significant challenges regarding its implementation arise that are likely to affect researchers especially those in early career stages. Hence monitoring early-career researchers' views knowledge and skills on OS and related policies is crucial for its advancement. The main aim of this exploratory study was to gain new perspectives regarding the awareness of and attitudes towards OS and related practices having in consideration geographical economic and research career variables. Method(s): The survey was conducted during May-August 2020 as part of a collaboration between Eurodoc and the Open Research Europe project. The data from the survey were analyzed by European region Gross domestic product Gross domestic expenditure on research and development as a percentage of gross domestic product field of study and career stage. Result(s): The awareness and positive attitude regarding OS specifically among early-career researchers is high in Europe. However there are significant career stage group differences in views and knowledge about OS. Generally awareness and positive attitude tend to increase with increasing career seniority. Regarding European regions we spotted three main groups sharing similar awareness levels and attitudes: researchers in Western Europe - the most informed group towards OS; researchers in northern central and southern Europe - a moderately informed group with some minor differences; and researchers in eastern Europe - the least informed group whose opinions deviate the most. Conclusion(s): We found that there is an ""evolution of needs and focus"" regarding scientific publishing: researchers in most European regions are in different stages of transition from the competitive to collaborative levels while researchers in eastern Europe are largely beginning their transition to the competitive level. Copyright: © 2021 Berezko O et al.","","","2021","10.12688/f1000research.74831.1","","","unknown-1154.pdf","unknown-1154"
"High-performance work systems, innovation and knowledge sharing: an empirical analysis in the context of project-based organizations","Bhatti, S.h. And Zakariya, R. And Vrontis, D. And Santoro, G. And Christofi, M.","Employee Relations","","Purpose: this article aims to explore the relationship among high performance work systems (hpws), innovation, and knowledge sharing in project-based organizations. Design/methodology/approach: using the ability, motivation, and opportunity (amo) framework under the theory of hpws, our article hypothesizes that the amo enhancing practices of project-based organizations lead to better innovation performance of their employees through the mediating role of knowledge sharing. Time-lagged data of amo practices and knowledge sharing practices were collected from the employees of these organizations over three weeks. Furthermore, the innovation performance data were collected from the supervisors of these employees over an additional three-week period. Findings: our results confirm the initial hypothesis of the causal relationship of two of the amo hrm practices, that is, ability and motivation with innovation performance with the mediation of knowledge sharing, while the third hypothesis of opportunity enhancing hrm practice was not accepted. Originality/value: this research has implications for both theory and practice and it can help the project managers of these organizations to better design hrm practices in order to improve the creativity and innovation performance of their employees. Accordingly, this is one of the first studies dealing with the effectiveness of hrm on amo, and the key role of knowledge sharing. © 2020, emerald publishing limited.","","","2021","10.1108/er-10-2019-0403","","","scopus-2-s2.0-85080064862.pdf","scopus-2-s2.0-85080064862"
"Real-world evidence in support of precision medicine: clinico-genomic cancer data as a case study","Agarwala, V. And Khozin, S. And Singal, G. And O'connell, C. And Kuk, D. And Li, G. And Gossai, A. And Miller, V. And Abernethy, A.p.","Health Affairs","","The majority of us adult cancer patients today are diagnosed and treated outside the context of any clinical trial (that is, in the real world). Although these patients are not part of a research study, their clinical data are still recorded. Indeed, data captured in electronic health records form an ever-growing, rich digital repository of longitudinal patient experiences, treatments, and outcomes. Likewise, genomic data from tumor molecular profiling are increasingly guiding oncology care. Linking real-world clinical and genomic data, as well as information from other co-occurring data sets, could create study populations that provide generalizable evidence for precision medicine interventions. However, the infrastructure required to link, ensure quality, and rapidly learn from such composite data is complex. We outline the challenges and describe a novel approach to building a real-world clinico-genomic database of patients with cancer. This work represents a case study in how data collected during routine patient care can inform precision medicine efforts for the population at large. We suggest that health policies can promote innovation by defining appropriate uses of real-world evidence, establishing data standards, and incentivizing data sharing. © 2018 project hope- the people-to-people health foundation, inc.","","","2018","10.1377/hlthaff.2017.1579","","","scopus-2-s2.0-85046707162.pdf","scopus-2-s2.0-85046707162"
"Determining what healthcare should be","Karr, T.","Industrial Engineer","","Work flow studies and standardization concepts are working their way into the healthcare field. Standardized work and best practices share a common development cycle. The most basic elements of standardization address three key questions, such as who determines and defines the best practices, where and how are best practices documented and implemented, and who evaluates whether best practices were applied and whether they provided desired outcomes. To improve patient safety, hospitals must figure out how to get physicians more involved. A formal infrastructure would encourage doctors to design scientifically rigorous quality-improvement interventions, develop performance measures, monitor performance, implement interventions and monitor their impact. Standard work documents should focus on the best way to execute a process given the fact that the process may be performed by a host of different caregivers and providers.","","","2011","","","","scopus-2-s2.0-84255183007.pdf","scopus-2-s2.0-84255183007"
"Efficient certificate-based proxy re-encryption scheme for data sharing in public clouds","Lu, Y.","Ksii Transactions On Internet And Information Systems","","Nowadays, public cloud storage is gaining popularity and a growing number of users are beginning to use the public cloud storage for online data storing and sharing. However, how the encrypted data stored in public clouds can be effectively shared becomes a new challenge. Proxy re-encryption is a public-key primitive that can delegate the decryption right from one user to another. In a proxy re-encryption system, a semi-trusted proxy authorized by a data owner is allowed to transform an encrypted data under the data owner’s public key into a re-encrypted data under an authorized recipient’s public key without seeing the underlying plaintext. Hence, the paradigm of proxy re-encryption provides a promising solution to effectively share encrypted data. In this paper, we propose a new certificate-based proxy re-encryption scheme for encrypted data sharing in public clouds. In the random oracle model, we formally prove that the proposed scheme achieves chosen-ciphertext security. The simulation results show that it is more efficient than the previous certificate-based proxy re-encryption schemes. © 2015 ksii.","","","2015","10.3837/tiis.2015.07.021","","","scopus-2-s2.0-84938411206.pdf","scopus-2-s2.0-84938411206"
"Design and implementation of a workshop for evaluation of the role of power in shaping and solving challenges in a smart foodshed","Hyder, A. And Blatt, A. And Hollander, A.d. And Hoy, C. And Huber, P.r. And Lange, M.c. And Quinn, J.f. And Riggle, C.m. And Sloan, R. And Tomich, T.p.","Sustainability (Switzerland)","","Current studies on data sharing via data commons or shared vocabularies using ontologies mainly focus on developing the infrastructure for data sharing yet little attention has been paid to the role of power in data sharing among food system stakeholders. Stakeholders within food systems have different interpretations of the types and magnitudes of their own and other’s level of power to solve food system challenges. Politically neutral, yet scientifically/socioeconomically accurate power classification systems are yet to be developed, and must be capable of enumerating and characterizing what power means to each stakeholder, existing power dynamics within the food system, as well as alternative forms of power not currently utilized to their full capacity. This study describes the design and implementation of a workshop, which used methods from community-based participatory modeling, to examine the role of power relative to data sharing and equitable health outcomes. Workshop participants co-created several boundary objects that described the power relationships among food system stakeholders and the changes needed to current power relationships. Our results highlight current imbalances in power relationships among food system stakeholders. The information we collected on specific relationships among broad categories of stakeholders highlighted needs for initiatives and activities to increase the types and varieties of power especially across consumers, farmers, and labor stakeholder groups. Furthermore, by utilizing this workshop methodology, food system stakeholders may be able to envision new power relationships and bring about a fundamental re-orienting of current power relationships capable of valorizing food system sustainability/resiliency, especially the health of its workers and consumers. © 2022 by the authors. Licensee mdpi, basel, switzerland.","","","2022","10.3390/su14052642","","","scopus-2-s2.0-85125787223.pdf","scopus-2-s2.0-85125787223"
"Citizen science. One of the eight pillars of open science identified by the european union","Morriello, R.","Jlis.it","","Although it is not a new phenomenon, citizen science is a form of collaborative research whose importance has grown in recent years. There is no single definition of citizen science and although this is the prevailing expression, activities are often referred to by other terms. However, the various terms used emphasize the key element, which is the voluntary participation of non-expert citizens in scientific research. Citizen science encompasses a wide range of activities and practices that can cover the entire life cycle of a research, from data collection to publication of results, and even evaluation. The first part of the article briefly traces the history of citizen science, highlighting the implications of the different facets through which it is defined. Then, it gives an overview of the state of the art, the initiatives, guidelines and good practices, the open issues, and the most representative institutions and organizations. A series of data are also provided regarding its dissemination, and reflections on the impact of this form of research on the scientific community and society, as well as on specific aspects related to open science and sustainable development. Finally, the article focuses on the role of university libraries and public libraries for citizen science. © 2021 the author(s).","","","2021","10.4403/jlis.it-12761","","","scopus-2-s2.0-85128175325.pdf","scopus-2-s2.0-85128175325"
"Comparative evaluation of reverse engineering gene regulatory networks with relevance networks graphical gaussian models and bayesian networks","Werhli A. V., Grzegorczyk M., Husmeier D.","Bioinformatics","","MOTIVATION: An important problem in systems biology is the inference of biochemical pathways and regulatory networks from postgenomic data. Various reverse engineering methods have been proposed in the literature and it is important to understand their relative merits and shortcomings. In the present paper we compare the accuracy of reconstructing gene regulatory networks with three different modelling and inference paradigms: (1) Relevance networks (RNs): pairwise association scores independent of the remaining network; (2) graphical Gaussian models (GGMs): undirected graphical models with constraint-based inference and (3) Bayesian networks (BNs): directed graphical models with score-based inference. The evaluation is carried out on the Raf pathway a cellular signalling network describing the interaction of 11 phosphorylated proteins and phospholipids in human immune system cells. We use both laboratory data from cytometry experiments as well as data simulated from the gold-standard network. We also compare passive observations with active interventions.\\\\\\\\rRESULTS: On Gaussian observational data BNs and GGMs were found to outperform RNs. The difference in performance was not significant for the non-linear simulated data and the cytoflow data though. Also we did not observe a significant difference between BNs and GGMs on observational data in general. However for interventional data BNs outperform GGMs and RNs especially when taking the edge directions rather than just the skeletons of the graphs into account. This suggests that the higher computational costs of inference with BNs over GGMs and RNs are not justified when using only passive observations but that active interventions in the form of gene knockouts and over-expressions are required to exploit the full potential of BNs.\\\\\\\\rAVAILABILITY: Data software and supplementary material are available from http://www.bioss.sari.ac.uk/staff/adriano/research.html","","","2006","","","","medline-16844710.pdf","medline-16844710"
"Vpl-based big data analysis system: udas","Choi, H. And Gim, J. And Seo, Y.-D. And Baik, D.-K.","Ieee Access","","Over the past five years, research on big data analysis has been actively conducted, and many services have been developed to find valuable data. However, low quality of raw data and data loss problem during data analysis make it difficult to perform accurate data analysis. With the enormous generation of both unstructured and structured data, refinement of data is becoming increasingly difficult. As a result, data refinement plays an important role in data analysis. In addition, as part of efforts to ensure research reproducibility, the importance of reuse of researcher data and research methods is increasing;  however, the research on systems supporting such roles has not been conducted sufficiently. Therefore, in this paper, we propose a big data analysis system named the unified data analytics suite (udas) that focuses on data refinement. Udas performs data refinement based on the big data platform and ensures the reusability and reproducibility of refinement and analysis through the visual programming language interface. It also recommends open source and visualization libraries to users for statistical analysis. The qualitative evaluation of udas using the functional evaluation factor of the big data analysis platform demonstrated that the average satisfaction of the users is significantly high. © 2013 ieee.","","","2018","10.1109/access.2018.2857845","","","scopus-2-s2.0-85050407551.pdf","scopus-2-s2.0-85050407551"
"Optimizing the leveraging of real-world data to improve the development and use of medicines","Berger, M.l. And Lipset, C. And Gutteridge, A. And Axelsen, K. And Subedi, P. And Madigan, D.","Value In Health","","Health research, including health outcomes and comparative effectiveness research, is on the cusp of a golden era of access to digitized real-world data, catalyzed by the adoption of electronic health records and the integration of clinical and biological information with other data. This era promises more robust insights into what works in health care. Several barriers, however, will need to be addressed if the full potential of these new data are fully realized;  these will involve both policy solutions and stakeholder cooperation. Although a number of these issues have been widely discussed, we focus on the one we believe is the most important - the facilitation of greater openness among public and private stakeholders to collaboration, connecting information and data sharing, with the goal of making robust and complete data accessible to all researchers. In this way, we can better understand the consequences of health care delivery, improve the effectiveness and efficiency of health care systems, and develop advancements in health technologies. Early real-world data initiatives illustrate both potential and the need for future progress, as well as the essential role of collaboration and data sharing. Health policies critical to progress will include those that promote open source data standards, expand access to the data, increase data capture and connectivity, and facilitate communication of findings. © 2015 international society for pharmacoeconomics and outcomes research (ispor).","","","2015","10.1016/j.jval.2014.10.009","","","scopus-2-s2.0-84920821005.pdf","scopus-2-s2.0-84920821005"
"Safe sharing sites","Austin, L.m. And Lie, D.","New York University Law Review","","In this article we argue that data sharing is an activity that sits at the crossroads of privacy concerns and the broader challenges of data governance surrounding access and use. Using the sidewalk toronto “smart city” proposal as a starting point for discussion, we outline these concerns to include resistance to data monopolies, public control over data collected through the use of public infrastructure, public benefit from the generation of intellectual property, the desire to broadly share data for innovation in the public interest, social—rather than individual— surveillance and harms, and that data use be held to standards of fairness, justice, and accountability. Data sharing is sometimes the practice that generates these concerns and sometimes the practice that is involved in the solution to these concerns. Our safe sharing site approach to data sharing focuses on resolving key risks associated with data sharing, including protecting the privacy and security of data subjects, but aims to do so in a manner that is independent of the various legal contexts of regulation and governance. Instead, we propose that safe sharing sites connect with these different contexts through a legal interface consisting of a registry that provides transparency in relation to key information that supports different forms of regulation. Safe sharing sites could also offer assurances and auditability regarding the data sharing, further supporting a range of regulatory interventions. It is therefore not an alternative to these interventions but an important tool that can enable effective regulation. A central feature of a safe sharing site is that it offers an alternative to the strategy of de-identifying data and then releasing it, whether within an “open data” context or in a more controlled environment. In a safe sharing site, computations may be performed on the data in a secure and privacy-protective manner without releasing the raw data, and all data sharing is transparent and auditable. Transparency does not mean that all data sharing becomes a matter of “public” view, but rather that there is the ability to make these activities visible to organizations and regulators in appropriate circumstances while recognizing the potential confidentiality interests in data uses. In this way, safe sharing sites facilitate data sharing in a manner that manages the complexities of sharing while reducing the risks and enabling a variety of forms of governance and regulation. As such, the safe sharing site offers a flexible and modular piece of legal-technical infrastructure for the new economy. © 2019 by lisa m. Austin & david lie.","","","2019","","","","scopus-2-s2.0-85074029232.pdf","scopus-2-s2.0-85074029232"
"Digital transparency: dimensions, antecedents and consequences on the quality of customer relationships","Portes, A. And N’goala, G. And Cases, A.-S.","Recherche Et Applications En Marketing","","This research focuses on transparency in a digital environment, examines how it is perceived by customers through different evaluations (perceived clarity, objectivity, and openness), and examines how each of these dimensions affects customer trust and engagement to the brand. It pointed out that judgments of transparency differ according to the relationship that consumers have personally developed with their digital environment (literacy, consumer acumen, and concern for privacy). Based on an empirical study conducted in e-commerce (n = 445), the results show that perceived clarity – unlike perceived objectivity – is accompanied by a decline in trust and has a direct impact on engagement. On the contrary, perceived openness encourages engagement but not trust. This research highlights how consumer literacy and consumer acumen promote the perception of transparency, while concern for privacy degrades it. Theoretical and practical implications are then drawn from this research. © l’association française du marketing, 2020.","","","2020","10.1177/2051570720973548","","","scopus-2-s2.0-85097927178.pdf","scopus-2-s2.0-85097927178"
"Open data 5 years on: A case series of 12 freedom of information requests for regulatory data to the European Medicines Agency","Doshi P., Jefferson T.","Trials","","Background: Clinical trial (and other) data from the European Medicines Agency (EMA) offers the best available opportunity to address the extensive reporting bias in pharmaceutical trial literature. Data are requested via freedom of information requests but 5years on little is known about how the system is working. Method(s): Case series of 12 requests for regulatory data (clinical study reports and other regulatory data) relating to 29 different compounds. We logged start and end dates for correspondence with and data releases from the EMA the need for additional correspondence and appeal of initial negative decisions and inspected data releases for redaction. We measured: time from initial request to first substantive response from the EMA to final decision from the EMA (in case of appeal) to initial receipt of documents and to completion of request; number of data transmission batches generated; number of pages received for each request; average number of pages per batch over time (for releases in multiple batches); judgment as to whether the request was satisfied. Result(s): We found great variability in time to receive an initial decision from the EMA (1 to 13weeks). Additional correspondence with the EMA was necessary in 10 of 12 requests. Four of 12 were initially refused but 3 of 4 were allowed on appeal after 3 to 33 additional weeks. One request was denied despite appeal. Time to final decision was 1 to 43weeks. We received data for 11 of 12 requests in 98 batches. While two requests remain outstanding as at June 2015 the remaining nine requests took a median 43weeks to completion (range: 17 to 186weeks). Despite redaction in 10 of 11 releases (mainly of researcher and participant identifying information) 8 requested were wholly satisfied. Conclusion(s): The EMA is the only regulator in the world that is routinely releasing original clinical trial data but release can take considerable time to occur and often only after a lengthy correspondence. Given its importance for research and significance for transparency we suggest ways in which the process could be made more efficient. Copyright © 2016 Doshi and Jefferson.","","","2016","10.1186/s13063-016-1194-7","","","medline-26865363.pdf","medline-26865363"
"Towards a paradigm for open and free sharing of scientific data on global change science in china","Peng, C. And Song, X. And Jiang, H. And Zhu, Q. And Chen, H. And Chen, J.m. And Gong, P. And Jie, C. And Xiang, W. And Yu, G. And Zhou, X.","Ecosystem Health And Sustainability","","Despite great progress in data sharing that has been made in china in recent decades, cultural, policy, and technological challenges have prevented chinese researchers from maximizing the availability of their data to the global change science community. To achieve full and open exchange and sharing of scientific data, chinese research funding agencies need to recognize that preservation of, and access to, digital data are central to their mission, and must support these tasks accordingly. The chinese government also needs to develop better mechanisms, incentives, and rewards, while scientists need to change their behavior and culture to recognize the need to maximize the usefulness of their data to society as well as to other researchers. The chinese research community and individual researchers should think globally and act personally to promote a paradigm of open, free, and timely data sharing, and to increase the effectiveness of knowledge development. © 2016, © 2016 peng et al.","","","2016","10.1002/ehs2.1225","","","scopus-2-s2.0-85066468635.pdf","scopus-2-s2.0-85066468635"
"A toolbox of IgG subclass-switched recombinant monoclonal antibodies for enhanced multiplex immunolabeling of brain","Andrews N. P., Boeckman J. X., Manning C. F., Nguyen J. T., Bechtold H., Dumitras C., Gong B., Nguyen K., van der List D., Murray K. D., Engebrecht J., Trimmer J. S.","Elife","","Generating recombinant monoclonal antibodies (R-mAbs) from mAb-producing hybridomas offers numerous advantages that increase the effectiveness reproducibility and transparent reporting of research. We report here the generation of a novel resource in the form of a library of recombinant R-mAbs validated for neuroscience research. We cloned immunoglobulin G (IgG) variable domains from cryopreserved hybridoma cells and input them into an integrated pipeline for expression and validation of functional R-mAbs. To improve efficiency over standard protocols we eliminated aberrant Sp2/0-Ag14 hybridoma-derived variable light transcripts using restriction enzyme treatment. Further we engineered a plasmid backbone that allows for switching of the IgG subclasses without altering target binding specificity to generate R-mAbs useful in simultaneous multiplex labeling experiments not previously possible. The method was also employed to rescue IgG variable sequences and generate functional R-mAbs from a non-viable cryopreserved hybridoma. All R-mAb sequences and plasmids will be archived and disseminated from open source suppliers.","","","2019","10.7554/elife.43322","","","medline-30667360.pdf","medline-30667360"
"A weather features dataset for prediction of short-term rainfall quantities in Uganda","Tumusiime A. G., Eyobu O. S., Mugume I., Oyana T. J.","Data in Brief","","Weather data is of great importance to the development of weather prediction models. However the availability and quality of this data remains a significant challenge for most researchers around the world. In Uganda obtaining observational weather data is very challenging due to the sparse distribution of weather stations and inconsistent data records. This has created critical gaps in data availability to run and develop efficient weather prediction models. To bridge this gap we obtained country-specific time series hourly observational weather data. The data period is from 2020 to 2022 of 11 weather stations distributed in the four regions of Uganda. The data was accessed from the Ogimet data repository using the ""climate"" R-package. The automated procedures in the R-programming language environment allowed us to download user-defined data at a time resolution from an hourly to an annual basis. However the raw data acquired cannot be used to learn rainfall patterns because it includes duplicates and non-uniform data. Therefore this article presents a prepared and cleaned dataset that can be used for the prediction of short-term rainfall quantities in Uganda. Copyright © 2023 The Author(s).","","","2023","10.1016/j.dib.2023.109613","","","medline-37808539.pdf","medline-37808539"
"Problem-based learning in a theoretical course in civil engineering: students’ perspectives","Naveh, G. And Bakun-Mazor, D. And Tavor, D. And Shelef, A.","Advances In Engineering Education","","More than a half century has passed since the first integration of problem-based learning (pbl) in higher education teaching. Despite the extensive investigation focused on this pedagogy, rigorous research on the impact of pbl in civil engineering is limited. Thus, this study aims to provide a thorough evaluation of students’ perceptions of pbl in a civil engineering course. The course was designed based on best practices from the literature while addressing, with the intent to minimize, the inhibitors of pbl success indicated in past research. The semester-long project was focused on creating an artifact to demonstrate geological phenomena chosen by the students, to then be displayed in an exhibition. The course included formative and summative assessments of students’ performance throughout the semester. Data was collected and analyzed methodically from over 150 students from two cohorts, one with a one-year post-course perspective, using a survey. The results indicate high satisfaction with several aspects of the course, including the perception of soft skill development. The analysis also showed that students from an ethnic minority group had significantly higher satisfaction and perceived benefit from the course. These findings demonstrate the possibility of turning a theoretical civil engineering course into a valuable pbl course, suggesting that pbl may promote greater equality for ethnic minority groups. © 2022, advances in engineering education. All rights reserved.","","","2022","10.18260/3-1-1153-36033","","","scopus-2-s2.0-85138061638.pdf","scopus-2-s2.0-85138061638"
"Trust and digital privacy in healthcare: a cross-sectional descriptive study of trust and attitudes towards uses of electronic health data among the general public in sweden","Belfrage, S. And Helgesson, G. And Lynøe, N.","Bmc Medical Ethics","","Background: the ability of healthcare to protect sensitive personal data in medical records and registers might influence public trust, which in turn might influence willingness to allow healthcare to use such data. The aim of this study was to examine how the general public’s trust relates to their attitudes towards uses of health data. Methods: a stratified sample from the general swedish population received a questionnaire about their willingness to share health data. Respondents were also asked about their trust in the management and protection of electronic health data. Results: a large majority (81.9%) of respondents revealed high levels of trust in the ability of healthcare to protect electronic patient data. Good health was associated with significantly higher levels of trust compared to bad health. Respondents with low levels of trust were significantly less willing to allow personal data to be used for different purposes and were more inclined to insist on being asked for permission beforehand. Those with low levels of trust also perceived risks of unauthorized access to personal data to be higher and the likely damage of such unauthorized access worse, compared to those with high levels of trust. Conclusions: trust in the ability of healthcare to protect electronic health is generally high in sweden. Those with higher levels of trust are more willing to let their data be used, including without informed consent. It thus seems crucial to promote trust in order to be able to reap the benefits that digitalization makes possible through increased access and use of data in healthcare. © 2022, the author(s).","","","2022","10.1186/s12910-022-00758-z","","","scopus-2-s2.0-85125788176.pdf","scopus-2-s2.0-85125788176"
"Expanding Perspectives on Open Science: Communities Cultures and Diversity in Concepts and Practices - Proceedings of the 21st International Conference on Electronic Publishing","Chan L., Loizides F.","","","The proceedings contain 28 papers. The topics discussed include: benefits of open science: an analytical framework illustrated with case study; grey literature publishing in public policy: production and management costs and benefits; imparting knowledge in humanities. about some practices of scientific blogging on hypotheáses; rethinking openness: challenges and new approaches to open scholarly journals; alternative metrics for the evaluation of scholarly activities: an analysis of articles authored by Greek researchers; claims about benefits of open access to society (beyond academia); framing a situated and inclusive open science: emerging lessons from the open and collaborative science in development network; openness in scholarship: a return to core values?; OpenAIRE: supporting the H2020 open access mandate; new toolkits on the block: peer review alternatives in scholarly communication; open access policy and funding in Cyprus University of Technology a case study; Arxiv-based commenting resources by and for astrophysicists and physicists: an initial survey; and open science and accelerating discovery in rare and neglected diseases.","","","2017","","","","scopus-2-s2.0-85020758009.pdf","scopus-2-s2.0-85020758009"
"A multi-dimensional evaluation of synthetic data generators","Dankar, F.k. And Ibrahim, M.k. And Ismail, L.","Ieee Access","","Synthetic datasets are gradually emerging as solutions for data sharing. Multiple synthetic data generators have been introduced in the last decade fueled by advancement in machine learning and by the increased demand for fast and inclusive data sharing, yet their utility is not well understood. Prior research tried to compare the utility of synthetic data generators using different evaluation metrics. These metrics have been found to generate conflicting conclusions making direct comparison of synthetic data generators very difficult. This paper identifies four criteria (or dimensions) for masked data evaluation by classifying available utility metrics into different categories based on the measure they attempt to preserve: attribute fidelity, bivariate fidelity, population fidelity, and application fidelity. A representative metric from each category is chosen based on popularity and consistency, and the four metrics are used to compare the overall utility of four recent data synthesizers across 19 datasets of different sizes and feature counts. The paper also examines correlations between the selected metrics in an attempt to streamline synthetic data utility. © 2013 ieee.","","","2022","10.1109/access.2022.3144765","","","scopus-2-s2.0-85123384612.pdf","scopus-2-s2.0-85123384612"
"Assessing incapacity at early stages of multiple sclerosis using the edss","Brochet, B.","Revue Neurologique","","The expanded disability status score (edss) is the most commonly used scale to assess disability in multiple sclerosis (ms). A major criticism concerns its low interobserver reproducibility. To improve this reproducibility, we propose scoring guidelines for french-speaking neurologists (neuroscore).","","","2009","10.1016/s0035-3787(09)72131-9","","","scopus-2-s2.0-69849112044.pdf","scopus-2-s2.0-69849112044"
"Unreported data sources in public sector organizations","Abbas, S.w. And Rasul, S. And Ahmad, M.","Statistical Journal Of The Iaos","","Almost every public sector department produces some statistics and accumulates its share in the formulation of national statistics. The accurate and timely statistics are vital for planning and development, budgeting and evaluation of the implemented programs. It may be reasonable to assume that datasets are being produced at almost all levels of the departments;  nonetheless, a substantial number of valuable data-items are left unreported and hence they are unable to play their role in evidence-based planning and decision-making. There is a need to uncover these sources, to explore the reasons behind the non-reporting of data and to devise strategies to utilize these sources in the production of official statistics. In this paper, we present the results of a national-level survey conducted to collect information on data-processing and reporting mechanisms of public-sector organizations in pakistan. Along with presenting the survey results, the paper discusses the potential sources of unreported data (including big data), the reasons for non-reporting at different sectoral levels and the confidentiality, privacy, and data-sharing constraints. Based on the above, the paper ends by proposing the compilation of a directory of administrative data sources (dads) in order to establish an improved administrative infrastructure in the country. © 2019 - ios press and the authors.","","","2019","10.3233/sji-180466","","","scopus-2-s2.0-85072179854.pdf","scopus-2-s2.0-85072179854"
"A sharing data model for wireless body sensor networks in different application scenarios of heterogeneous platforms","Yu, H. And Wang, H. And Wang, C.","Ad-Hoc And Sensor Wireless Networks","","Body sensor networks (bsns) represent an emerging technology which has attracted much attention recently due to its enormous potential to enable remote, real-time, continuous and non-invasive monitoring of people in health-care, entertainment, fitness, sport, and social interaction. At present, the semantic expressions of bsns data depend on the specific application scenarios, then have no unified standard. Such a lack of compatibility in the standard will lead to a subsequent bottleneck in data sharing of bsns. This paper presents a model that addresses the issue, from low-layer data encapsulation to higher layer data storage, to top-layer application scenarios in bsns. The physiological data from bsns are encapsulated with some metadata, including bsns context, sensor position, time and human health state in the model. The proposed model is cross-platform in terms of sharing physiological data. The results of experiments validate the effectiveness of data sharing in bsns under the proposed model. © 2014 old city publishing, inc.","","","2014","","","","scopus-2-s2.0-84906486398.pdf","scopus-2-s2.0-84906486398"
"Distributed Quasi-Poisson regression algorithm for modeling multi-site count outcomes in distributed data networks","Edmondson M. J., Luo C., Nazmul Islam M., Sheils N. E., Buresh J., Chen Z., Bian J., Chen Y.","Journal of Biomedical Informatics","","BACKGROUND: Observational studies incorporating real-world data from multiple institutions facilitate study of rare outcomes or exposures and improve generalizability of results. Due to privacy concerns surrounding patient-level data sharing across institutions methods for performing regression analyses distributively are desirable. Meta-analysis of institution-specific estimates is commonly used but has been shown to produce biased estimates in certain settings. While distributed regression methods are increasingly available methods for analyzing count outcomes are currently limited. Count data in practice are commonly subject to overdispersion exhibiting greater variability than expected under a given statistical model.\\\\\\\\rOBJECTIVE: We propose a novel computational method a one-shot distributed algorithm for quasi-Poisson regression (ODAP) to distributively model count outcomes while accounting for overdispersion.\\\\\\\\rMETHODS: ODAP incorporates a surrogate likelihood approach to perform distributed quasi-Poisson regression without requiring patient-level data sharing only requiring sharing of aggregate data from each participating institution. ODAP requires at most three rounds of non-iterative communication among institutions to generate coefficient estimates and corresponding standard errors. In simulations we evaluate ODAP under several data scenarios possible in multi-site analyses comparing ODAP and meta-analysis estimates in terms of error relative to pooled regression estimates considered the gold standard. In a proof-of-concept real-world data analysis we similarly compare ODAP and meta-analysis in terms of relative error to pooled estimatation using data from the OneFlorida Clinical Research Consortium modeling length of stay in COVID-19 patients as a function of various patient characteristics. In a second proof-of-concept analysis using the same outcome and covariates we incorporate data from the UnitedHealth Group Clinical Discovery Database together with the OneFlorida data in a distributed analysis to compare estimates produced by ODAP and meta-analysis.\\\\\\\\rRESULTS: In simulations ODAP exhibited negligible error relative to pooled regression estimates across all settings explored. Meta-analysis estimates while largely unbiased were increasingly variable as heterogeneity in the outcome increased across institutions. When baseline expected count was 0.2 relative error for meta-analysis was above 5% in 25% of iterations (250/1000) while the largest relative error for ODAP in any iteration was 3.59%. In our proof-of-concept analysis using only OneFlorida data ODAP estimates were closer to pooled regression estimates than those produced by meta-analysis for all 15 covariates. In our distributed analysis incorporating data from both OneFlorida and the UnitedHealth Group Clinical Discovery Database ODAP and meta-analysis estimates were largely similar while some differences in estimates (as large as 13.8%) could be indicative of bias in meta-analytic estimates.\\\\\\\\rCONCLUSIONS: ODAP performs privacy-preserving communication-efficient distributed quasi-Poisson regression to analyze count outcomes using data stored within multiple institutions. Our method produces estimates nearly matching pooled regression estimates and sometimes more accurate than meta-analysis estimates most notably in settings with relatively low counts and high outcome heterogeneity across institutions. Copyright © 2022 Elsevier Inc. All rights reserved.","","","2022","10.1016/j.jbi.2022.104097","","","medline-35643272.pdf","medline-35643272"
"[Re-evaluation of systematic reviews of acupuncture and moxibustion for childhood autism]","Meng X. R., Cao X., Sun M. L., Deng H., He L. Y., Liu J.","Zhongguo Zhenjiu","","OBJECTIVE: To re-evaluate the systematic review/Meta-analysis of acupuncture and moxibustion for childhood autism (CA) aiming to provide decision-making basis for clinical diagnosis and treatment.\\\\\\\\rMETHODS: The systematic review and/or Meta-analysis of acupuncture and moxibustion for CA were searched in PubMed EMbase Cochrane Library SinoMed CNKI and Wanfang databases. The retrieval time was from the database establishment to May 5th 2022. PRISMA (preferred reporting items for systematic reviews and Meta-analyses) was used to evaluate the report quality and AMSTAR 2 (a measurement tool to assess systematic reviews 2) was used to evaluate the methodological quality bubble map was used to construct the evidence map and GRADE was used to evaluate the quality of evidence.\\\\\\\\rRESULTS: A total of 9 systematic reviews were included. The PRISMA scores ranged from 13 to 26. The report quality was low and there was a serious lack in the aspects of program and registration search other analysis and funding. The main problems in methodology included not making prespecified protocol incomplete retrieval strategy not providing a list of excluded literatures and incomplete explanation on heterogeneity analysis and bias risk. The evidence map showed that 6 conclusions were valid 2 conclusions were possible valid and 1 conclusion was uncertain valid. The overall quality of evidence was low and the main factors leading to the downgrade were limitations followed by inconsistency imprecision and publication bias.\\\\\\\\rCONCLUSION: Acupuncture and moxibustion has a certain effect for CA but the quality of reporting methodology and evidence in included literature need to be improved. It is suggested to perform high-quality and standardized research in the future to provide evidence-based basis.","","","2023","10.13703/j.0255-2930.20220526-k0002","","","medline-36808520.pdf","medline-36808520"
"The Changes in Red Blood Cell Indices That Occur in Pre-Diabetic Patients of all Ethnicities from the 25-45 Years of Age: A Protocol for a Systematic Review and Meta-Analysis","Mzimela N. C., Sosibo A. M., Ngubane P. S., Khathi A.","Methods and Protocols","","Introduction: Pre-diabetes is an intermediate asymptomatic state between normoglycaemia and the onset of type 2 diabetes mellitus (T2D). Recent reports indicate that there are sub-clinical changes observed in red blood cells during pre-diabetes. This systematic review protocol will provide an outline of all procedures in the synthesis of the available data on the changes in red blood cell indices. Methods and Analysis: This protocol was prepared by adhering to the PRISMA 2015 guidelines for reporting protocols. Published clinical studies that involve observation whether it is cross-sectional comparative cross-sectional case-control or cohort study designs that involve normal/non-diabetic and pre-diabetes reports were used. Additionally this was accomplished by using clinical MeSH headings to search on MEDLINE COCHRANE library and African Journal Online. Three reviewers (NCM AMS & AK) screened all the results for eligibility criteria. Then Downs and Black checklist was used to check the risk of bias. Review Manager v5.4 Forrest plot was used for meta-analysis and sensitivity analysis. Strength of evidence was then assessed using the Grading of Recommendations Assessment Development and Evaluation approach (GRADE). Results and Conclusion: This protocol will give direction on the exploration of articles that report on changes in red blood cell indices in the pre-diabetic state. The results obtained from this protocol will further give direction on the research to be done at in the eThekwini district of South Africa. Ethics and Dissemination: The data that will be analyzed will be data that has already been published thus there will be no data collection from subjects. Therefore no ethical clearance is required. Registration Details: This protocol has been registered with the International Prospective Registry of Systematic Reviews (PROSPERO) registration number ""CRD42020189080"" dated 05-07-2020.","","","2023","10.3390/mps6010013","","","medline-36827500.pdf","medline-36827500"
"Data Governance for Real-World Data Management: A Proposal for a Checklist to Support Decision Making","Sola-Morales O., Sigurardottir K., Akehurst R., Murphy L. A., Mestre-Ferrandiz J., Cunningham D., de Pouvourville G.","Value in Health","","OBJECTIVES: Real-world data (RWD) and real-world evidence (RWE) can provide extensive information on healthcare for use in health technology assessment and decision making. Nevertheless there is a lack of consensus surrounding the appropriate data governance (DG) practices for RWD/RWE. Data sharing is also a large concern especially considering evolving data protection regulations. Our objective is to propose recommendations for international standards of evaluating the acceptability of RWD governance practices.\\\\\\\\rMETHODS: After reviewing the literature we created a checklist targeting DG practices for RWD/RWE. We then carried out a 3-round Delphi panel including European policy makers health technology assessment experts and hospital managers. The consensus for each statement was measured and the checklist adjusted accordingly.\\\\\\\\rRESULTS: The literature review identified the main topics regarding RWD/RWE DG practices: data privacy and security data management and linkage data access management and the generation and use of RWE. Members of the Delphi panel (21 experts/25 invited) were presented a total of 24 statements related to each of the topics. Experts demonstrated a progressive level of consensus and importance ratings in all topics and to most statements. We suggest a refined checklist in which the statements rated less important or with less consensus have been removed.\\\\\\\\rCONCLUSIONS: This study suggests how the DG of RWD/RWE could be qualitatively evaluated. We propose checklists that could be used by all RWD/RWE users to help ensure the quality and integrity of RWD/RWE governance and complement data protection law. Copyright © 2023 International Society for Pharmacoeconomics and Outcomes Research Inc. Published by Elsevier Inc. All rights reserved.","","","2023","10.1016/j.jval.2023.02.012","","","medline-36870678.pdf","medline-36870678"
"Social Isolation Selectively Increases Anxiety in Mice without Affecting Depression-like Behavior","Kwak C., Lee S. H., Kaang B. K.","Korean Journal of Physiology & Pharmacology","","It is hypothesized that a number of environmental factors affect animals' behavior. Without controlling these variables it is very hard for researchers to get not only reliable but replicable data from various behavioral experiments testing animals' cognitive as well as emotional functions. For example laboratory mice which had restricted environment showed different synaptic potentiation properties with wild mice (Zhao MG et al. 2009). While performing behavioral experiments however it is sometimes inevitable that the researcher changes the animals' environments as by switching the cages in which experimental animals are housed and separating animals raised together into small experimental groups. In this study we investigated the effect of environmental changes on mice's emotional behaviors by socially isolating them or reducing the size of their cage. We found that social isolation selectively increases the animals' levels of anxiety while leaving depression-like behaviors unchanged. On the other hand alteration of the housing dimensions affected neither their anxiety levels nor their depression-like behaviors. These results suggest that environmental variables may have a prominent impact on experimental animals' emotional behaviors and possibly their psychological states leading to bias in the behavioral data produced from experiments.","","","2009","10.4196/kjpp.2009.13.5.357","","","medline-19915697.pdf","medline-19915697"
"Paucity of Health Data in Africa: An Obstacle to Digital Health Implementation and Evidence-Based Practice","Musa S. M., Haruna U. A., Manirambona E., Eshun G., Ahmad D. M., Dada D. A., Gololo A. A., Musa S. S., Abdulkadir A. K., Lucero-Prisno Iii D. E.","Public Health Reviews","","Background: Among the numerous challenges that Africa faces in improving its healthcare systems the paucity of health data stands out as paramount. This study aims to examine the challenges related to the paucity of health data in Africa and its impact on the implementation of digital health and evidence-based practice. The findings of the study reveal that health data availability in Africa is both limited and frequently of poor quality. Several factors contribute to this concerning situation encompassing inadequate infrastructure a shortage of resources and cultural barriers. Furthermore the available data despite its limitations is often underutilized due to a lack of capacity and expertise in data analysis and interpretation. Policy Options and Recommendations: To improve healthcare delivery in Africa we recommend implementing novel strategies for data collection. It's important to recognize that effective information technology service is crucial for enhancing healthcare delivery and a holistic approach is necessary to achieve this. Conclusion: This brief presents information to help policymakers develop long-term solutions to Africa's health data poverty. Taking action based on this evidence can assist in addressing the problem. Copyright © 2023 Musa Haruna Manirambona Eshun Ahmad Dada Gololo Musa Abdulkadir and Lucero-Prisno III.","","","2023","10.3389/phrs.2023.1605821","","","medline-37705873.pdf","medline-37705873"
"Harmonization of cortical thickness measurements across scanners and sites","Fortin J.-P. And Cullen N. And Sheline Y.i. And Taylor W.d. And Aselcioglu I. And Cook P.a. And Adams P. And Cooper C. And Fava M. And Mcgrath P.j. And Mcinnis M. And Phillips M.l. And Trivedi M.h. And Weissman M.m. And Shinohara R.t.","Neuroimage","","With the proliferation of multi-site neuroimaging studies, there is a greater need for handling non-biological variance introduced by differences in mri scanners and acquisition protocols. Such unwanted sources of variation, which we refer to as ""scanner effects"", can hinder the detection of imaging features associated with clinical covariates of interest and cause spurious findings. In this paper, we investigate scanner effects in two large multi-site studies on cortical thickness measurements across a total of 11 scanners. We propose a set of tools for visualizing and identifying scanner effects that are generalizable to other modalities. We then propose to use combat, a technique adopted from the genomics literature and recently applied to diffusion tensor imaging data, to combine and harmonize cortical thickness values across scanners. We show that combat removes unwanted sources of scan variability while simultaneously increasing the power and reproducibility of subsequent statistical analyses. We also show that combat is useful for combining imaging data with the goal of studying life-span trajectories in the brain.copyright © 2017 elsevier inc.","","","2018","10.1016/j.neuroimage.2017.11.024","","","embase-619354356.pdf","embase-619354356"
"An integrated organisation-wide data quality management and information governance framework: theoretical underpinnings","Liaw, S.-T. And Pearce, C. And Liyanage, H. And Liaw, G.s.s. And De Lusignan, S.","Informatics In Primary Care","","Introduction increasing investment in ehealth aims to improve cost effectiveness and safety of care. Data extraction and aggregation can create new data products to improve professional practice and provide feedback to improve the quality of source data. A previous systematic review concluded that locally relevant clinical indicators and use of clinical record systems could support clinical governance. We aimed to extend and update the review with a theoretical framework. Methods we searched pubmed, medline, web of science, abi inform (proquest) and business source premier (ebsco) using the terms curation, information ecosystem, data quality management (dqm), data governance, information governance (ig) and data stewardship. We focused on and analysed the scope of dqm and ig processes, theoretical frameworks, and determinants of the processing, quality assurance, presentation and sharing of data across the enterprise. Findings there are good theoretical reasons for integrated governance, but there is variable alignment of dqm, ig and health system objectives across the health enterprise. Ethical constraints exist that require health information ecosystems to process data in ways that are aligned with improving health and system efficiencyand ensuring patient safety. Despite an increasingly 'big-data' environment, dqm and ig in health services are still fragmented across the data production cycle. We extend current work on dqm and ig with a theoretical framework for integrated ig across the data cycle. Conclusions the dimensions of this theory-based framework would require testing with qualitative and quantitative studies to examine the applicability and utility, along with an evaluation of its impact on data quality across the health enterprise. Copyright © 2014 the author(s).","","","2014","10.14236/jhi.v21i4.87","","","scopus-2-s2.0-84910152395.pdf","scopus-2-s2.0-84910152395"
"The credibility chasm in policy research from academics, think tanks, and advocacy organizations","Doberstein, C.","Canadian Public Policy","","How do key policy professionals inside government view various sources of policy research? Are there systematic differences in the perceptions of the quality and credibility of research derived from different sources? This is a replication of and expansion on doberstein (2017), which presented a randomized controlled survey experiment using policy analysts to systematically test the source effects of policy research. Doberstein's experimental findings provide evidence for the hypothesis that academic research is perceived to be substantially more credible to government policy analysts than think tank or advocacy organization research, regardless of its content, and that sources perceived as more ideological are much less credible. This study replicates that experiment in three additional canadian provincial governments to verify whether the relationship found in the original study persists in a larger sample and in conjunction with further randomization procedures. This study corroborates the original study's findings, confirming that external policy advice systems are subject to powerful heuristics that bureaucrats use to sift through evidence and advice.","","","2017","10.3138/cpp.2016-067","","","scopus-2-s2.0-85039156695.pdf","scopus-2-s2.0-85039156695"
"Accelerating drug development for Alzheimer's disease through the use of data standards","Neville J., Kopko S., Romero K., Corrigan B., Stafford B., LeRoy E., Broadbent S., Cisneroz M., Wilson E., Reiman E., Vanderstichele H., Arneric S. P., Stephenson D.","Alzheimer's & Dementia : Translational Research & Clinical Interventions","","INTRODUCTION: The exceedingly high rate of failed trials in Alzheimer's disease (AD) calls for immediate attention to improve efficiencies and learning from past ongoing and future trials. Accurate highly rigorous standardized data are at the core of meaningful scientific research. Data standards allow for proper integration of clinical data sets and represent the essential foundation for regulatory endorsement of drug development tools. Such tools increase the potential for success and accuracy of trial results. METHODS: The development of the Clinical Data Interchange Standards Consortium (CDISC) AD therapeutic area data standard was a comprehensive collaborative effort by CDISC and Coalition Against Major Diseases a consortium of the Critical Path Institute. Clinical concepts for AD and mild cognitive impairment were defined and a data standards user guide was created from various sources of input including data dictionaries used in AD clinical trials and observational studies. RESULTS: A comprehensive collection of AD-specific clinical data standards consisting of clinical outcome measures leading candidate genes and cerebrospinal fluid and imaging biomarkers was developed. The AD version 2.0 (V2.0) Therapeutic Area User Guide was developed by diverse experts working with data scientists across multiple consortia through a comprehensive review and revision process. The AD CDISC standard is a publicly available resource to facilitate widespread use and implementation. DISCUSSION: The AD CDISC V2.0 data standard serves as a platform to catalyze reproducible research data integration and efficiencies in clinical trials. It allows for the mapping and integration of available data and provides a foundation for future studies data sharing and long-term registries in AD. The availability of consensus data standards for AD has the potential to facilitate clinical trial initiation and increase sharing and aggregation of data across observational studies and among clinical trials thereby improving our understanding of disease progression and treatment.","","","2017","10.1016/j.trci.2017.03.006","","","pubmed-29067333.pdf","pubmed-29067333"
"Achieving accountable and efficient data sharing in industrial internet of things","Huang, C. And Liu, D. And Ni, J. And Lu, R. And Shen, X.","Ieee Transactions On Industrial Informatics","","In this article, we propose an accountable and efficient data sharing scheme for industrial iot (iiot), named an accountable and data sharing scheme (ads), in which a data owner can pursue the responsibility of a data receiver if the latter leaks some sensitive shared data to the public for profits while without permission (i.e., accountability). Specifically, ads is built upon an adaptive decentralized oblivious transfer protocol together with a zero-knowledge proof technique, which enables the data receiver's private key to be hidden from the data owner and yet correctly embedded into the shared data during the process of data sharing. Once data breaches occur, the private key can be automatically revealed to the data owner so as to achieve the accountability. In addition, with ads, a group of sharing providers can also assist iiot devices in handling heavy computational tasks via the secret sharing technique without sacrificing the security. Extensive performance evaluations are conducted, and the simulation results demonstrate that ads has high computational efficiency, making it well fit for iiot. © 2005-2012 ieee.","","","2021","10.1109/tii.2020.2982942","","","scopus-2-s2.0-85094160257.pdf","scopus-2-s2.0-85094160257"
"Some methodologic considerations in nursing diagnosis research","Phd, M.l.m. And Hardy, M.a. And Craft, M.","International Journal Of Nursing Terminologies And Classifications","","The validation of nursing diagnostic concepts, interventions, and desired outcomes is necessary for the development of nursing science. The purpose of this article is to contribute to the development of more rigorous methods for research of nursing diagnoses. Methodologic problems and issues are discussed and illustrated in the context of a descriptive study of the nursing diagnoses of patients at a large long‐term care facility. Issues surrounding the selection of setting and samples, the source and presentation of data collected, and methods used for data analysis and interpretation are described. The need for consistency among research questions, setting and sample, data collection methods, and data analysis and interpretation are emphasized. Researchers are encouraged to explicate the issues and decisions in nursing diagnosis research to encourage scholarly criticism and refinement by clinicians and scientists. Copyright © 1990, wiley blackwell. All rights reserved","","","1990","10.1111/j.1744-618x.1990.tb00229.x","","","scopus-2-s2.0-84985123284.pdf","scopus-2-s2.0-84985123284"
"Theoretical equilibrium lead(II) solubility revisited: Open source code and practical relationships","Wahman D. G., Pinelli M. D., Schock M. R., Lytle D. A.","Awwa Water Science","","A theoretical equilibrium lead(II) (Pb(II)) solubility model coded in Fortran (LEADSOL) was updated and implemented in open source R code verified against LEADSOL output and used to simulate theoretical equilibrium total soluble Pb(II) (TOTSOLPb) concentrations under a variety of practical scenarios. The developed R code file (app.R) is publicly available for download at GitHub (https://github.com/USEPA/TELSS) along with instructions to run the R code locally allowing the user to explore Pb(II) solubility by selecting desired simulation conditions (e.g. water quality equilibrium constants and Pb(II) solids to consider). In addition the R code serves as a reproducible baseline for alternative model development and future model improvements allowing users to update modify and share the R code to meet their needs. Using the R code several solubility diagrams were generated to highlight practical relationships related to TOTSOLPb concentrations including the impact of pH and dissolved inorganic carbon orthophosphate sulfate and chloride concentrations.","","","2021","10.1002/aws2.1250","","","medline-34938979.pdf","medline-34938979"
"An overview of reproducible 3d seismic data processing and imaging using madagascar","Oren, C. And Nowack, R.l.","Geophysics","","We present an overview of reproducible 3d seismic data processing and imaging using the madagascar open-source software package. So far, there has been a limited number of studies on the processing of real 3ddata sets using open-source software packages.madagascarwith its wide range of individual programs and tools available provides the capability to fully process 3d seismic data sets. The goal is to provide a streamlined illustration of the approach for the implementation of 3d seismic data processing and imaging using the madagascar open-sourcesoftwarepackage.abriefintroductionisfirstgiven to themadagascar open-source software package and the publicly available 3d teapot dome seismic data set. Several processing steps are applied tothe data set, including amplitude gaining, ground roll attenuation, muting, deconvolution, static corrections,spike-likerandomnoiseelimination,normalmoveout (nmo) velocity analysis, nmo correction, stacking, and band-pass filtering.a3dvelocitymodel in depth is created using dix conversion and time-to-depth scaling. Three-dimensional poststack depth migration is then performed followed by f-x deconvolution and structure-enhancing filtering of the migrated image to suppress randomnoise and enhance the useful signal.weshowthatmadagascar,asapowerfulopen-source environment, can be used toconstruct a basicworkflowtoprocess and image 3d seismic data in a reproducible manner. © 2018 society of exploration geophysicists.","","","2018","10.1190/geo2016-0603.1","","","scopus-2-s2.0-85040448715.pdf","scopus-2-s2.0-85040448715"
"Presenting artificial intelligence, deep learning, and machine learning studies to clinicians and healthcare stakeholders: an introductory reference with a guideline and a clinical ai research (cair) checklist proposal","Olczak J. And Pavlopoulos J. And Prijs J. And Ijpma F.f.a. And Doornberg J.n. And Lundstrom C. And Hedlund J. And Gordon M.","Acta Orthop","","Background and purpose - artificial intelligence (ai), deep learning (dl), and machine learning (ml) have become common research fields in orthopedics and medicine in general. Engineers perform much of the work. While they gear the results towards healthcare professionals, the difference in competencies and goals creates challenges for collaboration and knowledge exchange. We aim to provide clinicians with a context and understanding of ai research by facilitating communication between creators, researchers, clinicians, and readers of medical ai and ml research. Methods and results - we present the common tasks, considerations, and pitfalls (both methodological and ethical) that clinicians will encounter in ai research. We discuss the following topics: labeling, missing data, training, testing, and overfitting. Common performance and outcome measures for various ai and ml tasks are presented, including accuracy, precision, recall, f1 score, dice score, the area under the curve, and roc curves. We also discuss ethical considerations in terms of privacy, fairness, autonomy, safety, responsibility, and liability regarding data collecting or sharing. Interpretation - we have developed guidelines for reporting medical ai research to clinicians in the run-up to a broader consensus process. The proposed guidelines consist of a clinical artificial intelligence research (cair) checklist and specific performance metrics guidelines to present and evaluate research using ai components. Researchers, engineers, clinicians, and other stakeholders can use these proposal guidelines and the cair checklist to read, present, and evaluate ai research geared towards a healthcare setting.copyright © 2021 the author(s). Published by taylor & francis on behalf of the nordic orthopedic federation.","","","2021","10.1080/17453674.2021.1918389","","","embase-2011515340.pdf","embase-2011515340"
"Assessing the impact of transdisciplinary research: the usefulness of relevance, credibility, and legitimacy for understanding the link between process and impact","Hansson, S. And Polk, M.","Research Evaluation","","There is a call for more transdisciplinary (td) research, from academia, society, and funding agencies. Consequently, the field of td research is searching for ways of proving the value and providing evidence to support the effectiveness of such research. The main challenge for evaluating td research is attribution, that is how to link societal change to the td research process. However, little attention has been paid to the relationship between the quality of the research process and the effects and impacts that are being evaluated. Building upon earlier attempts at evaluating td research, this article tests three key aspects of effective sustainability research: its relevance, credibility, and legitimacy. To explore the link between the quality of process and societal effects, we analyze and compare outputs, outcomes, and impact of five td projects. Overall, our analysis shows that while relevance, credibility, and legitimacy gave important insights regarding the links between process and impacts, they are not adequate for evaluating td research impact. Process qualities such as practitioner motivation and perceived importance of the project, together with breadth of perspectives, the openness/flexibility of participants, and in-depth exchanges of expertise and knowledge, contributed to producing internally relevant, credible, and legitimate results. However, we also saw a need to develop the relevance, credibility, and legitimacy framework, in relation to the external dynamics of the project process, heterogeneous stakeholder groups, and the credibility of practice-based knowledge, which together with institutional factors and the political context significantly shape the possibility of impact. ©the author(s) 2018. Published by oxford university press.","","","2018","10.1093/reseval/rvy004","","","scopus-2-s2.0-85045514978.pdf","scopus-2-s2.0-85045514978"
"Informatics progress of the Global Burden of Animal Diseases programme towards data for One Health","Raymond K., BenSassi N., Patterson G. T., Huntington B., Rushton J., Stacey D. A., Bernardo T. M.","Revue Scientifique et Technique","","The Global Burden of Animal Diseases (GBADs) programme will provide data-driven evidence that policy-makers can use to evaluate options inform decisions and measure the success of animal health and welfare interventions. The GBADs' Informatics team is developing a transparent process for identifying analysing visualising and sharing data to calculate livestock disease burdens and drive models and dashboards. These data can be combined with data on other global burdens (human health crop loss foodborne diseases) to provide a comprehensive range of information on One Health required to address such issues as antimicrobial resistance and climate change. The programme began by gathering open data from international organisations (which are undergoing their own digital transformations). Efforts to achieve an accurate estimate of livestock numbers revealed problems in finding accessing and reconciling data from different sources over time. Ontologies and graph databases are being developed to bridge data silos and improve the findability and interoperability of data. Dashboards data stories a documentation website and a Data Governance Handbook explain GBADs data now available through an application programming interface. Sharing data quality assessments builds trust in such data encouraging their application to livestock and One Health issues. Animal welfare data present a particular challenge as much of this information is held privately and discussions continue regarding which data are the most relevant. Accurate livestock numbers are an essential input for calculating biomass which subsequently feeds into calculations of antimicrobial use and climate change. The GBADs data are also essential to at least eight of the United Nations Sustainable Development Goals.","","","2023","10.20506/rst.42.3365","","","medline-37232302.pdf","medline-37232302"
"Revocable identity-based broadcast proxy re-encryption for data sharing in clouds","Ge, C. And Liu, Z. And Xia, J. And Fang, L.","Ieee Transactions On Dependable And Secure Computing","","Cloud computing has become prevalent due to its nature of massive storage and vast computing capabilities. Ensuring a secure data sharing is critical to cloud applications. Recently, a number of identity-based broadcast proxy re-encryption (ib-bpre) schemes have been proposed to resolve the problem. However, the ib-bpre requires a cloud user (alice) who wants to share data with a bunch of other users (e.g., colleagues) to participate the group shared key renewal process because alice's private key is a prerequisite for shared key generation. This, however, does not leverage the benefit of cloud computing and causes the inconvenience for cloud users. Therefore, a novel security notion named revocable identity-based broadcast proxy re-encryption (rib-bpre) is presented to address the issue of key revocation in this work. In a rib-bpre scheme, a proxy can revoke a set of delegates, designated by the delegator, from the re-encryption key. The performance evaluation reveals that the proposed scheme is efficient and practical. © 2004-2012 ieee.","","","2021","10.1109/tdsc.2019.2899300","","","scopus-2-s2.0-85106052467.pdf","scopus-2-s2.0-85106052467"
"Embracing research in nursing practice","Jones, S.","British Journal Of Nursing","","The establishment of an integrated research culture in medicine has contributed to the ongoing success of medical science in treating disease. Research examining the effectiveness of services and care is of increasing priority, and is a branch of research open to all health professionals. This article provides an overview of the research process aimed at health professionals with novice research skills. It will provide tools and resources to guide health professionals in the development of research concepts leading to a feasible protocol.","","","2014","10.12968/bjon.2014.23.18.994","","","scopus-2-s2.0-84910035792.pdf","scopus-2-s2.0-84910035792"
"Shared care for diabetes: supporting communication between primary and secondary care","Branger P. J., van't Hooft A., van der Wouden J. C., Moorman P. W., van Bemmel J. H.","International Journal of Medical Informatics","","OBJECTIVE: To assess the effects on information exchange of electronic communication between physicians co-treating diabetic patients.\\\\\\\\rDESIGN: Comparison of traditional paper-based communication for reporting and electronic communication.\\\\\\\\rSETTING: General practitioners and an internal medicine outpatient clinic of an urban public hospital.\\\\\\\\rSUBJECTS: A total of 275 diabetic patients and the 32 general practitioners and one internal medicine consultant who cared for them.\\\\\\\\rINTERVENTION: An electronic communication network linking up the computer-based patient records of the physicians thus enabling electronic data interchange.\\\\\\\\rMAIN OUTCOME MEASURES: Number of letters sent and received per year by the general practitioners the number of diabetes-related parameters (e.g. results of laboratory tests) in the patient records and HBA1C levels.\\\\\\\\rRESULTS: INTERVENTION GPs received more messages per year (1.6 per patient) than control GPs (0.5 per patient P<0.05). Significant higher availability (P<0.05) was achieved for data on HBA1C levels fructosamine levels blood pressure measurements cholesterol levels triglyceride levels and weight measurements. INTERVENTION patients showed a slight but significant decrease of HBA1C levels in the second semester of 1994 (from 7.0 to 6.8 P = 0.03) control patients also showed a slightly decreased group mean but this change was not significant (from 6.6 to 6.5 P = 0.52). The magnitudes of these mean differences however were not significantly different (intervention group: 0.21; control group: 0.12 P = 0.68).\\\\\\\\rCONCLUSIONS: The electronic communication network for exchanging consultation outcomes significantly increased frequency of communication and the availability of data to the general practitioner on diagnostic procedures performed in the hospital thus providing more complete information about the care that patients are receiving. A large-scale experiment over a longer period of time is needed to assess the effects of improved communication on quality of care.","","","1999","10.1016/s1386-5056(98)00154-3","","","medline-10193883.pdf","medline-10193883"
"Application of a selected pseudorandom number generator for the reliability of farm tractors","Durczak, K. And Rybacki, P. And Sujak, A.","Applied Sciences (Switzerland)","","Knowledge of the use-to-failure periods of process equipment, including agricultural vehicles, is essential for the determination of their durability and reliability. Obtaining any empirical data on this issue is difficult and sometimes impossible. Experimental studies are costly and time-consuming. Manufacturers are usually reluctant to share such data, claiming that the information is classified for the sake of their companies. The purpose of this study was to compare empirical data with data generated using adequate statistical tools. The newly generated and very similar in value pseudorandom numbers were obtained by simulations using the monte carlo, latin hypercube sampling and iman-conover methods. Reliability function graphs obtained from the generated time-series (use-to-failure periods) with matching weibull distribution had very similar shape and scale parameters. They were are also comparable to parameters from experimental data extracted from a polish zetor agricultural tractor service station. The validation of the applied methods was limited as it was carried out only on the basis of the available data. Analysis of line graphs of cumulative deviations of the values of use-to-failure periods (times-to-fail) generated against empirical times-to-fail indicated that the best method in the studied case was the monte carlo method. © 2022 by the authors.","","","2022","10.3390/app122312452","","","scopus-2-s2.0-85143832712.pdf","scopus-2-s2.0-85143832712"
"A case for using grid architecture for state public health informatics: the Utah perspective","Staes C. J., Xu W., LeFevre S. D., Price R. C., Narus S. P., Gundlapalli A., Rolfs R., Nangle B., Samore M., Facelli J. C.","BMC Medical Informatics & Decision Making","","This paper presents the rationale for designing and implementing the next-generation of public health information systems using grid computing concepts and tools. Our attempt is to evaluate all grid types including data grids for sharing information and computational grids for accessing computational resources on demand. Public health is a broad domain that requires coordinated uses of disparate and heterogeneous information systems. System interoperability in public health is limited. The next-generation public health information systems must overcome barriers to integration and interoperability leverage advances in information technology address emerging requirements and meet the needs of all stakeholders. Grid-based architecture provides one potential technical solution that deserves serious consideration. Within this context we describe three discrete public health information system problems and the process by which the Utah Department of Health (UDOH) and the Department of Biomedical Informatics at the University of Utah in the United States has approached the exploration for eventual deployment of a Utah Public Health Informatics Grid. These three problems are: i) integration of internal and external data sources with analytic tools and computational resources; ii) provide external stakeholders with access to public health data and services; and iii) access integrate and analyze internal data for the timely monitoring of population health status and health services. After one year of experience we have successfully implemented federated queries across disparate administrative domains and have identified challenges and potential solutions concerning the selection of candidate analytic grid services data sharing concerns security models and strategies for reducing expertise required at a public health agency to implement a public health grid.","","","2009","10.1186/1472-6947-9-32","","","medline-19545428.pdf","medline-19545428"
"Reporting of “theoretical design” in explanatory research: a critical appraisal of research on early life exposure to antibiotics and the occurrence of asthma","Bentouhami, H. And Casas, L. And Weyler, J.","Clinical Epidemiology","","“Theoretical design” comprises the development of an occurrence relation and the specification of the study domain. In explanatory research, the occurrence relation causally relates one determinant to the occurrence (of an event or a state) taking into account other relevant characteristics (confounders and modifiers). Conflicting results in explanatory research might be (partially) explained by differences in the “theoretical design” or by a mismatch between the “theoretical design” and the “design of data collection”. In this critical review, the reporting of “theoretical design” is assessed in articles on the association between early life antibiotic use and the occurrence of asthma. Articles investigating a relationship between early life antibiotic use and the occurrence of asthma were searched in pubmed and systematically selected for critical review. The full text was read and important elements of study design were extracted (the research question/hypothesis, seven key elements of “theoretical design” (measure of occurrence, case (event or state) definition, conceptualization (and operationalization) of the exposure, temporal relation between out-come and exposure, confounders and effect modifiers taken into account and the domain of the study), the method of data collection and the method of data processing). A comparison was made between articles published before and after the publication of the “strengthening the reporting of observational studies in epidemiology” (strobe) statement (2007). Sixty-three articles were included for review. Thirteen articles reported the seven key elements of “theoretical design” that were questioned. No marked differences in reporting were observed pre-and post-strobe. All articles reported some key elements of “theore-tical design”;  however, the reporting is not structured and not linked to the concept of “theoretical design”. Conceptualizing, delineating and explicit reporting of “theoretical design” is quintessential for the quality and transparency of explanatory research. © 2021 bentouhami et al.","","","2021","10.2147/clep.s318287","","","scopus-2-s2.0-85114172997.pdf","scopus-2-s2.0-85114172997"
"Advancing mechanisms of implementation to accelerate sustainable evidence-based practice integration: protocol for generating a research agenda","Lewis, C.c. And Powell, B.j. And Brewer, S.k. And Nguyen, A.m. And Schriger, S.h. And Vejnoska, S.f. And Walsh-Bailey, C. And Aarons, G.a. And Beidas, R.s. And Lyon, A.r. And Weiner, B. And Williams, N. And Mittman, B.","Bmj Open","","Introduction mechanisms explain how implementation strategies work. Implementation research requires careful operationalisation and empirical study of the causal pathway(s) by which strategies effect change, and factors that may amplify or weaken their effects. Understanding mechanisms is critically important to replicate findings, learn from negative studies or adapt an implementation strategy developed in one setting to another. Without understanding implementation mechanisms, it is difficult to design strategies to produce expected effects across contexts, which may have disproportionate effects on settings in which priority populations receive care. This manuscript outlines the protocol for an agency for healthcare research and quality-funded initiative to: (1) establish priorities for an agenda to guide research on implementation mechanisms in health and public health, and (2) disseminate the agenda to research, policy and practice audiences. Methods and analysis a network of scientific experts will convene in 'deep dive' meetings across 3 years. A research agenda will be generated through analysis and synthesis of information from six sources: (1) systematic reviews, (2) network members' approaches to studying mechanisms, (3) new proposals presented in implementation proposal feedback sessions, (4) working group sessions conducted in a leading implementation research training institute, (5) breakout sessions at the society for implementation research collaboration's (sirc) 2019 conference and (6) sirc conference abstracts. Two members will extract mechanism-relevant text segments from each data source and a third member will generate statements as an input for concept mapping. Concept mapping will generate unique clusters of challenges, and the network will engage in a nominal group process to identify priorities for the research agenda. Ethics and dissemination this initiative will yield an actionable research agenda to guide research to identify and test mechanisms of change for implementation strategies. The agenda will be disseminated via multiple channels to solicit feedback and promote rigorous research on implementation mechanisms. © 2021 author(s). Published by bmj.","","","2021","10.1136/bmjopen-2021-053474","","","scopus-2-s2.0-85117788290.pdf","scopus-2-s2.0-85117788290"
"A systematic mapping of funders of maternal health intervention research 2000-2012","Footman, K. And Chersich, M. And Blaauw, D. And Campbell, O.m.r. And Dhana, A. And Kavanagh, J. And Dumbaugh, M. And Thwala, S. And Bijlmakers, L. And Vargas, E. And Kern, E. And Becerra, F. And Penn-Kekana, L.","Globalization And Health","","Background: the priorities of research funding bodies govern the research agenda, which has important implications for the provision of evidence to inform policy. This study examines the research funding landscape for maternal health interventions in low- and middle-income countries (lmics). Methods: this review draws on a database of 2340 academic papers collected through a large-scale systematic mapping of research on maternal health interventions in lmics published from 2000-2012. The names of funders acknowledged on each paper were extracted and categorised into groups. It was noted whether support took a specific form, such as staff fellowships or drugs. Variations between funder types across regions and topics of research were assessed. Results: funding sources were only reported in 1572 (67%) of articles reviewed. A high number of different funders (685) were acknowledged, but only a few dominated funding of published research. Bilateral funders, national research agencies and private foundations were most prominent, while private companies were most commonly acknowledged for support 'in kind'. The intervention topics and geographic regions of research funded by the various funder types had much in common, with hiv being the most common topic and sub-saharan africa being the most common region for all types of funder. Publication outputs rose substantially for several funder types over the period, with the largest increase among bilateral funders. Conclusions: a considerable number of organisations provide funding for maternal health research, but a handful account for most funding acknowledgements. Broadly speaking, these organisations address similar topics and regions. This suggests little coordination between funding agencies, risking duplication and neglect of some areas of maternal health research, and limiting the ability of organisations to develop the specialised skills required for systematically addressing a research topic. Greater transparency in reporting of funding is required, as the role of funders in the research process is often unclear. © 2014 footman et al.;  licensee biomed central ltd.","","","2014","10.1186/s12992-014-0072-x","","","scopus-2-s2.0-84925794701.pdf","scopus-2-s2.0-84925794701"
"Study on consistency for shielding problem of objects in ar","Ohmura, Y. And Hamamoto, K.","Ieej Transactions On Electronics, Information And Systems","","Ar technology lias become to attract attention in various fields. In addition, device in which you can see direct ar like see-through hmd has also been developed. As a result, the ar is related with our lives even more is expected. However. Ar current technology is not perfect. For example, there is a case where the relationship before and after of the object and the virtual reality is not made up. Solutions as existing research, using a transparent model exists. However because it is manually create transparent model, lack versatility. So, i propose a method to automatically create the shape of the transparent model from video. © 2014 the institute of electrical engineers of japan.","","","2014","10.1541/ieejeiss.134.1483","","","scopus-2-s2.0-84907695701.pdf","scopus-2-s2.0-84907695701"
"Participatory complexity in tourism policy: understanding sustainability programmes with participatory systems mapping","Suno Wu, J. And Barbrook-Johnson, P. And Font, X.","Annals Of Tourism Research","","Linear logic models are insufficient to understand how interventions work in complex areas such as sustainable tourism. We present participatory systems mapping (psm), a novel method to develop shared understandings and collective management of complex policy issues among stakeholders. We use psm with stakeholders in barcelona to support the design of an upcoming evaluation of an existing sustainability programme. Discussion during workshops, and analysis of the psm map produced, suggest sharing best practices and improving peer-to-peer learning are pivotal to improving sustainability. We show how a complex systems approach, implemented via psm, can provide a more holistic understanding of the contexts and interactions of tourism policy. We offer learning and guidance on how the method can be used by others. © 2021 the authors","","","2021","10.1016/j.annals.2021.103269","","","scopus-2-s2.0-85110123030.pdf","scopus-2-s2.0-85110123030"
"A protocol for the development of the STROCSS guideline: Strengthening the Reporting of Cohort Studies in Surgery","Agha R. A., Borrelli M. R., Vella-Baldacchino M., Thavayogan R., Orgill D. P.","International Journal of Surgery Protocols","","INTRODUCTION: Strengthening the reporting of observational studies in epidemiology (STROBE) coined in 2007 highlighted the importance of improving the quality of observational research by providing an item checklist in order to avoid inadequate reporting of research. However currently there are no reporting guidelines specific to surgical cohort studies which have an extremely important role within the surgical literature. The recent development of surgery specific guidelines has underscored how surgical and procedural interventions require additional detail for readers to have a complete clear transparent and reproducible understanding. The objective of this research is to conduct a Delphi consensus exercise to develop the STROCSS guideline (Strengthening the Reporting of Cohort Studies in Surgery). METHODS AND ANALYSIS: Current guidelines for case series (PROCESS) Cohort Studies (STROBE) and randomised controlled trials (CONSORT) will be analysed to compile items to form baseline material for developing cohort guidelines in the Delphi consensus exercise. The Delphi questionnaire will be administered via Google Forms and conducted using standard Delphi Methodology. Surgeons and individuals with significant experience of reviewing cohort studies as well as those with experience in developing reporting guidelines will be invited to participate. In the first round existing items from PROCESS and STROBE will be put forward and participants will be invited to augment them or contribute further items for consideration. The provisional guidelines will then be updated in successive rounds using the nine-point Likert scale as proposed by the Grading Recommendations Assessment Development and Evaluations (GRADE) working group. This process will be used to agree Standard definitions for the outcomes. DISSEMINATION: The work will be published in a peer-reviewed journal and presented at national and international meetings. Findings will be disseminated to interested parties and journals will be encouraged to endorse the reporting guidelines.","","","2017","10.1016/j.isjp.2017.08.001","","","pubmed-31851747.pdf","pubmed-31851747"
"Consequences of common data analysis inaccuracies in CNS trauma injury basic research","Burke D. A., Whittemore S. R., Magnuson D. S.","Journal of Neurotrauma","","The development of successful treatments for humans after traumatic brain or spinal cord injuries (TBI and SCI respectively) requires animal research. This effort can be hampered when promising experimental results cannot be replicated because of incorrect data analysis procedures. To identify and hopefully avoid these errors in future studies the articles in seven journals with the highest number of basic science central nervous system TBI and SCI animal research studies published in 2010 (N=125 articles) were reviewed for their data analysis procedures. After identifying the most common statistical errors the implications of those findings were demonstrated by reanalyzing previously published data from our laboratories using the identified inappropriate statistical procedures then comparing the two sets of results. Overall 70% of the articles contained at least one type of inappropriate statistical procedure. The highest percentage involved incorrect post hoc t-tests (56.4%) followed by inappropriate parametric statistics (analysis of variance and t-test; 37.6%). Repeated Measures analysis was inappropriately missing in 52.0% of all articles and among those with behavioral assessments 58% were analyzed incorrectly. Reanalysis of our published data using the most common inappropriate statistical procedures resulted in a 14.1% average increase in significant effects compared to the original results. Specifically an increase of 15.5% occurred with Independent t-tests and 11.1% after incorrect post hoc t-tests. Utilizing proper statistical procedures can allow more-definitive conclusions facilitate replicability of research results and enable more accurate translation of those results to the clinic.","","","2013","10.1089/neu.2012.2704","","","medline-23186206.pdf","medline-23186206"
"Evaluation of the Completeness of Interventions Reported in Published Randomized Controlled Trials in Plastic Surgery: A Systematic Review","Evans S., Rauh S., Jellison S., Diener B., Agha R., Vassar M.","Aesthetic Surgery Journal","","BACKGROUND: With the increasing number of randomized control trials being conducted and published in plastic surgery complete reporting of trial information is critical for readers to properly evaluate a trial's methodology and arrive at appropriate conclusions about its merits and applicability to patients. The Template for Intervention Description and Replication (TIDieR) checklist was introduced to address the limited guidance for reporting trial interventions.\\\\\\\\rOBJECTIVES: The authors applied the TIDieR checklist to evaluate the completeness of intervention reporting of randomized control trials in plastic surgery compare the quality of intervention reporting before and after the guideline was published and evaluate characteristics associated with TIDieR compliance.\\\\\\\\rMETHODS: A PubMed search identified 1 cohort published prior to the release of TIDieR and another published after its release. From the final sample the TIDieR checklist was applied to intervention descriptions and relevant study characteristics were extracted in a duplicate blinded manner.\\\\\\\\rRESULTS: In total 130 trials were included for analysis. The mean TIDieR score was 6.4 of 12. Five items were reported 90% of the time and 4 items were reported less than 10% of the time. We found that TIDieR publication did not affect intervention reporting (P = 0.22).\\\\\\\\rCONCLUSIONS: Our study identified areas in which intervention reporting could be improved. The extent of TIDieR adoption by trialists appears to be limited and greater efforts are needed to disseminate this reporting guideline if widespread uptake is to be expected. Alternately it may be beneficial to incorporate TIDieR into the more widely recognized Consolidated Standards of Reporting Trials statement. Copyright © 2020 The Aesthetic Society. Reprints and permission: journals.permissions@oup.com.","","","2021","10.1093/asj/sjaa166","","","medline-32530461.pdf","medline-32530461"
"Solving problems of disclosure risk in an academic setting: using a combination of restricted data and restricted access methods","Rodgers W., Nolte M.","Journal of Empirical Research on Human Research Ethics","","THE HEALTH AND RETIREMENT STUDY collects a vast amount of information about a sample of the U.S. population over age 50 from biennial interviews supplemental questionnaires and through linkages with administrative data including Social Security earnings and benefits records and Medicare claims records. To h onor i ts p ledge to t he r espondents that their data will be kept confidential but at the same time meet its objective of providing useful data to researchers it has develop ed procedures for stripping sensitive information (i.e. information that could facilitate re-identification of sample members) from data sets that are publicly released and also for providing mechanisms for qualified researchers to gain access to a variety of restricted-access data files. These mechanisms include a procedure whereby highly qualified researchersin particular only those who have a current grant from a federal agencycan apply to obtain restricted-access data sets for a limited amount of time with the understanding that they will make no attempt to r e-identify s amp le m embers and t hat they w ill be audited to ensure that they have adhered to the agreedupon safeguards. For those who meet some but not all of the requirements for receiving these data the files can be analyzed in a data enclave (a controlled secure environment in which eligible researchers can perform analyses). This paper focuses on approaches to restricting data access that may need to be considered by investigators who plan to share their data and by their institutional officials who will need to support that effort with appropriate infrastructure and policies. It also provides guidance to investigators and institutional review boards (IRBs) who seek access to restricted data generated and archived elsewhere.","","","2006","10.1525/jer.2006.1.3.85","","","medline-19385825.pdf","medline-19385825"
"The transparency paradox: when transparency cues helps or backfires for brands?","Reck, R. And Castagna, A.c. And Shuqair, S. And Costa Pinto, D.","Journal Of Cleaner Production","","Prior research indicates that transparency of corporate social responsibility (csr) claims increases consumers' positive reactions to the firm. However, this article suggests that this effect depends on the interplay between transparency cues (presence vs. absence) and brand strength (small vs. large). Our set of experimental studies examine the effect of information transparency and brand strength on consumers' purchasing intentions toward fashion products. Findings indicate a surprising effect of transparency cues: while its presence improves consumers' responses to csr of small brands, it reduces consumers’ outcomes towards large brands. Results also suggest that trust mediates the effects since transparency cues boost consumers' trust toward small (vs. large) brands. This research further suggests that greenwashing practices as a boundary condition of transparency effects, since csr communication with an honest (vs. greenwashing) focus fosters the transparency effects. The findings have important implications for effective csr strategies in the fashion industry. © 2022 elsevier ltd","","","2022","10.1016/j.jclepro.2022.133381","","","scopus-2-s2.0-85137161932.pdf","scopus-2-s2.0-85137161932"
"How to know what works in alleviating poverty: Learning from experimental approaches in qualitative research","Hartman A., Kern F. G.","World Development","","Experimental studies of poverty alleviation have stimulated an interdisciplinary discussion on what constitutes robust evidence to inform policy and benefit the poor. These studies emphasize research transparency and reporting standards pre-registration data sharing replication and aggregated evidence. Though imperfect such practices help to identify what works under what conditions. We argue that researchers should also explore how similar practices could be tailored for qualitative research on the politics of poverty alleviation. We outline a research framework motivated by the experiment focused Metaketa initiative that incorporates the strengths of qualitative inquiry. We present the eleven pillars of a qualitative Metaketa. © 2019 Elsevier Ltd","","","2020","10.1016/j.worlddev.2019.104804","","","scopus-2-s2.0-85076840308.pdf","scopus-2-s2.0-85076840308"
"Treatment of paediatric trigger finger: a systematic review and treatment algorithm","Womack M. E., Ryan J. C., Shillingford-Cole V., Speicher S., Hogue G. D.","Journal of Childrens Orthopaedics","","PURPOSE: Paediatric trigger finger (PTF) is a rare condition as seen by the lack of studies published about paediatric populations. Due to this general lack of information the steps to employ to correct this disorder whether surgically or non-surgically have not yet reached consensus status. The objective of this study is to review the published literature regarding treatment options for PTF in order to develop a proposed step-wise treatment algorithm for children presenting with trigger finger.\\\\\\\\rMETHODS: A systematic review of the literature was conducted on PubMed to locate English language studies reporting on treatment interventions of PTF. Data was collected on number of patients/fingers seen in the study the category of the fingers involved the number of patients/fingers undergoing each intervention and reported outcomes.\\\\\\\\rRESULTS: Seven articles reporting on 118 trigger fingers were identified. In all 64 fingers were treated non-surgically with 57.8% (37/64) resolving. In all 54 fingers were initially surgically treated with 87% (47/54) resolving. In total 34 fingers did not have resolution of symptoms following primary treatment and 27 fingers received follow-up treatment with 92.6% (25/27) resolving. Overall 92.4% (109/118) of fingers achieved resolution of symptoms after all treatments were completed.\\\\\\\\rCONCLUSION: Limitations for this study included few prospective studies and small sample sizes. This is likely due to the rarity of PTF. This review of the literature indicated that a step-wise approach including non-operative and surgical techniques should be employed in the management of PTF.\\\\\\\\rLEVEL OF EVIDENCE III: This work meets the requirements of the PRISMA guidelines (Preferred Reporting Items for Systematic Reviews and Meta-Analyses).","","","2018","10.1302/1863-2548.12.180058","","","medline-29951119.pdf","medline-29951119"
"An evaluation of different measures of dynamically recrystallized grain size for paleopiezometry or paleowattometry studies","Lopez-Sanchez, M.a. And Llana-Fúnez, S.","Solid Earth","","Paleopiezometry and paleowattometry studies are essential to validate models of lithospheric deformation and therefore increasingly common in structural geology. These studies require a single measure of dynamically recrystallized grain size in natural mylonites to estimate the magnitude of differential paleostress (or the rate of mechanical work). This contribution tests the various measures of grain size used in the literature and proposes the frequency peak of a grain size distribution as the most robust estimator for paleopiezometry or paleowattometry studies. The novelty of the approach resides in the use of the gaussian kernel density estimator as an alternative to the classical histograms, which improves reproducibility. A free, open-source, easyto- handle script named grainsizetools (https://sourceforge. net/projects/grainsizetools/) was developed with the aim of facilitating the adoption of this measure of grain size in paleopiezometry or paleowattometry studies. The major advantage of the script over other programs is that by using the gaussian kernel density estimator and by avoiding manual steps in the estimation of the frequency peak, the reproducibility of results is improved. © author(s) 2015. Cc attribution 3.0 license.","","","2015","10.5194/se-6-475-2015","","","scopus-2-s2.0-84929164168.pdf","scopus-2-s2.0-84929164168"
"Reacting to prognostic covariate imbalance in randomised controlled trials","Coskinas, X. And Schou, I.m. And Simes, J. And Martin, A.","Contemporary Clinical Trials","","Clinical trialists may regard an observed imbalance on a prognostic covariate as sufficiently troubling to warrant action. Objective: to elucidate the issues associated with selecting, and switching between, an unadjusted versus an adjusted analysis in response to an observed covariate imbalance. Study design and setting: simulation study performed under the null hypothesis of no treatment effect using data from a large secondary prevention trial of statin therapy. The operating characteristics of three reaction strategies to baseline imbalances observed post-hoc were assessed. Results: unadjusted analyses produced valid p-values irrespective of chance imbalance on a prognostic covariate. Switching to an adjusted analysis introduced no bias when the decision was made without knowledge of the direction of the imbalance. When the decision was based on the direction of the imbalance, the risk of incorrectly declaring the experimental treatment superior was inflated (by up to 48% in the scenarios investigated). Conclusion: overreaction to baseline imbalances observed post-hoc is unwarranted and we support adherence to the ich guideline recommendations on the use of covariates. A legitimate case for switching to an adjusted analysis prior to finalisation of the statistical analysis plan (sap) could nevertheless be potentially made provided that the direction of an observed covariate imbalance is unknown. Investigators should avoid reviewing the distribution of baseline characteristics across randomised groups in an unblinded fashion, for open-label and blinded studies alike, prior to finalisation of the sap. What is new: ich guidelines on adjustment for covariates in rct analyses appropriately advise against overreaction to baseline imbalances observed post-hoc. Consort reporting guidelines nevertheless place an emphasis on comparability of baseline characteristics across randomised groups. We demonstrate through a series of simulation studies why the ich guidance is sound, but that a switch to an adjusted analysis in reaction to an observed prognostic covariate imbalance could legitimately be made provided that, when reaching the decision, treatment allocation is masked, and the direction of the imbalance is unknown. Trialists should therefore consider preserving the masking of actual treatment assignment when assessing the distribution of baseline characteristics across randomised groups. © 2021 elsevier inc.","","","2021","10.1016/j.cct.2021.106544","","","scopus-2-s2.0-85114140555.pdf","scopus-2-s2.0-85114140555"
"Achieving searchable and privacy-preserving data sharing for cloud-assisted e-healthcare system","Xu, C. And Wang, N. And Zhu, L. And Sharif, K. And Zhang, C.","Ieee Internet Of Things Journal","","The integration of wearable wireless devices and cloud computing in e-health systems has significantly improved their effectiveness and availability. Patients can upload their personal health information (phi) files to the cloud, from where the health service providers (hsps) can obtain appropriate information to determine the health state. This system not only reduces the costs associated to healthcare but also provides timely diagnosis to save lives. However, a number of privacy concerns arise while sharing sensitive information. In this paper, we propose a novel privacy-preserving patient health information sharing scheme, which allows hsps to access and search phi files in a secure yet efficient manner. We make use of the searchable encryption technique with keyword range search and multikeyword search. The proposed privacy-preserving equality test protocol allows different types of numeric comparison searches on encrypted data. We also use a variant of bloom filter and message authentication code to classify phi files, filter false data, and check integrity of search results. The simulations on real-world and synthetic data show the feasibility and efficiency of the system, and security analysis proves the privacy-preservation properties. © 2014 ieee.","","","2019","10.1109/jiot.2019.2917186","","","scopus-2-s2.0-85073415277.pdf","scopus-2-s2.0-85073415277"
"A preliminary comparative study on the expressive power of reo and linda","Amaro, S. And Pimentel, E. And Roldan, A.m.","Electronic Notes In Theoretical Computer Science","","Component-based software development is an emerging discipline in the field of software engineering. In this context, coordination languages may be used to specify the interactive behavior of software components, and most of the proposals presented in the literature are based on shared data-space models, as linda. On the other hand, a new model for coordination based on communication channels (reo) is also emerging, and we argue it also can be used to describe component protocols in a very elegant way. Making a comparative analysis on the expressiveness of this channel based model and linda is the main objective of the present work, which presents a first step to make an exhaustive formal study. Thus, in this paper we provide a couple of modular embeddings for the synchronous case and the asynchronous case by defining a common formalism in order to allow the comparison of both models at an homogeneous level of abstraction. We hope these results will help us to develop a complete study about the reo's expressiveness, and to define an interaction description language based on reo for component coordination, as it has already made in the context of linda. © 2007 elsevier b.v. All rights reserved.","","","2007","10.1016/j.entcs.2006.10.043","","","scopus-2-s2.0-34250220306.pdf","scopus-2-s2.0-34250220306"
"A Bayesian statistics tutorial for clinical research: Prior distributions and meaningful results for small clinical samples","Larson C., Kaplan D., Girolamo T., Kover S. T., Eigsti I. M.","Journal of Clinical Psychology","","OBJECTIVES: Bayesian statistics provides an effective reliable approach for research with small clinical samples and yields clinically meaningful results that can bridge research and practice. This tutorial demonstrates how Bayesian statistics can be effectively and reliably implemented with a small heterogeneous participant sample to promote reproducible and clinically relevant research.\\\\\\\\rMETHODS/RESULTS: We tested example research questions pertaining to language and clinical features in autism spectrum disorder (ASD; n = 20) a condition characterized by significant heterogeneity. We provide step-by-step instructions and visualizations detailing how to (1) identify and develop prior distributions from the literature base (2) evaluate model convergence and reliability and (3) compare models with different prior distributions to select the best performing model. Moreover in step three we demonstrate how to determine whether a sample size is sufficient for reliably interpreting model results. We also provide instructions detailing how to examine results with varied bounds of clinical interest such as the probability that an effect will reflect at least one standard deviation change in scores on a standardized assessment. This information facilitates generalization and application of Bayesian results to a variety of clinical research questions and settings.\\\\\\\\rCONCLUSION: The tutorial concludes with suggestions for future clinical research ensuring the utility of our step-by-step instructions for a broad clinical audience. Copyright © 2023 Wiley Periodicals LLC.","","","2023","10.1002/jclp.23570","","","medline-37477577.pdf","medline-37477577"
"Science and industry: sharing knowledge for innovation","Hoarau, H. And Kline, C.","Annals Of Tourism Research","","This paper contributes to a better understanding of the absorption of scientific knowledge in tourism innovation processes. Based on a synthesis of the literature and empirical study we present the model of innovation through co-creation. The cases of researchers working together with three whale-watching firms have allowed us to illustrate examples of co-creation, knowledge sharing and reflexivity during tourism firms' innovation processes. Intensive interaction of the tourism industry with researchers pays off in terms of innovation because flows of knowledge are intimately linked to social capital developed through intensive and frequent shared practice. Besides the theoretical implications of our model, we contribute to the field by providing practical implications for how tourism firms can organize their learning and innovation processes. © 2014 elsevier ltd.","","","2014","10.1016/j.annals.2014.01.005","","","scopus-2-s2.0-84896357468.pdf","scopus-2-s2.0-84896357468"
"Design principles for shared digital twins in distributed systems","Haße, H. And Van Der Valk, H. And Möller, F. And Otto, B.","Business And Information Systems Engineering","","Digital twins offer considerable potential for cross-company networks. Recent research primarily focuses on using digital twins within the limits of a single organization. However, shared digital twins extend application boundaries to cross-company utilization through their ability to act as a hub to share data. This results in the need to consider additional design dimensions which help practitioners design digital twins tailored for inter-company use. The article addresses precisely that issue as it investigates how shared digital twins should be designed to achieve business success. For this purpose, the article proposes a set of design principles for shared digital twins stemming from a qualitative interview study with 18 industry experts. The interview study is the primary data source for formulating and evaluating the design principles. © 2022, the author(s).","","","2022","10.1007/s12599-022-00751-1","","","scopus-2-s2.0-85128165713.pdf","scopus-2-s2.0-85128165713"
"Fit for purpose assessment: a new direction for iacucs","Kinter, L.b. And Johnson, D.k. And Weichbrod, R.h. And Prentice, E.d. And Simmonds, R.c. And Houghton, P.w. And Whitney, R.a., Jr And Degeorge, J. And Dehaven, W.r. And Kramer, K. And Detolla, L.","Ilar Journal","","The organization and function of the institutional animal care and use committee (iacuc) is the key component of government regulation and oversight of necessary scientific research using live animals and of aaalac - international accreditation of animal care and use programs in the united states. The regulations, roles, and responsibilities of iacucs have evolved since their inception 35 years ago from a limited focus on animal welfare and specific animal procedures to embracing scientific quality, data reproducibility and translation, and animal welfare as inextricably interdependent and critical components of generation of new scientific knowledge and medical treatments. A current challenge for iacucs is in evaluating whether benefits to be derived (eg, new knowledge or treatments) justify any unavoidable pain, stress, or injury associated with proposed research protocols, because the former are long-term and at best speculative outcomes, whereas the latter are immediate and tangible for the study animals. Scientific consensus is that research most likely to generate significant new knowledge and medical treatments is that conducted to high scientific, technical, and quality standards and reported with full transparency to facilitate reproducibility. As an alternative to current benefits evaluations included in risk benefit and harm benefit constructs, the authors propose that iacucs assess the proposed research for scientific quality and alignment of study elements with the study purpose (e.g., fit for purpose [ffp]), including justifications for study design components, selection of primary endpoints and technologies, rationale for data and statistical analyses, and research communication plans. Fit for purpose endpoints are objective, immediate, and impactful as are the potential risks for study animals, and at the same time they are the best predictors for achievement of longer-term benefits. We propose that iacucs and any revision of the ilar guide consider ffp concepts in place of traditional benefits assessment to accelerate the generation of new knowledge and treatments benefiting medical and veterinary patients and the environment through better science and animal welfare rather than to continue to rely on speculative future outcomes. © the author(s) 2021. Published by oxford university press on behalf of the national academies of sciences, engineering, and medicine. All rights reserved. For permissions, please email: journals.permissions@oup.com.","","","2021","10.1093/ilar/ilac006","","","scopus-2-s2.0-85145425657.pdf","scopus-2-s2.0-85145425657"
"Guidelines for inclusion of patient-reported outcomes in clinical trial protocols the spirit-pro extension","Calvert, M. And Kyte, D. And Mercieca-Bebber, R. And Slade, A. And Chan, A.-W. And King, M.t.","Jama - Journal Of The American Medical Association","","Importance patient-reported outcome (pro) data from clinical trials can provide valuable evidence to inform shared decision making, labeling claims, clinical guidelines, and health policy;  however, the pro content of clinical trial protocols is often suboptimal. The spirit (standard protocol items: recommendations for interventional trials) statement was published in 2013 and aims to improve the completeness of trial protocols by providing evidence-based recommendations for the minimum set of items to be addressed, but it does not provide pro-specific guidance. Objective to develop international, consensus-based, pro-specific protocol guidance (the spirit-pro extension). Design, setting, and participants the spirit-pro extensionwas developed following the enhancing quality and transparency of health research (equator) network'smethodological framework for guideline development. This included (1) a systematic review of existing pro-specific protocol guidance to generate a list of potential pro-specific protocol items (published in 2014);  (2) refinements to the list and removal of duplicate items by the international society for quality of life research (isoqol) protocol checklist taskforce;  (3) an international stakeholder survey of clinical trial research personnel, pro methodologists, health economists, psychometricians, patient advocates, funders, industry representatives, journal editors, policy makers, ethicists, and researchers responsible for evidence synthesis (distributed by 38 international partner organizations in october 2016);  (4) an international delphi exercise (n = 137 invited;  october 2016 to february 2017);  and (5) consensus meeting (n = 30 invited;  may 2017). Prior to voting, consensus meeting participantswere informed of the results of the delphi exercise and given data from structured reviews evaluating the pro protocol content of 3 defined samples of trial protocols. Results the systematic review identified 162 pro-specific protocol recommendations from 54 sources. The isoqol taskforce (n = 21) reduced this to 56 items, which were considered by 138 international stakeholder survey participants and 99 delphi panelists. The final wording of the spirit-pro extension was agreed on at a consensus meeting (n = 29 participants) and reviewed by external group of experts during a consultation period. Eleven extensions and 5 elaborations to the spirit 2013 checklist were recommended for inclusion in clinical trial protocols in which pros are a primary or key secondary outcome. Extension items focused on pro-specific issues relating to the trial rationale, objectives, eligibility criteria, concepts used to evaluate the intervention, time points for assessment, pro instrument selection and measurement properties, data collection plan, translation to other languages, proxy completion, strategies to minimize missing data, and whether pro data will be monitored during the study to inform clinical care. Conclusions and relevance the spirit-pro guidelines provide recommendations for items that should be addressed and included in clinical trial protocols in which pros are a primary or key secondary outcome. Improved design of clinical trials including pros could help ensure high-quality data that may inform patient-centered care. © 2018 american medical association. All rights reserved.","","","2018","10.1001/jama.2017.21903","","","scopus-2-s2.0-85041638171.pdf","scopus-2-s2.0-85041638171"
"The mediation role of intention in knowledge sharing behavior","Mafabi, S. And Nasiima, S. And Muhimbise, E.m. And Kasekende, F. And Nakiyonga, C.","Vine Journal Of Information And Knowledge Management Systems","","Purpose: this paper aims to examine the mediation role of behavioral intention in the relationship between attitude, subjective norm, perceived behavioral control and knowledge sharing behavior. Design/methodology/approach: the study adopted a cross-sectional design to collect data used to carry out mediation analysis. Structural equation modeling was used to test for the mediation effect based on the theory of planned behavior. Findings: the results reveal positive and significant relationships between attitude, subjective norm, perceived behavioral control and behavioral intention. There is a full mediation effect of behavioral intention between attitude, subjective norm, perceived behavioral control and knowledge sharing behavior. This implies that behavioral intention wholly processes planned behavior prediction. Research limitations/implications: the sample size was small, covering only two referral hospitals which affects the generalization of findings across all the hospitals in uganda. The study was cross-sectional focusing on a one-off perception, which does not examine knowledge sharing behavior over time. This may necessitate follow-up studies in a longitudinal design to capture the trend of results. Practical implications: managers in referral hospitals should create opportunities for health professionals to enhance knowledge sharing behavior. Knowledge sharing practices should be embedded in the performance appraisal and reward systems which should promote positive knowledge sharing attitudes and norms and develop self-efficacy. Originality/value: the study generates empirical evidence on less studied phenomena in the health sector focusing on behavioral intention mediation in predicting knowledge sharing behavior. © 2017, © emerald publishing limited.","","","2017","10.1108/vjikms-02-2016-0008","","","scopus-2-s2.0-85020300458.pdf","scopus-2-s2.0-85020300458"
"Role of the slovak academy of sciences during the period of transition in the slovak republic","Luby, S.","Higher Education In Europe","","The transformation of a socialist-type academy of sciences into an institution capable of functioning in a democratic market economy is described. Prior to 1989, the slovak academy of sciences was the state mandated coordinator of science and technology in slovakia and was funded directly by the state budget. Since 1990, the academy has had to share many of its prerogatives with other authorities and institutions, as in the case of the universities in regard to doctoral programmes, or to cede them outright, as in the case of the ministry of education and science in regard to the coordination of basic research. Its budget has been drastically cut. It has also had to contend with the introduction of a western type of grant programme and system of evaluation for its subordinate institutes, some of which have been closed. In short, the slovak academy of sciences must compete in an increasingly open science market in which it must give proof both of the quality of its work and of the relevance of the latter to the needs of society. © 1995 by taylor & francis group. All rights reserved.","","","1995","10.1080/0379772950200419","","","scopus-2-s2.0-84958414852.pdf","scopus-2-s2.0-84958414852"
"Reporting and Guidelines in Propensity Score Analysis: A Systematic Review of Cancer and Cancer Surgical Studies","Yao X. I., Wang X., Speicher P. J., Hwang E. S., Cheng P., Harpole D. H., Berry M. F., Schrag D., Pang H. H.","Journal of the National Cancer Institute","","Background: Propensity score (PS) analysis is increasingly being used in observational studies especially in some cancer studies where random assignment is not feasible. This systematic review evaluates the use and reporting quality of PS analysis in oncology studies. Methods: We searched PubMed to identify the use of PS methods in cancer studies (CS) and cancer surgical studies (CSS) in major medical cancer and surgical journals over time and critically evaluated 33 CS published in top medical and cancer journals in 2014 and 2015 and 306 CSS published up to November 26 2015 without earlier date limits. The quality of reporting in PS analysis was evaluated. It was also compared over time and among journals with differing impact factors. All statistical tests were two-sided. Results: More than 50% of the publications with PS analysis from the past decade occurred within the past two years. Of the studies critically evaluated a considerable proportion did not clearly provide the variables used to estimate PS (CS 12.1% CSS 8.8%) incorrectly included non baseline variables (CS 3.4% CSS 9.3%) neglected the comparison of baseline characteristics (CS 21.9% CSS 15.6%) or did not report the matching algorithm utilized (CS 19.0% CSS 36.1%). In CSS the reporting of the matching algorithm improved in 2014 and 2015 ( P = .04) and the reporting of variables used to estimate PS was better in top surgery journals ( P = .008). However there were no statistically significant differences for the inclusion of non baseline variables and reporting of comparability of baseline characteristics. Conclusions: The use of PS in cancer studies has dramatically increased recently but there is substantial room for improvement in the quality of reporting even in top journals. Herein we have proposed reporting guidelines for PS analyses that are broadly applicable to different areas of medical research that will allow better evaluation and comparison across studies applying this approach.","","","2017","10.1093/jnci/djw323","","","medline-28376195.pdf","medline-28376195"
"Need for ethnic and population diversity in psychosis research","Burkhard, C. And Cicek, S. And Barzilay, R. And Radhakrishnan, R. And Guloksuz, S.","Schizophrenia Bulletin","","This article aims to evaluate ""racial"", ethnic, and population diversity-or lack thereof-in psychosis research, with a particular focus on socio-environmental studies. Samples of psychosis research remain heavily biased toward western, educated, industrialized, rich, and democratic (weird) societies. Furthermore, we often fail to acknowledge the lack of diversity, thereby implying that our findings can be generalized to all populations regardless of their social, ethnic, and cultural background. This has major consequences. Clinical trials generate findings that are not generalizable across ethnicity. The genomic-based prediction models are far from being applicable to the ""majority world.""Socio-environmental theories of psychosis are solely based on findings of the empirical studies conducted in weird populations. If and how these socio-environmental factors affect individuals in entirely different geographic locations, gene pools, social structures and norms, cultures, and potentially protective counter-factors remain unclear. How socio-environmental factors are assessed and studied is another major shortcoming. By embracing the complexity of environment, the exposome paradigm may facilitate the evaluation of interdependent exposures, which could explain how variations in socio-environmental factors across different social and geographical settings could contribute to divergent paths to psychosis. Testing these divergent paths to psychosis will however require increasing the diversity of study populations that could be achieved by establishing true partnerships between weird societies and the majority world with the support of funding agencies aspired to foster replicable research across diverse populations. The time has come to make diversity in psychosis research more than a buzzword. © 2021 the author(s) 2021. Published by oxford university press on behalf of the maryland psychiatric research center.","","","2021","10.1093/schbul/sbab048","","","scopus-2-s2.0-85110312807.pdf","scopus-2-s2.0-85110312807"
"Strengthen the process report of clinical trials promote full transparency of clinical trials. [Chinese]","Dong C., Yan X., Tian R., Bian Z., Yao C.","Chinese Journal of Evidence-Based Medicine","","The concept of clinical trial transparency has been promoted for more than 40 years. The act of clinical trial registration report guidelines development and data sharing has has been strongly pushed forward and become a common practice. The clinical trial process being the key procedure of trial operation and quality control determines the accuracy of the results. However the process report of clinical trials is insufficient. In this article we summarize the importance of clinical trial process report and provide corresponding suggestions. We propose that medical journals reporting guidelines developers and clinical trial registration platforms should work together to strengthen the process report of clinical trials and promote full transparency of clinical trials. Copyright © 2018 West China University of Medical Science. All rights reserved.","","","2018","10.7507/1672-2531.201806071","","","unknown-1414.pdf","unknown-1414"
"Virtual track networks: a hierarchical modeling framework and open-source tools for simplified and efficient connected and automated mobility (cam) system design based on general modeling network specification (gmns)","Lu, J. And Zhou, X.s.","Transportation Research Part C: Emerging Technologies","","This study presents a novel framework and open-source tools for simulating and managing connected and automated mobility (cam) systems, taking into account their hierarchical nature and various levels of scheduling. The framework is based on a multi-layered network representation, which allows for efficient and accurate modeling of cam systems at different levels of granularity, from macroscopic to microscopic. By employing this hierarchical approach, we achieve a balance between the level of detail in the representation and computational efficiency. Additionally, a spatial-discrete virtual track-based representation is introduced for precise vehicle dynamics modeling and for ensuring consistency with higher-level routing decisions. This facilitates individualized active traffic management for cam applications. As part of our research, we have developed osm2gmns, an open-source package that allows users to effortlessly access and process transportation networks from openstreetmap in the general modeling network specification (gmns) format, facilitating data sharing and research collaboration. Furthermore, we explore traffic simulation, optimization, and operation methodologies for cam systems, particularly focusing on the extent of scheduling capabilities. To support the research community, we further introduce an open-source package camlite for cam system modeling. The effectiveness of our proposed methodologies and tools is demonstrated through a series of numerical experiments. © 2023 elsevier ltd","","","2023","10.1016/j.trc.2023.104223","","","scopus-2-s2.0-85163417466.pdf","scopus-2-s2.0-85163417466"
"Protocol for the development of consensus-based clinical case reporting guideline extension: care for acupuncture","Duan, Y. And Chen, Y. And Chen, J. And Chen, Z. And Riley, D. And Xu, N. And Zheng, Y. And Wang, Q. And Deng, J. And Lu, L. And Tang, C.","Complementary Therapies In Medicine","","Background: health research reporting guidelines for case reports (care - case report) published in 2013 and 2017 have become a generally accepted standard for publishing case reports. The care guidelines represent an architectural framework for writing an evidence-based case report that can be customized as need for a specialty (or disease) if needed. We aim to develop a care guideline extension for acupuncture following the equator network (enhancing the quality and transparency of health research) and the 2010″guidance for developers of health research reporting”. We have established a group of international experts including;  clinicians, researchers and methodologists. We performed a needs assessment based on a review of acupuncture case reports published in the indexed medical literature. The needs assessment will be followed by (1) a series of expert interviews to establish a draft, (2) a modified delphi process, and (3) a consensus meeting. Following the consensus meeting we will pilot test the care draft before publishing the care extension for acupuncture. Methods: we will develop the care extensions for acupuncture following recommendations of the equator network and the 2010 “guidance for developers of health research reporting”. We will establish an international multidisciplinary group including clinical practitioners, acupuncturists, researchers of reporting guidelines on acupuncture, clinical epidemiologists and statisticians. We performed a needs assessment, reviewing published case reports using acupuncture as a therapeutic intervention from indexed medical journals (pubmed-pmc and medline, scopus, embase, the allied and complementary medicine database (amed), cumulative index to nursing and allied health literature (cinahl), wan fang database, chinese biomedicine database (cbm), china national knowledge infrastructure (cnki), and vip). In consultations with advisors we will develop a draft of potential items to be included in the care extension for acupuncture. Then we will conduct a modified delphi process of at least three rounds, hold a face-to-face consensus meeting, pilot test and submit the care extension for acupuncture for publication. Conclusion: the development of a widely accepted care extension for acupuncture for case reports published in indexed medical journals. These guidelines will follow the equator network recommendations and the 2010 “guidance for developers of health research reporting”. © 2019 the authors","","","2019","10.1016/j.ctim.2019.06.004","","","scopus-2-s2.0-85067845585.pdf","scopus-2-s2.0-85067845585"
"Expressive data sharing and self-controlled fine-grained data deletion in cloud-assisted iot","Mei, Q. And Yang, M. And Chen, J. And Wang, L. And Xiong, H.","Ieee Transactions On Dependable And Secure Computing","","Expressive data sharing and efficient data deletion are essential to drive the development of cloud-assisted iot. But insecure transmission and the vulnerability of the cloud server may cause potential threats to iot data, attribute-based encryption (abe) is widely applied to ensure data confidentially. Nonetheless, the potential data exposure caused by the compromised long-term key and the contradiction between conventional access structures in abe and the various demands of data owners are still two huge challenges. To overcome these challenges, this article designs an unbounded and puncturable ciphertext-policy abe with arithmetic span program (up-cp abe-asp) scheme and presents an expressive data sharing and self-controlled fine-grained data deletion solution in cloud-assisted iot, which allows data owners to efficiently encrypt and share data with various computable access policies, but also enables data owners and data users to independently delete specific data stored in the cloud. The designed up-cp-abe-asp leverages unbounded abe and puncturable encryption to support the flexible update of system parameters and the deletion of specific data. Also, the arithmetic span program access structure is combined to realize expressive data sharing. Moreover, the up-cp-abe-asp is adaptively secure in the standard model, and comprehensive performance evaluations demonstrate its practicability and scalability in cloud-assisted iot. © 2004-2012 ieee.","","","2023","10.1109/tdsc.2022.3188740","","","scopus-2-s2.0-85134228185.pdf","scopus-2-s2.0-85134228185"
"The trouble with reporting and utilization of workplace violence data in health care","Morphet, J. And Griffiths, D. And Innes, K.","Journal Of Nursing Management","","Aim: the study aimed to evaluate the reporting, monitoring and use of workplace violence data in victorian health services. Background: surveillance of workplace violence is important in understanding the circumstances in which workplace violence occurs and development of relevant and appropriate prevention and intervention strategies. Method: a descriptive exploratory approach was used. Fifteen staff from occupational health and safety, quality and safety, and nurse unit managers, from five major metropolitan health services were interviewed. Recorded interviews were transcribed verbatim and thematically analysed. Results: three themes were identified: (a) “under-reporting of workplace violence,” (b) “inconsistent guidance” caused subjective and variable data coding and (c) “application of data” described how health services used the data available to them, to inform the development and implementation of systems designed to prevent workplace violence. Conclusions: improved reporting systems may increase consistency in reporting, enable data sharing across organisations and assist in planning of prevention strategies. Implications for nursing management: staff should be encouraged to complete incident reports for each episode of workplace violence. Incident reporting systems must be simplified to reduce the burden of reporting. Nurse managers should advocate for the sharing of health service workplace violence data, to enable improved prevention across all services. © 2018 john wiley & sons ltd","","","2019","10.1111/jonm.12717","","","scopus-2-s2.0-85055100595.pdf","scopus-2-s2.0-85055100595"
"Use of broad consent and related procedures in genomics research: Perspectives from research participants in the Genetics of Rheumatic Heart Disease (RHDGen) study in a University Teaching Hospital in Zambia","Mweemba O., Musuku J., Mayosi B. M., Parker M., Rutakumwa R., Seeley J., Tindana P., De Vries J.","Global Bioethics","","The use of broad consent for genomics research raises important ethical questions for the conduct of genomics research including relating to its acceptability to research participants and comprehension of difficult scientific concepts. To explore these and other challenges we conducted a study using qualitative methods with participants enrolled in an H3Africa Rheumatic Heart Disease genomics study (the RHDGen network) in Zambia to explore their views on broad consent sample and data sharing and secondary use. In-depth interviews were conducted with RHDGen participants (n = 18) study staff (n = 5) and with individuals who refused to participate (n = 3). In general broad consent was seen to be reasonable if reasons for storing the samples for future research use were disclosed. Some felt that broad consent should be restricted by specifying planned future studies and that secondary research should ideally relate to original disease for which samples were collected. A few participants felt that broad consent would delay the return of research results to participants. This study echoes findings in other similar studies in other parts of the continent that suggested that broad consent could be an acceptable consent model in Africa if careful thought is given to restrictions on re-use.","","","2019","10.1080/11287462.2019.1592868","","","pubmed-33343192.pdf","pubmed-33343192"
"Guidelines for clinical applications of spatio-temporal gait analysis in older adults","Kressig R. W., Beauchet O.","Aging-Clinical & Experimental Research","","Quantifying spatio-temporal gait parameters in stationary and ambulatory geriatric settings may aid the early identification of potential fallers as well as the documentation of illness-specific gait disorders and intervention-related changes in rehabilitative medicine. Bringing gait analysis out of the laboratory and into a clinical setting is the goal of the European GAITRite network group initiated in 2003 in Geneva. To enhance reproducibility of gait measures and for better comparability of outcomes in clinical environments a consensus on data collection was formulated and presented at the 2nd European GAITRite Meeting in Marseilles. The guidelines presented here are intended to facilitate network collaborations and to provide guidance to clinicians who wish to implement spatio-temporal gait analysis in clinical settings.","","","2006","10.1007/bf03327437","","","medline-16702791.pdf","medline-16702791"
"A question of trust: can we build an evidence base to gain trust in systematic review automation technologies?","O'connor, A.m. And Tsafnat, G. And Thomas, J. And Glasziou, P. And Gilbert, S.b. And Hutton, B.","Systematic Reviews","","Background: although many aspects of systematic reviews use computational tools, systematic reviewers have been reluctant to adopt machine learning tools. Discussion: we discuss that the potential reason for the slow adoption of machine learning tools into systematic reviews is multifactorial. We focus on the current absence of trust in automation and set-up challenges as major barriers to adoption. It is important that reviews produced using automation tools are considered non-inferior or superior to current practice. However, this standard will likely not be sufficient to lead to widespread adoption. As with many technologies, it is important that reviewers see ""others"" in the review community using automation tools. Adoption will also be slow if the automation tools are not compatible with workflows and tasks currently used to produce reviews. Many automation tools being developed for systematic reviews mimic classification problems. Therefore, the evidence that these automation tools are non-inferior or superior can be presented using methods similar to diagnostic test evaluations, i.e., precision and recall compared to a human reviewer. However, the assessment of automation tools does present unique challenges for investigators and systematic reviewers, including the need to clarify which metrics are of interest to the systematic review community and the unique documentation challenges for reproducible software experiments. Conclusion: we discuss adoption barriers with the goal of providing tool developers with guidance as to how to design and report such evaluations and for end users to assess their validity. Further, we discuss approaches to formatting and announcing publicly available datasets suitable for assessment of automation technologies and tools. Making these resources available will increase trust that tools are non-inferior or superior to current practice. Finally, we identify that, even with evidence that automation tools are non-inferior or superior to current practice, substantial set-up challenges remain for main stream integration of automation into the systematic review process. © 2019 the author(s).","","","2019","10.1186/s13643-019-1062-0","","","scopus-2-s2.0-85062765017.pdf","scopus-2-s2.0-85062765017"
"Regulatory standards and consequences for industry architecture: the case of uk open banking","Dinçkol, D. And Ozcan, P. And Zachariadis, M.","Research Policy","","In this inductive qualitative study, we analyze the standardization efforts in the uk banking sector via open banking regulations. We examine the role of regulatory standards and how these standards evolve, highlight key decisions and factors in the process of standardization, and show how the standards implementation can lead to the emergence of new roles and connections in the industry architecture. We find that standardization is a continuous, multi-stakeholder process where not only formulation decisions, but also the adjustment of industry players to roadblocks in implementation cause recalibration of standards and shifts in industry architecture. We also unravel the architectural implications of data sharing and interoperability standardization both within and across industries. © 2023 the authors","","","2023","10.1016/j.respol.2023.104760","","","scopus-2-s2.0-85150780791.pdf","scopus-2-s2.0-85150780791"
"Reliability and Generalizability of Similarity-Based Fusion of MEG and fMRI Data in Human Ventral and Dorsal Visual Streams","Mohsenzadeh Y., Mullin C., Lahner B., Cichy R. M., Oliva A.","Vision","","To build a representation of what we see the human brain recruits regions throughout the visual cortex in cascading sequence. Recently an approach was proposed to evaluate the dynamics of visual perception in high spatiotemporal resolution at the scale of the whole brain. This method combined functional magnetic resonance imaging (fMRI) data with magnetoencephalography (MEG) data using representational similarity analysis and revealed a hierarchical progression from primary visual cortex through the dorsal and ventral streams. To assess the replicability of this method we here present the results of a visual recognition neuro-imaging fusion experiment and compare them within and across experimental settings. We evaluated the reliability of this method by assessing the consistency of the results under similar test conditions showing high agreement within participants. We then generalized these results to a separate group of individuals and visual input by comparing them to the fMRI-MEG fusion data of Cichy et al (2016) revealing a highly similar temporal progression recruiting both the dorsal and ventral streams. Together these results are a testament to the reproducibility of the fMRI-MEG fusion approach and allows for the interpretation of these spatiotemporal dynamic in a broader context.","","","2019","10.3390/vision3010008","","","medline-31735809.pdf","medline-31735809"
"A Tale of Two Capacities: Including Children and Decisionally Vulnerable Adults in Biomedical Research","Dalpe G., Thorogood A., Knoppers B. M.","Frontiers in Genetics","","The participation of individuals who lack decision-making capacity is essential for advancing genomics research and neuroscience but raises ethical and legal challenges relating to vulnerability consent and exclusion. Capacity differences between populations and individuals the dynamics of capacity over time and evolving legal consent and capacity regimes all raise uncertainty for researchers institutional review boards and policy makers. We review international ethical and legal best practices for including children and decisionally vulnerable adults in health research. Research ethics norms and literature tend to split such groups into narrow silos which results in inconsistency and conceptual confusion or to lump them together which fails to take into account morally relevant differences. Through a narrative review of international norms we identify challenges common to both groups while drawing out distinctions reflecting their opposite capacity trajectories. Our comparison between these two populations clarifies underlying ethical concepts and offers opportunities for critique. Children need protection to foster their long-term autonomy while decisionally vulnerable adults need to be provided with support in order to exercise their autonomy. This leads to differences in how researchers determine who lacks capacity who has authority to consent and what criteria guide such decision-making. We also consider how capacity issues color contemporary research governance debates over broad consent data protection compliance data sharing and the return of individual research results and incidental findings.","","","2019","10.3389/fgene.2019.00289","","","medline-31024616.pdf","medline-31024616"
"The Gene Environment Association Studies consortium (GENEVA): maximizing the knowledge obtained from GWAS by collaboration across studies of multiple conditions","Cornelis M. C., Agrawal A., Cole J. W., Hansel N. N., Barnes K. C., Beaty T. H., Bennett S. N., Bierut L. J., Boerwinkle E., Doheny K. F., Feenstra B., Feingold E., Fornage M., Haiman C. A., Harris E. L., Hayes M. G., Heit J. A., Hu F. B., Kang J. H., Laurie C. C., Ling H., Manolio T. A., Marazita M. L., Mathias R. A., Mirel D. B., Paschall J., Pasquale L. R., Pugh E. W., Rice J. P., Udren J., van Dam R. M., Wang X., Wiggs J. L., Williams K., Yu K.","Genetic Epidemiology","","Genome-wide association studies (GWAS) have emerged as powerful means for identifying genetic loci related to complex diseases. However the role of environment and its potential to interact with key loci has not been adequately addressed in most GWAS. Networks of collaborative studies involving different study populations and multiple phenotypes provide a powerful approach for addressing the challenges in analysis and interpretation shared across studies. The Gene Environment Association Studies (GENEVA) consortium was initiated to: identify genetic variants related to complex diseases; identify variations in gene-trait associations related to environmental exposures; and ensure rapid sharing of data through the database of Genotypes and Phenotypes. GENEVA consists of several academic institutions including a coordinating center two genotyping centers and 14 independently designed studies of various phenotypes as well as several Institutes and Centers of the National Institutes of Health led by the National Human Genome Research Institute. Minimum detectable effect sizes include relative risks ranging from 1.24 to 1.57 and proportions of variance explained ranging from 0.0097 to 0.02. Given the large number of research participants (N>80000) an important feature of GENEVA is harmonization of common variables which allow analyses of additional traits. Environmental exposure information available from most studies also enables testing of gene-environment interactions. Facilitated by its sizeable infrastructure for promoting collaboration GENEVA has established a unified framework for genotyping data quality control analysis and interpretation. By maximizing knowledge obtained through collaborative GWAS incorporating environmental exposure information GENEVA aims to enhance our understanding of disease etiology potentially identifying opportunities for intervention. Copyright (c) 2010 Wiley-Liss Inc.","","","2010","10.1002/gepi.20492","","","medline-20091798.pdf","medline-20091798"
"A meta-analysis and meta-regression of incidental second language word learning from spoken input","De Vos, J.f. And Schriefers, H. And Nivard, M.g. And Lemhöfer, K.","Language Learning","","We meta-analyzed the effectiveness of incidental second language word learning from spoken input. Our sample contained 105 effect sizes from 32 primary studies employing meaning-focused word-learning activities with 1,964 participants with typical cognitive functioning. The random-effects meta-analysis yielded a mean effect size of g = 1.05, reflecting generally large vocabulary gains from spoken input in meaning-focused activities. A meta-regression with three substantive and two methodological predictors also revealed that adult participants outperformed children in terms of word learning and that interactive learning tasks were more effective than noninteractive ones. Furthermore, learning scores were higher when measured with recognition than with recall tests. Methodologically, the use of a no-input control group seemed to protect against an overestimation of learning effects, evidenced by smaller effect sizes. Finally, whether a pretest–posttest design was used did not influence effect sizes. All data and the analysis script are publicly available. Open practices: this article has been awarded an open data badge. All data and the analysis script are publicly accessible via the open science framework at https://osf.io/92vfw. Learn more about the open practices badges from the center for open science: https://osf.io/tvyxz/wiki. © 2018 the authors. Language learning published by wiley periodicals, inc. on behalf of language learning research club, university of michigan","","","2018","10.1111/lang.12296","","","scopus-2-s2.0-85055965706.pdf","scopus-2-s2.0-85055965706"
"Reproducibility of the hydrodynamic performance and measurements in a liquid-liquid kühni extraction column - relevance to theoretical model evaluation","Gomes, L.n. And Guimaraes, M.l. And Lopes, J.c. And Madureira, C.n. And Stichlmair, J. And Cruz-Pinto, J.j.","Industrial And Engineering Chemistry Research","","Liquid-liquid systems research increasingly concentrates on computer simulations. However, the possibility of adequately testing complex theoretical models against experiments is hindered by a lack of reliable reproducibility data for laboratory and pilot-plant measurements. This strongly limits meaningful evaluation of the increasingly complex process and equipment models/algorithms that are being developed. In this work, experimental data are obtained in a pilot-scale kühni column, and model parameters and simulated data are generated using a drop population balance model and algorithm. The results can be summarized as follows: (i) as measured by the magnitude of careful random error and corresponding confidence limits estimates, the simulation results exhibit excellent agreement with experimental drop-size distributions and fair conformity with measured dispersed-phase hold-ups. (ii) both experimental and simulated results show that interdrop coalescence is always present within a column extractor, even at low dispersed-phase hold-ups, and thus cannot be neglected in any physically realistic and accurate modeling.","","","2004","10.1021/ie030277i","","","scopus-2-s2.0-1042289750.pdf","scopus-2-s2.0-1042289750"
"Professional youth football academy injury data: collection procedures, perceived value, and use","Mccunn, R. And Gibson, N.v. And Fullagar, H.h.k. And Harper, L.d.","Science And Medicine In Football","","Purpose: there is a paucity of descriptive injury data relevant to professional academy football, with little to no evidence reporting how sports science/medicine staff within academies collect and use injury data. Materials and methods: an online survey relating to the perceptions surrounding injury data collection, its value and use was developed. Forty-seven applied practitioners working for different professional football academies completed the survey. Results: injury data collection procedures conducted by appropriately trained medical staff are widespread among football academies. Injury data collection within academies was deemed worthwhile and important by 79% of practitioners. Similarly, 79% strongly agreed/agreed that using injury data for academic research is worthwhile. The engagement with and use of injury data by coaching staff appears to be relatively poor, with only 49% of practitioners stating coaches formally review data. Conclusions: injury data are widely collected within academies and practitioners consider this information valuable. However, improving engagement with coaches and using the data for academic research could further improve applied practice. Practical implications: applied practitioners should consider sharing injury data with both researchers and coaches. In doing so evidence-guided injury prevention interventions may be developed and subsequently applied in the field. © 2017, © 2017 informa uk limited, trading as taylor & francis group.","","","2018","10.1080/24733938.2017.1410564","","","scopus-2-s2.0-85066839335.pdf","scopus-2-s2.0-85066839335"
"Rigor in information systems positivist case research: current practices, trends, and recommendations","Dubé, L. And Paré, G.","Mis Quarterly: Management Information Systems","","Case research has commanded respect in the information systems (is) discipline for at least a decade. Notwithstanding the relevance and potential value of case studies, this methodological approach was once considered to be one of the least systematic. Toward the end of the 1980s, the issue of whether is case research was rigorously conducted was first raised. Researchers from our field (e.g., benbasat et al. 1987;  lee 1989) and from other disciplines (e.g., eisenhardt 1989;  yin 1994) called for more rigor in case research and, through their recommendations, contributed to the advancement of the case study methodology. Considering these contributions, the present study seeks to determine the extent to which the field of is has advanced in its operational use of case study method. Precisely, it investigates the level of methodological rigor in positivist is case research conducted over the past decade. To fulfill this objective, we identified and coded 183 case articles from seven major is journals. Evaluation attributes or criteria considered in the present review focus on three main areas, namely, design issues, data collection, and data analysis. While the level of methodological rigor has experienced modest progress with respect to some specific attributes, the overall assessed rigor is somewhat equivocal and there are still significant areas for improvement. One of the keys is to include better documentation particularly regarding issues related to the data collection and analysis processes.","","","2003","10.2307/30036550","","","scopus-2-s2.0-9744258804.pdf","scopus-2-s2.0-9744258804"
"Early intervention for acute back injury: can we finally develop an evidence-based approach?","Smith, D. And Mcmurray, N. And Disler, P.","Clinical Rehabilitation","","Objective: several reviews of the treatment of acute low back pain have been published in the past and have formed the basis of clinical guidelines. However, these lack consistency in some areas and valid data in others. As the literature in this field has continued to expand, the present review was undertaken to establish whether the guidelines in current use are supported by more recently published, scientifically rigorous research, and whether additional consensus regarding treatment of acute low back injury has been forthcoming in recent years. Design: a review, and critical analysis, of literature relating to the treatment of acute low back pain that has been published since the production of the currently used clinical guidelines. The guidelines have been reviewed to assess whether their recommendations remain supportable. Conclusions: recent research appears to support current clinical guidelines, i.e. exercise may have a positive effect while bed rest is ineffective and may be harmful, simple analgesics and nonsteroidal anti-inflammatory drugs (nsaids) have short-term benefits, and spinal manipulation may be effective in the first four weeks;  no evidence was found for traction or back schools. However, we need more randomized controlled trials of treatments shown to be successful with the chronic population, e.g. focused on understanding psychological determinants, and using a multidisciplinary biopsychosocial approach. In the future this may help us to prevent acute low back progressing to the chronic state.","","","2002","10.1191/0269215502cr461oa","","","scopus-2-s2.0-0036151519.pdf","scopus-2-s2.0-0036151519"
"Standardized analysis of juvenile pyroclasts in comparative studies of primary magma fragmentation: 2. Choice of size fraction and method optimization for particle cross-sections","Comida, P.p. And Ross, P.-S. And Dürig, T. And White, J.d.l. And Lefebvre, N.","Bulletin Of Volcanology","","The morphological and textural features of juvenile pyroclasts record crucial details on magma conditions at the time of fragmentation. Their study is therefore essential to better understand the dynamics of explosive eruptions. Unfortunately, the absence of a standardized protocol of investigation hinders data reproducibility and comparison among different laboratories. Here we focus on morphometric parameters, 2d crystallinity and 2d vesicularity resulting from cross-section analysis of juvenile particles using backscattered electron imaging, and address the following questions: (i) how to prepare polished epoxy grain mounts, (ii) which pixel density to be used, (iii) how to facilitate image preparation and image analysis, (iv) which sample size is necessary to obtain statistically robust results, and (v) what is the optimum size fraction for analysis. We test juvenile particles in grain size bins ranging from 2–1 mm (− 1 to 0ɸ) to 88–63 µm (+ 3.5 to + 4ɸ), using samples from the 1977 ukinrek eruption. We find that the required resolution ranges from 75 000 to 10 000 pixels per particle, depending on the size fraction, higher than previously postulated. In the same size ranges, less than 50 grains per size fraction and sample are needed to get robust averages. Based on theoretical, empirical, and practical considerations, we propose 0.71–0.5 mm (+ 0.5 to + 1ɸ) as the optimum size fraction to be analyzed as particle cross-sections in standardized comparative studies of magma fragmentation. We provide a detailed guide for preparing polished epoxy grain mounts and introduce a software package (pasta) for semi-automated image preparation, image processing, and measurement of morphological and textural parameters. © 2021, international association of volcanology & chemistry of the earth's interior.","","","2022","10.1007/s00445-021-01517-5","","","scopus-2-s2.0-85121664759.pdf","scopus-2-s2.0-85121664759"
"The relationship between communication via social networking sites and the political participation of youth ""an applied study on egyptian presidential election""","Hasan, A.a.","Dirasat: Human And Social Sciences","","This study aims to investigate the relationship between communications via social networking sites (snss) and the political participation of youth (aged from 18 to 35 years) in the egyptian presidential election 2012. An analytical model is developed as a guideline to test the relationships between research variables. A quantitative method with deductive approach is chosen in this research. Data has been collected before and after the election through the electronic questionnaire and the size of samples were 600 and 500 users. Based on data analyses with spss, results show that: there is a significant relationship between communications (communication, collaboration, and material sharing) via social networking sites (snss) and the political participation of youth before the primary election. There is a significant relationship between collaboration and material sharing from one side and the political participation from the other side, but there is no significant relationship between communication and the political participation after the primary election. In addition, results show that: there is no significant relationship between demographic variables (age, education, monthly income of family and marital status) and the political participation of youth before and after the primary election, and there is a significant relationship between gender and the political participation before the primary election, where the political participation of males is higher than females, but there was no significant relationship between gender and the political participation after the primary election. The study recommended that the planers of the presidential election campaigns must focus on designing an effective marketing strategy taking into account mixing snss into integrated marketing communication (imc) mix, because of the importance of these snss in the effect on the political participation of youth.","","","2016","10.12816/0028440","","","scopus-2-s2.0-84964059462.pdf","scopus-2-s2.0-84964059462"
"Federated learning improves site performance in multicenter deep learning without data sharing","Sarma K. V., Harmon S., Sanford T., Roth H. R., Xu Z., Tetreault J., Xu D., Flores M. G., Raman A. G., Kulkarni R., Wood B. J., Choyke P. L., Priester A. M., Marks L. S., Raman S. S., Enzmann D., Turkbey B., Speier W., Arnold C. W.","Journal of the American Medical Informatics Association","","OBJECTIVE: To demonstrate enabling multi-institutional training without centralizing or sharing the underlying physical data via federated learning (FL). MATERIALS AND METHODS: Deep learning models were trained at each participating institution using local clinical data and an additional model was trained using FL across all of the institutions. RESULTS: We found that the FL model exhibited superior performance and generalizability to the models trained at single institutions with an overall performance level that was significantly better than that of any of the institutional models alone when evaluated on held-out test sets from each institution and an outside challenge dataset. DISCUSSION: The power of FL was successfully demonstrated across 3 academic institutions while avoiding the privacy risk associated with the transfer and pooling of patient data. CONCLUSION: Federated learning is an effective methodology that merits further study to enable accelerated development of models across institutions enabling greater generalizability in clinical use.","","","2021","10.1093/jamia/ocaa341","","","medline-33537772.pdf","medline-33537772"
"An Exploration of Barriers Facilitators and Suggestions for Improving Electronic Health Record Inbox-Related Usability: A Qualitative Analysis","Murphy D. R., Giardina T. D., Satterly T., Sittig D. F., Singh H.","JAMA Network Open","","Importance: Managing messages in the electronic health record (EHR) inbox consumes substantial amounts of physician time. Certain factors associated with inbox management such as poor usability and excessive and unnecessary inbox messages have been associated with physician burnout. Additionally inbox design usability and workflows are associated with physicians' situational awareness (ie perception comprehension and projection of clinical status) and efficiency of processing EHR inbox messages. Understanding factors associated with inbox usability could improve future EHR inbox designs and workflows thus reducing risk of burnout while improving patient safety. Objective: To determine barriers facilitators and suggestions associated with EHR inbox-related usability. Design Setting and Participants: This qualitative study included cognitive walkthroughs of EHR inbox management with 25 physicians (17 primary care physicians and 8 specialists) at 6 large health care organizations using 4 different EHR systems between May 6 2015 and September 19 2016. While processing EHR inbox messages participants identified facilitators and barriers associated with EHR inbox situational awareness and processing efficiency and potential interventions to address such barriers. A qualitative analysis was performed on transcribed recordings using an inductive thematic approach with an 8-dimension sociotechnical model as a theoretical lens from May 6 2015 to August 15 2019. Results: The cognitive walkthroughs identified 60 barriers 32 facilitators and 28 suggestions for improving the EHR inbox. Emergent data fit within 5 major themes: message processing complexity inbox interface design cognitive load team communication and inbox message content. Within these themes similar barriers were identified across sites such as poor usability due the high numbers of clicks needed to accomplish actions. In certain instances an identified facilitator at one site provided the exact solution needed to address a barrier identified at another site. Conclusions and Relevance: This qualitative study found that usability of the EHR inbox is often suboptimal and variable across sites suggesting lack of shared best practices related to information management. Implementation of optimized design features and workflows will require EHR developers and health care organizations to collectively share this responsibility. Development of regional or national consortia to support collaborative sharing and implementation of EHR system best practices across EHR developers and health care organizations could also improve safety and efficiency and reduce physician burnout.","","","2019","10.1001/jamanetworkopen.2019.12638","","","medline-31584683.pdf","medline-31584683"
"Why they shared: recovering early arguments for sharing social scientific data","Hauptmann E.","Sci Context","","Most social scientists today think of data sharing as an ethical imperative essential to making social science more transparent, verifiable, and replicable. But what moved the architects of some of the u.s.'s first university-based social scientific research institutions, the university of michigan's institute for social research (isr), and its spin-off, the inter-university consortium for political and social research (icpsr), to share their data? Relying primarily on archived records, unpublished personal papers, and oral histories, i show that angus campbell, warren miller, philip converse, and others understood sharing data not as an ethical imperative intrinsic to social science but as a useful means to the diverse ends of financial stability, scholarly and institutional autonomy, and epistemological reproduction. I conclude that data sharing must be evaluated not only on the basis of the scientific ideals its supporters affirm, but also on the professional objectives it serves.","","","2020","10.1017/s0269889720000204","","","embase-634573802.pdf","embase-634573802"
"Further evaluation of a modified micronucleus assay with V79 cells for detection of aneugenic effects","Seelbach A., Fissler B., Madle S.","Mutation Research","","In an earlier publication we reported on the development of a modified micronucleus assay with V79 cells enabling preferential detection of aneugen-induced micronuclei (Seelbach et al. 1993). Here we present a further evaluation of the modified micronucleus assay based on the investigation of seven further suspected aneugens. Five compounds gave positive results: cadmium chloride chloral hydrate hydroquinone thimerosal and vinblastine. Econazole and pyrimethamine were negative. Up to now our experience has shown that data produced by the modified V79/micronucleus assay are quite reliable: the variation of spontaneous micronucleus frequencies was low (0.8-1.7%) and the reproducibility of the data was good.","","","1993","10.1016/0165-7992(93)90018-q","","","medline-7694134.pdf","medline-7694134"
"An open-science crowdsourcing approach for producing community noise maps using smartphones","Picaut, J. And Fortin, N. And Bocher, E. And Petit, G. And Aumond, P. And Guillaume, G.","Building And Environment","","An alternative method is proposed for the assessment of the noise environment, on the basis of a crowdsourcing approach. For this purpose, a smartphone application and a spatial data infrastructure have been specifically developed in order to collect physical data (noise indicators, gps positions, etc.) and perceptual data (pleasantness), without territorial limits, of the sound environment. As the project is developed within an open science framework, all source codes, methodologies, tools and raw data are freely available, and if necessary, can be duplicated for any specific use. In particular, the collected data can be used by the scientific community, cities, associations, or any institution, which would like to develop new tools for the evaluation and representation of sound environments. In this paper, all the methodological and technical issues are detailed, and a first analysis of the collected data is proposed. © 2018 the authors","","","2019","10.1016/j.buildenv.2018.10.049","","","scopus-2-s2.0-85055902081.pdf","scopus-2-s2.0-85055902081"
"Similar Outcomes of Web-Based and Face-to-Face Training of the GRADE Approach for the Certainty of Evidence: Randomized Controlled Trial","Tokalic R., Poklepovic Pericic T., Marusic A.","Journal of Medical Internet Research","","BACKGROUND: The GRADE (Grading of Recommendations Assessment Development and Evaluation) approach is a system for transparent evaluation of the certainty of evidence used in clinical practice guidelines and systematic reviews. GRADE is a key part of evidence-based medicine (EBM) training of health care professionals.\\\\\\\\rOBJECTIVE: This study aimed to compare web-based and face-to-face methods of teaching the GRADE approach for evidence assessment.\\\\\\\\rMETHODS: A randomized controlled trial was conducted on 2 delivery modes of GRADE education integrated into a course on research methodology and EBM with third-year medical students. Education was based on the Cochrane Interactive Learning ""Interpreting the findings"" module which had a duration of 90 minutes. The web-based group received the web-based asynchronous training whereas the face-to-face group had an in-person seminar with a lecturer. The main outcome measure was the score on a 5-question test that assessed confidence interval interpretation and overall certainty of evidence among others. Secondary outcomes included writing a recommendation for practice and course satisfaction.\\\\\\\\rRESULTS: In all 50 participants received the web-based intervention and 47 participants received the face-to-face intervention. The groups did not differ in the overall scores for the Cochrane Interactive Learning test with a median of 2 (95% CI 1.0-2.0) correct answers for the web-based group and 2 (95% CI 1.3-3.0) correct answers for the face-to-face group. Both groups gave the most correct answers to the question about rating a body of evidence (35/50 70% and 24/47 51% for the web-based and face-to-face group respectively). The face-to-face group better answered the question about the overall certainty of evidence question. The understanding of the Summary of Findings table did not differ significantly between the groups with a median of 3 correct answers to 4 questions for both groups (P=.352). The writing style for the recommendations for practice also did not differ between the 2 groups. Students' recommendations mostly reflected the strengths of the recommendations and focused on the target population but they used passive words and rarely mentioned the setting for the recommendation. The language of the recommendations was mostly patient centered. Course satisfaction was high in both groups.\\\\\\\\rCONCLUSIONS: Training in the GRADE approach could be equally effective when delivered asynchronously on the web or face-to-face.\\\\\\\\rTRIAL REGISTRATION: Open Science Framework akpq7; https://osf.io/akpq7/. Copyright ©Ruzica Tokalic Tina Poklepovic Pericic Ana Marusic. Originally published in the Journal of Medical Internet Research (https://www.jmir.org) 06.06.2023.","","","2023","10.2196/43928","","","medline-37279050.pdf","medline-37279050"
"Probing the effects of culture on the communication of websites design","Hsieh, H.c.l.","Theoretical Issues In Ergonomics Science","","Cultural diversity makes it impossible for designers to depend on instinctive knowledge or personal experiences. Therefore, it is vital to understand the requirements, communication patterns, and mental models of users from diverse cultures. The aim of this research is to probe whether incorporating cultural factors into web design can improve the web communication (usability). In this research, two cultures are selected based on hofstede's cultural dimension model, and the local website audit is further constructed to check if there are significantly different preferences for a web interface design between two cultures (taiwanese and australian cultures). The web usability experiment is then established to test if those culturally preferred characteristics can improve the web communication (usability). The results of the usability test reveal that cultural preferences can facilitate the web communication. Furthermore, the suggestions for cross-cultural interaction design are concluded based on the results of the web communication evaluation. Relevance to human factors/ergonomics theory this research is relevant to human factors/ergonomics theory. © 2015 taylor & francis.","","","2015","10.1080/1463922x.2015.1084398","","","scopus-2-s2.0-84944448116.pdf","scopus-2-s2.0-84944448116"
"Geospatial data sharing based on geospatial semantic web technologies","Zhang, C. And Li, W. And Zhao, T.","Journal Of Spatial Science","","Geospatial data sharing is a concern in geospatial science because of the heterogeneity of existing geographical information systems. This study aims to examine the use of geospatial semantic web technologies such as ontology web services and the service-oriented architecture for enabling disparate heterogeneous legacy gis to share and integrate information in a cost effective way to reduce spatial data duplication. A framework based on the geospatial semantic web technologies is proposed in this study. Experimental results from an implemented prototype show that the proposed framework allows searching and accessing geospatial data and services at the semantic level based on their content instead of keywords in the metadata. © 2007, taylor & francis group, llc.","","","2007","10.1080/14498596.2007.9635121","","","scopus-2-s2.0-38549179388.pdf","scopus-2-s2.0-38549179388"
"A Mixed-Methods Systematic Review and Synthesis of Secondary Care Interventions to Reduce Secondhand Smoke Exposure Among Children and Young People","Ferris E., Cummins C., Chiswell C., Jones L. L.","Nicotine & Tobacco Research","","INTRODUCTION: Childhood secondhand smoke exposure (SHSe) is linked with increased morbidity and mortality. Hospital or secondary care contact presents a ""teachable moment"" to support parents to change their home smoking behaviors to reduce children's SHSe.\\\\\\\\rAIMS AND METHODS: This mixed-methods review explores: (1) if existing interventions in this context are effective (2) if they are reported in sufficient detail to be replicated (3) the experiences of health care professionals delivering such interventions and (4) the experiences of parents receiving such interventions. Five electronic databases and the gray literature were searched for relevant literature published and indexed January 1980 to February 2020. Fourteen papers reporting 12 studies (nine quantitative and five qualitative) were included. Aligned with the Joanna Briggs Institute method a segregated approach was used involving independent syntheses of the quantitative and qualitative data followed by an overall mixed-methods synthesis.\\\\\\\\rRESULTS: There was some evidence of effective interventions that resulted in a short-term (<6 months) reduction in children's SHSe when SHSe was subjectively measured. This was not seen in longer-term follow-up (>6 months) or when SHSe was measured objectively. Inconsistencies with reporting make replication challenging. Experiential evidence suggests a mismatch between stakeholder preferences and interventions being offered.\\\\\\\\rCONCLUSIONS: The pediatric secondary care interventions included in this analysis failed to show statistically significant evidence of longer-term effectiveness to reduce children's SHSe in all but one low-quality study. There was also inadequate reporting of interventions limiting assessment of effectiveness. It offers further insights into areas to target to develop effective interventions.\\\\\\\\rIMPLICATIONS: This review used rigorous methods to explore the current global literature on how children's exposure to secondhand smoke is being tackled in secondary care. This review identified only one low-quality intervention study showing a statistically significant reduction in children's SHSe beyond 6 months. Synthesis with qualitative research identifies a mismatch between what parents want in an intervention and what has been delivered to date. Reporting quality needs to be improved to ensure that interventions can be replicated and studies conducted within the National Health Service to ensure suitability to this setting. Copyright © The Author(s) 2020. Published by Oxford University Press on behalf of the Society for Research on Nicotine and Tobacco. All rights reserved. For permissions please e-mail: journals.permissions@oup.com.","","","2021","10.1093/ntr/ntaa216","","","medline-33098295.pdf","medline-33098295"
"Challenges of research assessment oriented towards knowledge mobilization in the transition to open science: an analysis based on the case of the Working Groups from the Latin American Council of Social Sciences","Vommaro P., Rovelli L.","Analecta Politica","","Various recent debates and initiatives have once again brought to the forefront the need to reform research evaluation and its greater link with society based on a growing openness collaboration and participation in the field of knowledge following some of the principles of transition to open science. The foregoing entails multiple challenges for the design of research promotion instruments and their evaluation. Taking as a sample case an experience in the Research Area of the Latin American Council of Social Sciences (Clacso) this article aims to describe and analyze the challenges of evaluating research aimed at mobilizing knowledge based on the configuration of Clacso's Groups of Work with a focus on the criteria of the 2019-2022 call. In particular the specific characteristics of the evaluation criteria involved in this program and its scope in relation to inclusion openness collaboration and interaction with society are explored. The approach is qualitative in nature and benefits from the collection of mainly documentary data related to the bases of the call for the 2019-2022 Working Groups the evaluation grids used and the organizational actions promoted around some of the principles of open access and open science.","","","2022","10.18566/apolit.v12n22.a02","","","wos-001017290500002.pdf","wos-001017290500002"
"Data replication in mobile edge computing systems to reduce latency in internet of things","Saranya, N. And Geetha, K. And Rajan, C.","Wireless Personal Communications","","The progress in the development in the field of information technology has brought the internet of things (iot) into existence to play a crucial role in our daily lives. There are interconnected sensors or devices that can both collect and also exchange various data among themselves by employing a modern network of communication as an infrastructure that has been connected by many millions of the iot nodes. After this, there are various applications of the iot that may be able to provide accurate and fine-grained services to the users. Using this as a strategy which can mitigate an escalation to the congestion of resources, edge computing is emerging as the new paradigm that solves the needs of localized computing and the iot. The mobile edge computing (mec) has been emerging to handle the volume of data produced and this can reach a latency of demand of the iot applications that are intensive in terms of computation. Even though the mec has advanced in terms of latency of service and has been solidly investigated, the efficiency of data usage and security are not identified clearly. Replication of data is well suited for improving the time taken for a response, global traffic and data sharing as even at the time of server disconnection this can be done. In this work, efficient techniques of data replication for the mobile ad hoc networks (manet) like the simple and the random applications are evaluated for improving availability of data which considers all the issues that are related to the manet like consumption of power, availability of resource, time taken for response and consistency management. The results of the experiment have shown that a random algorithm for replication can achieve a bandwidth that is better in terms of savings compared to a simple replication algorithm. © 2020, springer science+business media, llc, part of springer nature.","","","2020","10.1007/s11277-020-07168-7","","","scopus-2-s2.0-85078365184.pdf","scopus-2-s2.0-85078365184"
"Insertion of fiocruz’s scientific production in initiatives to promote open access to research data in national and international journals","Martins, M.f.m. And Dos Santos, H.l.c. And Jorge, V.a. And De Oliveira, J.g.","Ciencia Da Informacao","","The study aimed to identify the inclusion of fiocruz’s scientific production in initiatives to promote open access to research data in national and international journals, from 2012 to 2018. It presents reflections on the alignment of editorial policies with international open science guidelines, in order to consider this indicator as a component of the evaluation and qualification of the application for good practices by researchers linked to fiocruz. To carry out the work and fulfill the objectives, a descriptive methodology was adopted, through systematic mapping. To this end, an exploratory research was conducted through bibliographic review, by affiliation, followed by documentary research on the website of the selected journals, which consisted of several steps, resulting in a list of 10 magazine titles for comparison and analysis, according to the ranking. generated by the scientific production indexed in the databases. The results showed that journals should be stimulated to meet the standards demanded by the open science movement, the limits and possibilities of establishing a policy for managing, opening and sharing research data for fiocruz, both as a producer and publisher. The theme needs further studies involving this theme. © 2019, brazilian institute for information in science and technology. All rights reserved.","","","2019","","","","scopus-2-s2.0-85082511666.pdf","scopus-2-s2.0-85082511666"
"Respecting values and perspectives in biobanking and genetic research governance: Outcomes of a qualitative study in Bengaluru India","Vaz M., Warrier P., Wai-Loon Ho C., Bull S.","Wellcome Open Research","","Background: The promise of biobanking and genetic research (BGR) in the context of translational research towards improving public health and personalised medicine has been recognised in India. Worldwide experience has shown that incorporating stakeholders' expectations and values into the governance of BGR is essential to address ethical aspects of BGR. This paper draws on engagement with various stakeholders in the South Indian city of Bengaluru to understand how incorporating people's values and beliefs can inform policy making decisions and strengthen BGR governance within India. Methods: We adopted a qualitative research approach and conducted six focus group discussions with civil society members and seven in-depth interviews with key informants in BGR identified through a targeted web search and snowballing methods until data saturation was reached. Data were thematically analysed to identify emergent patterns. Results: Specific themes relating to the ethics and governance of BGR emerged. Fears and uncertainty about future sample and data use possibilities of discrimination and exploitation in the use of findings and the lack of comprehensive data protection policies in India along with expectations of enhanced contributor agency control in future use of samples and data benefit sharing enhanced utility of samples sustained BGR and public good reflected tensions between different stakeholders' values and beliefs. Fair governance processes through an independent governance committee for biobanks and a system of ongoing engagement with stakeholders emerged as best practice towards building trust and respecting diversity of views and values. Conclusions: Ensuring public trust in BGR requires listening to stakeholders' voices being open to counter narratives and a commitment to long term engagement embedded in principles of participatory democracy. This is central to a 'people-centred governance framework' involving a negotiated middle ground and an equilibrium of governance which promotes social justice by being inclusive transparent equitable and trustworthy. Copyright: © 2023 Vaz M et al.","","","2022","10.12688/wellcomeopenres.17628.2","","","medline-37485294.pdf","medline-37485294"
"The MetaboLights repository: curation challenges in metabolomics","Salek R. M., Haug K., Conesa P., Hastings J., Williams M., Mahendraker T., Maguire E., Gonzalez-Beltran A. N., Rocca-Serra P., Sansone S. A., Steinbeck C.","Database: The Journal of Biological Databases and Curation","","MetaboLights is the first general-purpose open-access curated repository for metabolomic studies their raw experimental data and associated metadata maintained by one of the major open-access data providers in molecular biology. Increases in the number of depositions number of samples per study and the file size of data submitted to MetaboLights present a challenge for the objective of ensuring high-quality and standardized data in the context of diverse metabolomic workflows and data representations. Here we describe the MetaboLights curation pipeline its challenges and its practical application in quality control of complex data depositions. Database URL: http://www.ebi.ac.uk/metabolights.","","","2013","10.1093/database/bat029","","","medline-23630246.pdf","medline-23630246"
"“There is no link between resource allocation and use of local data”: a qualitative study of district-based health decision-making in west bengal, india","Bhattacharyya, S. And Issac, A. And Girase, B. And Guha, M. And Schellenberg, J. And Avan, B.i.","International Journal Of Environmental Research And Public Health","","Background: effective coordination among multiple departments, including data-sharing, is needed for sound decision-making for health services. India has a district planning process involving departments for local resource-allocation based on shared data. This study assesses the decision-making process at the district level, with a focus on the extent of local data-use for resource allocation for maternal and child health. Methods: direct observations of key decision-making meetings and qualitative interviews with key informants were conducted in two districts in the state of west bengal, india. Content analysis of the data maintained within the district health system was done to understand the types of data available and sharing mechanisms. This information was triangulated thematically based on who health system blocks. Results: there was no structured decision-making process and only limited inter-departmental data-sharing. Data on all 21 issues discussed in the district decision-making meetings observed were available within the information systems. Yet indicators for only nine issues—such as institutional delivery and immunisation services were discussed. Discussions about infrastructure and supplies were not supported by data, and planning targets were not linked to health outcomes. Conclusion: existing local data is highly under-used for decision-making at the district level. There is strong potential for better interaction between departments and better use of data for priority-setting, planning and follow-up. © 2020 by the authors. Licensee mdpi, basel, switzerland.","","","2020","10.3390/ijerph17218283","","","scopus-2-s2.0-85095811299.pdf","scopus-2-s2.0-85095811299"
"Evaluating the replicability and specificity of evidence for natural pedagogy theory","Silverstein, Priya","Dissertation Abstracts International: Section B: The Sciences And Engineering","","Do infants understand that they are being communicated to? This thesis first outlines issues facing the field of infancy research that affect confidence in the literature on this (and any) topic to date. Following this, an introductory chapter evaluates evidence for the three core claims of natural pedagogy (np), and the compatibility of this evidence with alternative theories. This is followed by three experimental chapters. In study 1, we attempted two replications of the study with the highest theoretical value for np (yoon et al., 2008). This study has high stakes theoretically, as it is the only study providing evidence for the most specific claim of np that is difficult to explain by low-level mechanisms. Therefore, a replication of this result that included a reduction of possible confounds and a more sophisticated measure of attention throughout the task was of great theoretical value. In this study, we were unable to replicate the original findings. In study 2 we went beyond the evidence for the claims made in the outline of np, and instead generated a new, specific prediction that we believe np would make. This is important, as theories are only useful if they can make clear, testable predictions. In this study, we pitted pedagogically demonstrated actions and simple actions against each other and evaluated infants' transmission of these actions to someone else. We found no evidence for np, finding evidence for preferential transmission of simple actions instead. In study 3 we went beyond np, and tested a clear prediction stemming from an alternative low-level theory for how infants develop gaze-following ability. We found evidence that infants learn to gaze-follow through reinforcement. Overall, this thesis contributes to the vast literature on infants as recipients of communication, as well as highlighting methods for conducting open and reproducible infancy research. (Psycinfo database record (c) 2021 apa, all rights reserved)","","","2021","","","","psychinfo-2020-97496-004.pdf","psychinfo-2020-97496-004"
"Data Science Solution to Event Prediction in Outsourced Clinical Trial Models","Dalevi D., Lovick S., Mann H., Metcalfe P. D., Spencer S., Hollis S., Ruau D.","Studies in Health Technology & Informatics","","Late phase clinical trials are regularly outsourced to a Contract Research Organisation (CRO) while the risk and accountability remain within the sponsor company. Many statistical tasks are delivered by the CRO and later revalidated by the sponsor. Here we report a technological approach to standardised event prediction. We have built a dynamic web application around an R-package with the aim of delivering reliable event predictions simplifying communication and increasing trust between the CRO and the in-house statisticians via transparency. Short learning curve interactivity reproducibility and data diagnostics are key here. The current implementation is motivated by time-to-event prediction in oncology. We demonstrate a clear benefit of standardisation for both parties. The tool can be used for exploration communication sensitivity analysis and generating standard reports. At this point we wish to present this tool and share some of the insights we have gained during the development.","","","2015","","","","medline-26262364.pdf","medline-26262364"
"Community expectations for research artifacts and evaluation processes","Hermann B., Winter S., Siegmund J., Devanbu P., Cohen M., Zimmermann T.","","","Background. Artifact evaluation has been introduced into the software engineering and programming languages research community with a pilot at ESEC/FSE 2011 and has since then enjoyed a healthy adoption throughout the conference landscape. Objective. In this qualitative study we examine the expectations of the community toward research artifacts and their evaluation processes. Method. We conducted a survey including all members of artifact evaluation committees of major conferences in the software engineering and programming language field since the first pilot and compared the answers to expectations set by calls for artifacts and reviewing guidelines. Results. While we find that some expectations exceed the ones expressed in calls and reviewing guidelines there is no consensus on quality thresholds for artifacts in general. We observe very specific quality expectations for specific artifact types for review and later usage but also a lack of their communication in calls. We also find problematic inconsistencies in the terminology used to express artifact evaluation's most important purpose - replicability. Conclusion. We derive several actionable suggestions which can help to mature artifact evaluation in the inspected community and also to aid its introduction into other communities in computer science. © 2020 ACM.","","","2020","10.1145/3368089.3409767","","","scopus-2-s2.0-85097193422.pdf","scopus-2-s2.0-85097193422"
"Selecting healthcare information systems provided by third-party vendors: a mind map beyond the manuals","Gortzis L. G.","Informatics for health & social care","","The selection of a new healthcare information system (HIS) has always been a daunting process for clinicians health care providers and policy makers. The objective of this study is to present the lessons learned and the main findings from several relevant case studies to support this process. Data were collected by retrospectively reviewing the summative results of three well-established systems acquiring feedback from two E.U. projects and conducting semi-structured interviews with a number of collaborators involved in electronic healthcare interventions. Selection issues were identified and classified into the following five categories: (i) data creation (ii) data management (iii) data sharing (iv) data presentation and (v) modules management. A mind map was also structured to provide a more manageable list of issues concerning the most common electronic clinical technologies (e-CT). The vendor manual is intended as an overview of the merchandise e-CT and therefore has limited potential in supporting effectively the selection process of a new HIS. The present classification and the mind map - based on lessons learned - provide a ready-to-use toolkit for supporting the HIS selection process when healthcare organisations are unable to employ research development groups to lay the groundwork for building a new HIS from scratch.","","","2010","10.3109/17538150903123071","","","medline-20302435.pdf","medline-20302435"
"Associative big data sharing in community clouds: the meepo approach","Wu, Y. And Su, M. And Zheng, W. And Hwang, K. And Zomaya, A.y.","Ieee Cloud Computing","","In a community cloud, multiple user groups dynamically share a massive number of data blocks. The authors present a new associative data sharing method that uses virtual disks in the meepo cloud, a research storage cloud built at tsinghua university. Innovations in the meepo cloud design include big data metering, associative data sharing, data block prefetching, privileged access control (pac), and privacy preservation. These features are improved or extended from competing features implemented in dropbox, cloudviews, and myspace. The reported results support the effectiveness of the meepo cloud. © 2015 ieee.","","","2015","10.1109/mcc.2015.123","","","scopus-2-s2.0-84964792167.pdf","scopus-2-s2.0-84964792167"
"Poor reporting quality in basic nutrition research: a case study based on a scoping review of recent folate research in mouse models (2009–2021)","Munezero, E. And Behan, N.a. And Diaz, S.g. And Neumann, E.-M. And Macfarlane, A.j.","Advances In Nutrition","","Transparent reporting of nutrition research promotes rigor, reproducibility, and relevance to human nutrition. We performed a scoping review of recent articles reporting dietary folate interventions in mice as a case study to determine the reporting frequency of generic study design items (i.e., sex, strain, and age) and nutrition-specific items (i.e., base diet composition, intervention doses, duration, and exposure verification) in basic nutrition research. We identified 798 original research articles in the embase, medline, food science and technology abstracts (fsta), global health, and international pharmaceutical abstracts (ipa) databases published between january 2009 and july 2021 in which a dietary folic acid (fa) intervention was used in mice. We identified 312 original peer-reviewed articles including 191 studies in nonpregnant and 126 in pregnant mice. Most studies reported sex (99%), strain (99%), and age (83%). The majority of studies used c57bl/6 (53%) or balb/c (11%) mice aged 3–9 wk. Nonpregnancy studies were more likely to use only male mice (57%). Dietary fa interventions varied considerably and overlapped: deficiency (0–3 mg/kg), control (0–16 mg/kg), and supplemented (0–50 mg/kg). Only 63% of studies used an open-formula base diet with a declared fa content and 60% of studies verified fa exposure using folate status biomarkers. The duration of intervention ranged from 1 to 104 wk for nonpregnancy studies. The duration of intervention for pregnancy studies was 1–19 wk, occurring variably before pregnancy and/or during pregnancy and/or lactation. Overall, 17% of studies did not report ≥1 generic study design item(s) and 40% did not report ≥1 nutrition-specific study design item(s). The variability and frequent lack of reporting of important generic and nutrition-specific study design details in nutrition studies limit their generalizability, reproducibility, and interpretation. The use of reporting checklists for animal research would enhance reporting quality of key study design and conduct factors in animal-based nutrition research. © 2022 her majesty the queen in right of canada, as represented by the minister of health, 2022","","","2022","10.1093/advances/nmac056","","","scopus-2-s2.0-85143505386.pdf","scopus-2-s2.0-85143505386"
"Reconcilable differences","Green, T.j. And Ives, Z.g. And Tannen, V.","Theory Of Computing Systems","","In this paper we study a problem motivated by the management of changes in databases. It turns out that several such change scenarios, e. g., the separately studied problems of view maintenance (propagation of data changes) and view adaptation (propagation of view definition changes) can be unified as instances of query reformulation using views provided that support for the relational difference operator exists in the context of query reformulation. Exact query reformulation using views in positive relational languages is well understood, and has a variety of applications in query optimization and data sharing. Unfortunately, most questions about queries become undecidable in the presence of difference (or negation), whether we use the foundational set semantics or the more practical bag semantics. We present a new way of managing this difficulty by defining a novel semantics, z-relations, where tuples are annotated with positive or negative integers. Z-relations conveniently represent data, insertions, and deletions in a uniform way, and can apply deletions with the union operator (deletions are tuples with negative counts). We show that under z-semantics relational algebra ([inlineequation not available: see fulltext.]) queries have a normal form consisting of a single difference of positive queries, and this leads to the decidability of their equivalence. We provide a sound and complete algorithm for reformulating [inlineequation not available: see fulltext.] queries, including queries with difference, over z-relations. Additionally, we show how to support standard view maintenance and view adaptation over set or bag semantics, through an excursion into the z-semantics setting. Our algorithm turns out to be sound and complete also for bag semantics, albeit necessarily only for a subclass of [inlineequation not available: see fulltext.]. This subclass turns out to be quite large and covers generously the applications of interest to us. We also show a subclass of [inlineequation not available: see fulltext.] where reformulation and evaluation under z-semantics can be combined with duplicate elimination to obtain the answer under set semantics. We investigate related complexity questions, and we also extend our results to queries with built-in predicates. © 2011 springer science+business media, llc.","","","2011","10.1007/s00224-011-9323-x","","","scopus-2-s2.0-79958018911.pdf","scopus-2-s2.0-79958018911"
"Designing asynchronous online fermentation science materials including using a home fermented foods project to engage online learners","Holle, M.j. And Miller, M.j.","Journal Of Food Science Education","","The number of online courses offered by universities in america continues to increase. Due to limited direct interactions with students, these courses can struggle to promote student engagement. Food science is uniquely situated for implementation of hands-on project-based learning opportunities since basic experiments can be performed in a kitchen with minimal supplies and equipment. The purpose of this teaching and learning tip is to share materials designed for an asynchronous online course, instructional fermentation vignettes, and the home fermented foods project assignment, which tasks students with creating two fermented foods with two accompanying documents explaining the science of each employed steps. Students are engaged with the projects while connecting the lecture material to familiar products that they create such as sauerkraut, yogurt, and bread. Overall, based on student evaluations and our interactions with the students, our implementation of this project has been positive. Downloadable handouts containing assignment details are available as supporting information. © 2020 institute of food technologists®","","","2021","10.1111/1541-4329.12212","","","scopus-2-s2.0-85092894843.pdf","scopus-2-s2.0-85092894843"
"Testing the theory of relative defect proneness for closed-source software","Koru, G. And Liu, H. And Zhang, D. And El Emam, K.","Empirical Software Engineering","","Recent studies on open-source software (oss) products report that smaller modules are proportionally more defect prone compared to larger ones. This phenomenon, referred to as the theory of relative defect proneness (rdp), challenges the traditional qa approaches that give a higher priority to larger modules, and it attracts growing interest from closed-source software (css) practitioners. In this paper, we report the findings of a study where we tested the theory of rdp using ten css products. The results clearly confirm the theory of rdp. We also demonstrate the useful practical implications of this theory in terms of defect-detection effectiveness. Therefore, this study does not only make research contributions by rigorously testing a scientific theory for a different category of software products, but also provides useful insights and evidence to practitioners for revising their existing qa practices. © 2010 springer science+business media, llc.","","","2010","10.1007/s10664-010-9132-x","","","scopus-2-s2.0-77956751740.pdf","scopus-2-s2.0-77956751740"
"Health & demographic surveillance system profile: the nairobi urban health and demographic surveillance system (nuhdss)","Beguy, D. And Elung'ata, P. And Mberu, B. And Oduor, C. And Wamukoya, M. And Nganyi, B. And Ezeh, A.","International Journal Of Epidemiology","","The nairobi urban health and demographic surveillance system (nuhdss) was the first urban-based longitudinal health and demographic surveillance platform in sub-saharan africa (ssa). The nuhdss was established in 2002 to provide a platform to investigate the long-term social, economic and health consequences of urban residence, and to serve as a primary research tool for intervention and impact evaluation studies focusing on the needs of the urban poor in ssa. Since its inception, the nuhdss has successfully followed every year a population of about 65 000 individuals in 24 000 households in two slum communities-korogocho and viwandani-in nairobi, kenya. Data collected include key demographic and health information (births, deaths including verbal autopsy, in- and out-migration, immunization) and other information that characterizes living conditions in the slums (livelihood opportunities, household amenities and possessions, type of housing etc.). In addition to the routine data, it has provided a robust platform for nesting several studies examining the challenges of rapid urbanization in ssa and associated health and poverty dynamics. Nuhdss data are shared through internal and external collaborations, in accordance with the centre's guidelines for publications, data sharing. © the author 2015;  all rights reserved. Published by oxford university press on behalf of the international epidemiological association.","","","2015","10.1093/ije/dyu251","","","scopus-2-s2.0-84936746593.pdf","scopus-2-s2.0-84936746593"
"What do future trends in medical education mean to the scientific development of iran's health system?","Poursheikhali, A. And Dehnavieh, R. And Haghdoost, A. And Seyedi, S.m. And Heidari, A.h. And Masoud, A. And Bamir, M. And Chashmyazdan, M.r. And Sajady, S.m.k.","Medical Journal Of The Islamic Republic Of Iran","","Background: medical education system in iran has an essential role in responding to scientific development targets from both education and research perspectives. Investigating future trends and analyzing how they interact with the medical education system helps increase awareness and give insight into the preferred future. Methods: the present qualitative study consists of systematic reviews and interviews that have been analyzed using content analysis. Afterward, the themes and codes were visualized in the form of maps and presented in a focus group discussion of experts to define how medical education trends will impact scientific development. Results: the future trends of iran's medical education system were classified into six groups: workplace changes, demographic changes, changes in concepts, the emergence of new players, structural changes in universities, and technology development. The next point is how they will influence science development. Their impact on science development is classified into five main groups or main streams of change of new financial models, open science, redesigning the research management, the role of universities, and capacity building. Conclusion: our findings showed that redesigning the structure of medical education is the most important priority to make the system as agile as needed to capture the signs and act. New meanings and concepts should also be considered in restructuring, like power balance, competency-based and personalized education, cost-effectiveness, and openness © iran university of medical sciences","","","2023","10.47176/mjiri.37.32","","","scopus-2-s2.0-85152404650.pdf","scopus-2-s2.0-85152404650"
"From blurry space to a sharper sky: keeping twenty-three years of astronomical data alive","Boscoe, Bernadette Marie","Dissertation Abstracts International Section A: Humanities And Social Sciences","","In compute-heavy and data-driven scientific fields, digital data play a central role in the creation of knowledge. For science fields that rely on data that can only be observed once, the preservation of these data is crucial to analytic processes. Time-domain astronomy is one such field, involving celestial observations such as exploding supernovae and passing comets. This dissertation examines the data and code practices of a university-based astronomy research group who have managed to keep their data ""alive"" for twenty-three years with limited resources. Keeping data alive means both understanding the knowledge contained within and having the associated technologies operable. The human aspects necessary to keep data alive are equally as important as the technological elements. This three-year ethnographic research project examines the factors involved in analyzing, preserving, and curating astronomy data as these data wend their way through socio-technical, physical, and digital infrastructures that shape and are shaped by the knowledge contained within the data. Dissertation research took place at six field sites: the case study's university, the observatory of the case study, the archive of the observatory, and three other astronomy archives. The findings of this study show two main ways that data are kept alive in astronomy: 1) publicly: data are curated and preserved with the intention to be made available via web interfaces, engendering relationships among stakeholders, and 2) privately: data are preserved by astronomy research groups at universities that continually reuse them and their associated code, in a collaborative way. Findings suggest how a better understanding of the relationships between public and private astronomy data can inform scientific data preservation and curation practices. (Psycinfo database record (c) 2021 apa, all rights reserved)","","","2019","","","","psychinfo-2019-46352-235.pdf","psychinfo-2019-46352-235"
"Reusing training data with generative/discriminative hybrid model for practical acceleration-based activity recognition","Kong, Q. And Maekawa, T.","Computing","","This paper proposes a new daily activity recognition method that can learn an activity classification model with small quantities of training data by sharing training data among different activity classes. Many existing activity recognition studies employ a supervised machine learning approach and thus require an end user's labeled training data, this approach places a large burden on the user. In this study, we assume that a user wears sensors (accelerometers) on several parts of the body such as the hands, waist, and thigh, and we attempt to share sensor data obtained from only selected accelerometers (e.g., only waist and thigh sensors) among two different activity classes based on a sensor data similarity measure. This approach permits us to correctly learn parameters of an activity classification model by using sufficient quantities of shared sensor data without adding new training data. We confirmed the effectiveness of our method by using 48 h of sensor data obtained from 20 participants, and achieved a good recognition accuracy. © 2013 springer-verlag wien.","","","2014","10.1007/s00607-013-0326-0","","","scopus-2-s2.0-84906786885.pdf","scopus-2-s2.0-84906786885"
"How gender impacts career development and leadership in rehabilitation medicine: a report from the AAPM&R research committee","Wagner A. K., McElligott J., Chan L., Wagner E. P. 2nd, Segal N. A., Gerber L. H.","Archives of Physical Medicine & Rehabilitation","","OBJECTIVE: To examine the role that gender plays in meeting the medical academic mission by assessing career development leadership and research productivity among rehabilitation researchers.\\\\\\\\rDESIGN: Prospective cross-sectional cohort study.\\\\\\\\rSETTING: National survey.\\\\\\\\rPARTICIPANTS: Three hundred sixty rehabilitation professionals linked to the American Academy of Physical Medicine and Rehabilitation Association of Academic Physiatrists and/or the American Congress of Rehabilitation Medicine.\\\\\\\\rINTERVENTION: Online or paper survey.\\\\\\\\rMAIN OUTCOME MEASURES: Research skills resources and productivity salary leadership and academic advancement.\\\\\\\\rRESULTS: Results suggested that women rated themselves as being less skilled and having fewer resources for research compared with their male counterparts. Additionally significantly fewer women applied for grant funding and had a lower publication rate compared with men. A proportionally larger number of women remained at lower academic ranks than men and fewer women achieved senior academic ranks or positions of leadership. Even after adjusting for potential confounding factors female sex remained a significant variable associated with lower salaries and lower manuscript production. Unlike men female respondents tended to believe that being a woman was a negative factor with respect to academic advancement leadership opportunities salary and resources.\\\\\\\\rCONCLUSIONS: Female rehabilitation researchers were less developed professionally than their male counterparts and saw themselves as disadvantaged. These findings have potential implications for attracting women into rehabilitation research and the rehabilitation research community's efforts to sustain its academic mission to improve research capacity and to meet the needs of the 52 million people in the United States with disabilities.","","","2007","10.1016/j.apmr.2007.01.014","","","medline-17466723.pdf","medline-17466723"
"Ontology-based data integration of open source electronic medical record and data capture systems","Guidry, Alicia F","Dissertation Abstracts International Section A: Humanities And Social Sciences","","In low-resource settings, the prioritization of clinical care funding is often determined by immediate health priorities. As a result, investment directed towards the development of standards for clinical data representation and exchange are rare and accordingly, data management systems are often redundant. Open-source systems such as openmrs and openclinica provide an opportunity to leverage available systems to improve standards and increase interoperability. Nevertheless, continuity of care and data sharing between these systems remains a challenge, particularly in populations with changing health needs, and inconsistent access to health resources. The overarching goal of this project is to enable sharing of data across low cost systems like openmrs and openclinica using ontologies. The project consists of three aims: 1) describing clinical research and visit data related to the treatment and care of hiv/aids patients, 2) developing a prototype data integration system between electronic medical record and electronic data capture systems, and 3) evaluating the utility of the prototype system using simulated and real-world data. In the first aim, i developed a patient identifier and a hiv/aids treatment and care ontology to represent the types of data and information created and used by clinicians. This was achieved by gathering data forms used in hiv/aids clinics in low-resource settings. From these forms, the patient identifier and hiv/aids variables were extracted and used to create the ontologies. In aim 2, the ontologies from aim 1, along with simulated data, were used to develop a prototype data integration system that improves the ability of developers to implement integration systems that meet the needs of users, based on previously created use cases. In the third aim, i evaluated whether the matching algorithm used in the prototype can correctly identify matching patients, and whether the prototype is generalizable to clinical care and research data collected in a real world setting. This work contributes two ontologies to the medical and public health fields that are useful in providing standardization of data elements. Additionally, i provide a prototype data integration system that is useful in facilitating access to previously siloed data and helps reduce the burden of integrating future systems. (Psycinfo database record (c) 2021 apa, all rights reserved)","","","2014","","","","psychinfo-2014-99210-410.pdf","psychinfo-2014-99210-410"
"Exploring pre-service teachers’ beliefs and practices about two inclusive frameworks: universal design for learning and differentiated instruction","Griful-Freixenet, J. And Struyven, K. And Vantieghem, W.","Teaching And Teacher Education","","The interrelationship between udl and di has long been a topic of debate. This empirical study of pre-service teachers has been carried out to explore underlying beliefs and practices about these two inclusive frameworks and to tap into their potential interrelationship. The results show that udl and di practices are different but highly interrelated. Both practices share important predictors (i.e., ongoing assessment, self-efficacy, self-regulation and motivation). However, flexible grouping was found to be a predictor of udl only. Overall, udl and di are perceived as two complementary approaches with sufficient internal consistency to be integrated. © 2021 elsevier ltd","","","2021","10.1016/j.tate.2021.103503","","","scopus-2-s2.0-85113967971.pdf","scopus-2-s2.0-85113967971"
"Combining contextualized word representation and sub-document level analysis through bi-lstm+crf architecture for clinical de-identification","Catelli, R. And Casola, V. And De Pietro, G. And Fujita, H. And Esposito, M.","Knowledge-Based Systems","","Clinical de-identification aims to identify protected health information in clinical data, enabling data sharing and publication. First automatic de-identification systems were based on rules or on machine learning methods, limited by language changes, lack of context awareness and time consuming feature engineering. Newer deep learning techniques for sequence labeling have shown better results with a reduction in feature engineering efforts and the use of word representation techniques in vector space. However, they are not able to jointly represent the polysemic and context-dependent nature of words, as well as their morpho-syntactic mutations characteristic of handwriting. To address these limitations, a new de-identification approach based on deep learning techniques for named entity recognition has been proposed, whose key factors are: (i) a bidirectional long short-term memory + conditional random field architecture for sequence labeling that takes advantage of the widest possible representation context;  (ii) a contextualized language model, working at character level, to capture the polysemy of words and manage the morpho-syntactic variations typical of handwritten notes;  (iii) more word representations stacked to better capture latent syntactic and semantic similarities. This approach has been tested on the official informatics for integrating biology & the bedside 2014 de-identification dataset, showing similar or higher performance than state of the art with respect to category and binary recognition, but without any feature engineering or handcrafted rules. The experiments demonstrate the effectiveness of the proposed approach, in particular with regard to category level recognition which is essential to correctly replace entities with surrogates for anonymization purposes. © 2020 elsevier b.v.","","","2021","10.1016/j.knosys.2020.106649","","","scopus-2-s2.0-85098056798.pdf","scopus-2-s2.0-85098056798"
"An approach for de-identification of point locations of livestock premises for further use in disease spread modeling","Martin M. K., Helm J., Patyk K. A.","Preventive Veterinary Medicine","","We describe a method for de-identifying point location data used for disease spread modeling to allow data custodians to share data with modeling experts without disclosing individual farm identities. The approach is implemented in an open-source software program that is described and evaluated here. The program allows a data custodian to select a level of de-identification based on the K-anonymity statistic. The program converts a file of true farm locations and attributes into a file appropriate for use in disease spread modeling with the locations randomly modified to prevent re-identification based on location. Important epidemiological relationships such as clustering are preserved to as much as possible to allow modeling similar to those using true identifiable data. The software implementation was verified by visual inspection and basic descriptive spatial analysis of the output. Performance is sufficient to allow de-identification of even large data sets on desktop computers available to any data custodian. Copyright © 2015 Elsevier B.V. All rights reserved.","","","2015","10.1016/j.prevetmed.2015.04.010","","","medline-25944175.pdf","medline-25944175"
"[Repeatability and variability of total T4 measurements at three German veterinary laboratories]","Bohm T., Klinger C., Classen J., Udraite L., Linek M., Mueller R. S.","Tierarztliche Praxis. Ausgabe K Kleintiere/Heimtiere","","OBJECTIVE: To evaluate the reproducibility of serum testing for total thyroxine (T4) in three German laboratories.\\\\\\\\rMATERIALS AND METHODS: Serum was taken from 53 dogs with suspected hypothyroidism and divided into five aliquots. Three aliquots of each sample were marked with different names and sent to one laboratory (two aliquots simultaneously and one aliquot 1-3 days later). The remaining aliquots were sent to two other laboratories. Laboratory 1 used an enzyme immunoassay for T4 measurements whereas laboratories 2 and 3 used a chemiluminescence immunoassay. The agreement between the three laboratories (values within or below the reference interval) was determined using the Cohen's Kappa test. The intra- and interassay variability was calculated for each laboratory and the agreement between samples submitted to the same laboratory was also determined using the Cohen's Kappa test.\\\\\\\\rRESULTS: For n = 23/41 patients tested simultaneously in the three laboratories all three values were either uniformly below within or above the respective reference interval. The Cohen's Kappa value for intra- and interassay agreement was 1.0 in laboratory 2 (n = 15 complete agreement) 0.33 in laboratory 1 (n = 16) and 0.37 (intra-) and 0.19 (interassay agreement) in laboratory 3 (n = 16 low agreement). There was a low agreement between laboratories 1 and 2 and between laboratories 1 and 3 (kappa = 0.30 and 0.25 respectively) while a high agreement was determined between laboratories 2 and 3 (kappa = 0.68). The intrassay variability of laboratories 1 2 and 3 was 13.6% 5.0% and 10.4% the interassay variability 17.2% 5.1% and 17.4% respectively.\\\\\\\\rCONCLUSION AND CLINICAL RELEVANCE: The differences in the measurement of thyroxine concentrations of the same serum sample in different laboratories and at different time points in the same laboratory underline the high relevance of interpreting laboratory results in context with the clinical signs of hypothyroidism as well as other laboratory values such as TSH concentration.","","","2017","10.15654/tpk-161137","","","medline-29099903.pdf","medline-29099903"
"Systematic Review of Economic Evaluations of Services Provided by Community Pharmacists","Sanyal C., Husereau D.","Applied Health Economics & Health Policy","","BACKGROUND: Community pharmacists' scope of practice has been evolving from a traditional dispensing role to providing patient-centered services. Given the constraints in healthcare budget and a need for efficient use of finite resources decision makers may require convincing evidence of value to recommend these services for public funding. Several economic evaluations have aimed to demonstrate the value of services provided by community pharmacists.\\\\\\\\rOBJECTIVE: The objective of this study was to systematically review the reporting and methodological quality of full economic evaluations of services provided by community pharmacists.\\\\\\\\rMETHODS: A literature search was conducted in the bibliographic databases MEDLINE EMBASE and the NHS Economic Evaluations Database since their inception to February 2019. Two independent reviewers performed title abstract full text screening and data abstraction and assessed the quality of reporting and methodological approaches using the Consolidated Health Economic Evaluation Reporting Standards (CHEERS) and Quality of Health Economic Studies (QHES) checklists.\\\\\\\\rRESULTS: Twenty full economic evaluations were included in the review. Most of these studies were conducted in the UK (40%) followed by the USA (35%) Canada (10%) the Netherlands (5%) Thailand (5%) and Australia (5%). The efficacy or effectiveness data were drawn from individual level or cluster randomized trials or observational studies. About half of these studies (45%) adopted the perspective of the public healthcare system. Four studies used decision analytic modeling. We identified issues in these studies with selection of study population efficacy or effectiveness data time horizon outcomes measured measurement or resources used and cost estimation analytical approaches and handling of uncertainty with study parameters. The quality of reporting and methodological considerations was variable across these studies with none of the studies adequately fulfilling all 24 items of CHEERS or 16 questions of QHES checklists.\\\\\\\\rCONCLUSIONS: Our findings suggest there are various issues related to the quality of conduct and reporting of economic evaluations of services provided by community pharmacists. Interpretation of these studies should be treated with caution to facilitate decision making in the local context. In an era of scarce resources and demand for evidence-informed decision making there may be a need for guidance on methodological approaches to assess the value of these services.","","","2020","10.1007/s40258-019-00535-x","","","medline-31755015.pdf","medline-31755015"
"Free automatic software for quality assurance of computed tomography calibration edges and radiomics metrics reproducibility","Saborido-Moral J. D., Fernandez-Paton M., Tejedor-Aguilar N., Cristian-Marin A., Torres-Espallardo I., Campayo-Esteban J. M., Perez-Calatayud J., Baltas D., Marti-Bonmati L., Carles M.","Physica Medica","","PURPOSE: To develop a QA procedure easy to use reproducible and based on open-source code to automatically evaluate the stability of different metrics extracted from CT images: Hounsfield Unit (HU) calibration edge characterization metrics (contrast and drop range) and radiomic features.\\\\\\\\rMETHODS: The QA protocol was based on electron density phantom imaging. Home-made open-source Python code was developed for the automatic computation of the metrics and their reproducibility analysis. The impact on reproducibility was evaluated for different radiation therapy protocols and phantom positions within the field of view and systems in terms of variability (Shapiro-Wilk test for 15 repeated measurements carried out over three days) and comparability (Bland-Altman analysis and Wilcoxon Rank Sum Test or Kendall Rank Correlation Coefficient).\\\\\\\\rRESULTS: Regarding intrinsic variability most metrics followed a normal distribution (88% of HU 63% of edge parameters and 82% of radiomic features). Regarding comparability HU and contrast were comparable in all conditions and drop range only in the same CT scanner and phantom position. The percentages of comparable radiomic features independent of protocol position and system were 59% 78% and 54% respectively. The non-significantly differences in HU calibration curves obtained for two different institutions (7%) translated in comparable Gamma Index G (1 mm 1% >99%).\\\\\\\\rCONCLUSIONS: An automated software to assess the reproducibility of different CT metrics was successfully created and validated. A QA routine proposal is suggested. Copyright © 2023 Associazione Italiana di Fisica Medica e Sanitaria. Published by Elsevier Ltd. All rights reserved.","","","2023","10.1016/j.ejmp.2023.103153","","","medline-37778209.pdf","medline-37778209"
"Feasibility of studying subfertility using retrospective self reports","Joffe M.","Journal of Epidemiology & Community Health","","During an investigation of possible reproductive effects of environmental agents 261 male and 155 female workers were interviewed concerning subfertility at some time in the past: the time taken to conceive for all births; and the occurrence of one or more fertile phases lasting for 6 months or more. When these two variables were compared the quality of reporting was acceptable in 89.7% of instances and data editing enabled accuracy to be improved. Reporting was more reliable with shorter duration of recall and female workers' reports were somewhat more reliable than those of male workers. The distribution of time taken to conceive was similar for male workers to that observed in previously published prospective series though with a higher estimate of subfertility when infertile phases were also considered. Comparison with published estimates of reduced fertility appeared to be reassuring. As predicted the equivalent comparisons for female workers showed the presence of a strong selection effect.","","","1989","10.1136/jech.43.3.268","","","medline-2607307.pdf","medline-2607307"
"Secure delivery scheme of common data model for decentralized cloud platforms","Cho, J.h. And Kang, Y. And Park, Y.b.","Applied Sciences (Switzerland)","","The common data model (cdm) is being used to deal with problems caused by the various electronic medical record structures in the distributed hospital information system. The concept of cdm is emerging as a collaborative method of exchanging data from each hospital in the same format and conducting various clinical studies based on shared data. The baseline of a cdm system is centralized with an infrastructure typically controlled by a single entity with full authority. The characteristics of this centralized system can pose serious security issues. Therefore, the proposed sc-cdm system is designed as a platform for distributed ledger and provides data with a high level of confidentiality, security, and scalability. This framework provides a reference model that supports multiple channels, using secure cdm as an encryption method. The data confidentiality of cdm is guaranteed by asymmetric and symmetric protocols. Delivering cdm is protected by a symmetric key signed by the cdm creator and maintains lightweight distributed ledger transactions on inter planetary file system (ipfs), which acts as a file share. To deliver an encrypted cdm on the sc-cdm platform, the cdm is encrypted with a block cipher by a random symmetric key and initialization vector (iv). The symmetric key protocol is used for the fast encryption of large-capacity data. The sc-cdm is implemented the repository with ipfs for storing the encrypted cdm, in which symmetric key, two hash values, and iv are shared through blockchain. Data confidentiality of sc-cdm is guaranteed by only registered users accessing the data. In conclusion, the sc-cdm is the first approach to demultiplexing with the data confidentiality proof based on asymmetric key cryptography. We analyze and verify the security of sc-cdm by comparing qualitative factors and performance with existing cdm. Moreover, we adopt a byte-level processing method with encryption to ensure efficiency while handling a large cdm. © 2020 by the authors. Licensee mdpi, basel, switzerland.","","","2020","10.3390/app10207134","","","scopus-2-s2.0-85092773873.pdf","scopus-2-s2.0-85092773873"
"An alliance chain-based incentive mechanism for psg data sharing","Zhang, W. And Huo, X. And Bao, Z.","Peer-To-Peer Networking And Applications","","Deep learning-based sleep staging can identify the signal characteristics of each stage of polysomnography (psg) and classify them automatically, but the sleep staging learning model for pursuing higher classification accuracy cannot be separated from the aggregation of a large number of data sets. To meet the needs of decentralized medical institution deployment and data security, this paper proposes an alliance chain-based psg data sharing model. Considering the need for psg data to carry tags when sharing and the access of wearable iot devices when collecting, we design an alliance chain-based intra- and inter-medical institution chain to ensure data security and privacy, and a labeled off-chain storage scheme based on the planetary file system (ipfs), which guarantees the blockchain performance and meets the need for labeling. At the same time, psg is a kind of precious medical data, and it is difficult for each medical institution to share the dataset spontaneously without compensation. Therefore, this paper designs an incentive mechanism based on data value and access credit, and obtains the incentive evaluation value by evaluating the dataset quality and institutional access behavior through an open and transparent mechanism, which not only guarantees the activity of the sharing system but also restrains the access behavior of each institution. Finally, this paper uses hyperledger fabric to implement a resource access control model based on permission hierarchy through smart contracts, and narrows the scope of policy retrieval by introducing incentive evaluation values, and the model is tested under six different policy scales with different degrees of significant improvement in access efficiency. © 2023, the author(s), under exclusive licence to springer science+business media, llc, part of springer nature.","","","2023","10.1007/s12083-023-01571-0","","","scopus-2-s2.0-85174598749.pdf","scopus-2-s2.0-85174598749"
"Cross-jurisdictional data exchange impact on the estimation of the hiv population living in the district of columbia: evaluation study","Hamp, A.d. And Doshi, R.k. And Lum, G.r. And Allston, A.","Jmir Public Health And Surveillance","","Background: accurate hiv surveillance data are essential to monitor trends to help end the hiv epidemic. Owing to strict policies around data security and confidentiality, hiv surveillance data have not been routinely shared across jurisdictions except a biannual case-by-case review process to identify and remove duplicate cases (routine interstate duplicate review, ridr). Hiv surveillance estimates for the district of columbia (dc) are complicated by migration and care seeking throughout the metropolitan area, which includes maryland and virginia. To address gaps in hiv surveillance data, health departments of dc, maryland, and virginia have established hiv surveillance data sharing agreements. Although the black box (a privacy data integration tool external to the health departments) facilitates the secure exchange of data between dc, maryland, and virginia, its previous iterations were limited by the frequency and scope of information exchanged. The health departments of dc, maryland, and virginia engaged in data sharing to further improve hiv surveillance estimates. Objective: this study assessed the impact of cross-jurisdictional data sharing on the estimation of people living with hiv in dc and reduction of cases in the ridr process. Methods: data sharing agreements established in 2014 allowed for the exchange of hiv case information (eg, current residential address) and laboratory information (eg, test types, result dates, and results) from the enhanced hiv/aids reporting system (ehars). Regular data exchanges began in 2017. The participating jurisdictions transferred data (via secure file transfer protocol) for individuals having a residential address in a partnering jurisdiction at the time of hiv diagnosis or evidence of receiving hiv-related services at a facility located in a partnering jurisdiction. The dc department of health compared the data received to dc ehars and imported updated data that matched existing cases. Evaluation of changes in current residential address and hiv prevalence was conducted by comparing data before and after hiv surveillance data exchanges. Results: after the hiv surveillance data exchange, an average of 396 fewer cases were estimated to be living in dc each year from 2012 to 2016. Among cases with a residential status change, 66.4% (1316/1982) had relocated to maryland and 19.8% (392/1982) to virginia;  majority of these had relocated to counties bordering dc. Relocation in and out of dc differed by mode of transmission, race and ethnicity, age group, and gender. After data exchange, the volume of hiv cases needing ridr decreased by 74% for dc-maryland and 81% for dc-virginia. Conclusions: hiv surveillance data exchange between the public health departments of dc, maryland, and virginia reduced the number of cases misclassified as dc residents and reduced the number of cases needing ridr. Continued data exchanges will enhance the ability of dc department of health to monitor the local hiv epidemic. © auntre d hamp, rupali k doshi, garret r lum, adam allston. Originally published in jmir public health and surveillance (http://publichealth.jmir.org), 13.08.2018. This is an open-access article distributed under the terms of the creative commons attribution license.","","","2018","10.2196/publichealth.9800","","","scopus-2-s2.0-85052857173.pdf","scopus-2-s2.0-85052857173"
"Evaluating the evidential value of empirically supported psychological treatments (ests): a meta-scientific review","Sakaluk, J.k. And Williams, A.j. And Kilshaw, R.e. And Rhyner, K.t.","Journal Of Abnormal Psychology","","Empirically supported treatments (or therapies;  ests) are the gold standard in therapeutic interventions for psychopathology. Based on a set of methodological and statistical criteria, the apa has assigned particular treatment-diagnosis combinations est status and has further rated their empirical support as strong, modest, and/or controversial. Emerging concerns about the replicability of research findings in clinical psychology highlight the need to critically examine the evidential value of est research. We therefore conducted a metascientific review of the est literature, using clinical trials reported in an existing online apa database of ests, and a set of novel evidential value metrics (i.e., rates of misreported statistics, statistical power, r-index, and bayes factors). Our analyses indicated that power and replicability estimates were concerningly low across almost all ests, and individually, some ests scored poorly across multiple metrics, with strong ests failing to continuously outperform their modest counterparts. Lastly, we found evidence of improvements over time in statistical power within the est literature, but not for the strength of evidence of est efficacy. We describe the implications of our findings for practicing psychotherapists and offer recommendations for improving the evidential value of est research moving forward. © 2019 american psychological association.","","","2019","10.1037/abn0000421","","","scopus-2-s2.0-85067667857.pdf","scopus-2-s2.0-85067667857"
"Carbonate reservoir fracture prediction by using pre-stack and post-stack seismic techniques in nanpu2 buried-hill","Geng, F.","Geophysical Prospecting For Petroleum","","Based on wide-azimuth seismic data and drilling data, the seismic comprehensive prediction of ordovician heterogeneous carbonate fracture-carst reservoir was conducted in the top of nanpu2 buried-hill.on the basis of seismic data amplitude-preservation processing, the surface layer and fracture pattern of nanpu2 buried-hill is identified by fine structure interpretation. Meanwhile, the p-wave azimuth anisotropy analysis technique is used to carry out pre-stack fracture prediction and curvature attribute is adopted to carry out post-stack fracture prediction. Moreover, post-stack attenuation gradient is utilized to detect the distribution of caves. By comparing the pre-stack and post-stack prediction results, combined with fmi imaging logging interpretation result and drilling data, we proved the correctness of our research clue and the effectiveness of the prediction methods. The comprehensive prediction results provide a basis for identifying the potential target area of ordovician carbonate reservoir in the nanpu2 buried-hill.","","","2013","10.3969/j.issn.1000-1441.2013.01.014","","","scopus-2-s2.0-84877065638.pdf","scopus-2-s2.0-84877065638"
"Nursing midwifery and allied health professions research capacities and cultures: a survey of staff within a university and acute healthcare organisation","Palmer S., Coad J., Gamble J., Jones C., Lees-Deutsch L., McWilliams D., Murphy E., Kneafsey R.","BMC Health Services Research","","BACKGROUND: There is an increasing focus on the development of research capacity and culture in Nursing Midwifery and Allied Health Professions (NMAHP). However better understanding of the existing research success and skills motivators barriers and development needs of NMAHP professionals is required to inform this development. This study sought to identify such factors within a university and an acute healthcare organisation.\\\\\\\\rMETHODS: An online survey incorporating the Research Capacity and Culture tool was administered to NMAHP professionals and students at a university and an acute healthcare organisation in the United Kingdom. Ratings of success/skill levels of teams and individuals were compared between professional groups using Mann-Whitney U tests. Motivators barriers and development needs were reported using descriptive statistics. Descriptive thematic analysis was used for open-ended text responses.\\\\\\\\rRESULTS: A total of 416 responses were received (N&M n = 223 AHP n = 133 Other n = 60). N&M respondents were more positive than their AHP counterparts about the success/skill levels of their teams. There were no significant differences between N&M and AHP in their ratings of individual successes/skills. Finding and critically reviewing relevant literature were identified as specific individual strengths; with weaknesses in securing research funding submitting ethics applications writing for publication and advising less experienced researchers. The main motivators for research were to develop skills increased job satisfaction and career advancement; whilst barriers included lack of time for research and other work roles taking priority. Key support needs identified included mentorship (for teams and individuals) and in-service training. Open-ended questions generated main themes of 'Employment & staffing' 'Professional services support' 'Clinical & academic management' 'Training & development' 'Partnerships' and 'Operating principles'. Two cross-cutting themes described issues common to multiple main themes: 'Adequate working time for research' and 'Participating in research as an individual learning journey'.\\\\\\\\rCONCLUSIONS: Rich information was generated to inform the development of strategies to enhance research capacity and culture in NMAHP. Much of this can be generic but some nuances may be required to address some specific differences between professional groups particularly related to perceived team success/skills and priorities identified for support and development. Copyright © 2023. The Author(s).","","","2023","10.1186/s12913-023-09612-3","","","medline-37328877.pdf","medline-37328877"
"The critical-size supraalveolar peri-implant defect model: reproducibility in histometric data acquisition of alveolar bone formation and osseointegration","Lee J., Tran Q., Seeba G., Wikesjo U. M., Susin C.","Journal of Clinical Periodontology","","OBJECTIVE: The objective of this report is to present the reproducibility of outcomes assessments in the Critical-Size Supraalveolar Peri-Implant Defect Model.\\\\\\\\rMATERIALS AND METHODS: Two examiners without specific experience in histological analysis and one experienced examiner performed the histometric evaluation. A comprehensive training program in data acquisition and histological analysis was established the inexperienced examiners underwent approximately 12 h of training over multiple sessions. A custom-designed image analysis software macro and a computer-based image system were used to analyse digital images generated by a microscope camera system. Nine parameters for newly formed and resident bone were evaluated. Examiners performed histometric analysis using 36 histologic sections selected from critical-size supraalveolar peri-implant defects in 12 male Hound Labrador Mongrel dogs. Buccal and lingual measurements were performed in 72 sites. Intra- and inter-examiner reproducibility were evaluated using the concordance correlation coefficient (CCC) and means +/- SD of the differences. Systematic errors were evaluated using an F-test for equality of means and variances.\\\\\\\\rRESULTS: Intra-examiner reproducibility was high for all parameters evaluated the lowest CCC observed being 0.87. Inter-examiner reproducibility was also high most CCCs exceeding 0.90. Minor systematic errors for intra- and inter-examiner comparisons were occasionally observed. The results imply a high temporal stability because recordings were performed 3 months apart. Measurement errors were stable throughout the range of observations for all parameters.\\\\\\\\rCONCLUSIONS: High examiner reproducibility and temporal stability can be achieved for histometric data acquisition using the Critical-Size Supraalveolar Peri-Implant Defect Model. Examiner reproducibility should be routinely assessed reported and accounted for to assure the quality of evidence generated by preclinical studies.","","","2009","10.1111/j.1600-051x.2009.01487.x","","","medline-19929958.pdf","medline-19929958"
"Reproducible Research Practices and Transparency across the Biomedical Literature","Iqbal S. A., Wallach J. D., Khoury M. J., Schully S. D., Ioannidis J. P. A.","PLoS Biology","","There is a growing movement to encourage reproducibility and transparency practices in the scientific community including public access to raw data and protocols the conduct of replication studies systematic integration of evidence in systematic reviews and the documentation of funding and potential conflicts of interest. In this survey we assessed the current status of reproducibility and transparency addressing these indicators in a random sample of 441 biomedical journal articles published in 2000-2014. Only one study provided a full protocol and none made all raw data directly available. Replication studies were rare (n = 4) and only 16 studies had their data included in a subsequent systematic review or meta-analysis. The majority of studies did not mention anything about funding or conflicts of interest. The percentage of articles with no statement of conflict decreased substantially between 2000 and 2014 (94.4% in 2000 to 34.6% in 2014); the percentage of articles reporting statements of conflicts (0% in 2000 15.4% in 2014) or no conflicts (5.6% in 2000 50.0% in 2014) increased. Articles published in journals in the clinical medicine category versus other fields were almost twice as likely to not include any information on funding and to have private funding. This study provides baseline data to compare future progress in improving these indicators in the scientific literature. Copyright © 2016 Public Library of Science. All Rights Reserved.","","","2016","10.1371/journal.pbio.1002333","","","medline-26726926.pdf","medline-26726926"
"A privacy-enhanced human activity recognition using gan & entropy ranking of microaggregated data","Aleroud, A. And Shariah, M. And Malkawi, R. And Khamaiseh, S.y. And Al-Alaj, A.","Cluster Computing","","The convergence of internet of things (iot) and edge computing allows for the collection and sharing of data from human wearable devices. With the huge amount of data transferred among those devices, privacy lies at the forefront of the concerns that must be addressed while preserving the usefulness of the shared data. This research proposes a microaggregation-generative based privacy-preserving model for human activity recognition by analyzing iot data. Although generative deep neural networks have been widely used for data perturbation and privacy-preserving models, data leakage and disclosing private information of the training samples through linkage attacks remain as major threats when employing traditional anonymization approaches. In addition, noisy records pose a threat to both privacy and quality of the resulting anonymized data. To address these challenges, we propose a novel approach to perturb iot data using generative adversarial networks (gan) and microaggregation while preserving both data privacy and utility. Our approach reduces the size of the original dataset by employing an entropy-preserving measure to discard outlier records when data is microaggregated. The performance of the proposed approach was measured using several criteria such as classification accuracy, precision, recall, and f-score to compare before and after anonymization. As a result, the proposed gan-microaggregation privacy-preserving technique showed a remarkable performance in terms of preserving accuracy after anonymization. Moreover, the privacy of the anonymized data was measured, showing the benefits of the proposed approach when sharing iot datasets with minimal data inference attack surface. © 2023, the author(s), under exclusive licence to springer science+business media, llc, part of springer nature.","","","2023","10.1007/s10586-023-04063-1","","","scopus-2-s2.0-85162696078.pdf","scopus-2-s2.0-85162696078"
"Plan quality evaluation 1994–2012: growth and contributions, limitations, and new directions","Lyles, W. And Stevens, M.","Journal Of Planning Education And Research","","During the last twenty years, more than forty-five publications have sought to measure and evaluate the quality of plans using content analysis methods. We examine reasons for this growth in the literature and its contributions and limitations. We also examine whether the research methods described in these publications conform to recommended practices in the methodological literature on content analysis to determine whether plan quality researchers are likely to be generating reliable and reproducible plan quality data. We provide seven recommendations plan quality researchers can follow to address these weaknesses and improve the reliability and reproducibility of their data. © the author(s) 2014.","","","2014","10.1177/0739456x14549752","","","scopus-2-s2.0-84910663145.pdf","scopus-2-s2.0-84910663145"
"Repositioning the high street: evidence and reflection from the uk","Millington, S. And Ntounis, N.","Journal Of Place Management And Development","","Purpose: drawing on evidence from ten towns (across england, wales and northern ireland) participating in the high street uk 2020 (hsuk2020) project, the purpose of this paper is to reveal how local stakeholders involved in place management respond to high street decline through a strategy of repositioning. Design/methodology/approach: this paper identifies the challenges faced by the towns considering repositioning, and highlights examples of good practice of relevance to the practitioners. First, it outlines the perspectives on repositioning from the academic research and theory, before drawing on evidence from across ten uk towns that participated in the hsuk2020 project, to reveal how repositioning involves more than just taking a snapshot profile of a place. Findings: the research revealed major challenges faced by local stakeholders in clearly identifying and communicating their market position, in particular, the maintenance of up-to-date information on catchments was lacking at all the locations. Despite having local knowledge and some data, stakeholders still did not possess a clear (or shared) understanding of the identity or function of their towns. This evidence reflects the complexity of analysing and understanding repositioning and developing coherent strategies. Practical implications: knowledge exchange between stakeholders involved in place management can help inform the identification of new strategic objectives, appropriate interventions and project planning and delivery. Where resources are limited, particularly in smaller towns and settlements, the research demonstrates the significance of collecting and sharing data and analysis with other stakeholders, because this can generate positive outcomes for all. Originality value: by offering empirical evidence based on the experience of local practitioners, this paper provides valuable insight into how town centre stakeholders collect, interpret and analyse data, revealing the challenges, opportunities and practicalities involved in developing and implementing repositioning strategies. © 2017, steve millington and nikos ntounis.","","","2017","10.1108/jpmd-08-2017-0077","","","scopus-2-s2.0-85042944426.pdf","scopus-2-s2.0-85042944426"
"Cscript: a distributed programming language for building mixed-consistency applications","De Porre, K. And Myter, F. And Scholliers, C. And Gonzalez Boix, E.","Journal Of Parallel And Distributed Computing","","Current programming models only provide abstractions for sharing data under a homogeneous consistency model. It is, however, not uncommon for a distributed application to provide strong consistency for one part of the shared data and eventual consistency for another part. Because mixing consistency models is not supported by current programming models, writing such applications is extremely difficult. In this paper we propose cscript, a distributed object-oriented programming language with built-in support for data replication. At its core are consistent and available replicated objects. Cscript regulates the interactions between these objects to avoid subtle inconsistencies that arise when mixing consistency models. Our evaluation compares a collaborative text editor built atop cscript with a state-of-the-art implementation. The results show that our approach is flexible and more memory efficient. © 2020 elsevier inc.","","","2020","10.1016/j.jpdc.2020.05.010","","","scopus-2-s2.0-85086441831.pdf","scopus-2-s2.0-85086441831"
"Joint secret sharing and data hiding for block truncation coding compressed image transmission","Luo, H. And Zhao, Z. And Lu, Z.-M.","Information Technology Journal","","This study proposed a scheme that incorporates secret sharing and data hiding techniques for block truncation coding compressed image transmission. The bitmap of each compressed block is encrypted and meanwhile two quantization levels are hidden in two share images. The secure transmission system still preserves the properties such as low complexity and acceptable reconstruction image quality of the standard block truncation coding compression. In addition, each share image is half size of the compressed version such that no extra burden is laid on available transmission resources. Experimental results demonstrate the effectiveness of our scheme. © 2011 asian network for scientific information.","","","2011","10.3923/itj.2011.681.685","","","scopus-2-s2.0-78651376869.pdf","scopus-2-s2.0-78651376869"
"Reproducibility of the alcoholic beverages and illicit drug modules of the 2015 national survey of school health","De Almeida, C.s. And Andrade, S.n. And Abreu, M.n.s. And Malta, D.c. And Lana, F.c.f.","Revista Da Escola De Enfermagem","","Objective: to evaluate the reproducibility of the modules of use of alcoholic beverages and illicit drugs of the 2015 national survey of school health. Method: cross-sectional epidemiological study aimed at evaluating the reproducibility of collection instruments, conducted in the city of divinópolis, minas gerais. The sample consisted of students attending the 9th grade of public and private primary schools in 2017. The reproducibility of the modules of use of alcohol and illicit drugs was applied to the sample and the retest occurred within 15 to 20 days with the same students. In the analysis of the test-retest agreement, the kappa coefficient was used to analyze the nominal categorical variables;  kappa with linear weighting, in the analysis of ordinal categorical variables;  and intraclass correlation coefficient in the analysis of numerical variables. Results: participation of 303 students. The agreement of responses was between satisfactory and moderate and there was no indicator with reasonable or poor agreement. Frequencies were close between the test-retest. Conclusion: the analyzed modules were satisfactory and considered replicable and reliable sources to support public policies and programs aimed at adolescents. © 2020 all rights reserved","","","2020","10.1590/s1980-220x2019014903660","","","scopus-2-s2.0-85098605389.pdf","scopus-2-s2.0-85098605389"
"A research on information technology applied to improving performance for tourism enterprises","Huang, H. And Peng, Q.","Journal Of Chemical And Pharmaceutical Research","","The information technology has great influence on both the structure of the tourism industry and the strategy of the tourism enterprises in this age of big data. This paper focuses on the problem how information technology can be used to improve the performance of tourism enterprises. Considering the specialty of tourism industry, this paper develops a data-sharing model including internal and external data-sharing center to promote performance by reducing cost, improving service quality and extending market volume etc. Data-sharing is a complicated process including several steps, such as collection, evaluation, selection, classification and integration. These steps form a data mining cycle to provide more resourceful information for the tourism enterprises and its stakeholders, thus the business performance of the enterprises can be improved steadily and continuously. It can be expected that data-sharing model will be extensively applied to many tourism conglomerates in the near future. © 2014, journal of chemical and pharmaceutical research. All rights reserved.","","","2014","","","","scopus-2-s2.0-84924666502.pdf","scopus-2-s2.0-84924666502"
"Multipurpose practice guideline modules for clinical decision analysis and quality improvement","Balas, E.a. And Gardner, D. And Hamdy, O. And Li, Z.r. And Mitchell, J.a.","Medinfo. Medinfo","","This study aimed to measure the loss of information in communication between clinical researchers and information system developers, to design a tool for sharing clinical practice guidelines, and to test the feasibility of this tool in knowledge base development. The analysis of a sample of 101 randomized controlled clinical trials indicated that exact numeric results were published in only 64 percent of the trials. While structured abstracts were associated with improved total quality scores (p0.001), there was no significant improvement in reporting numeric results (p=0.31). Based on the documented loss of information and the needs of various parties involved, the concept of a multipurpose knowledge module was developed for sharing clinical practice recommendations. Such clinical practice guideline modules were applied in developing the knowledge base of a quality feedback expert system (qfes).","","","1995","","","","scopus-2-s2.0-0029447206.pdf","scopus-2-s2.0-0029447206"
"Trust and legal governance: a case study of ethiopian criminal justice","Wandall, R.h.","Journal Of Law And Society","","Current empirical research on trust in criminal justice focuses on those who do the trusting. Working from the theoretical position that trust is relational, this article expands that research by showing how trust relationships between the public and criminal justice institutions are shaped by the legal framework governing them. Reporting empirical case studies from the plural legal governance of criminal justice in ethiopia, the article shows that the country's different legal frameworks produce different constructions of trust relationships between the public and criminal justice institutions. Furthermore, the empirical study shows that the practical organization of daily case handling in criminal justice institutions make for an important mechanism to mediate and link these differently constructed trust relationships. © 2015 cardiff university law school.","","","2015","10.1111/j.1467-6478.2015.00708.x","","","scopus-2-s2.0-84928954566.pdf","scopus-2-s2.0-84928954566"
"Stake health monitoring system epithetical on iot and cloud an efficient data stockpile","Geetha, K. And Chaithanya, B.n. And Dayanand Lal, N. And Neetha, K.s.","International Journal Of Electrical Engineering And Technology","","Iot is a heterogeneous network of smart connected devices - each of which collect and share data about how they are used and the environments in which they are operated. The iot network consists of sensors / devices transmitting data to the cloud through various device-based communication technologies. Post uploading the data to the cloud, software processes the data and can then start taking an action such as sending a notification or updating the sensors / devices automatically without a manual intervention. Innovation assumes that the important and significant element in medicinal activities or services for substantial or substantial contraptions as well as in affiliation with affiliation, recording and appear contraption. It is crucial to show or screen distinctive therapeutic parameters conjointly post operational days. Here after the foremost advanced or later design in healthcare specialized too master strategy utilizing iot is balanced the microcontroller gets the sensor data and sends it to the framework all the way through wi-fi and subsequently gives persistent watching of the human administrations or exercises parameters for master or masters. The data can be gotten to whenever by the pro. The controller to boot related with flag to caution the supervisor almost assortment in sensor surrender. However, the noteworthy issue in farther understanding checking system is that the data has to be securely transmitted to the objective conclusion and course of action is made to empower fair affirmed client to induce to the information. © iaeme publication scopus indexed","","","2020","10.34218/ijeet.11.4.2020.029","","","scopus-2-s2.0-85087351719.pdf","scopus-2-s2.0-85087351719"
"Mc-gen: multi-level clustering for private synthetic data generation","Li, M. And Zhuang, D. And Chang, J.m.","Knowledge-Based Systems","","With the development of machine learning and data science, data sharing is very common between companies and research institutes to avoid data scarcity. However, sharing original datasets that contain private information can cause privacy leakage. A reliable solution is to utilize private synthetic datasets which preserve statistical information from original datasets. In this paper, we propose mc-gen, a privacy-preserving synthetic data generation method under differential privacy guarantee for machine learning classification tasks. Mc-gen applies multi-level clustering and differential private generative model to improve the utility of synthetic data. In the experimental evaluation, we evaluated the effects of parameters and the effectiveness of mc-gen. The results showed that mc-gen can achieve significant effectiveness under certain privacy guarantees on multiple classification tasks. Moreover, we compare mc-gen with three existing methods. The results showed that mc-gen outperforms other methods in terms of utility. © 2023 elsevier b.v.","","","2023","10.1016/j.knosys.2022.110239","","","scopus-2-s2.0-85147415248.pdf","scopus-2-s2.0-85147415248"
"Applications of the SWAT Model Special Section: Overview and Insights","Gassman P. W., Sadeghi A. M., Srinivasan R.","Journal of Environmental Quality","","The Soil and Water Assessment Tool (SWAT) model has emerged as one of the most widely used water quality watershed- and river basin-scale models worldwide applied extensively for a broad range of hydrologic and/or environmental problems. The international use of SWAT can be attributed to its flexibility in addressing water resource problems extensive networking via dozens of training workshops and the several international conferences that have been held during the past decade comprehensive online documentation and supporting software and an open source code that can be adapted by model users for specific application needs. The catalyst for this special collection of papers was the 2011 International SWAT Conference & Workshops held in Toledo Spain which featured over 160 scientific presentations representing SWAT applications in 37 countries. This special collection presents 22 specific SWAT-related studies most of which were presented at the 2011 SWAT Conference; it represents SWAT applications on five different continents with the majority of studies being conducted in Europe and North America. The papers cover a variety of topics including hydrologic testing at a wide range of watershed scales transport of pollutants in northern European lowland watersheds data input and routing method effects on sediment transport development and testing of potential new model algorithms and description and testing of supporting software. In this introduction to the special section we provide a synthesis of these studies within four main categories: (i) hydrologic foundations (ii) sediment transport and routing analyses (iii) nutrient and pesticide transport and (iv) scenario analyses. We conclude with a brief summary of key SWAT research and development needs. Copyright © by the American Society of Agronomy Crop Science Society of America and Soil Science Society of America Inc.","","","2014","10.2134/jeq2013.11.0466","","","medline-25602534.pdf","medline-25602534"
"Lightweight privacy-preserving raw data publishing scheme","Chen, J. And Liu, G. And Liu, Y.","Ieee Transactions On Emerging Topics In Computing","","Data publishing or data sharing is an important part of analyzing network environments and improving the quality of service (qos) in the internet of things (iot). In order to stimulate data providers (i.e., iot end-users) to contribute their data, privacy requirement is necessary when data is collected and published. In traditional privacy preservation techniques, such as k-anonymity, data aggregation and differential privacy, data is modified, aggregated, or added noise, the utility of the published data are reduced. Privacy-preserving raw data publishing is a more valuable solution, and nn-source anonymity based raw data collection is most promising by delinking raw data and their sources. In this article, a lightweight raw data collection scheme for publishing is proposed, in which the rawness and the unlinkability of published data are all really guaranteed with shamir's secret sharing, and shuffling algorithm. Moreover, it is lightweight and practical for the iot environment by the performance evaluation. © 2013 ieee.","","","2021","10.1109/tetc.2020.2974183","","","scopus-2-s2.0-85082416859.pdf","scopus-2-s2.0-85082416859"
"MicroRNA biomarkers of type 2 diabetes: evidence synthesis from meta-analyses and pathway modelling","Zhu H., Leung S. W.","Diabetologia","","AIMS/HYPOTHESIS: MicroRNAs are being sought as biomarkers for the early identification of type 2 diabetes. This study aimed to synthesise the evidence from microRNA-type 2 diabetes association studies and microRNA-regulated type 2 diabetes pathway delineation studies that met stringent quality criteria to identify and validate microRNAs of both statistical and biological significance as type 2 diabetes biomarkers.\\\\\\\\rMETHODS: Eligible controlled studies on microRNA expression profiling of type 2 diabetes were retrieved from PubMed ScienceDirect and Web of Science. MicroRNA-regulated type 2 diabetes pathway delineation studies were conducted by integrating and cross-verifying the data from miRTarBase TransmiR miRecords TargetScanHuman the Kyoto Encyclopedia of Genes and Genomes (KEGG) and the Retraction Watch database. Before meta-analysis quality assessment was performed according to the corresponding reporting guidelines for evidence-based medicine. To select the most statistically significant microRNAs we conducted extensive meta-analyses according to the latest methodology. Subgroup and sensitivity analyses were carried out to further examine the microRNA candidates for their tissue specificity and blood fraction specificity and the robustness of the evidence. Signalling pathway impact analysis of dysregulated microRNAs identified from meta-analyses was performed to select biologically significant microRNAs that were enriched in our newly built microRNA-regulated pathways.\\\\\\\\rRESULTS: Of the 404 differentially expressed microRNAs identified in the 156 controlled profiling studies with a combined sample size of >15000 only 60 were both consistently and significantly dysregulated in human type 2 diabetes. No microRNAs were both consistently and significantly dysregulated in multiple tissues according to subgroup analyses. In total 58 microRNAs were found to be robust in sensitivity analyses. A total of 1966 pathway delineation studies were identified including 3290 microRNA-target interactions which were further combined with KEGG pathways producing 225 microRNA-regulated pathways. Impact analysis found that 16 dysregulated microRNAs identified from extensive meta-analyses were statistically significantly enriched in the augmented KEGG type 2 diabetes pathway.\\\\\\\\rCONCLUSIONS/INTERPRETATION: Sixteen microRNAs met the criteria for biomarker selection. In terms of both significance and relevance the order of priority for verification of these microRNAs is as follows: miR-29a-3p miR-221-3p miR-126-3p miR-26a-5p miR-503-5p miR-100-5p miR-101-3p mIR-103a-3p miR-122-5p miR-199a-3p miR-30b-5p miR-130a-3p miR-143-3p miR-145-5p miR-19a-3p and miR-311-3p.\\\\\\\\rREGISTRATION: PROSPERO registration number CRD42017081659. Copyright © 2022. The Author(s).","","","2023","10.1007/s00125-022-05809-z","","","medline-36269347.pdf","medline-36269347"
"Power distance and leader integrity: the roles of moral disengagement and narcissism","Shen, H. And Zhao, X. And Jiang, X. And Wang, A.","Social Behavior And Personality","","The focus in most research on leader integrity has been on its positive consequences;  however, studies on the antecedents of leader integrity are still lacking. Drawing on moral disengagement theory, in this empirical study we examined the relationship between power distance and leader integrity, and the roles of moral disengagement and narcissism in this relationship.we analyzed paired leader-subordinate data obtained from a survey conducted with 253 leaders and their direct subordinates in china. The results show that leaders' power distance was negatively related to their integrity, leader moral disengagement mediated the relationship between power distance and integrity, andnarcissism positively moderated the relationship between power distance and moral disengagement. Moreover, narcissism strengthened themediating effect of moral disengagement: the higher the level of narcissism, the stronger the indirect effect of power distance on leader integrity via moral disengagement. Our findings enrich the theory of leader integrity and provide guidance for preventing damage to leader integrity. © 2021 scientific journal publishers. All rights reserved.","","","2021","10.2224/sbp.10162","","","scopus-2-s2.0-85113817884.pdf","scopus-2-s2.0-85113817884"
"Therapeutic area data standards for autosomal dominant polycystic kidney disease: a report from the polycystic kidney disease outcomes consortium (pkdoc)","Perrone, R.d. And Neville, J. And Chapman, A.b. And Gitomer, B.y. And Miskulin, D.c. And Torres, V.e. And Czerwiec, F.s. And Dennis, E. And Kisler, B. And Kopko, S. And Krasa, H.b. And Leroy, E. And Castedo, J. And Schrier, R.w. And Broadbent, S.","American Journal Of Kidney Diseases","","Data standards provide a structure for consistent understanding and exchange of data and enable the integration of data across studies for integrated analysis. There is no data standard applicable to kidney disease. We describe the process for development of the first-ever clinical data interchange standards consortium (cdisc) data standard for autosomal dominant polycystic kidney disease (adpkd) by the polycystic kidney disease outcomes consortium (pkdoc). Definition of common data elements and creation of adpkd-specific data standards from case report forms used in long-term adpkd registries, an observational cohort (consortium for radiologic imaging studies of polycystic kidney disease [crisp] 1 and 2), and a randomized clinical trial (halt progression of polycystic kidney disease [halt-pkd]) are described in detail. This data standard underwent extensive review, including a global public comment period, and is now available online as the first pkd-specific data standard (www.cdisc.org/therapeutic). Submission of clinical trial data that use standard data structures and terminology will be required for new electronic submissions to the us food and drug administration for all disease areas by the end of 2016. This data standard will allow for the mapping and pooling of available data into a common data set in addition to providing a foundation for future studies, data sharing, and long-term registries in adpkd. This data set will also be used to support the regulatory qualification of total kidney volume as a prognostic biomarker for use in clinical trials. The availability of consensus data standards for adpkd has the potential to facilitate clinical trial initiation and increase sharing and aggregation of data across observational studies and among completed clinical trials, thereby improving our understanding of disease progression and treatment. © 2015 national kidney foundation, inc.","","","2015","10.1053/j.ajkd.2015.04.044","","","scopus-2-s2.0-84942294959.pdf","scopus-2-s2.0-84942294959"
"Achieving data privacy for decision support systems in times of massive data sharing","Fazal R., Shah M. A., Khattak H. A., Rauf H. T., Al-Turjman F.","Cluster Computing","","The world is suffering from a new pandemic of Covid-19 that is affecting human lives. The collection of records for Covid-19 patients is necessary to tackle that situation. The decision support systems (DSS) are used to gather that records. The researchers access the patient's data through DSS and perform predictions on the severity and effect of the Covid-19 disease; in contrast unauthorized users can also access the data for malicious purposes. For that reason it is a challenging task to protect Covid-19 patient data. In this paper we proposed a new technique for protecting Covid-19 patients' data. The proposed model consists of two folds. Firstly Blowfish encryption uses to encrypt the identity attributes. Secondly it uses Pseudonymization to mask identity and quasi-attributes then all the data links with one another such as the encrypted masked sensitive and non-sensitive attributes. In this way the data becomes more secure from unauthorized access. Copyright © The Author(s) under exclusive licence to Springer Science+Business Media LLC part of Springer Nature 2022.","","","2022","10.1007/s10586-021-03514-x","","","medline-35035271.pdf","medline-35035271"
"Sharing individual patient and parasite-level data through the WorldWide Antimalarial Resistance Network platform: A qualitative case study","Pisani E., Botchway S.","Wellcome Open Research","","BACKGROUND: Increasingly biomedical researchers are encouraged or required by research funders and journals to share their data but there's very little guidance on how to do that equitably and usefully especially in resource-constrained settings. We performed an in-depth case study of one data sharing pioneer: the WorldWide Antimalarial Resistance Network (WWARN). METHODS: The case study included a records review a quantitative analysis of WAARN-related publications in-depth interviews with 47 people familiar with WWARN and a witness seminar involving a sub-set of 11 interviewees. RESULTS: WWARN originally aimed to collate clinical in vitro pharmacological and molecular data into linked open-access databases intended to serve as a public resource to guide antimalarial drug treatment policies. Our study describes how WWARN navigated challenging institutional and academic incentive structures alongside funders' reluctance to invest in capacity building in malaria-endemic countries which impeded data sharing. The network increased data contributions by focusing on providing free online tools to improve the quality and efficiency of data collection and by inviting collaborative authorship on papers addressing policy-relevant questions that could only be answered through pooled analyses. By July 1 2016 the database included standardised data from 103 molecular studies and 186 clinical trials representing 135000 individual patients. Developing the database took longer and cost more than anticipated and efforts to increase equity for data contributors are on-going. However analyses of the pooled data have generated new methods and influenced malaria treatment recommendations globally. Despite not achieving the initial goal of real-time surveillance WWARN has developed strong data governance and curation tools which are now being adapted relatively quickly for other diseases. CONCLUSIONS: To be useful data sharing requires investment in long-term infrastructure. To be feasible it requires new incentive structures that favour the generation of reusable knowledge.","","","2017","10.12688/wellcomeopenres.12259.1","","","pubmed-29018840.pdf","pubmed-29018840"
"Debtholder stewardship","Gomtsian, S.","Modern Law Review","","Debtholder stewardship refers to the involvement of corporate creditors in a firm's governance framework with the aim of improving corporate decision-making. This article develops the theory of debtholder stewardship by identifying the mechanisms of debtholder influence, assessing their effectiveness in modern capital markets, and outlining the implications of this analysis for investor stewardship and regulatory efforts to support it. The impetus of this study is the expansion of the uk stewardship code across a broader range of asset classes, stewardship activities, and topics. The code has moved away from the traditional focus on shareholders by adding investors in other assets to the list of the stewards of corporate activities. Also, the revised concept of stewardship covers broader topics, including environmental, social, and governance (esg) factors. But our understanding of debtholder stewardship, especially on sustainability matters, is inadequate. This article explains whether corporate creditors, both public and private, can promote responsible business practices through the stewardship of borrowers. © 2022 the authors. The modern law review published by john wiley & sons ltd on behalf of modern law review limited.","","","2023","10.1111/1468-2230.12766","","","scopus-2-s2.0-85139388794.pdf","scopus-2-s2.0-85139388794"
"Exemplars for advancing standardized terminology in nursing to achieve sharable, comparable quality data based upon evidence","Mccormick, K.a. And Sensmeier, J. And Dykes, P.c. And Grace, E.n. And Matney, S.a. And Schwarz, K.m. And Weston, M.j.","Online Journal Of Nursing Informatics","","Purpose : this paper describes the need for advancing standardized terminology in nursing to achieve sharable, comparable, quality data based upon evidence. Three exemplars are presented to outline repeatable steps within a data standardization framework that can be used across healthcare settings. Implications for international and u.s. standards efforts are described. Recommendations are made to further advance these efforts in nursing practice, research, education, and policy. Organizing construct : research from three exemplars in acute-care settings in the united states are described to inform stakeholders about the use of standards that benefit nursing quality measurement and information sharing in healthcare using evidence-based principles. These exemplars, deriving from research studies at partners healthcare, intermountain healthcare, and kaiser/va, focus on measures of pain, falls, and decubitus ulcers. Because each environment used different nursing terminologies, harmonization using broader healthcare standards, including systemized nomenclature of medicine clinical terms (snomed ct ®) and logical observation identifiers names and codes (loinc®), was necessary to compare data. The steps for acquiring comparability of data are defined. Implications for international nursing standards and recommendations for further research and policy are summarized. Methods : through the use of electronic health records (ehr), clinical documentation not only serves to record individual patient experiences but, if the data are collected and reported in a standardized fashion, they can also be aggregated to discern best practices in clinical care which will ultimately lead to improved care and outcomes. Aggregating these data for quality improvement is one form of reuse. To date, quality improvement activities have focused primarily on reuse of medical data. The use of standardized terminology will significantly improve the reuse of nursing data by increasing the ability to share and compare quality data. The ability to share data will enable meaningful analysis of those data for all users who perform clinical care, quality audits, clinical research and other healthcare related operations. Ultimately, the successful sharing of comparable evidence-based healthcare data, including nursing data, will foster improvements in the quality of care(iom, 2012). The three exemplar populations extracted nursing content based upon clinical practice guidelines. They developed a 10-step, repeatable process to aggregate and harmonize nursing data using snomed ct® and loinc®. Findings : adopting and implementing loinc® for nursing assessments and outcomes, and snomed ct® for nursing documentation of diagnoses or problem lists, and interventions will increase the reuse of nursing data(committee on patient safety and health information technology, 2012). Mapping nursing specific terminologies to these healthcare standards provides a way to harmonize data when different healthcare organizations have used different nursing terminologies. Further recommendations are made to continue to map nursing terms from american nurses association (ana) recognized terminologies into snomed ct® and loinc®. Conclusions : when common nursing terms have not been used in clinical documentation, aggregation to snomed ct® and loinc® through a standardization framework provides a harmonization capability. Further research is needed to explore the use of this framework across the continuum of care as well as in international settings. A set of recommendations for practice, research, and policy is provided. Clinical relevance : the repeatable steps for standardization of nursing data are described to provide the nursing community with evidence necessary to exchange sharable, comparable data to improve the quality of care to patients and consumers. These exemplars can also be used to inform future roadmaps, strategies for gaining consensus, and potential funding proposals. © 2016 healthcare information and management systems society (himss).","","","2015","","","","scopus-2-s2.0-84957061831.pdf","scopus-2-s2.0-84957061831"
"Effects of low-dose hydrocortisone and hydrocortisone plus fludrocortisone in adults with septic shock: a protocol for a systematic review and meta-analysis of individual participant data","Annane, D. And Pirracchio, R. And Billot, L. And Waschka, A. And Chevret, S. And Cohen, J. And Finfer, S. And Gordon, A. And Hammond, N. And Myburgh, J. And Venkatesh, B. And Delaney, A.","Bmj Open","","Introduction the benefits and risks of low-dose hydrocortisone in patients with septic shock have been investigated in numerous randomised controlled trials and trial-level meta-analyses. Yet, the routine use of this treatment remains controversial. To overcome the limitations of previous meta-analyses inherent to the use of aggregate data, we will perform an individual patient data meta-analysis (ipdma) on the effect of hydrocortisone with or without fludrocortisone compared with placebo or usual care on 90-day mortality and other outcomes in patients with septic shock. Methods and analysis to assess the benefits and risks of hydrocortisone, with or without fludrocortisone for adults with septic shock, we will search major electronic databases from inception to september 2020 (cochrane central register of controlled trials, medline, embase and latin american caribbean health sciences literature), complimented by a search for unpublished trials. The primary analysis will compare hydrocortisone with or without fludrocortisone to placebo or no treatment in adult patients with septic shock. Secondary analyses will compare hydrocortisone to placebo (or usual care), hydrocortisone plus fludrocortisone to placebo (or usual care), and hydrocortisone versus hydrocortisone plus fludrocortisone. The primary outcome will be all cause mortality at 90 days. We will conduct both one-stage ipdma using mixed-effect models and machine learning with targeted maximum likelihood analyses. We will assess the risk of bias related to unshared data and related to the quality of individual trial. Ethics and dissemination this ipdma will use existing data from completed randomised clinical trials and will comply with the ethical and regulatory requirements regarding data sharing for each of the component trials. The findings of this study will be submitted for publication in a peer-review journal with straightforward policy for open access. © author(s) (or their employer(s)) 2020.","","","2020","10.1136/bmjopen-2020-040931","","","scopus-2-s2.0-85097125547.pdf","scopus-2-s2.0-85097125547"
"Reform and implementation path of university evaluation under the internet environment","Xiao, S. And Wen, T.","Journal Of Library And Information Science In Agriculture","","[Purpose/significance] at present, with the rapid development of china's internet, modern information technology with the internet technology as the core has been widely used in all walks of life and different fields. An internet model has come into being. It has changed the way people live, study and work, and university evaluation is faced with changes under the internet environment. Taking environmental changes as the starting point for the examination of efficient ways of evaluation and reform, we aim to deeply explore the evaluation reform of universities in the internet environment and the realization path. [Method/process] through literature review, case study and investigation, an in-depth analysis of three major functions of colleges and universities in the internet environment are performed, the reform of talent training, scientific research and social services, and talent cultivation mainly explored from educational resources, distance education and personalized talent training. Scientific research is mainly conducted from three aspects: scientific research resources, online scientific research mutual assistance and online scientific research interaction. Social services are mainly analyzed from the sharing of expert resources, network remote services and network think tank services, and then the changes in university evaluation data, evaluation indicators and evaluation results in the internet environment are explored, including data source changes, data acquisition methods and data processing changes. Changes in evaluation indicators include new characteristics of evaluation indicators. The reform of evaluation results includes the personalization of evaluation results, the real-time nature of evaluation results, the diversification of evaluation results and the networking of evaluation results, and the research and discussion of evaluation reform and realization path of universities in the internet environment. [Results/conclusions]the research results indicate to carry out changes in university evaluation, determine the realization path of elements at all levels, and construct a university evaluation model, build a university evaluation platform, and strengthen the cultivation of university evaluation specialists in the internet environment, of which the university evaluation model explores the aspects of evaluation subject, subject elements and their relationships, and the university evaluation platform includes the evaluation data perception layer, the evaluation data resource layer and the evaluation data sharing layer. The study provides a reference for promoting the research and practice of university evaluation in the internet environment and building a new university evaluation ecology. © 2022 authors. All rights reserved.","","","2022","10.13998/j.cnki.issn1002-1248.21-0551","","","scopus-2-s2.0-85161984436.pdf","scopus-2-s2.0-85161984436"
"Data quality evaluation in open data in the municipality context:a systematic literature review","Troncoso-González, A. And Rodríguez, A. And Caro, A.","Ingeniare","","Nowadays, governments often share their data with the citizens through diverse digital platforms. This sharing of data, which has no restrictions or costs, has been called open government data. The increased use of this kind of data poses several challenges, such as the quality of the provided data. It becomes necessary to evaluate factors like the reliability, integrity, and accuracy of data and apply guidelines and metrics to ensure its quality for the intended use. This way, it is no longer sufficient to make data available, as having guidelines to evaluate its quality for other public agencies and citizens becomes a necessity. This article presents the realization of a systematic literature review to research existing proposals focused on evaluating open government data quality at a municipal level. As a result of this review, 56 articles have been identified. These are presented based on 3 posed research questions. © 2022, universidad de tarapaca. All rights reserved.","","","2022","10.4067/s0718-33052022000200255","","","scopus-2-s2.0-85137874155.pdf","scopus-2-s2.0-85137874155"
"Biomedical conferences' author instructions rarely mention guidelines for reporting abstracts of trials and systematic reviews","Saric L., Dosenovic S., Mihanovic J., Puljak L.","Journal of Comparative Effectiveness Research","","<b>Aim:</b> To analyze whether instructions for authors of biomedical conference abstracts mention guidelines for writing randomized controlled trial and systematic review abstracts and to evaluate reasons for their absence from instructions. <b>Materials & methods:</b> We analyzed instructions for authors of biomedical conferences advertized in 2019 and assessed whether they mentioned Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Abstracts and Consolidated Standards of Reporting Trials for Abstracts guidelines. We surveyed contact persons from abstract/publication committees of selected conferences to analyze why relevant guidelines were missing.","","","2020","10.2217/cer-2019-0158","","","pubmed-31950848.pdf","pubmed-31950848"
"Evidence-based practice: review of clinical evidence on the efficacy of glucosamine and chondroitin in the treatment of osteoarthritis","Distler, J. And Anguelouch, A.","Journal Of The American Academy Of Nurse Practitioners","","Purpose: to evaluate past and current evidence from randomized controlled trials on the efficacy of glucosamine sulfate (gs), glucosamine hydrochloride (gh), and chondroitin sulfate (cs) for the treatment of osteoarthritis (oa). Data sources: an extensive review of four meta-analyses and a review of the findings of the recently published glucosamine/chondroitin arthritis intervention trial (gait) funded by the national institutes of health. Findings: review of previous studies on the efficacy of gs, gh, and cs in the treatment of oa showed inconclusive results because of weak research design. The gait attempted to provide clarity on the use of gh and cs in treating knee pain from oa by using a rigorous research design to elicit cause and effect. The gait results showed that gh and cs were not effective in reducing knee pain in the study group overall;  however, these may be effective in combination for patients with moderate-to-severe knee pain. Implications for practice: there is now clinical evidence indicating that recommending gs, gh, and cs for the treatment of mild knee pain from oa is ineffective. Further research needs to be done to identify specific characteristics in patients that results in a positive response. Until the findings of the gait undergo further peer review, the results of the research needs to be interpreted with caution. © 2006 american academy of nurse practitioners.","","","2006","10.1111/j.1745-7599.2006.00166.x","","","scopus-2-s2.0-34247881874.pdf","scopus-2-s2.0-34247881874"
"Proxy re-encryption with equality test for secure data sharing in internet of things-based healthcare systems","Li, W. And Jin, C. And Kumari, S. And Xiong, H. And Kumar, S.","Transactions On Emerging Telecommunications Technologies","","The integration of the internet of things (iot) and cloud computing brings tremendous convenience and efficiency to process and store growing sensor data in healthcare systems. For the security of sensor data collected by healthcare systems, encrypting data before uploading is necessary. Nevertheless, these encrypted form sensor data make it a research challenge to achieve efficient data search and data sharing on the cloud-assisted iot simultaneously. Encrypting data by public key encryption with equality test (pke-et) scheme, identified as a viable solution, is capable to search data encrypted with different keys efficiently. However, how to efficiently share searched healthcare record on the cloud server is still an unsettled problem. To address this problem, we combine the concepts of proxy re-encryption (pre) and pke-et to obtain proxy re-encryption with equality test (pre-et). Inheriting the advantages of pke-et and pre, the user can search the required healthcare record data from data encrypted under different public keys. Meanwhile, the searched healthcare record can be shared securely and flexibly without disclosing the secret key and plaintext. We prove the security of our pre-et construction based on divisible computation diffie-hellman assumption in the random oracle model. Eventually, the proposed scheme is proven useful according to extensive efficiency analysis and comparison. © 2020 john wiley & sons, ltd.","","","2022","10.1002/ett.3986","","","scopus-2-s2.0-85087157345.pdf","scopus-2-s2.0-85087157345"
"An intensely sympathetic awareness: experiential similarity and cultural norms as means for gaining older african americans' trust of scientific research","Sabir, M.g. And Pillemer, K.a.","Journal Of Aging Studies","","Well-known trust-building methods are routinely used to recruit and retain older african americans into scientific research studies, yet the quandary over how to overcome this group's hesitance to participate in research remains. We present two innovative and testable methods for resolving the dilemma around increasing older african americans' participation in scientific research studies. Certain specific and meaningful experiential similarities between the primary researcher and the participants, as well as clear recognition of the elders' worth and dignity, improved older african americans' willingness to adhere to a rigorous research design. Steps taken in an intervention study produced a potentially replicable strategy for achieving strong results in recruitment, retention and engagement of this population over three waves of assessment. Sixty-two (n. = 62) older african americans were randomized to treatment and control conditions of a reminiscence intervention. Sensitivity to an african american cultural form of respect for elders (recognition of worth and dignity), and intersections between the lived experience of the researcher and participants helped dispel this population's well-documented distrust of scientific research. Results suggest that intentional efforts to honor the worth and dignity of elders through high level hospitality and highlighting meaningful experiential similarities between the researcher and the participants can improve recruitment and retention results. Experiential similarities, in particular, may prove more useful to recruitment and retention than structural similarities such as age, race, or gender, which may not in themselves result in the trust experiential similarities elicit. © 2014 elsevier inc.","","","2014","10.1016/j.jaging.2013.11.005","","","scopus-2-s2.0-84897819388.pdf","scopus-2-s2.0-84897819388"
"Are physical activity studies in Hispanics meeting reporting guidelines for continuous monitoring technology? A systematic review. [Review]","Layne C. S., Parker N. H., Soltero E. G., Rosales Chavez, O'Connor D. P., Gallagher M. R., Lee R. E.","BMC Public Health","","BACKGROUND: Continuous monitoring technologies such as accelerometers and pedometers are the gold standard for physical activity (PA) measurement. However inconsistencies in use analysis and reporting limit the understanding of dose-response relationships involving PA and the ability to make comparisons across studies and population subgroups. These issues are particularly detrimental to the study of PA across different ethnicities with different PA habits. This systematic review examined the inclusion of published guidelines involving data collection processing and reporting among articles using accelerometers or pedometers in Hispanic or Latino populations. METHODS: English (PubMed; EbscoHost) and Spanish (SCIELO; Biblioteca Virtual en Salud) articles published between 2000 and 2013 using accelerometers or pedometers to measure PA among Hispanics or Latinos were identified through systematic literature searches. Of the 253 abstracts which were initially reviewed 57 met eligibility criteria (44 accelerometer 13 pedometer). Articles were coded and reviewed to evaluate compliance with recommended guidelines (N = 20) and the percentage of accelerometer and pedometer articles following each guideline were computed and reported. RESULTS: On average 57.1 % of accelerometer and 62.2 % of pedometer articles reported each recommended guideline for data collection. Device manufacturer and model were reported most frequently and provision of instructions for device wear in Spanish was reported least frequently. On average 29.6 % of accelerometer articles reported each guideline for data processing. Definitions of an acceptable day for inclusion in analyses were reported most frequently and definitions of an acceptable hour for inclusion in analyses were reported least frequently. On average 18.8 % of accelerometer and 85.7 % of pedometer articles included each guideline for data reporting. Accelerometer articles most frequently included average number of valid days and least frequently included percentage of wear time. DISCUSSION: Inclusion of standard collection and reporting procedures in studies using continuous monitoring devices in Hispanic or Latino population is generally low. CONCLUSIONS: Lack of reporting consistency in continuous monitoring studies limits researchers' ability to compare studies or draw meaningful conclusions concerning amounts quality and benefits of PA among Hispanic or Latino populations. Reporting data collection computation and decision-making standards should be required. Improved interpretability would allow practitioners and researchers to apply scientific findings to promote PA.","","","2015","10.1186/s12889-015-2266-4","","","medline-26384488.pdf","medline-26384488"
"Perception of radiology reporting efficacy by neurologists in general and university hospitals","Olthof A. W., de Groot J. C., Zorgdrager A. N., Callenbach P. M. C., van Ooijen P. M. A.","Clinical Radiology","","AIM: To investigate how neurologists perceive the value of the radiology report and to analyse the relation with the neurologists own expertise in radiology and the level of subspecialisation of radiologists.\\\\\\\\rMATERIALS AND METHODS: A web-based survey was distributed to neurologists. The level of subspecialisation was assessed by the percentage of fellowship-trained radiologists and the percentage of radiologists that were members of the Dutch Society of Neuroradiology.\\\\\\\\rRESULTS: Most neurologists interpret all computed tomography (CT) and magnetic resonance imaging (MRI) studies themselves and their self-confidence in making correct interpretations is high. Residents gave higher scores than neurologists for ""Radiologist report answers the question"" (p=0.039) and for ""Radiologist reports give helpful advice"" (p=0.001). Neurologists from university hospitals stated more frequently that the report answered their questions than neurologists from general hospitals (p=0.008). The general appreciation for radiology reports was higher for neurologists from university hospitals than from general hospitals (8.2 versus 7.2; p=0.003). Radiologists at university hospitals have a higher level of subspecialisation than those at general hospitals.\\\\\\\\rCONCLUSION: Subspecialisation of radiologists leads to higher quality of radiology reporting as perceived by neurologists. Because of their expertise in radiology neurologists are valuable sources of feedback for radiologists. Paying attention to the clinical questions and giving advice tailored to the needs of the referring physicians are opportunities to improve radiology reporting. Copyright © 2018 The Royal College of Radiologists. Published by Elsevier Ltd. All rights reserved.","","","2018","10.1016/j.crad.2018.03.001","","","medline-29622361.pdf","medline-29622361"
"Reproducibility of color Doppler imaging for orbital arteries in Japanese patients with normal-tension glaucoma","Niwa Y., Yamamoto T., Kawakami H., Kitazawa Y.","Japanese Journal of Ophthalmology","","The reproducibility of measurements by color Doppler imaging (CDI) were evaluated in Japanese patients with normal-tension glaucoma. Measurements were taken in the central retinal artery the ophthalmic artery and the short posterior ciliary arteries. Reproducibility was evaluated by calculating the coefficients of reproducibility for the peak systolic and end diastolic velocities and for the resistance index. The coefficient of reproducibility was calculated as magnitude of V1 - V2/(V1 + V2)/2 where V1 is the value of the first measurement and V2 is the value of the measurement taken 48 hours later. In calculating the resistance index of the orbital arteries the central retinal artery and the short posterior ciliary artery temporal to the optic nerve both had coefficients of reproducibility of 0.04 +/- 0.04 (mean +/- standard deviation); the ophthalmic artery and the short posterior ciliary artery nasal to the optic nerve both had coefficients of reproducibility of 0.04 +/- 0.05. The high reproducibility of the CDI technique supports the validity of using CDI in a clinical setting to measure the hemodynamic parameters of small retrobulbar blood vessels.","","","1998","10.1016/s0021-5155(98)00025-2","","","medline-9822969.pdf","medline-9822969"
"Modeling distributed data representation and its effect on parallel data accesses","Jin, D. And Ziavras, S.g.","Journal Of Parallel And Distributed Computing","","Pc clusters have emerged as viable alternatives for high-performance, low-cost computing. In such an environment, sharing data among processes is essential. Accessing the shared data, however, may often stall parallel executing threads. We propose a novel data representation scheme where an application data entity can be incarnated into a set of objects that are distributed in the cluster. The runtime support system manages the incarnated objects and data access is possible only via an appropriate interface. This distributed data representation facilitates parallel accesses for updates. Thus, tasks are subject to few limitations and application programs can harness high degrees of parallelism. Our pc cluster experiments prove the effectiveness of our approach. © 2005 elsevier inc. All rights reserved.","","","2005","10.1016/j.jpdc.2005.04.021","","","scopus-2-s2.0-24144459103.pdf","scopus-2-s2.0-24144459103"
"Workplace: an empirical study on spiritual leadership in pakistani higher education","Abbas, A. And Ekowati, D. And Suhariadi, F. And Anwar, A.","International Journal Of Business And Systems Research","","Management that encourages workplace support can successfully cover productive work, a sense of identity, and organisational goals. Spirituality inculcates a positive workplace environment that connects individuals and groups. It generates confidence in workers by promoting membership and meaningfulness towards corporate life. A causal framework containing hope, faith, and altruism works for an individual s well-being by imparting meaningfulness to the desire to make an undeniable impact on organisational productivity and commitment. In this study, a likert scale questionnaire was used with public and private sector university employees in pakistan to test the hypothetical model using convenient sampling. Overall, 232 interested employees filled out the printed questionnaire computed for completing statistical analysis consuming spss and smart-pls. We discussed the strengths and weaknesses of the causal framework through rigorous research and theoretical reasoning. Moreover, we also discussed individual well-being, psychological beliefs, and strategic directions with practical and social implications. © 2023 inderscience enterprises ltd.. All rights reserved.","","","2023","10.1504/ijbsr.2023.131721","","","scopus-2-s2.0-85166438109.pdf","scopus-2-s2.0-85166438109"
"Thoughtful selection and use of scientific terms in clinical research: the case of â € pragmatic' trials","Dal-Ré, R. And Mentz, R.j. And Rosendaal, F.r.","Journal Of Investigative Medicine","","Clinical research is a discipline prone to the use of technical terms that may be particularly at risk for misunderstanding given the complex interpretation that is required. In this century, what is happening with the word â € pragmatic' when describing a randomized controlled trial (rct) with medicines deserves a public reflection. Explanatory trials are conducted in ideal conditions to assess the comparative efficacy of interventions and are useful to explain whether interventions work. Pragmatic trials are those conducted in a way that resembles usual clinical practice conditions to assess the comparative effectiveness of interventions in a manner directly applicable for decision-makers. This, however, did not prevent 36% of authors of placebo-controlled, or prelicensing trials to identify their medicines rcts as pragmatic in the title of their articles. The current situation is such that scientific literature has accepted that â € pragmatic' can convey the original meaning-that obtained in trials mimicking usual clinical practice-and a distorted one-that is focused on streamlining any trial procedure. Those involved in clinical trials should emphasize the importance of precision in the use of terms when describing rcts through standardized solutions when possible. Unless clinical trial stakeholders agree when it would be correct to label an rct as pragmatic, in a short period of time the term will be in danger of becoming meaningless. It is suggested that the enhancing the quality and transparency of health research (equator) network, the consolidated standards of reporting trials (consort) group and the international committee of medical journal editors (icmje) could address this topic and provide a consensus way forward. © american federation for medical research 2021. No commercial re-use. See rights and permissions. Published by bmj.","","","2021","10.1136/jim-2021-001789","","","scopus-2-s2.0-85103200392.pdf","scopus-2-s2.0-85103200392"
"A better way: training for direct observations in healthcare","Alfred, M. And Del Gaizo, J. And Kanji, F. And Lawton, S. And Caron, A. And Nemeth, L.s. And Alekseyenko, A.v. And Shouhed, D. And Savage, S. And Anger, J.t. And Catchpole, K. And Cohen, T.","Bmj Quality And Safety","","Direct observation is valuable for identifying latent threats and elucidating system complexity in clinical environments. This approach facilitates prospective risk assessment and reveals workarounds, near-misses and recurrent safety problems difficult to diagnose retrospectively or via outcome data alone. As observers are an instrument of data collection, developing effective and comprehensive observer training is critical to ensuring the reliability of the data collection and reproducibility of the research. However, methodological rigour for ensuring these data collection properties remains a key challenge in direct observation research in healthcare. Although prior literature has offered key considerations for observational research in healthcare, operationalising these recommendations may pose a challenge and unless guidance is also provided on observer training. In this article, we offer guidelines for training non-clinical observers to conduct direct observations including conducting a training needs analysis, incorporating practice observations and evaluating observers and inter-rater reliability. The operationalisation of these guidelines is described in the context of a 5-year multisite observational study investigating technology integration in the operating room. We also discuss novel tools developed during the course our project to support data collection and examine inter-rater reliability among observers in direct observation studies. ©","","","2022","10.1136/bmjqs-2021-014171","","","scopus-2-s2.0-85137214410.pdf","scopus-2-s2.0-85137214410"
"Quality assessment and its influencing factors of lung cancer clinical research registration: a cross-sectional analysis","Ye Q. M., Chen Z. G., Chen L. L., Si-Tu B., Mai Y. Y., Xiao J. Y., Yang Y. J.","Journal of Thoracic Disease","","Background: A better understanding of the current features of lung cancer clinical research registration is important for improving registration quality and standardizing the registration. This study aimed to assess the registration quality of lung cancer studies on ClinicalTrials.gov and analyze the influencing factors.\\\\\\\\rMethods: Lung cancer clinical researches registered in the ClinicalTrials.gov database were searched on 7 July 2021. The characteristics of trials that registered up to 7 July 2021 were assessed. The quality of completed and terminated lung cancer studies from 1 July 2007 to 7 July 2020 was assessed using a modified version of the World Health Organization (WHO) Trial Registration Data Set (TRDS V.1.3.1). Multivariate logistic regression analysis was also used to analyze the factors influencing study registration quality. An above-average registration quality score represented a high registration quality.\\\\\\\\rResults: A total of 6448 clinical studies on lung cancer were used to summarise the registration characteristics. Most interventional studies were randomized (41.88%) single group (48.07%) and open-label (82.86%) studies while most observational studies were cohort studies (59.08%). In total 2171 completed and terminated studies were assessed with an average quality score (out of 54) of 36.76+/-5.69. None of the assessed studies had a 100% modified TRDS reporting rate and missing summary results were the main factor affecting the quality scores. Multivariate logistic regression analyses showed that prospective registrations [adjusted odds ratio (aOR) 2.18; 95% confidence interval (CI) 1.79-2.65] multi-center studies (aOR 1.73; 95% CI 1.39-2.16) government-sponsored studies (aOR 3.09; 95% CI 1.48-6.42) and published studies (aOR 1.43; 95% CI 1.15-1.78) were more likely to be high quality research.\\\\\\\\rConclusions: To improve the quality of registration awareness of prospective registration should be further improved and government investment should be increased. At the same time more efficient and extensive data sharing after completion of the studies should be actively promoted. Copyright 2022 Journal of Thoracic Disease. All rights reserved.","","","2022","10.21037/jtd-22-975","","","medline-36245581.pdf","medline-36245581"
"Randomised controlled trials evaluating endometrial scratching: assessment of methodological issues","Li W., Suke S., Wertaschnigg D., Lensen S., Wang R., Gurrin L., Mol B. W.","Human Reproduction","","STUDY QUESTION: Do randomised controlled trials (RCTs) evaluating endometrial scratching suffer from methodological issues including insufficient trial registration statistical errors or irreproducibility randomisation errors or miscellaneous issues? SUMMARY ANSWER: The majority of RCTs investigating endometrial scratching have methodological issues. WHAT IS KNOWN ALREADY: A large number of small RCTs investigating the effectiveness of endometrial scratching prior to in vitro fertilisation (IVF) and intrauterine insemination (IUI)/intercourse have reported favourable findings. Subsequently systematic reviews incorporating these RCTs yielded meta-analyses in favour of endometrial scratching. Endometrial scratching has been widely adopted by infertility specialists around the world. Recently an international RCT including 1364 women reported no benefit from endometrial scratching before IVF. STUDY DESIGN SIZE DURATION: We evaluated several methodological issues of RCTs investigating the effectiveness of endometrial scratching prior to IVF and IUI/intercourse. We identified 25 RCTs for IVF and 12 RCTs for IUI/intercourse with full-text publication. PARTICIPANTS/MATERIALS SETTING METHODS: We assessed the RCTs on the following criteria: adequacy of trial registration statistical issues (description of statistical methods and reproducibility of univariable statistical analysis) excessive similarity or difference in baseline characteristics that is not compatible with chance (Monte Carlo simulations and Kolmogorov-Smirnov test) and miscellaneous methodological issues. MAIN RESULTS AND THE ROLE OF CHANCE: Of 25 RCTs evaluating endometrial scratching prior to IVF only eight (32%) had adequate trial registration. In total 10 (40%) RCTs had issues regarding statistical methods. Nine (69% 13 applicable) RCTs had at least one inconsistency between reported and reproduced univariable statistical analysis for categorical baseline/intermediate characteristics. Statistical results of at least one outcome were not reproducible in 14 (74% 19 applicable) RCTs. Only two (8%) RCTs had none of the above issues. Suggested by the simulations these RCTs did not significantly violate the null hypothesis that the baseline characteristics were the results of a properly conducted randomisation process (P = 0.4395). Of 12 IUI/intercourse RCTs only 2 (17%) had adequate trial registration. In total five (42%) studies had issues of statistical methods. Inconsistency between reported and reproduced univariable analysis for baseline/intermediate categorical variable(s) was found in four (57% 7 applicable) RCTs. Statistical analysis was not reproducible for at least one outcome in eight (80% 10 applicable) studies. All RCTs had at least one of the above issues. These RCTs were inconsistent with the null hypothesis that their baseline characteristics were the results of proper randomised allocation (P = 1.659*10-7). LIMITATIONS REASONS FOR CAUTION: We were unable to assess RCTs which were not published as full-text papers. We could not analyse individual participant data to investigate possible reasons for statistical inconsistencies. The method to infer the likelihood of proper random sampling rests on assumptions including independent baseline characteristics simple randomisation and no publication bias. WIDER IMPLICATIONS OF THE FINDINGS: The methodological issues common to RCTs evaluating endometrial scratching may have biased the results of the trials. Further development and validation of these novel methods may be helpful for the critical appraisal of RCTs. STUDY FUNDING/COMPETING INTEREST(S): No external funding was sought to support this work. B.W.M. is supported by a National Health Medical Research Council (NHMRC) Practitioner Fellowship (GNT1082548). B.W.M. reports consultancy for ObsEva Merck and Guerbet. D.W. is supported by a grant from the Paracelsus Medical University Salzburg Austria (PMU Research Fund-PMU FFF Number: L-18/02/006-WET) and by Drs Haackert Foundation Germany. S.L. is an author of a trial included in this study an author of an included systematic review and a Cochrane editor. All other authors have no conflicts of interest. Trial registration number: N/a.","","","2019","10.1093/humrep/dez207","","","medline-31825478.pdf","medline-31825478"
"Comparison of registered and published primary outcomes in randomized controlled trials of gastroenterology and hepatology","Li X. Q., Yang G. L., Tao K. M., Zhang H. Q., Zhou Q. H., Ling C. Q.","Scandinavian Journal of Gastroenterology","","OBJECTIVES . The need for trial registration as well as the benefits it has brought for the transparency of medical research has been recognized for years. Trial registration has turned from an exception to a mandatory guideline in recent years. The present study aimed to examine the characteristics of registered randomized controlled trials (RCTs) in a sample of recently published gastroenterology RCTs and to assess the consistency of registered and published primary outcome (PO) in RCTs. METHODS. Articles published in the top five ""general and internal journals"" and top five ""gastroenterology and hepatology journals"" categories between 2009 and 2012 were searched in PubMed. Basic characteristics and the registration information were identified and extracted from the included RCTs. PO consistency analysis was conducted to compare between the registered and published format. RESULTS . A total of 305 RCTs were included; among them 252 could be identified with a registration number. Nearly half of these RCTs were funded solely by industry (141/305 46.3%). ClinicalTrials.gov was the most popular registry for these RCTs (214/252 84.9%). A total of 155 RCTs were included in the PO consistency analysis. Among them 22 (14.2%) RCTs had discrepancies between POs registered in the trial registry compared to the published article. CONCLUSIONS . Based on the results of the present study selective outcome reporting of gastroenterology RCTs published in leading medical journals has been much improved over the past years. However there might be a sampling bias to say that consistency of registered and published POs of gastroenterology RCTs has been better than before.","","","2013","10.3109/00365521.2013.845909","","","medline-24131272.pdf","medline-24131272"
"Reproducibility measurements of three methods for calculating in vivo MR-based knee kinematics","Lansdown D. A., Zaid M., Pedoia V., Subburaj K., Souza R., Benjamin C., Li X.","Journal of Magnetic Resonance Imaging","","PURPOSE: To describe three quantification methods for magnetic resonance imaging (MRI)-based knee kinematic evaluation and to report on the reproducibility of these algorithms.\\\\\\\\rMATERIALS AND METHODS: T2 -weighted fast-spin echo images were obtained of the bilateral knees in six healthy volunteers. Scans were repeated for each knee after repositioning to evaluate protocol reproducibility. Semiautomatic segmentation defined regions of interest for the tibia and femur. The posterior femoral condyles and diaphyseal axes were defined using the previously defined tibia and femur. All segmentation was performed twice to evaluate segmentation reliability. Anterior tibial translation (ATT) and internal tibial rotation (ITR) were calculated using three methods: a tibial-based registration system a combined tibiofemoral-based registration method with all manual segmentation and a combined tibiofemoral-based registration method with automatic definition of condyles and axes. Intraclass correlation coefficients and standard deviations across multiple measures were determined.\\\\\\\\rRESULTS: Reproducibility of segmentation was excellent (ATT = 0.98; ITR = 0.99) for both combined methods. ATT and ITR measurements were also reproducible across multiple scans in the combined registration measurements with manual (ATT = 0.94; ITR = 0.94) or automatic (ATT = 0.95; ITR = 0.94) condyles and axes.\\\\\\\\rCONCLUSION: The combined tibiofemoral registration with automatic definition of the posterior femoral condyle and diaphyseal axes allows for improved knee kinematics quantification with excellent in vivo reproducibility. Copyright © 2014 Wiley Periodicals Inc.","","","2015","10.1002/jmri.24790","","","medline-25545617.pdf","medline-25545617"
"Cross-Cultural Awareness and Attitudes Toward Threatened Animal Species","Bruder J., Burakowski L. M., Park T., Al-Haddad R., Al-Hemaidi S., Al-Korbi A., Al-Naimi A.","Frontiers in Psychology","","The preservation of our planet's decreasing biodiversity is a global challenge. Human attitudes and preferences toward animals have profound impacts on conservation policies and decisions. To date the vast majority of studies about human attitudes and concern toward animals have focused largely on western educated industrialized rich and democratic (i.e. WEIRD) populations. In order to mitigate biodiversity loss globally an understanding of how humans make decisions about animals from multicultural perspectives is needed. The present study examines familiarity liking and endorsement of government protection amongst six broad cultural groups living in Qatar for five threatened animal species indigenous to the Arabian Gulf. Our findings highlight similarities and differences across cultures toward animals. Overall familiarity did not predict endorsement for government protection after liking was accounted for. Liking however emerged as an important predictor of endorsement for government protection across cultures although the degree of animal liking varied culturally. WEIRD and South East Asian participants showed similar and more positive attitudes toward animals compared to the other groups. Participants from the Arabian Gulf Sub-Saharan Africa Middle East and North Africa and South Asia responded similarly toward the animals. Interestingly the Arabian Gulf group demonstrated significantly less liking and protection endorsement for animals including those animals which play an important role in their culture. This research highlights intriguing avenues for future research and points to liking as a possible universal human attitude toward animals that influences decision making about conservation across all cultures while suggesting applications for improving education. Copyright © 2022 Bruder Burakowski Park Al-Haddad Al-Hemaidi Al-Korbi and Al-Naimi.","","","2022","10.3389/fpsyg.2022.898503","","","medline-35712146.pdf","medline-35712146"
"Review of free software tools for image analysis of fluorescence cell micrographs","Wiesmann, V. And Franz, D. And Held, C. And Münzenmayer, C. And Palmisano, R. And Wittenberg, T.","Journal Of Microscopy","","Summary: an increasing number of free software tools have been made available for the evaluation of fluorescence cell micrographs. The main users are biologists and related life scientists with no or little knowledge of image processing. In this review, we give an overview of available tools and guidelines about which tools the users should use to segment fluorescence micrographs. We selected 15 free tools and divided them into stand-alone, matlab-based, imagej-based, free demo versions of commercial tools and data sharing tools. The review consists of two parts: first, we developed a criteria catalogue and rated the tools regarding structural requirements, functionality (flexibility, segmentation and image processing filters) and usability (documentation, data management, usability and visualization). Second, we performed an image processing case study with four representative fluorescence micrograph segmentation tasks with figure-ground and cell separation. The tools display a wide range of functionality and usability. In the image processing case study, we were able to perform figure-ground separation in all micrographs using mainly thresholding. Cell separation was not possible with most of the tools, because cell separation methods are provided only by a subset of the tools and are difficult to parametrize and to use. Most important is that the usability matches the functionality of a tool. To be usable, specialized tools with less functionality need to fulfill less usability criteria, whereas multipurpose tools need a well-structured menu and intuitive graphical user interface. © 2015 royal microscopical society.","","","2015","10.1111/jmi.12184","","","scopus-2-s2.0-84912567159.pdf","scopus-2-s2.0-84912567159"
"De-identification of clinical narratives through writing complexity measures","Li M., Carrell D., Aberdeen J., Hirschman L., Malin B. A.","International Journal of Medical Informatics","","PURPOSE: Electronic health records contain a substantial quantity of clinical narrative which is increasingly reused for research purposes. To share data on a large scale and respect privacy it is critical to remove patient identifiers. De-identification tools based on machine learning have been proposed; however model training is usually based on either a random group of documents or a pre-existing document type designation (e.g. discharge summary). This work investigates if inherent features such as the writing complexity can identify document subsets to enhance de-identification performance.\\\\\\\\rMETHODS: We applied an unsupervised clustering method to group two corpora based on writing complexity measures: a collection of over 4500 documents of varying document types (e.g. discharge summaries history and physical reports and radiology reports) from Vanderbilt University Medical Center (VUMC) and the publicly available i2b2 corpus of 889 discharge summaries. We compare the performance (via recall precision and F-measure) of de-identification models trained on such clusters with models trained on documents grouped randomly or VUMC document type.\\\\\\\\rRESULTS: For the Vanderbilt dataset it was observed that training and testing de-identification models on the same stylometric cluster (with the average F-measure of 0.917) tended to outperform models based on clusters of random documents (with an average F-measure of 0.881). It was further observed that increasing the size of a training subset sampled from a specific cluster could yield improved results (e.g. for subsets from a certain stylometric cluster the F-measure raised from 0.743 to 0.841 when training size increased from 10 to 50 documents and the F-measure reached 0.901 when the size of the training subset reached 200 documents). For the i2b2 dataset training and testing on the same clusters based on complexity measures (average F-score 0.966) did not significantly surpass randomly selected clusters (average F-score 0.965).\\\\\\\\rCONCLUSIONS: Our findings illustrate that in environments consisting of a variety of clinical documentation de-identification models trained on writing complexity measures are better than models trained on random groups and in many instances document types. Copyright © 2014 Elsevier Ireland Ltd. All rights reserved.","","","2014","10.1016/j.ijmedinf.2014.07.002","","","medline-25106934.pdf","medline-25106934"
"A proposal for a bbs with visual representation for online data analysis","Takama, Y. And Seo, Y.","Data Science Journal","","The concept of a bulletin board system (bbs) equipped with information visualization techniques is proposed for supporting online data analysis. Although group discussion is known to be effective for analyzing data from various viewpoints, the number of participants is limited by time and space constraints. To solve that problem, this paper proposes to augment a bbs, a popular web based tool. In order for discussion participants to share data online, the system provides them with a visual representation of target data, which elicits comments from participants as well as compares these comments. In order to illustrate the concept's potential, a bbs equipped with keygraph is also developed for supporting online chance discovery. It has functions for making visual annotations on the keygraph as well as a function for retrieving similar scenarios. The experimental results show the effectiveness of the bbs in terms of the usefulness of scenario generation support functions as well as that of scenario retrieval engines.","","","2007","10.2481/dsj.6.s28","","","scopus-2-s2.0-34547201697.pdf","scopus-2-s2.0-34547201697"
"Blockchain-enabled secure and trusted federated data sharing in iiot","Zhou, Z. And Tian, Y. And Xiong, J. And Ma, J. And Peng, C.","Ieee Transactions On Industrial Informatics","","Federated learning breaks down data silos and promotes the intelligence of the industrial internet of things (iiot). However, the principal-agent architecture commonly used in federated learning not only increases the cost but also fails to take into account the privacy protection and trustworthiness of flexible on-demand data sharing. To tackle the above challenges, we propose a secure and trusted federated data sharing (stfs) based on blockchain. Initially, we construct an autonomous and reliable federated extreme gradient boosting learning algorithm to crack the data isolation problem, providing privacy protection and verifiability. Furthermore, we design a secure and trusted data sharing and trading mechanism to ensure secure on-demand controlled data sharing and fair trading. Finally, the security of stfs is proved based on the universal composable theory. The results of ample experimental simulations demonstrate the good effectiveness and performance of stfs for iiot applications. © 2005-2012 ieee.","","","2023","10.1109/tii.2022.3215192","","","scopus-2-s2.0-85140786133.pdf","scopus-2-s2.0-85140786133"
"The role of trust in the resolution of conservation conflicts","Young, J.c. And Searle, K. And Butler, A. And Simmons, P. And Watt, A.d. And Jordan, A.","Biological Conservation","","Conflicts between biodiversity conservation and other human activities are intensifying as a result of growing pressure on natural resources and concomitant demands by some for greater conservation. Approaches to reducing conflicts are increasingly focusing on engaging stakeholders in processes that are perceived as fair, i.e. independent and where stakeholders have influence, and which in turn can generate trust between stakeholders. Hitherto, there has been limited empirical research supporting the claim that conservation conflicts can be reduced by building trust through fair participation. Using quantitative and qualitative empirical data from three case studies, we analysed whether fair participation processes were directly related to conflict resolution and if this relationship was mediated by trust. Our research provided empirical quantitative evidence that increased trust through fair processes makes conflict resolution more likely. The qualitative analysis revealed caveats to this finding, including the different understandings of the definition of conflict by stakeholders, the complex nature of trust in conservation conflicts where most stakeholders have high levels of ecological knowledge, and the atypical nature (i.e. presence of a local champion) of one of the case studies. Building and maintaining trust with landowners and managers may be central to conserving biodiversity. Such trust-building requires effort and resources, opportunities for appropriate dialogue between stakeholders and a willingness to share power in terms of knowledge and policy implementation, especially when local stakeholders are dependent on and knowledgeable about natural resources. © 2016 elsevier ltd.","","","2016","10.1016/j.biocon.2015.12.030","","","scopus-2-s2.0-84955260982.pdf","scopus-2-s2.0-84955260982"
"An evaluation of the current state of genomic data privacy protection technology and a roadmap for the future","Malin B. A.","Journal of the American Medical Informatics Association","","The incorporation of genomic data into personal medical records poses many challenges to patient privacy. In response various systems for preserving patient privacy in shared genomic data have been developed and deployed. Although these systems de-identify the data by removing explicit identifiers (e.g. name address or Social Security number) and incorporate sound security design principles they suffer from a lack of formal modeling of inferences learnable from shared data. This report evaluates the extent to which current protection systems are capable of withstanding a range of re-identification methods including genotype-phenotype inferences location-visit patterns family structures and dictionary attacks. For a comparative re-identification analysis the systems are mapped to a common formalism. Although there is variation in susceptibility each system is deficient in its protection capacity. The author discovers patterns of protection failure and discusses several of the reasons why these systems are susceptible. The analyses and discussion within provide guideposts for the development of next-generation protection methods amenable to formal proofs.","","","2005","10.1197/jamia.m1603","","","medline-15492030.pdf","medline-15492030"
"Identifying map users with eye movement data from map-based spatial tasks: user privacy concerns","Liao, H. And Dong, W. And Zhan, Z.","Cartography And Geographic Information Science","","Individuals with different characteristics exhibit different eye movement patterns in map reading and wayfinding tasks. In this study, we aim to explore whether and to what extent map users’ eye movements can be used to detect who created them. Specifically, we focus on the use of gaze data for inferring users’ identities when users are performing map-based spatial tasks. We collected 32 participants’ eye movement data as they utilized maps to complete a series of self-localization and spatial orientation tasks. We extracted five sets of eye movement features and trained a random forest classifier. We used a leave-one-task-out approach to cross-validate the classifier and achieved the best identification rate of 89%, with a 2.7% equal error rate. This result is among the best performances reported in eye movement user identification studies. We evaluated the feature importance and found that basic statistical features (e.g. pupil size, saccade latency and fixation dispersion) yielded better performance than other feature sets (e.g. spatial fixation densities, saccade directions and saccade encodings). The results open the potential to develop personalized and adaptive gaze-based map interactions but also raise concerns about user privacy protection in data sharing and gaze-based geoapplications. © 2021 cartography and geographic information society.","","","2022","10.1080/15230406.2021.1980435","","","scopus-2-s2.0-85116463809.pdf","scopus-2-s2.0-85116463809"
"Profile of information professionals: between the traditional and the emerging","Morillo, J.p. And Salazar Álvarez, M.","Revista Interamericana De Bibliotecologia","","The article sets out the results of the research ""characterization of graduates of archival science, library science, and information science in colombia: 2013-2018"" based on the recognition of the professional in the labor field and the correspondence between training and needs of the environment;  key elements for the evaluation and decision-making in the curricular processes and the design of policies that strengthen the relationship with the working environment. The results of this research made it possible to identify current needs and challenges to qualify professional training processes, to consolidate the relevance of academic programs, and to strengthen the impact of graduates in the labor field. It is highlighted how the results of previous studies persist or are valid: high employability and low mobility;  university libraries and state administrative archives as the main employer;  the education and services sectors as the main sources of employment, with a defined term contract employment relationship as the predominant contractual modality and with remuneration of between 2 and 3 current legal monthly minimum wages. These results are in medium tune with current training content, especially from the perspective of fundamental knowledge, and in low tune with emerging areas such as electronic documentation, blockchain, data analytics, open science, big data, and business intelligence. All this is framed in revolution 4.0 and in the problems that these professionals must face in correspondence with other problems in the field of information and knowledge, such as fake news, the phenomenon of disinformation, and the manipulation of the information on social networks. © 2021 escuela interamericana de bibliotecologia. All rights reserved.","","","2021","10.17533/udea.rib.v44n3e344766","","","scopus-2-s2.0-85122145354.pdf","scopus-2-s2.0-85122145354"
"Preserving privacy between features in distributed estimation","Heinze-Deml, C. And Mcwilliams, B. And Meinshausen, N.","Stat","","Privacy is crucial in many applications of machine learning. Legal, ethical and societal issues restrict the sharing of sensitive data, making it difficult to learn from data sets that are partitioned between many parties. One important instance of such a distributed setting arises when information about each record in the data set is held by different data owners (the design matrix is “vertically partitioned”). In this setting, few approaches exist for private data sharing for the purpose of statistical estimation, and the classical set-up of differential privacy with a “trusted curator” preparing the data does not apply. We work with the notion of (ε, δ)-distributed differential privacy, which extends single-party differential privacy to the distributed, vertically partitioned case. We propose pride, a scalable framework for distributed estimation where each party communicates perturbed random projections of their locally held features ensuring (ε, δ)-distributed differential privacy is preserved. For l 2 -penalized supervised learning problems, pride has bounded estimation error compared with the optimal estimates obtained without privacy constraints in the non-distributed setting. We confirm this empirically on real world and synthetic data sets. © 2018 john wiley & sons, ltd.","","","2018","10.1002/sta4.189","","","scopus-2-s2.0-85050486522.pdf","scopus-2-s2.0-85050486522"
"Statistical validation of synthetic data for lung cancer patients generated by using generative adversarial networks","Gonzalez-Abril, L. And Angulo, C. And Ortega, J.a. And Lopez-Guerra, J.-L.","Electronics (Switzerland)","","The development of healthcare patient digital twins in combination with machine learning technologies helps doctors in therapeutic prescription and in minimally invasive intervention procedures. The confidentiality of medical records or limited data availability in many health domains are drawbacks that can be overcome with the generation of synthetic data conformed to real data. The use of generative adversarial networks (gan) for the generation of synthetic data of lung cancer patients has been previously introduced as a tool to solve this problem in the form of anonymized synthetic patients. However, generated synthetic data are mainly validated from the machine learning domain (loss functions) or expert domain (oncologists). In this paper, we propose statistical decision making as a validation tool: is the model good enough to be used? Does the model pass rigorous hypothesis testing criteria? We show for the case at hand how loss functions and hypothesis validation are not always well aligned. © 2022 by the authors.","","","2022","10.3390/electronics11203277","","","scopus-2-s2.0-85140908217.pdf","scopus-2-s2.0-85140908217"
